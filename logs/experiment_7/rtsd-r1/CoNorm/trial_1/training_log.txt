I0409 19:41:25.638746 29000 caffe.cpp:217] Using GPUs 1
I0409 19:41:25.715354 29000 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0409 19:41:26.465509 29000 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/test.prototxt"
test_iter: 8
test_interval: 25
base_lr: 0.001
display: 1
max_iter: 2500
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 250
snapshot_prefix: "./snapshots/experiment_7/rtsd-r1/CoNorm/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0409 19:41:26.465674 29000 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/train.prototxt
I0409 19:41:26.466094 29000 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0409 19:41:26.466111 29000 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0409 19:41:26.466327 29000 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 132
    mean_value: 132
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
I0409 19:41:26.466488 29000 layer_factory.hpp:77] Creating layer data
I0409 19:41:26.467916 29000 net.cpp:100] Creating Layer data
I0409 19:41:26.467936 29000 net.cpp:408] data -> data
I0409 19:41:26.467973 29000 net.cpp:408] data -> label
I0409 19:41:26.469588 29079 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0409 19:41:26.491402 29000 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 19:41:26.541658 29000 net.cpp:150] Setting up data
I0409 19:41:26.541692 29000 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 19:41:26.541699 29000 net.cpp:157] Top shape: 1024 (1024)
I0409 19:41:26.541702 29000 net.cpp:165] Memory required for data: 28315648
I0409 19:41:26.541714 29000 layer_factory.hpp:77] Creating layer conv1
I0409 19:41:26.541743 29000 net.cpp:100] Creating Layer conv1
I0409 19:41:26.541751 29000 net.cpp:434] conv1 <- data
I0409 19:41:26.541766 29000 net.cpp:408] conv1 -> conv1
I0409 19:41:26.960194 29000 net.cpp:150] Setting up conv1
I0409 19:41:26.960227 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:26.960232 29000 net.cpp:165] Memory required for data: 750850048
I0409 19:41:26.960258 29000 layer_factory.hpp:77] Creating layer conv1_prescale
I0409 19:41:26.960274 29000 net.cpp:100] Creating Layer conv1_prescale
I0409 19:41:26.960281 29000 net.cpp:434] conv1_prescale <- conv1
I0409 19:41:26.960289 29000 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0409 19:41:26.960425 29000 net.cpp:150] Setting up conv1_prescale
I0409 19:41:26.960435 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:26.960440 29000 net.cpp:165] Memory required for data: 1473384448
I0409 19:41:26.960448 29000 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 19:41:26.960458 29000 net.cpp:100] Creating Layer conv1_sTanH
I0409 19:41:26.960463 29000 net.cpp:434] conv1_sTanH <- conv1
I0409 19:41:26.960469 29000 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 19:41:26.960716 29000 net.cpp:150] Setting up conv1_sTanH
I0409 19:41:26.960737 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:26.960743 29000 net.cpp:165] Memory required for data: 2195918848
I0409 19:41:26.960750 29000 layer_factory.hpp:77] Creating layer conv1_postscale
I0409 19:41:26.960764 29000 net.cpp:100] Creating Layer conv1_postscale
I0409 19:41:26.960772 29000 net.cpp:434] conv1_postscale <- conv1
I0409 19:41:26.960780 29000 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0409 19:41:26.960949 29000 net.cpp:150] Setting up conv1_postscale
I0409 19:41:26.960963 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:26.960968 29000 net.cpp:165] Memory required for data: 2918453248
I0409 19:41:26.960975 29000 layer_factory.hpp:77] Creating layer pool1
I0409 19:41:26.960985 29000 net.cpp:100] Creating Layer pool1
I0409 19:41:26.960990 29000 net.cpp:434] pool1 <- conv1
I0409 19:41:26.960996 29000 net.cpp:408] pool1 -> pool1
I0409 19:41:26.961056 29000 net.cpp:150] Setting up pool1
I0409 19:41:26.961066 29000 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 19:41:26.961071 29000 net.cpp:165] Memory required for data: 3099086848
I0409 19:41:26.961103 29000 layer_factory.hpp:77] Creating layer conv2
I0409 19:41:26.961133 29000 net.cpp:100] Creating Layer conv2
I0409 19:41:26.961140 29000 net.cpp:434] conv2 <- pool1
I0409 19:41:26.961148 29000 net.cpp:408] conv2 -> conv2
I0409 19:41:26.967188 29000 net.cpp:150] Setting up conv2
I0409 19:41:26.967208 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:26.967212 29000 net.cpp:165] Memory required for data: 3298152448
I0409 19:41:26.967229 29000 layer_factory.hpp:77] Creating layer conv2_prescale
I0409 19:41:26.967238 29000 net.cpp:100] Creating Layer conv2_prescale
I0409 19:41:26.967242 29000 net.cpp:434] conv2_prescale <- conv2
I0409 19:41:26.967249 29000 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0409 19:41:26.967383 29000 net.cpp:150] Setting up conv2_prescale
I0409 19:41:26.967394 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:26.967398 29000 net.cpp:165] Memory required for data: 3497218048
I0409 19:41:26.967404 29000 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 19:41:26.967414 29000 net.cpp:100] Creating Layer conv2_sTanH
I0409 19:41:26.967419 29000 net.cpp:434] conv2_sTanH <- conv2
I0409 19:41:26.967424 29000 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 19:41:26.969533 29000 net.cpp:150] Setting up conv2_sTanH
I0409 19:41:26.969554 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:26.969558 29000 net.cpp:165] Memory required for data: 3696283648
I0409 19:41:26.969563 29000 layer_factory.hpp:77] Creating layer conv2_postscale
I0409 19:41:26.969571 29000 net.cpp:100] Creating Layer conv2_postscale
I0409 19:41:26.969576 29000 net.cpp:434] conv2_postscale <- conv2
I0409 19:41:26.969583 29000 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0409 19:41:26.969700 29000 net.cpp:150] Setting up conv2_postscale
I0409 19:41:26.969710 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:26.969717 29000 net.cpp:165] Memory required for data: 3895349248
I0409 19:41:26.969722 29000 layer_factory.hpp:77] Creating layer pool2
I0409 19:41:26.969732 29000 net.cpp:100] Creating Layer pool2
I0409 19:41:26.969736 29000 net.cpp:434] pool2 <- conv2
I0409 19:41:26.969743 29000 net.cpp:408] pool2 -> pool2
I0409 19:41:26.969790 29000 net.cpp:150] Setting up pool2
I0409 19:41:26.969799 29000 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 19:41:26.969804 29000 net.cpp:165] Memory required for data: 3945115648
I0409 19:41:26.969807 29000 layer_factory.hpp:77] Creating layer conv3
I0409 19:41:26.969817 29000 net.cpp:100] Creating Layer conv3
I0409 19:41:26.969822 29000 net.cpp:434] conv3 <- pool2
I0409 19:41:26.969827 29000 net.cpp:408] conv3 -> conv3
I0409 19:41:26.977252 29000 net.cpp:150] Setting up conv3
I0409 19:41:26.977274 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:26.977279 29000 net.cpp:165] Memory required for data: 3981979648
I0409 19:41:26.977291 29000 layer_factory.hpp:77] Creating layer conv3_prescale
I0409 19:41:26.977301 29000 net.cpp:100] Creating Layer conv3_prescale
I0409 19:41:26.977306 29000 net.cpp:434] conv3_prescale <- conv3
I0409 19:41:26.977313 29000 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0409 19:41:26.977483 29000 net.cpp:150] Setting up conv3_prescale
I0409 19:41:26.977502 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:26.977511 29000 net.cpp:165] Memory required for data: 4018843648
I0409 19:41:26.977524 29000 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 19:41:26.977537 29000 net.cpp:100] Creating Layer conv3_sTanH
I0409 19:41:26.977546 29000 net.cpp:434] conv3_sTanH <- conv3
I0409 19:41:26.977558 29000 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 19:41:26.983785 29000 net.cpp:150] Setting up conv3_sTanH
I0409 19:41:26.983819 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:26.983825 29000 net.cpp:165] Memory required for data: 4055707648
I0409 19:41:26.983832 29000 layer_factory.hpp:77] Creating layer conv3_postscale
I0409 19:41:26.983847 29000 net.cpp:100] Creating Layer conv3_postscale
I0409 19:41:26.983911 29000 net.cpp:434] conv3_postscale <- conv3
I0409 19:41:26.983927 29000 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0409 19:41:26.984109 29000 net.cpp:150] Setting up conv3_postscale
I0409 19:41:26.984128 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:26.984136 29000 net.cpp:165] Memory required for data: 4092571648
I0409 19:41:26.984149 29000 layer_factory.hpp:77] Creating layer pool3
I0409 19:41:26.984163 29000 net.cpp:100] Creating Layer pool3
I0409 19:41:26.984171 29000 net.cpp:434] pool3 <- conv3
I0409 19:41:26.984182 29000 net.cpp:408] pool3 -> pool3
I0409 19:41:26.984252 29000 net.cpp:150] Setting up pool3
I0409 19:41:26.984266 29000 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 19:41:26.984274 29000 net.cpp:165] Memory required for data: 4101787648
I0409 19:41:26.984282 29000 layer_factory.hpp:77] Creating layer fc4_300
I0409 19:41:26.984299 29000 net.cpp:100] Creating Layer fc4_300
I0409 19:41:26.984308 29000 net.cpp:434] fc4_300 <- pool3
I0409 19:41:26.984320 29000 net.cpp:408] fc4_300 -> fc4_300
I0409 19:41:26.995254 29000 net.cpp:150] Setting up fc4_300
I0409 19:41:26.995276 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:26.995281 29000 net.cpp:165] Memory required for data: 4103016448
I0409 19:41:26.995290 29000 layer_factory.hpp:77] Creating layer fc4_prescale
I0409 19:41:26.995301 29000 net.cpp:100] Creating Layer fc4_prescale
I0409 19:41:26.995307 29000 net.cpp:434] fc4_prescale <- fc4_300
I0409 19:41:26.995316 29000 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0409 19:41:26.995483 29000 net.cpp:150] Setting up fc4_prescale
I0409 19:41:26.995503 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:26.995512 29000 net.cpp:165] Memory required for data: 4104245248
I0409 19:41:26.995524 29000 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 19:41:26.995537 29000 net.cpp:100] Creating Layer fc4_sTanH
I0409 19:41:26.995546 29000 net.cpp:434] fc4_sTanH <- fc4_300
I0409 19:41:26.995558 29000 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 19:41:26.995932 29000 net.cpp:150] Setting up fc4_sTanH
I0409 19:41:26.995955 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:26.995964 29000 net.cpp:165] Memory required for data: 4105474048
I0409 19:41:26.995973 29000 layer_factory.hpp:77] Creating layer fc4_postscale
I0409 19:41:26.995988 29000 net.cpp:100] Creating Layer fc4_postscale
I0409 19:41:26.996000 29000 net.cpp:434] fc4_postscale <- fc4_300
I0409 19:41:26.996011 29000 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0409 19:41:26.996186 29000 net.cpp:150] Setting up fc4_postscale
I0409 19:41:26.996206 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:26.996213 29000 net.cpp:165] Memory required for data: 4106702848
I0409 19:41:26.996227 29000 layer_factory.hpp:77] Creating layer drop4
I0409 19:41:26.996242 29000 net.cpp:100] Creating Layer drop4
I0409 19:41:26.996249 29000 net.cpp:434] drop4 <- fc4_300
I0409 19:41:26.996261 29000 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 19:41:26.996314 29000 net.cpp:150] Setting up drop4
I0409 19:41:26.996328 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:26.996336 29000 net.cpp:165] Memory required for data: 4107931648
I0409 19:41:26.996345 29000 layer_factory.hpp:77] Creating layer fc5_67
I0409 19:41:26.996359 29000 net.cpp:100] Creating Layer fc5_67
I0409 19:41:26.996368 29000 net.cpp:434] fc5_67 <- fc4_300
I0409 19:41:26.996381 29000 net.cpp:408] fc5_67 -> fc5_classes
I0409 19:41:26.999943 29000 net.cpp:150] Setting up fc5_67
I0409 19:41:26.999963 29000 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:41:26.999967 29000 net.cpp:165] Memory required for data: 4108206080
I0409 19:41:26.999989 29000 layer_factory.hpp:77] Creating layer loss
I0409 19:41:27.000005 29000 net.cpp:100] Creating Layer loss
I0409 19:41:27.000015 29000 net.cpp:434] loss <- fc5_classes
I0409 19:41:27.000026 29000 net.cpp:434] loss <- label
I0409 19:41:27.000039 29000 net.cpp:408] loss -> loss
I0409 19:41:27.000064 29000 layer_factory.hpp:77] Creating layer loss
I0409 19:41:27.000677 29000 net.cpp:150] Setting up loss
I0409 19:41:27.000713 29000 net.cpp:157] Top shape: (1)
I0409 19:41:27.000723 29000 net.cpp:160]     with loss weight 1
I0409 19:41:27.000754 29000 net.cpp:165] Memory required for data: 4108206084
I0409 19:41:27.000766 29000 net.cpp:226] loss needs backward computation.
I0409 19:41:27.000780 29000 net.cpp:226] fc5_67 needs backward computation.
I0409 19:41:27.000789 29000 net.cpp:226] drop4 needs backward computation.
I0409 19:41:27.000798 29000 net.cpp:226] fc4_postscale needs backward computation.
I0409 19:41:27.000807 29000 net.cpp:226] fc4_sTanH needs backward computation.
I0409 19:41:27.000814 29000 net.cpp:226] fc4_prescale needs backward computation.
I0409 19:41:27.000823 29000 net.cpp:226] fc4_300 needs backward computation.
I0409 19:41:27.000831 29000 net.cpp:226] pool3 needs backward computation.
I0409 19:41:27.000840 29000 net.cpp:226] conv3_postscale needs backward computation.
I0409 19:41:27.000849 29000 net.cpp:226] conv3_sTanH needs backward computation.
I0409 19:41:27.000856 29000 net.cpp:226] conv3_prescale needs backward computation.
I0409 19:41:27.000865 29000 net.cpp:226] conv3 needs backward computation.
I0409 19:41:27.000874 29000 net.cpp:226] pool2 needs backward computation.
I0409 19:41:27.000883 29000 net.cpp:226] conv2_postscale needs backward computation.
I0409 19:41:27.000892 29000 net.cpp:226] conv2_sTanH needs backward computation.
I0409 19:41:27.000900 29000 net.cpp:226] conv2_prescale needs backward computation.
I0409 19:41:27.000908 29000 net.cpp:226] conv2 needs backward computation.
I0409 19:41:27.000917 29000 net.cpp:226] pool1 needs backward computation.
I0409 19:41:27.000926 29000 net.cpp:226] conv1_postscale needs backward computation.
I0409 19:41:27.000936 29000 net.cpp:226] conv1_sTanH needs backward computation.
I0409 19:41:27.000943 29000 net.cpp:226] conv1_prescale needs backward computation.
I0409 19:41:27.000952 29000 net.cpp:226] conv1 needs backward computation.
I0409 19:41:27.000962 29000 net.cpp:228] data does not need backward computation.
I0409 19:41:27.000970 29000 net.cpp:270] This network produces output loss
I0409 19:41:27.001014 29000 net.cpp:283] Network initialization done.
I0409 19:41:27.001528 29000 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/test.prototxt
I0409 19:41:27.001910 29000 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 133
    mean_value: 133
    mean_value: 132
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0409 19:41:27.002130 29000 layer_factory.hpp:77] Creating layer data
I0409 19:41:27.006111 29000 net.cpp:100] Creating Layer data
I0409 19:41:27.006141 29000 net.cpp:408] data -> data
I0409 19:41:27.006158 29000 net.cpp:408] data -> label
I0409 19:41:27.010040 29202 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0409 19:41:27.010262 29000 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 19:41:27.059484 29000 net.cpp:150] Setting up data
I0409 19:41:27.059517 29000 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 19:41:27.059525 29000 net.cpp:157] Top shape: 1024 (1024)
I0409 19:41:27.059527 29000 net.cpp:165] Memory required for data: 28315648
I0409 19:41:27.059535 29000 layer_factory.hpp:77] Creating layer label_data_1_split
I0409 19:41:27.059553 29000 net.cpp:100] Creating Layer label_data_1_split
I0409 19:41:27.059563 29000 net.cpp:434] label_data_1_split <- label
I0409 19:41:27.059577 29000 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0409 19:41:27.059598 29000 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0409 19:41:27.059614 29000 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0409 19:41:27.059826 29000 net.cpp:150] Setting up label_data_1_split
I0409 19:41:27.059844 29000 net.cpp:157] Top shape: 1024 (1024)
I0409 19:41:27.059851 29000 net.cpp:157] Top shape: 1024 (1024)
I0409 19:41:27.059862 29000 net.cpp:157] Top shape: 1024 (1024)
I0409 19:41:27.059870 29000 net.cpp:165] Memory required for data: 28327936
I0409 19:41:27.059926 29000 layer_factory.hpp:77] Creating layer conv1
I0409 19:41:27.059958 29000 net.cpp:100] Creating Layer conv1
I0409 19:41:27.059968 29000 net.cpp:434] conv1 <- data
I0409 19:41:27.059980 29000 net.cpp:408] conv1 -> conv1
I0409 19:41:27.064884 29000 net.cpp:150] Setting up conv1
I0409 19:41:27.064909 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:27.064913 29000 net.cpp:165] Memory required for data: 750862336
I0409 19:41:27.064930 29000 layer_factory.hpp:77] Creating layer conv1_prescale
I0409 19:41:27.064944 29000 net.cpp:100] Creating Layer conv1_prescale
I0409 19:41:27.064954 29000 net.cpp:434] conv1_prescale <- conv1
I0409 19:41:27.064965 29000 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0409 19:41:27.065181 29000 net.cpp:150] Setting up conv1_prescale
I0409 19:41:27.065199 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:27.065209 29000 net.cpp:165] Memory required for data: 1473396736
I0409 19:41:27.065232 29000 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 19:41:27.065249 29000 net.cpp:100] Creating Layer conv1_sTanH
I0409 19:41:27.065258 29000 net.cpp:434] conv1_sTanH <- conv1
I0409 19:41:27.065269 29000 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 19:41:27.065623 29000 net.cpp:150] Setting up conv1_sTanH
I0409 19:41:27.065642 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:27.065651 29000 net.cpp:165] Memory required for data: 2195931136
I0409 19:41:27.065661 29000 layer_factory.hpp:77] Creating layer conv1_postscale
I0409 19:41:27.065675 29000 net.cpp:100] Creating Layer conv1_postscale
I0409 19:41:27.065685 29000 net.cpp:434] conv1_postscale <- conv1
I0409 19:41:27.065698 29000 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0409 19:41:27.065865 29000 net.cpp:150] Setting up conv1_postscale
I0409 19:41:27.065879 29000 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:41:27.065884 29000 net.cpp:165] Memory required for data: 2918465536
I0409 19:41:27.065891 29000 layer_factory.hpp:77] Creating layer pool1
I0409 19:41:27.065902 29000 net.cpp:100] Creating Layer pool1
I0409 19:41:27.065907 29000 net.cpp:434] pool1 <- conv1
I0409 19:41:27.065915 29000 net.cpp:408] pool1 -> pool1
I0409 19:41:27.065973 29000 net.cpp:150] Setting up pool1
I0409 19:41:27.065984 29000 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 19:41:27.065989 29000 net.cpp:165] Memory required for data: 3099099136
I0409 19:41:27.065994 29000 layer_factory.hpp:77] Creating layer conv2
I0409 19:41:27.066005 29000 net.cpp:100] Creating Layer conv2
I0409 19:41:27.066012 29000 net.cpp:434] conv2 <- pool1
I0409 19:41:27.066020 29000 net.cpp:408] conv2 -> conv2
I0409 19:41:27.071959 29000 net.cpp:150] Setting up conv2
I0409 19:41:27.071982 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:27.071988 29000 net.cpp:165] Memory required for data: 3298164736
I0409 19:41:27.072010 29000 layer_factory.hpp:77] Creating layer conv2_prescale
I0409 19:41:27.072033 29000 net.cpp:100] Creating Layer conv2_prescale
I0409 19:41:27.072044 29000 net.cpp:434] conv2_prescale <- conv2
I0409 19:41:27.072058 29000 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0409 19:41:27.072322 29000 net.cpp:150] Setting up conv2_prescale
I0409 19:41:27.072341 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:27.072350 29000 net.cpp:165] Memory required for data: 3497230336
I0409 19:41:27.072362 29000 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 19:41:27.072376 29000 net.cpp:100] Creating Layer conv2_sTanH
I0409 19:41:27.072384 29000 net.cpp:434] conv2_sTanH <- conv2
I0409 19:41:27.072397 29000 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 19:41:27.073503 29000 net.cpp:150] Setting up conv2_sTanH
I0409 19:41:27.073523 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:27.073529 29000 net.cpp:165] Memory required for data: 3696295936
I0409 19:41:27.073537 29000 layer_factory.hpp:77] Creating layer conv2_postscale
I0409 19:41:27.073554 29000 net.cpp:100] Creating Layer conv2_postscale
I0409 19:41:27.073591 29000 net.cpp:434] conv2_postscale <- conv2
I0409 19:41:27.073608 29000 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0409 19:41:27.073842 29000 net.cpp:150] Setting up conv2_postscale
I0409 19:41:27.073861 29000 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:41:27.073870 29000 net.cpp:165] Memory required for data: 3895361536
I0409 19:41:27.073884 29000 layer_factory.hpp:77] Creating layer pool2
I0409 19:41:27.073902 29000 net.cpp:100] Creating Layer pool2
I0409 19:41:27.073930 29000 net.cpp:434] pool2 <- conv2
I0409 19:41:27.073945 29000 net.cpp:408] pool2 -> pool2
I0409 19:41:27.074039 29000 net.cpp:150] Setting up pool2
I0409 19:41:27.074057 29000 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 19:41:27.074066 29000 net.cpp:165] Memory required for data: 3945127936
I0409 19:41:27.074074 29000 layer_factory.hpp:77] Creating layer conv3
I0409 19:41:27.074093 29000 net.cpp:100] Creating Layer conv3
I0409 19:41:27.074103 29000 net.cpp:434] conv3 <- pool2
I0409 19:41:27.074118 29000 net.cpp:408] conv3 -> conv3
I0409 19:41:27.081924 29000 net.cpp:150] Setting up conv3
I0409 19:41:27.081951 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:27.081956 29000 net.cpp:165] Memory required for data: 3981991936
I0409 19:41:27.081971 29000 layer_factory.hpp:77] Creating layer conv3_prescale
I0409 19:41:27.082001 29000 net.cpp:100] Creating Layer conv3_prescale
I0409 19:41:27.082012 29000 net.cpp:434] conv3_prescale <- conv3
I0409 19:41:27.082036 29000 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0409 19:41:27.082228 29000 net.cpp:150] Setting up conv3_prescale
I0409 19:41:27.082247 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:27.082255 29000 net.cpp:165] Memory required for data: 4018855936
I0409 19:41:27.082268 29000 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 19:41:27.082288 29000 net.cpp:100] Creating Layer conv3_sTanH
I0409 19:41:27.082296 29000 net.cpp:434] conv3_sTanH <- conv3
I0409 19:41:27.082311 29000 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 19:41:27.083576 29000 net.cpp:150] Setting up conv3_sTanH
I0409 19:41:27.083600 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:27.083606 29000 net.cpp:165] Memory required for data: 4055719936
I0409 19:41:27.083616 29000 layer_factory.hpp:77] Creating layer conv3_postscale
I0409 19:41:27.083628 29000 net.cpp:100] Creating Layer conv3_postscale
I0409 19:41:27.083638 29000 net.cpp:434] conv3_postscale <- conv3
I0409 19:41:27.083662 29000 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0409 19:41:27.083912 29000 net.cpp:150] Setting up conv3_postscale
I0409 19:41:27.083937 29000 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:41:27.083947 29000 net.cpp:165] Memory required for data: 4092583936
I0409 19:41:27.083961 29000 layer_factory.hpp:77] Creating layer pool3
I0409 19:41:27.083981 29000 net.cpp:100] Creating Layer pool3
I0409 19:41:27.083992 29000 net.cpp:434] pool3 <- conv3
I0409 19:41:27.084005 29000 net.cpp:408] pool3 -> pool3
I0409 19:41:27.084090 29000 net.cpp:150] Setting up pool3
I0409 19:41:27.084107 29000 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 19:41:27.084115 29000 net.cpp:165] Memory required for data: 4101799936
I0409 19:41:27.084125 29000 layer_factory.hpp:77] Creating layer fc4_300
I0409 19:41:27.084142 29000 net.cpp:100] Creating Layer fc4_300
I0409 19:41:27.084151 29000 net.cpp:434] fc4_300 <- pool3
I0409 19:41:27.084167 29000 net.cpp:408] fc4_300 -> fc4_300
I0409 19:41:27.091666 29000 net.cpp:150] Setting up fc4_300
I0409 19:41:27.091691 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:27.091694 29000 net.cpp:165] Memory required for data: 4103028736
I0409 19:41:27.091707 29000 layer_factory.hpp:77] Creating layer fc4_prescale
I0409 19:41:27.091743 29000 net.cpp:100] Creating Layer fc4_prescale
I0409 19:41:27.091756 29000 net.cpp:434] fc4_prescale <- fc4_300
I0409 19:41:27.091770 29000 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0409 19:41:27.091970 29000 net.cpp:150] Setting up fc4_prescale
I0409 19:41:27.092015 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:27.092025 29000 net.cpp:165] Memory required for data: 4104257536
I0409 19:41:27.092038 29000 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 19:41:27.092051 29000 net.cpp:100] Creating Layer fc4_sTanH
I0409 19:41:27.092061 29000 net.cpp:434] fc4_sTanH <- fc4_300
I0409 19:41:27.092075 29000 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 19:41:27.092453 29000 net.cpp:150] Setting up fc4_sTanH
I0409 19:41:27.092473 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:27.092478 29000 net.cpp:165] Memory required for data: 4105486336
I0409 19:41:27.092488 29000 layer_factory.hpp:77] Creating layer fc4_postscale
I0409 19:41:27.092507 29000 net.cpp:100] Creating Layer fc4_postscale
I0409 19:41:27.092519 29000 net.cpp:434] fc4_postscale <- fc4_300
I0409 19:41:27.092532 29000 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0409 19:41:27.092797 29000 net.cpp:150] Setting up fc4_postscale
I0409 19:41:27.092818 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:27.092826 29000 net.cpp:165] Memory required for data: 4106715136
I0409 19:41:27.092839 29000 layer_factory.hpp:77] Creating layer drop4
I0409 19:41:27.092854 29000 net.cpp:100] Creating Layer drop4
I0409 19:41:27.092864 29000 net.cpp:434] drop4 <- fc4_300
I0409 19:41:27.092878 29000 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 19:41:27.092933 29000 net.cpp:150] Setting up drop4
I0409 19:41:27.092949 29000 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:41:27.092957 29000 net.cpp:165] Memory required for data: 4107943936
I0409 19:41:27.092967 29000 layer_factory.hpp:77] Creating layer fc5_67
I0409 19:41:27.092979 29000 net.cpp:100] Creating Layer fc5_67
I0409 19:41:27.092988 29000 net.cpp:434] fc5_67 <- fc4_300
I0409 19:41:27.093003 29000 net.cpp:408] fc5_67 -> fc5_classes
I0409 19:41:27.093592 29000 net.cpp:150] Setting up fc5_67
I0409 19:41:27.093614 29000 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:41:27.093623 29000 net.cpp:165] Memory required for data: 4108218368
I0409 19:41:27.093649 29000 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0409 19:41:27.093667 29000 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0409 19:41:27.093675 29000 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0409 19:41:27.093689 29000 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0409 19:41:27.093705 29000 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0409 19:41:27.093721 29000 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0409 19:41:27.093827 29000 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0409 19:41:27.093842 29000 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:41:27.093852 29000 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:41:27.093861 29000 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:41:27.093869 29000 net.cpp:165] Memory required for data: 4109041664
I0409 19:41:27.093878 29000 layer_factory.hpp:77] Creating layer loss
I0409 19:41:27.093893 29000 net.cpp:100] Creating Layer loss
I0409 19:41:27.093901 29000 net.cpp:434] loss <- fc5_classes_fc5_67_0_split_0
I0409 19:41:27.093912 29000 net.cpp:434] loss <- label_data_1_split_0
I0409 19:41:27.093924 29000 net.cpp:408] loss -> loss
I0409 19:41:27.093950 29000 layer_factory.hpp:77] Creating layer loss
I0409 19:41:27.094609 29000 net.cpp:150] Setting up loss
I0409 19:41:27.094635 29000 net.cpp:157] Top shape: (1)
I0409 19:41:27.094645 29000 net.cpp:160]     with loss weight 1
I0409 19:41:27.094661 29000 net.cpp:165] Memory required for data: 4109041668
I0409 19:41:27.094671 29000 layer_factory.hpp:77] Creating layer accuracy_1
I0409 19:41:27.094687 29000 net.cpp:100] Creating Layer accuracy_1
I0409 19:41:27.094697 29000 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0409 19:41:27.094709 29000 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0409 19:41:27.094725 29000 net.cpp:408] accuracy_1 -> accuracy_1
I0409 19:41:27.094744 29000 net.cpp:150] Setting up accuracy_1
I0409 19:41:27.094777 29000 net.cpp:157] Top shape: (1)
I0409 19:41:27.094786 29000 net.cpp:165] Memory required for data: 4109041672
I0409 19:41:27.094795 29000 layer_factory.hpp:77] Creating layer accuracy_5
I0409 19:41:27.094808 29000 net.cpp:100] Creating Layer accuracy_5
I0409 19:41:27.094817 29000 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0409 19:41:27.094852 29000 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0409 19:41:27.094869 29000 net.cpp:408] accuracy_5 -> accuracy_5
I0409 19:41:27.094887 29000 net.cpp:150] Setting up accuracy_5
I0409 19:41:27.094899 29000 net.cpp:157] Top shape: (1)
I0409 19:41:27.094907 29000 net.cpp:165] Memory required for data: 4109041676
I0409 19:41:27.094915 29000 net.cpp:228] accuracy_5 does not need backward computation.
I0409 19:41:27.094925 29000 net.cpp:228] accuracy_1 does not need backward computation.
I0409 19:41:27.094934 29000 net.cpp:226] loss needs backward computation.
I0409 19:41:27.094944 29000 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0409 19:41:27.094952 29000 net.cpp:226] fc5_67 needs backward computation.
I0409 19:41:27.094961 29000 net.cpp:226] drop4 needs backward computation.
I0409 19:41:27.094969 29000 net.cpp:226] fc4_postscale needs backward computation.
I0409 19:41:27.094977 29000 net.cpp:226] fc4_sTanH needs backward computation.
I0409 19:41:27.094985 29000 net.cpp:226] fc4_prescale needs backward computation.
I0409 19:41:27.094992 29000 net.cpp:226] fc4_300 needs backward computation.
I0409 19:41:27.095000 29000 net.cpp:226] pool3 needs backward computation.
I0409 19:41:27.095010 29000 net.cpp:226] conv3_postscale needs backward computation.
I0409 19:41:27.095017 29000 net.cpp:226] conv3_sTanH needs backward computation.
I0409 19:41:27.095026 29000 net.cpp:226] conv3_prescale needs backward computation.
I0409 19:41:27.095034 29000 net.cpp:226] conv3 needs backward computation.
I0409 19:41:27.095042 29000 net.cpp:226] pool2 needs backward computation.
I0409 19:41:27.095052 29000 net.cpp:226] conv2_postscale needs backward computation.
I0409 19:41:27.095060 29000 net.cpp:226] conv2_sTanH needs backward computation.
I0409 19:41:27.095068 29000 net.cpp:226] conv2_prescale needs backward computation.
I0409 19:41:27.095075 29000 net.cpp:226] conv2 needs backward computation.
I0409 19:41:27.095084 29000 net.cpp:226] pool1 needs backward computation.
I0409 19:41:27.095093 29000 net.cpp:226] conv1_postscale needs backward computation.
I0409 19:41:27.095100 29000 net.cpp:226] conv1_sTanH needs backward computation.
I0409 19:41:27.095108 29000 net.cpp:226] conv1_prescale needs backward computation.
I0409 19:41:27.095116 29000 net.cpp:226] conv1 needs backward computation.
I0409 19:41:27.095127 29000 net.cpp:228] label_data_1_split does not need backward computation.
I0409 19:41:27.095136 29000 net.cpp:228] data does not need backward computation.
I0409 19:41:27.095144 29000 net.cpp:270] This network produces output accuracy_1
I0409 19:41:27.095154 29000 net.cpp:270] This network produces output accuracy_5
I0409 19:41:27.095162 29000 net.cpp:270] This network produces output loss
I0409 19:41:27.095229 29000 net.cpp:283] Network initialization done.
I0409 19:41:27.095360 29000 solver.cpp:72] Solver scaffolding done.
I0409 19:41:27.098835 29000 caffe.cpp:251] Starting Optimization
I0409 19:41:27.098858 29000 solver.cpp:291] Solving 
I0409 19:41:27.098865 29000 solver.cpp:292] Learning Rate Policy: step
I0409 19:41:27.103236 29000 solver.cpp:349] Iteration 0, Testing net (#0)
I0409 19:41:28.213205 29000 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0197754
I0409 19:41:28.213241 29000 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0546875
I0409 19:41:28.213251 29000 solver.cpp:416]     Test net output #2: loss = 4.65269 (* 1 = 4.65269 loss)
I0409 19:41:28.375957 29000 solver.cpp:240] Iteration 0, loss = 4.82293
I0409 19:41:28.375996 29000 solver.cpp:256]     Train net output #0: loss = 4.82293 (* 1 = 4.82293 loss)
I0409 19:41:28.376010 29000 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0409 19:41:28.749702 29000 solver.cpp:240] Iteration 1, loss = 5.38193
I0409 19:41:28.749764 29000 solver.cpp:256]     Train net output #0: loss = 5.38193 (* 1 = 5.38193 loss)
I0409 19:41:28.749774 29000 sgd_solver.cpp:106] Iteration 1, lr = 0.001
I0409 19:41:29.124189 29000 solver.cpp:240] Iteration 2, loss = 5.99203
I0409 19:41:29.124231 29000 solver.cpp:256]     Train net output #0: loss = 5.99203 (* 1 = 5.99203 loss)
I0409 19:41:29.124240 29000 sgd_solver.cpp:106] Iteration 2, lr = 0.001
I0409 19:41:29.502807 29000 solver.cpp:240] Iteration 3, loss = 5.7884
I0409 19:41:29.502847 29000 solver.cpp:256]     Train net output #0: loss = 5.7884 (* 1 = 5.7884 loss)
I0409 19:41:29.502856 29000 sgd_solver.cpp:106] Iteration 3, lr = 0.001
I0409 19:41:29.877430 29000 solver.cpp:240] Iteration 4, loss = 5.5405
I0409 19:41:29.877470 29000 solver.cpp:256]     Train net output #0: loss = 5.5405 (* 1 = 5.5405 loss)
I0409 19:41:29.877480 29000 sgd_solver.cpp:106] Iteration 4, lr = 0.001
I0409 19:41:30.253927 29000 solver.cpp:240] Iteration 5, loss = 5.57667
I0409 19:41:30.253968 29000 solver.cpp:256]     Train net output #0: loss = 5.57667 (* 1 = 5.57667 loss)
I0409 19:41:30.253975 29000 sgd_solver.cpp:106] Iteration 5, lr = 0.001
I0409 19:41:30.628923 29000 solver.cpp:240] Iteration 6, loss = 5.74755
I0409 19:41:30.628962 29000 solver.cpp:256]     Train net output #0: loss = 5.74755 (* 1 = 5.74755 loss)
I0409 19:41:30.628970 29000 sgd_solver.cpp:106] Iteration 6, lr = 0.001
I0409 19:41:30.999385 29000 solver.cpp:240] Iteration 7, loss = 6.06415
I0409 19:41:30.999425 29000 solver.cpp:256]     Train net output #0: loss = 6.06415 (* 1 = 6.06415 loss)
I0409 19:41:30.999434 29000 sgd_solver.cpp:106] Iteration 7, lr = 0.001
I0409 19:41:31.377509 29000 solver.cpp:240] Iteration 8, loss = 7.11416
I0409 19:41:31.377553 29000 solver.cpp:256]     Train net output #0: loss = 7.11416 (* 1 = 7.11416 loss)
I0409 19:41:31.377560 29000 sgd_solver.cpp:106] Iteration 8, lr = 0.001
I0409 19:41:31.754220 29000 solver.cpp:240] Iteration 9, loss = 7.62428
I0409 19:41:31.754258 29000 solver.cpp:256]     Train net output #0: loss = 7.62428 (* 1 = 7.62428 loss)
I0409 19:41:31.754266 29000 sgd_solver.cpp:106] Iteration 9, lr = 0.001
I0409 19:41:32.129586 29000 solver.cpp:240] Iteration 10, loss = 8.07502
I0409 19:41:32.129632 29000 solver.cpp:256]     Train net output #0: loss = 8.07502 (* 1 = 8.07502 loss)
I0409 19:41:32.129640 29000 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0409 19:41:32.500775 29000 solver.cpp:240] Iteration 11, loss = 9.87913
I0409 19:41:32.500818 29000 solver.cpp:256]     Train net output #0: loss = 9.87913 (* 1 = 9.87913 loss)
I0409 19:41:32.500828 29000 sgd_solver.cpp:106] Iteration 11, lr = 0.001
I0409 19:41:32.878566 29000 solver.cpp:240] Iteration 12, loss = 10.8823
I0409 19:41:32.878614 29000 solver.cpp:256]     Train net output #0: loss = 10.8823 (* 1 = 10.8823 loss)
I0409 19:41:32.878623 29000 sgd_solver.cpp:106] Iteration 12, lr = 0.001
I0409 19:41:33.251945 29000 solver.cpp:240] Iteration 13, loss = 12.5246
I0409 19:41:33.251991 29000 solver.cpp:256]     Train net output #0: loss = 12.5246 (* 1 = 12.5246 loss)
I0409 19:41:33.251999 29000 sgd_solver.cpp:106] Iteration 13, lr = 0.001
I0409 19:41:33.625802 29000 solver.cpp:240] Iteration 14, loss = 14.9935
I0409 19:41:33.625840 29000 solver.cpp:256]     Train net output #0: loss = 14.9935 (* 1 = 14.9935 loss)
I0409 19:41:33.625849 29000 sgd_solver.cpp:106] Iteration 14, lr = 0.001
I0409 19:41:34.008055 29000 solver.cpp:240] Iteration 15, loss = 15.7086
I0409 19:41:34.008095 29000 solver.cpp:256]     Train net output #0: loss = 15.7086 (* 1 = 15.7086 loss)
I0409 19:41:34.008103 29000 sgd_solver.cpp:106] Iteration 15, lr = 0.001
I0409 19:41:34.386710 29000 solver.cpp:240] Iteration 16, loss = 14.3961
I0409 19:41:34.386754 29000 solver.cpp:256]     Train net output #0: loss = 14.3961 (* 1 = 14.3961 loss)
I0409 19:41:34.386764 29000 sgd_solver.cpp:106] Iteration 16, lr = 0.001
I0409 19:41:34.762966 29000 solver.cpp:240] Iteration 17, loss = 15.1488
I0409 19:41:34.763116 29000 solver.cpp:256]     Train net output #0: loss = 15.1488 (* 1 = 15.1488 loss)
I0409 19:41:34.891214 29000 sgd_solver.cpp:106] Iteration 17, lr = 0.001
I0409 19:41:35.137812 29000 solver.cpp:240] Iteration 18, loss = 16.2493
I0409 19:41:35.137941 29000 solver.cpp:256]     Train net output #0: loss = 16.2493 (* 1 = 16.2493 loss)
I0409 19:41:35.137950 29000 sgd_solver.cpp:106] Iteration 18, lr = 0.001
I0409 19:41:35.508888 29000 solver.cpp:240] Iteration 19, loss = 17.0036
I0409 19:41:35.508931 29000 solver.cpp:256]     Train net output #0: loss = 17.0036 (* 1 = 17.0036 loss)
I0409 19:41:35.508940 29000 sgd_solver.cpp:106] Iteration 19, lr = 0.001
I0409 19:41:35.886410 29000 solver.cpp:240] Iteration 20, loss = 18.545
I0409 19:41:35.886463 29000 solver.cpp:256]     Train net output #0: loss = 18.545 (* 1 = 18.545 loss)
I0409 19:41:35.886472 29000 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0409 19:41:36.259860 29000 solver.cpp:240] Iteration 21, loss = 17.4637
I0409 19:41:36.259917 29000 solver.cpp:256]     Train net output #0: loss = 17.4637 (* 1 = 17.4637 loss)
I0409 19:41:36.259927 29000 sgd_solver.cpp:106] Iteration 21, lr = 0.001
I0409 19:41:36.633121 29000 solver.cpp:240] Iteration 22, loss = 16.6883
I0409 19:41:36.633168 29000 solver.cpp:256]     Train net output #0: loss = 16.6883 (* 1 = 16.6883 loss)
I0409 19:41:36.633177 29000 sgd_solver.cpp:106] Iteration 22, lr = 0.001
I0409 19:41:37.014636 29000 solver.cpp:240] Iteration 23, loss = 14.5624
I0409 19:41:37.014677 29000 solver.cpp:256]     Train net output #0: loss = 14.5624 (* 1 = 14.5624 loss)
I0409 19:41:37.014684 29000 sgd_solver.cpp:106] Iteration 23, lr = 0.001
I0409 19:41:37.393697 29000 solver.cpp:240] Iteration 24, loss = 13.2238
I0409 19:41:37.393755 29000 solver.cpp:256]     Train net output #0: loss = 13.2238 (* 1 = 13.2238 loss)
I0409 19:41:37.393764 29000 sgd_solver.cpp:106] Iteration 24, lr = 0.001
I0409 19:41:37.394086 29000 solver.cpp:349] Iteration 25, Testing net (#0)
I0409 19:41:38.691207 29000 solver.cpp:416]     Test net output #0: accuracy_1 = 0
I0409 19:41:38.691249 29000 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0980225
I0409 19:41:38.691262 29000 solver.cpp:416]     Test net output #2: loss = 11.8724 (* 1 = 11.8724 loss)
I0409 19:41:38.819495 29000 solver.cpp:240] Iteration 25, loss = 12.1743
I0409 19:41:38.819542 29000 solver.cpp:256]     Train net output #0: loss = 12.1743 (* 1 = 12.1743 loss)
I0409 19:41:38.819551 29000 sgd_solver.cpp:106] Iteration 25, lr = 0.001
I0409 19:41:39.189458 29000 solver.cpp:240] Iteration 26, loss = 10.4114
I0409 19:41:39.189496 29000 solver.cpp:256]     Train net output #0: loss = 10.4114 (* 1 = 10.4114 loss)
I0409 19:41:39.189504 29000 sgd_solver.cpp:106] Iteration 26, lr = 0.001
I0409 19:41:39.564868 29000 solver.cpp:240] Iteration 27, loss = 9.6687
I0409 19:41:39.564906 29000 solver.cpp:256]     Train net output #0: loss = 9.6687 (* 1 = 9.6687 loss)
I0409 19:41:39.564914 29000 sgd_solver.cpp:106] Iteration 27, lr = 0.001
I0409 19:41:39.939323 29000 solver.cpp:240] Iteration 28, loss = 9.7502
I0409 19:41:39.939363 29000 solver.cpp:256]     Train net output #0: loss = 9.7502 (* 1 = 9.7502 loss)
I0409 19:41:39.939371 29000 sgd_solver.cpp:106] Iteration 28, lr = 0.001
I0409 19:41:40.315352 29000 solver.cpp:240] Iteration 29, loss = 11.8041
I0409 19:41:40.315399 29000 solver.cpp:256]     Train net output #0: loss = 11.8041 (* 1 = 11.8041 loss)
I0409 19:41:40.315408 29000 sgd_solver.cpp:106] Iteration 29, lr = 0.001
I0409 19:41:40.695996 29000 solver.cpp:240] Iteration 30, loss = 12.6751
I0409 19:41:40.696035 29000 solver.cpp:256]     Train net output #0: loss = 12.6751 (* 1 = 12.6751 loss)
I0409 19:41:40.696044 29000 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0409 19:41:41.072197 29000 solver.cpp:240] Iteration 31, loss = 13.4378
I0409 19:41:41.072247 29000 solver.cpp:256]     Train net output #0: loss = 13.4378 (* 1 = 13.4378 loss)
I0409 19:41:41.072257 29000 sgd_solver.cpp:106] Iteration 31, lr = 0.001
I0409 19:41:41.445488 29000 solver.cpp:240] Iteration 32, loss = 14.9438
I0409 19:41:41.445533 29000 solver.cpp:256]     Train net output #0: loss = 14.9438 (* 1 = 14.9438 loss)
I0409 19:41:41.445569 29000 sgd_solver.cpp:106] Iteration 32, lr = 0.001
I0409 19:41:41.822000 29000 solver.cpp:240] Iteration 33, loss = 14.8427
I0409 19:41:41.822046 29000 solver.cpp:256]     Train net output #0: loss = 14.8427 (* 1 = 14.8427 loss)
I0409 19:41:41.822055 29000 sgd_solver.cpp:106] Iteration 33, lr = 0.001
I0409 19:41:42.201795 29000 solver.cpp:240] Iteration 34, loss = 14.4197
I0409 19:41:42.201838 29000 solver.cpp:256]     Train net output #0: loss = 14.4197 (* 1 = 14.4197 loss)
I0409 19:41:42.201845 29000 sgd_solver.cpp:106] Iteration 34, lr = 0.001
I0409 19:41:42.579485 29000 solver.cpp:240] Iteration 35, loss = 13.7289
I0409 19:41:42.579525 29000 solver.cpp:256]     Train net output #0: loss = 13.7289 (* 1 = 13.7289 loss)
I0409 19:41:42.579535 29000 sgd_solver.cpp:106] Iteration 35, lr = 0.001
I0409 19:41:42.954810 29000 solver.cpp:240] Iteration 36, loss = 13.2559
I0409 19:41:42.954861 29000 solver.cpp:256]     Train net output #0: loss = 13.2559 (* 1 = 13.2559 loss)
I0409 19:41:42.954869 29000 sgd_solver.cpp:106] Iteration 36, lr = 0.001
I0409 19:41:43.329391 29000 solver.cpp:240] Iteration 37, loss = 12.6688
I0409 19:41:43.329429 29000 solver.cpp:256]     Train net output #0: loss = 12.6688 (* 1 = 12.6688 loss)
I0409 19:41:43.329438 29000 sgd_solver.cpp:106] Iteration 37, lr = 0.001
I0409 19:41:43.711973 29000 solver.cpp:240] Iteration 38, loss = 12.1326
I0409 19:41:43.712015 29000 solver.cpp:256]     Train net output #0: loss = 12.1326 (* 1 = 12.1326 loss)
I0409 19:41:43.712024 29000 sgd_solver.cpp:106] Iteration 38, lr = 0.001
I0409 19:41:44.091622 29000 solver.cpp:240] Iteration 39, loss = 11.6211
I0409 19:41:44.091663 29000 solver.cpp:256]     Train net output #0: loss = 11.6211 (* 1 = 11.6211 loss)
I0409 19:41:44.091671 29000 sgd_solver.cpp:106] Iteration 39, lr = 0.001
I0409 19:41:44.469039 29000 solver.cpp:240] Iteration 40, loss = 10.7444
I0409 19:41:44.469079 29000 solver.cpp:256]     Train net output #0: loss = 10.7444 (* 1 = 10.7444 loss)
I0409 19:41:44.469086 29000 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0409 19:41:44.844218 29000 solver.cpp:240] Iteration 41, loss = 10.504
I0409 19:41:44.844264 29000 solver.cpp:256]     Train net output #0: loss = 10.504 (* 1 = 10.504 loss)
I0409 19:41:44.844272 29000 sgd_solver.cpp:106] Iteration 41, lr = 0.001
I0409 19:41:45.215003 29000 solver.cpp:240] Iteration 42, loss = 10.3378
I0409 19:41:45.215049 29000 solver.cpp:256]     Train net output #0: loss = 10.3378 (* 1 = 10.3378 loss)
I0409 19:41:45.215057 29000 sgd_solver.cpp:106] Iteration 42, lr = 0.001
I0409 19:41:45.595322 29000 solver.cpp:240] Iteration 43, loss = 9.94677
I0409 19:41:45.595376 29000 solver.cpp:256]     Train net output #0: loss = 9.94677 (* 1 = 9.94677 loss)
I0409 19:41:45.595384 29000 sgd_solver.cpp:106] Iteration 43, lr = 0.001
I0409 19:41:45.971961 29000 solver.cpp:240] Iteration 44, loss = 9.3208
I0409 19:41:45.972005 29000 solver.cpp:256]     Train net output #0: loss = 9.3208 (* 1 = 9.3208 loss)
I0409 19:41:45.972014 29000 sgd_solver.cpp:106] Iteration 44, lr = 0.001
I0409 19:41:46.347261 29000 solver.cpp:240] Iteration 45, loss = 8.74937
I0409 19:41:46.347306 29000 solver.cpp:256]     Train net output #0: loss = 8.74937 (* 1 = 8.74937 loss)
I0409 19:41:46.347314 29000 sgd_solver.cpp:106] Iteration 45, lr = 0.001
I0409 19:41:46.718528 29000 solver.cpp:240] Iteration 46, loss = 8.08933
I0409 19:41:46.718572 29000 solver.cpp:256]     Train net output #0: loss = 8.08933 (* 1 = 8.08933 loss)
I0409 19:41:46.718580 29000 sgd_solver.cpp:106] Iteration 46, lr = 0.001
I0409 19:41:47.098851 29000 solver.cpp:240] Iteration 47, loss = 7.70044
I0409 19:41:47.098896 29000 solver.cpp:256]     Train net output #0: loss = 7.70044 (* 1 = 7.70044 loss)
I0409 19:41:47.098904 29000 sgd_solver.cpp:106] Iteration 47, lr = 0.001
I0409 19:41:47.475126 29000 solver.cpp:240] Iteration 48, loss = 7.37251
I0409 19:41:47.475163 29000 solver.cpp:256]     Train net output #0: loss = 7.37251 (* 1 = 7.37251 loss)
I0409 19:41:47.475172 29000 sgd_solver.cpp:106] Iteration 48, lr = 0.001
I0409 19:41:47.850960 29000 solver.cpp:240] Iteration 49, loss = 6.85231
I0409 19:41:47.851003 29000 solver.cpp:256]     Train net output #0: loss = 6.85231 (* 1 = 6.85231 loss)
I0409 19:41:47.851011 29000 sgd_solver.cpp:106] Iteration 49, lr = 0.001
I0409 19:41:47.851327 29000 solver.cpp:349] Iteration 50, Testing net (#0)
I0409 19:41:49.150934 29000 solver.cpp:416]     Test net output #0: accuracy_1 = 0.000366211
I0409 19:41:49.150974 29000 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0596924
I0409 19:41:49.150982 29000 solver.cpp:416]     Test net output #2: loss = 6.57495 (* 1 = 6.57495 loss)
I0409 19:41:49.280748 29000 solver.cpp:240] Iteration 50, loss = 6.37674
I0409 19:41:49.280788 29000 solver.cpp:256]     Train net output #0: loss = 6.37674 (* 1 = 6.37674 loss)
I0409 19:41:49.280797 29000 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0409 19:41:49.655287 29000 solver.cpp:240] Iteration 51, loss = 6.43437
I0409 19:41:49.655324 29000 solver.cpp:256]     Train net output #0: loss = 6.43437 (* 1 = 6.43437 loss)
I0409 19:41:49.655333 29000 sgd_solver.cpp:106] Iteration 51, lr = 0.001
I0409 19:41:50.029852 29000 solver.cpp:240] Iteration 52, loss = 6.33204
I0409 19:41:50.029891 29000 solver.cpp:256]     Train net output #0: loss = 6.33204 (* 1 = 6.33204 loss)
I0409 19:41:50.029898 29000 sgd_solver.cpp:106] Iteration 52, lr = 0.001
I0409 19:41:50.408615 29000 solver.cpp:240] Iteration 53, loss = 6.18306
I0409 19:41:50.408651 29000 solver.cpp:256]     Train net output #0: loss = 6.18306 (* 1 = 6.18306 loss)
I0409 19:41:50.408659 29000 sgd_solver.cpp:106] Iteration 53, lr = 0.001
I0409 19:41:50.787024 29000 solver.cpp:240] Iteration 54, loss = 5.80604
I0409 19:41:50.787066 29000 solver.cpp:256]     Train net output #0: loss = 5.80604 (* 1 = 5.80604 loss)
I0409 19:41:50.787075 29000 sgd_solver.cpp:106] Iteration 54, lr = 0.001
I0409 19:41:51.163158 29000 solver.cpp:240] Iteration 55, loss = 5.56224
I0409 19:41:51.163194 29000 solver.cpp:256]     Train net output #0: loss = 5.56224 (* 1 = 5.56224 loss)
I0409 19:41:51.163203 29000 sgd_solver.cpp:106] Iteration 55, lr = 0.001
I0409 19:41:51.537431 29000 solver.cpp:240] Iteration 56, loss = 5.29659
I0409 19:41:51.537466 29000 solver.cpp:256]     Train net output #0: loss = 5.29659 (* 1 = 5.29659 loss)
I0409 19:41:51.537474 29000 sgd_solver.cpp:106] Iteration 56, lr = 0.001
I0409 19:41:51.910672 29000 solver.cpp:240] Iteration 57, loss = 5.14509
I0409 19:41:51.910706 29000 solver.cpp:256]     Train net output #0: loss = 5.14509 (* 1 = 5.14509 loss)
I0409 19:41:51.910714 29000 sgd_solver.cpp:106] Iteration 57, lr = 0.001
I0409 19:41:52.287585 29000 solver.cpp:240] Iteration 58, loss = 4.9701
I0409 19:41:52.287627 29000 solver.cpp:256]     Train net output #0: loss = 4.9701 (* 1 = 4.9701 loss)
I0409 19:41:52.287636 29000 sgd_solver.cpp:106] Iteration 58, lr = 0.001
I0409 19:41:52.662446 29000 solver.cpp:240] Iteration 59, loss = 5.03146
I0409 19:41:52.662484 29000 solver.cpp:256]     Train net output #0: loss = 5.03146 (* 1 = 5.03146 loss)
I0409 19:41:52.662492 29000 sgd_solver.cpp:106] Iteration 59, lr = 0.001
I0409 19:41:53.035632 29000 solver.cpp:240] Iteration 60, loss = 4.95108
I0409 19:41:53.035672 29000 solver.cpp:256]     Train net output #0: loss = 4.95108 (* 1 = 4.95108 loss)
I0409 19:41:53.035681 29000 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0409 19:41:53.418737 29000 solver.cpp:240] Iteration 61, loss = 4.95043
I0409 19:41:53.418774 29000 solver.cpp:256]     Train net output #0: loss = 4.95043 (* 1 = 4.95043 loss)
I0409 19:41:53.418782 29000 sgd_solver.cpp:106] Iteration 61, lr = 0.001
I0409 19:41:53.795717 29000 solver.cpp:240] Iteration 62, loss = 4.78238
I0409 19:41:53.795758 29000 solver.cpp:256]     Train net output #0: loss = 4.78238 (* 1 = 4.78238 loss)
I0409 19:41:53.795766 29000 sgd_solver.cpp:106] Iteration 62, lr = 0.001
I0409 19:41:54.171767 29000 solver.cpp:240] Iteration 63, loss = 4.70726
I0409 19:41:54.171816 29000 solver.cpp:256]     Train net output #0: loss = 4.70726 (* 1 = 4.70726 loss)
I0409 19:41:54.171844 29000 sgd_solver.cpp:106] Iteration 63, lr = 0.001
I0409 19:41:54.544209 29000 solver.cpp:240] Iteration 64, loss = 4.62652
I0409 19:41:54.544247 29000 solver.cpp:256]     Train net output #0: loss = 4.62652 (* 1 = 4.62652 loss)
I0409 19:41:54.544255 29000 sgd_solver.cpp:106] Iteration 64, lr = 0.001
I0409 19:41:54.917152 29000 solver.cpp:240] Iteration 65, loss = 4.67507
I0409 19:41:54.917204 29000 solver.cpp:256]     Train net output #0: loss = 4.67507 (* 1 = 4.67507 loss)
I0409 19:41:54.917212 29000 sgd_solver.cpp:106] Iteration 65, lr = 0.001
I0409 19:41:55.295248 29000 solver.cpp:240] Iteration 66, loss = 4.61616
I0409 19:41:55.295289 29000 solver.cpp:256]     Train net output #0: loss = 4.61616 (* 1 = 4.61616 loss)
I0409 19:41:55.295295 29000 sgd_solver.cpp:106] Iteration 66, lr = 0.001
I0409 19:41:55.669709 29000 solver.cpp:240] Iteration 67, loss = 4.88614
I0409 19:41:55.669880 29000 solver.cpp:256]     Train net output #0: loss = 4.88614 (* 1 = 4.88614 loss)
I0409 19:41:55.669891 29000 sgd_solver.cpp:106] Iteration 67, lr = 0.001
I0409 19:41:56.042518 29000 solver.cpp:240] Iteration 68, loss = 5.25666
I0409 19:41:56.042558 29000 solver.cpp:256]     Train net output #0: loss = 5.25666 (* 1 = 5.25666 loss)
I0409 19:41:56.042567 29000 sgd_solver.cpp:106] Iteration 68, lr = 0.001
I0409 19:41:56.424846 29000 solver.cpp:240] Iteration 69, loss = 5.18231
I0409 19:41:56.424890 29000 solver.cpp:256]     Train net output #0: loss = 5.18231 (* 1 = 5.18231 loss)
I0409 19:41:56.424897 29000 sgd_solver.cpp:106] Iteration 69, lr = 0.001
I0409 19:41:56.802136 29000 solver.cpp:240] Iteration 70, loss = 5.04077
I0409 19:41:56.802177 29000 solver.cpp:256]     Train net output #0: loss = 5.04077 (* 1 = 5.04077 loss)
I0409 19:41:56.802184 29000 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0409 19:41:57.177129 29000 solver.cpp:240] Iteration 71, loss = 5.16521
I0409 19:41:57.177166 29000 solver.cpp:256]     Train net output #0: loss = 5.16521 (* 1 = 5.16521 loss)
I0409 19:41:57.177175 29000 sgd_solver.cpp:106] Iteration 71, lr = 0.001
I0409 19:41:57.551358 29000 solver.cpp:240] Iteration 72, loss = 5.37573
I0409 19:41:57.551398 29000 solver.cpp:256]     Train net output #0: loss = 5.37573 (* 1 = 5.37573 loss)
I0409 19:41:57.551405 29000 sgd_solver.cpp:106] Iteration 72, lr = 0.001
I0409 19:41:57.928175 29000 solver.cpp:240] Iteration 73, loss = 5.5116
I0409 19:41:57.928220 29000 solver.cpp:256]     Train net output #0: loss = 5.5116 (* 1 = 5.5116 loss)
I0409 19:41:57.928228 29000 sgd_solver.cpp:106] Iteration 73, lr = 0.001
I0409 19:41:58.307863 29000 solver.cpp:240] Iteration 74, loss = 5.62785
I0409 19:41:58.307929 29000 solver.cpp:256]     Train net output #0: loss = 5.62785 (* 1 = 5.62785 loss)
I0409 19:41:58.307940 29000 sgd_solver.cpp:106] Iteration 74, lr = 0.001
I0409 19:41:58.308261 29000 solver.cpp:349] Iteration 75, Testing net (#0)
I0409 19:41:59.607956 29000 solver.cpp:416]     Test net output #0: accuracy_1 = 0.010376
I0409 19:41:59.607993 29000 solver.cpp:416]     Test net output #1: accuracy_5 = 0.126831
I0409 19:41:59.608003 29000 solver.cpp:416]     Test net output #2: loss = 6.01196 (* 1 = 6.01196 loss)
I0409 19:41:59.736726 29000 solver.cpp:240] Iteration 75, loss = 5.97352
I0409 19:41:59.736781 29000 solver.cpp:256]     Train net output #0: loss = 5.97352 (* 1 = 5.97352 loss)
I0409 19:41:59.736789 29000 sgd_solver.cpp:106] Iteration 75, lr = 0.001
I0409 19:42:00.109351 29000 solver.cpp:240] Iteration 76, loss = 6.31543
I0409 19:42:00.109390 29000 solver.cpp:256]     Train net output #0: loss = 6.31543 (* 1 = 6.31543 loss)
I0409 19:42:00.109398 29000 sgd_solver.cpp:106] Iteration 76, lr = 0.001
I0409 19:42:00.486490 29000 solver.cpp:240] Iteration 77, loss = 6.95611
I0409 19:42:00.486528 29000 solver.cpp:256]     Train net output #0: loss = 6.95611 (* 1 = 6.95611 loss)
I0409 19:42:00.486536 29000 sgd_solver.cpp:106] Iteration 77, lr = 0.001
I0409 19:42:00.863111 29000 solver.cpp:240] Iteration 78, loss = 8.52594
I0409 19:42:00.863152 29000 solver.cpp:256]     Train net output #0: loss = 8.52594 (* 1 = 8.52594 loss)
I0409 19:42:00.863162 29000 sgd_solver.cpp:106] Iteration 78, lr = 0.001
I0409 19:42:01.234993 29000 solver.cpp:240] Iteration 79, loss = 10.7269
I0409 19:42:01.235031 29000 solver.cpp:256]     Train net output #0: loss = 10.7269 (* 1 = 10.7269 loss)
I0409 19:42:01.235040 29000 sgd_solver.cpp:106] Iteration 79, lr = 0.001
I0409 19:42:01.617323 29000 solver.cpp:240] Iteration 80, loss = 13.2346
I0409 19:42:01.617363 29000 solver.cpp:256]     Train net output #0: loss = 13.2346 (* 1 = 13.2346 loss)
I0409 19:42:01.617372 29000 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0409 19:42:01.996053 29000 solver.cpp:240] Iteration 81, loss = 12.8816
I0409 19:42:01.996095 29000 solver.cpp:256]     Train net output #0: loss = 12.8816 (* 1 = 12.8816 loss)
I0409 19:42:01.996104 29000 sgd_solver.cpp:106] Iteration 81, lr = 0.001
I0409 19:42:02.372558 29000 solver.cpp:240] Iteration 82, loss = 12.5422
I0409 19:42:02.372632 29000 solver.cpp:256]     Train net output #0: loss = 12.5422 (* 1 = 12.5422 loss)
I0409 19:42:02.372642 29000 sgd_solver.cpp:106] Iteration 82, lr = 0.001
I0409 19:42:02.746474 29000 solver.cpp:240] Iteration 83, loss = 12.0064
I0409 19:42:02.746517 29000 solver.cpp:256]     Train net output #0: loss = 12.0064 (* 1 = 12.0064 loss)
I0409 19:42:02.746526 29000 sgd_solver.cpp:106] Iteration 83, lr = 0.001
I0409 19:42:03.116475 29000 solver.cpp:240] Iteration 84, loss = 11.6053
I0409 19:42:03.116516 29000 solver.cpp:256]     Train net output #0: loss = 11.6053 (* 1 = 11.6053 loss)
I0409 19:42:03.116524 29000 sgd_solver.cpp:106] Iteration 84, lr = 0.001
I0409 19:42:03.495492 29000 solver.cpp:240] Iteration 85, loss = 11.5567
I0409 19:42:03.495535 29000 solver.cpp:256]     Train net output #0: loss = 11.5567 (* 1 = 11.5567 loss)
I0409 19:42:03.495544 29000 sgd_solver.cpp:106] Iteration 85, lr = 0.001
I0409 19:42:03.870278 29000 solver.cpp:240] Iteration 86, loss = 10.5595
I0409 19:42:03.870324 29000 solver.cpp:256]     Train net output #0: loss = 10.5595 (* 1 = 10.5595 loss)
I0409 19:42:03.870332 29000 sgd_solver.cpp:106] Iteration 86, lr = 0.001
I0409 19:42:04.244042 29000 solver.cpp:240] Iteration 87, loss = 9.97846
I0409 19:42:04.244081 29000 solver.cpp:256]     Train net output #0: loss = 9.97846 (* 1 = 9.97846 loss)
I0409 19:42:04.244088 29000 sgd_solver.cpp:106] Iteration 87, lr = 0.001
I0409 19:42:04.626986 29000 solver.cpp:240] Iteration 88, loss = 9.78236
I0409 19:42:04.627022 29000 solver.cpp:256]     Train net output #0: loss = 9.78236 (* 1 = 9.78236 loss)
I0409 19:42:04.627030 29000 sgd_solver.cpp:106] Iteration 88, lr = 0.001
I0409 19:42:05.005267 29000 solver.cpp:240] Iteration 89, loss = 10.1318
I0409 19:42:05.005306 29000 solver.cpp:256]     Train net output #0: loss = 10.1318 (* 1 = 10.1318 loss)
I0409 19:42:05.005314 29000 sgd_solver.cpp:106] Iteration 89, lr = 0.001
I0409 19:42:05.382627 29000 solver.cpp:240] Iteration 90, loss = 9.18477
I0409 19:42:05.382670 29000 solver.cpp:256]     Train net output #0: loss = 9.18477 (* 1 = 9.18477 loss)
I0409 19:42:05.382679 29000 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0409 19:42:05.757956 29000 solver.cpp:240] Iteration 91, loss = 8.51361
I0409 19:42:05.757997 29000 solver.cpp:256]     Train net output #0: loss = 8.51361 (* 1 = 8.51361 loss)
I0409 19:42:05.758004 29000 sgd_solver.cpp:106] Iteration 91, lr = 0.001
I0409 19:42:06.136553 29000 solver.cpp:240] Iteration 92, loss = 9.00929
I0409 19:42:06.136590 29000 solver.cpp:256]     Train net output #0: loss = 9.00929 (* 1 = 9.00929 loss)
I0409 19:42:06.136598 29000 sgd_solver.cpp:106] Iteration 92, lr = 0.001
I0409 19:42:06.513958 29000 solver.cpp:240] Iteration 93, loss = 8.86982
I0409 19:42:06.514009 29000 solver.cpp:256]     Train net output #0: loss = 8.86982 (* 1 = 8.86982 loss)
I0409 19:42:06.514016 29000 sgd_solver.cpp:106] Iteration 93, lr = 0.001
I0409 19:42:06.889438 29000 solver.cpp:240] Iteration 94, loss = 8.89545
I0409 19:42:06.889474 29000 solver.cpp:256]     Train net output #0: loss = 8.89545 (* 1 = 8.89545 loss)
I0409 19:42:06.889483 29000 sgd_solver.cpp:106] Iteration 94, lr = 0.001
I0409 19:42:07.266993 29000 solver.cpp:240] Iteration 95, loss = 10.1639
I0409 19:42:07.267045 29000 solver.cpp:256]     Train net output #0: loss = 10.1639 (* 1 = 10.1639 loss)
I0409 19:42:07.267053 29000 sgd_solver.cpp:106] Iteration 95, lr = 0.001
I0409 19:42:07.647312 29000 solver.cpp:240] Iteration 96, loss = 9.78302
I0409 19:42:07.647358 29000 solver.cpp:256]     Train net output #0: loss = 9.78302 (* 1 = 9.78302 loss)
I0409 19:42:07.647367 29000 sgd_solver.cpp:106] Iteration 96, lr = 0.001
I0409 19:42:08.024502 29000 solver.cpp:240] Iteration 97, loss = 8.90057
I0409 19:42:08.024538 29000 solver.cpp:256]     Train net output #0: loss = 8.90057 (* 1 = 8.90057 loss)
I0409 19:42:08.024547 29000 sgd_solver.cpp:106] Iteration 97, lr = 0.001
I0409 19:42:08.400092 29000 solver.cpp:240] Iteration 98, loss = 6.91666
I0409 19:42:08.400130 29000 solver.cpp:256]     Train net output #0: loss = 6.91666 (* 1 = 6.91666 loss)
I0409 19:42:08.400166 29000 sgd_solver.cpp:106] Iteration 98, lr = 0.001
I0409 19:42:08.774673 29000 solver.cpp:240] Iteration 99, loss = 6.43704
I0409 19:42:08.774708 29000 solver.cpp:256]     Train net output #0: loss = 6.43704 (* 1 = 6.43704 loss)
I0409 19:42:08.774716 29000 sgd_solver.cpp:106] Iteration 99, lr = 0.001
I0409 19:42:08.775038 29000 solver.cpp:349] Iteration 100, Testing net (#0)
I0409 19:42:10.071219 29000 solver.cpp:416]     Test net output #0: accuracy_1 = 0.000732422
I0409 19:42:10.071254 29000 solver.cpp:416]     Test net output #1: accuracy_5 = 0.209106
I0409 19:42:10.071264 29000 solver.cpp:416]     Test net output #2: loss = 5.465 (* 1 = 5.465 loss)
I0409 19:42:10.200390 29000 solver.cpp:240] Iteration 100, loss = 6.28002
I0409 19:42:10.200425 29000 solver.cpp:256]     Train net output #0: loss = 6.28002 (* 1 = 6.28002 loss)
I0409 19:42:10.200433 29000 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0409 19:42:10.577165 29000 solver.cpp:240] Iteration 101, loss = 5.92777
I0409 19:42:10.577203 29000 solver.cpp:256]     Train net output #0: loss = 5.92777 (* 1 = 5.92777 loss)
I0409 19:42:10.577211 29000 sgd_solver.cpp:106] Iteration 101, lr = 0.001
I0409 19:42:10.946718 29000 solver.cpp:240] Iteration 102, loss = 5.32461
I0409 19:42:10.946758 29000 solver.cpp:256]     Train net output #0: loss = 5.32461 (* 1 = 5.32461 loss)
I0409 19:42:10.946766 29000 sgd_solver.cpp:106] Iteration 102, lr = 0.001
I0409 19:42:11.325253 29000 solver.cpp:240] Iteration 103, loss = 5.4151
I0409 19:42:11.325292 29000 solver.cpp:256]     Train net output #0: loss = 5.4151 (* 1 = 5.4151 loss)
I0409 19:42:11.325300 29000 sgd_solver.cpp:106] Iteration 103, lr = 0.001
I0409 19:42:11.704336 29000 solver.cpp:240] Iteration 104, loss = 5.44572
I0409 19:42:11.704375 29000 solver.cpp:256]     Train net output #0: loss = 5.44572 (* 1 = 5.44572 loss)
I0409 19:42:11.704385 29000 sgd_solver.cpp:106] Iteration 104, lr = 0.001
I0409 19:42:12.080838 29000 solver.cpp:240] Iteration 105, loss = 5.37548
I0409 19:42:12.080875 29000 solver.cpp:256]     Train net output #0: loss = 5.37548 (* 1 = 5.37548 loss)
I0409 19:42:12.080883 29000 sgd_solver.cpp:106] Iteration 105, lr = 0.001
I0409 19:42:12.449898 29000 solver.cpp:240] Iteration 106, loss = 5.30281
I0409 19:42:12.449934 29000 solver.cpp:256]     Train net output #0: loss = 5.30281 (* 1 = 5.30281 loss)
I0409 19:42:12.449942 29000 sgd_solver.cpp:106] Iteration 106, lr = 0.001
I0409 19:42:12.828722 29000 solver.cpp:240] Iteration 107, loss = 5.24321
I0409 19:42:12.828760 29000 solver.cpp:256]     Train net output #0: loss = 5.24321 (* 1 = 5.24321 loss)
I0409 19:42:12.828769 29000 sgd_solver.cpp:106] Iteration 107, lr = 0.001
I0409 19:42:13.207691 29000 solver.cpp:240] Iteration 108, loss = 5.11605
I0409 19:42:13.207727 29000 solver.cpp:256]     Train net output #0: loss = 5.11605 (* 1 = 5.11605 loss)
I0409 19:42:13.207736 29000 sgd_solver.cpp:106] Iteration 108, lr = 0.001
I0409 19:42:13.584270 29000 solver.cpp:240] Iteration 109, loss = 5.42114
I0409 19:42:13.584307 29000 solver.cpp:256]     Train net output #0: loss = 5.42114 (* 1 = 5.42114 loss)
I0409 19:42:13.584316 29000 sgd_solver.cpp:106] Iteration 109, lr = 0.001
I0409 19:42:13.962033 29000 solver.cpp:240] Iteration 110, loss = 5.29391
I0409 19:42:13.962067 29000 solver.cpp:256]     Train net output #0: loss = 5.29391 (* 1 = 5.29391 loss)
I0409 19:42:13.962075 29000 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0409 19:42:14.342989 29000 solver.cpp:240] Iteration 111, loss = 5.20112
I0409 19:42:14.343032 29000 solver.cpp:256]     Train net output #0: loss = 5.20112 (* 1 = 5.20112 loss)
I0409 19:42:14.343040 29000 sgd_solver.cpp:106] Iteration 111, lr = 0.001
I0409 19:42:14.720968 29000 solver.cpp:240] Iteration 112, loss = 5.06152
I0409 19:42:14.721005 29000 solver.cpp:256]     Train net output #0: loss = 5.06152 (* 1 = 5.06152 loss)
I0409 19:42:14.721014 29000 sgd_solver.cpp:106] Iteration 112, lr = 0.001
I0409 19:42:15.095216 29000 solver.cpp:240] Iteration 113, loss = 5.11394
I0409 19:42:15.095252 29000 solver.cpp:256]     Train net output #0: loss = 5.11394 (* 1 = 5.11394 loss)
I0409 19:42:15.095283 29000 sgd_solver.cpp:106] Iteration 113, lr = 0.001
I0409 19:42:15.471137 29000 solver.cpp:240] Iteration 114, loss = 4.92878
I0409 19:42:15.471179 29000 solver.cpp:256]     Train net output #0: loss = 4.92878 (* 1 = 4.92878 loss)
I0409 19:42:15.471187 29000 sgd_solver.cpp:106] Iteration 114, lr = 0.001
I0409 19:42:15.854488 29000 solver.cpp:240] Iteration 115, loss = 5.08116
I0409 19:42:15.854523 29000 solver.cpp:256]     Train net output #0: loss = 5.08116 (* 1 = 5.08116 loss)
I0409 19:42:15.854532 29000 sgd_solver.cpp:106] Iteration 115, lr = 0.001
I0409 19:42:16.230725 29000 solver.cpp:240] Iteration 116, loss = 5.09998
I0409 19:42:16.230762 29000 solver.cpp:256]     Train net output #0: loss = 5.09998 (* 1 = 5.09998 loss)
I0409 19:42:16.230770 29000 sgd_solver.cpp:106] Iteration 116, lr = 0.001
I0409 19:42:16.608439 29000 solver.cpp:240] Iteration 117, loss = 5.06812
I0409 19:42:16.608474 29000 solver.cpp:256]     Train net output #0: loss = 5.06812 (* 1 = 5.06812 loss)
I0409 19:42:16.608481 29000 sgd_solver.cpp:106] Iteration 117, lr = 0.001
I0409 19:42:16.984165 29000 solver.cpp:240] Iteration 118, loss = 5.04784
I0409 19:42:16.984319 29000 solver.cpp:256]     Train net output #0: loss = 5.04784 (* 1 = 5.04784 loss)
I0409 19:42:16.984333 29000 sgd_solver.cpp:106] Iteration 118, lr = 0.001
I0409 19:42:17.363732 29000 solver.cpp:240] Iteration 119, loss = 5.37785
I0409 19:42:17.363777 29000 solver.cpp:256]     Train net output #0: loss = 5.37785 (* 1 = 5.37785 loss)
I0409 19:42:17.363785 29000 sgd_solver.cpp:106] Iteration 119, lr = 0.001
I0409 19:42:17.740046 29000 solver.cpp:240] Iteration 120, loss = 5.13612
I0409 19:42:17.740082 29000 solver.cpp:256]     Train net output #0: loss = 5.13612 (* 1 = 5.13612 loss)
I0409 19:42:17.740090 29000 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0409 19:42:18.116538 29000 solver.cpp:240] Iteration 121, loss = 5.45215
I0409 19:42:18.116575 29000 solver.cpp:256]     Train net output #0: loss = 5.45215 (* 1 = 5.45215 loss)
I0409 19:42:18.116582 29000 sgd_solver.cpp:106] Iteration 121, lr = 0.001
I0409 19:42:18.485282 29000 solver.cpp:240] Iteration 122, loss = 5.31309
I0409 19:42:18.485332 29000 solver.cpp:256]     Train net output #0: loss = 5.31309 (* 1 = 5.31309 loss)
I0409 19:42:18.485345 29000 sgd_solver.cpp:106] Iteration 122, lr = 0.001
I0409 19:42:18.859251 29000 solver.cpp:240] Iteration 123, loss = 5.21638
I0409 19:42:18.859282 29000 solver.cpp:256]     Train net output #0: loss = 5.21638 (* 1 = 5.21638 loss)
I0409 19:42:18.859290 29000 sgd_solver.cpp:106] Iteration 123, lr = 0.001
I0409 19:42:19.239298 29000 solver.cpp:240] Iteration 124, loss = 5.45474
I0409 19:42:19.239344 29000 solver.cpp:256]     Train net output #0: loss = 5.45474 (* 1 = 5.45474 loss)
I0409 19:42:19.239352 29000 sgd_solver.cpp:106] Iteration 124, lr = 0.001
I0409 19:42:19.239679 29000 solver.cpp:349] Iteration 125, Testing net (#0)
I0409 19:42:20.545797 29000 solver.cpp:416]     Test net output #0: accuracy_1 = 0.11731
I0409 19:42:20.545833 29000 solver.cpp:416]     Test net output #1: accuracy_5 = 0.265381
I0409 19:42:20.545843 29000 solver.cpp:416]     Test net output #2: loss = 5.02435 (* 1 = 5.02435 loss)
I0409 19:42:20.675226 29000 solver.cpp:240] Iteration 125, loss = 5.37387
I0409 19:42:20.675263 29000 solver.cpp:256]     Train net output #0: loss = 5.37387 (* 1 = 5.37387 loss)
I0409 19:42:20.675271 29000 sgd_solver.cpp:106] Iteration 125, lr = 0.001
I0409 19:42:21.055286 29000 solver.cpp:240] Iteration 126, loss = 5.40064
I0409 19:42:21.055335 29000 solver.cpp:256]     Train net output #0: loss = 5.40064 (* 1 = 5.40064 loss)
I0409 19:42:21.055342 29000 sgd_solver.cpp:106] Iteration 126, lr = 0.001
I0409 19:42:21.431429 29000 solver.cpp:240] Iteration 127, loss = 5.41203
I0409 19:42:21.431464 29000 solver.cpp:256]     Train net output #0: loss = 5.41203 (* 1 = 5.41203 loss)
I0409 19:42:21.431473 29000 sgd_solver.cpp:106] Iteration 127, lr = 0.001
I0409 19:42:21.807394 29000 solver.cpp:240] Iteration 128, loss = 5.41789
I0409 19:42:21.807464 29000 solver.cpp:256]     Train net output #0: loss = 5.41789 (* 1 = 5.41789 loss)
I0409 19:42:21.807474 29000 sgd_solver.cpp:106] Iteration 128, lr = 0.001
I0409 19:42:22.187014 29000 solver.cpp:240] Iteration 129, loss = 5.14434
I0409 19:42:22.187047 29000 solver.cpp:256]     Train net output #0: loss = 5.14434 (* 1 = 5.14434 loss)
I0409 19:42:22.187053 29000 sgd_solver.cpp:106] Iteration 129, lr = 0.001
I0409 19:42:22.566530 29000 solver.cpp:240] Iteration 130, loss = 4.81349
I0409 19:42:22.566563 29000 solver.cpp:256]     Train net output #0: loss = 4.81349 (* 1 = 4.81349 loss)
I0409 19:42:22.566572 29000 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0409 19:42:22.943629 29000 solver.cpp:240] Iteration 131, loss = 4.87508
I0409 19:42:22.943661 29000 solver.cpp:256]     Train net output #0: loss = 4.87508 (* 1 = 4.87508 loss)
I0409 19:42:22.943670 29000 sgd_solver.cpp:106] Iteration 131, lr = 0.001
I0409 19:42:23.320480 29000 solver.cpp:240] Iteration 132, loss = 4.72054
I0409 19:42:23.320536 29000 solver.cpp:256]     Train net output #0: loss = 4.72054 (* 1 = 4.72054 loss)
I0409 19:42:23.320544 29000 sgd_solver.cpp:106] Iteration 132, lr = 0.001
I0409 19:42:23.698374 29000 solver.cpp:240] Iteration 133, loss = 4.8411
I0409 19:42:23.698417 29000 solver.cpp:256]     Train net output #0: loss = 4.8411 (* 1 = 4.8411 loss)
I0409 19:42:23.698426 29000 sgd_solver.cpp:106] Iteration 133, lr = 0.001
I0409 19:42:24.076313 29000 solver.cpp:240] Iteration 134, loss = 4.78218
I0409 19:42:24.076345 29000 solver.cpp:256]     Train net output #0: loss = 4.78218 (* 1 = 4.78218 loss)
I0409 19:42:24.076354 29000 sgd_solver.cpp:106] Iteration 134, lr = 0.001
I0409 19:42:24.452440 29000 solver.cpp:240] Iteration 135, loss = 5.77229
I0409 19:42:24.452473 29000 solver.cpp:256]     Train net output #0: loss = 5.77229 (* 1 = 5.77229 loss)
I0409 19:42:24.452481 29000 sgd_solver.cpp:106] Iteration 135, lr = 0.001
I0409 19:42:24.829437 29000 solver.cpp:240] Iteration 136, loss = 7.58439
I0409 19:42:24.829468 29000 solver.cpp:256]     Train net output #0: loss = 7.58439 (* 1 = 7.58439 loss)
I0409 19:42:24.829475 29000 sgd_solver.cpp:106] Iteration 136, lr = 0.001
I0409 19:42:25.210362 29000 solver.cpp:240] Iteration 137, loss = 10.1607
I0409 19:42:25.210410 29000 solver.cpp:256]     Train net output #0: loss = 10.1607 (* 1 = 10.1607 loss)
I0409 19:42:25.210418 29000 sgd_solver.cpp:106] Iteration 137, lr = 0.001
I0409 19:42:25.589298 29000 solver.cpp:240] Iteration 138, loss = 8.17341
I0409 19:42:25.589334 29000 solver.cpp:256]     Train net output #0: loss = 8.17341 (* 1 = 8.17341 loss)
I0409 19:42:25.589341 29000 sgd_solver.cpp:106] Iteration 138, lr = 0.001
I0409 19:42:25.965860 29000 solver.cpp:240] Iteration 139, loss = 5.98329
I0409 19:42:25.966063 29000 solver.cpp:256]     Train net output #0: loss = 5.98329 (* 1 = 5.98329 loss)
I0409 19:42:25.966074 29000 sgd_solver.cpp:106] Iteration 139, lr = 0.001
I0409 19:42:26.341187 29000 solver.cpp:240] Iteration 140, loss = 5.20994
I0409 19:42:26.341219 29000 solver.cpp:256]     Train net output #0: loss = 5.20994 (* 1 = 5.20994 loss)
I0409 19:42:26.341228 29000 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0409 19:42:26.722784 29000 solver.cpp:240] Iteration 141, loss = 5.22068
I0409 19:42:26.722815 29000 solver.cpp:256]     Train net output #0: loss = 5.22068 (* 1 = 5.22068 loss)
I0409 19:42:26.722825 29000 sgd_solver.cpp:106] Iteration 141, lr = 0.001
I0409 19:42:27.102802 29000 solver.cpp:240] Iteration 142, loss = 5.02223
I0409 19:42:27.102834 29000 solver.cpp:256]     Train net output #0: loss = 5.02223 (* 1 = 5.02223 loss)
I0409 19:42:27.102843 29000 sgd_solver.cpp:106] Iteration 142, lr = 0.001
I0409 19:42:27.479439 29000 solver.cpp:240] Iteration 143, loss = 4.92629
I0409 19:42:27.479470 29000 solver.cpp:256]     Train net output #0: loss = 4.92629 (* 1 = 4.92629 loss)
I0409 19:42:27.479477 29000 sgd_solver.cpp:106] Iteration 143, lr = 0.001
I0409 19:42:27.849267 29000 solver.cpp:240] Iteration 144, loss = 4.79847
I0409 19:42:27.849298 29000 solver.cpp:256]     Train net output #0: loss = 4.79847 (* 1 = 4.79847 loss)
I0409 19:42:27.849305 29000 sgd_solver.cpp:106] Iteration 144, lr = 0.001
I0409 19:42:28.223575 29000 solver.cpp:240] Iteration 145, loss = 4.84031
I0409 19:42:28.223606 29000 solver.cpp:256]     Train net output #0: loss = 4.84031 (* 1 = 4.84031 loss)
I0409 19:42:28.223614 29000 sgd_solver.cpp:106] Iteration 145, lr = 0.001
