I0409 20:01:11.134147  9650 caffe.cpp:217] Using GPUs 1
I0409 20:01:11.398563  9650 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0409 20:01:12.088835  9650 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/test.prototxt"
test_iter: 8
test_interval: 25
base_lr: 1
display: 1
max_iter: 2500
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 250
snapshot_prefix: "./snapshots/experiment_7/rtsd-r1/CoNorm/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0409 20:01:12.088989  9650 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/train.prototxt
I0409 20:01:12.089264  9650 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0409 20:01:12.089277  9650 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0409 20:01:12.089385  9650 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 132
    mean_value: 132
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
I0409 20:01:12.089468  9650 layer_factory.hpp:77] Creating layer data
I0409 20:01:12.091007  9650 net.cpp:100] Creating Layer data
I0409 20:01:12.091025  9650 net.cpp:408] data -> data
I0409 20:01:12.091050  9650 net.cpp:408] data -> label
I0409 20:01:12.092679  9723 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0409 20:01:12.113266  9650 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 20:01:12.180387  9650 net.cpp:150] Setting up data
I0409 20:01:12.180421  9650 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 20:01:12.180456  9650 net.cpp:157] Top shape: 1024 (1024)
I0409 20:01:12.180460  9650 net.cpp:165] Memory required for data: 28315648
I0409 20:01:12.180472  9650 layer_factory.hpp:77] Creating layer conv1
I0409 20:01:12.180497  9650 net.cpp:100] Creating Layer conv1
I0409 20:01:12.180507  9650 net.cpp:434] conv1 <- data
I0409 20:01:12.180522  9650 net.cpp:408] conv1 -> conv1
I0409 20:01:12.470499  9650 net.cpp:150] Setting up conv1
I0409 20:01:12.470530  9650 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 20:01:12.470535  9650 net.cpp:165] Memory required for data: 750850048
I0409 20:01:12.470562  9650 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 20:01:12.470580  9650 net.cpp:100] Creating Layer conv1_sTanH
I0409 20:01:12.470587  9650 net.cpp:434] conv1_sTanH <- conv1
I0409 20:01:12.470594  9650 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 20:01:12.470796  9650 net.cpp:150] Setting up conv1_sTanH
I0409 20:01:12.470809  9650 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 20:01:12.470815  9650 net.cpp:165] Memory required for data: 1473384448
I0409 20:01:12.470821  9650 layer_factory.hpp:77] Creating layer pool1
I0409 20:01:12.470832  9650 net.cpp:100] Creating Layer pool1
I0409 20:01:12.470837  9650 net.cpp:434] pool1 <- conv1
I0409 20:01:12.470844  9650 net.cpp:408] pool1 -> pool1
I0409 20:01:12.470902  9650 net.cpp:150] Setting up pool1
I0409 20:01:12.470911  9650 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 20:01:12.470916  9650 net.cpp:165] Memory required for data: 1654018048
I0409 20:01:12.470921  9650 layer_factory.hpp:77] Creating layer conv2
I0409 20:01:12.470937  9650 net.cpp:100] Creating Layer conv2
I0409 20:01:12.470942  9650 net.cpp:434] conv2 <- pool1
I0409 20:01:12.470948  9650 net.cpp:408] conv2 -> conv2
I0409 20:01:12.475383  9650 net.cpp:150] Setting up conv2
I0409 20:01:12.475402  9650 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 20:01:12.475407  9650 net.cpp:165] Memory required for data: 1853083648
I0409 20:01:12.475421  9650 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 20:01:12.475430  9650 net.cpp:100] Creating Layer conv2_sTanH
I0409 20:01:12.475433  9650 net.cpp:434] conv2_sTanH <- conv2
I0409 20:01:12.475442  9650 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 20:01:12.476209  9650 net.cpp:150] Setting up conv2_sTanH
I0409 20:01:12.476225  9650 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 20:01:12.476228  9650 net.cpp:165] Memory required for data: 2052149248
I0409 20:01:12.476233  9650 layer_factory.hpp:77] Creating layer pool2
I0409 20:01:12.476239  9650 net.cpp:100] Creating Layer pool2
I0409 20:01:12.476244  9650 net.cpp:434] pool2 <- conv2
I0409 20:01:12.476253  9650 net.cpp:408] pool2 -> pool2
I0409 20:01:12.476310  9650 net.cpp:150] Setting up pool2
I0409 20:01:12.476318  9650 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 20:01:12.476321  9650 net.cpp:165] Memory required for data: 2101915648
I0409 20:01:12.476327  9650 layer_factory.hpp:77] Creating layer conv3
I0409 20:01:12.476343  9650 net.cpp:100] Creating Layer conv3
I0409 20:01:12.476349  9650 net.cpp:434] conv3 <- pool2
I0409 20:01:12.476356  9650 net.cpp:408] conv3 -> conv3
I0409 20:01:12.485592  9650 net.cpp:150] Setting up conv3
I0409 20:01:12.485616  9650 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 20:01:12.485627  9650 net.cpp:165] Memory required for data: 2138779648
I0409 20:01:12.485648  9650 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 20:01:12.485664  9650 net.cpp:100] Creating Layer conv3_sTanH
I0409 20:01:12.485673  9650 net.cpp:434] conv3_sTanH <- conv3
I0409 20:01:12.485682  9650 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 20:01:12.487679  9650 net.cpp:150] Setting up conv3_sTanH
I0409 20:01:12.487700  9650 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 20:01:12.487709  9650 net.cpp:165] Memory required for data: 2175643648
I0409 20:01:12.487716  9650 layer_factory.hpp:77] Creating layer pool3
I0409 20:01:12.487726  9650 net.cpp:100] Creating Layer pool3
I0409 20:01:12.487735  9650 net.cpp:434] pool3 <- conv3
I0409 20:01:12.487778  9650 net.cpp:408] pool3 -> pool3
I0409 20:01:12.487854  9650 net.cpp:150] Setting up pool3
I0409 20:01:12.487874  9650 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 20:01:12.487898  9650 net.cpp:165] Memory required for data: 2184859648
I0409 20:01:12.487905  9650 layer_factory.hpp:77] Creating layer fc4_300
I0409 20:01:12.487917  9650 net.cpp:100] Creating Layer fc4_300
I0409 20:01:12.487926  9650 net.cpp:434] fc4_300 <- pool3
I0409 20:01:12.487936  9650 net.cpp:408] fc4_300 -> fc4_300
I0409 20:01:12.498078  9650 net.cpp:150] Setting up fc4_300
I0409 20:01:12.498102  9650 net.cpp:157] Top shape: 1024 300 (307200)
I0409 20:01:12.498111  9650 net.cpp:165] Memory required for data: 2186088448
I0409 20:01:12.498123  9650 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 20:01:12.498136  9650 net.cpp:100] Creating Layer fc4_sTanH
I0409 20:01:12.498144  9650 net.cpp:434] fc4_sTanH <- fc4_300
I0409 20:01:12.498153  9650 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 20:01:12.498441  9650 net.cpp:150] Setting up fc4_sTanH
I0409 20:01:12.498459  9650 net.cpp:157] Top shape: 1024 300 (307200)
I0409 20:01:12.498467  9650 net.cpp:165] Memory required for data: 2187317248
I0409 20:01:12.498474  9650 layer_factory.hpp:77] Creating layer drop4
I0409 20:01:12.498486  9650 net.cpp:100] Creating Layer drop4
I0409 20:01:12.498495  9650 net.cpp:434] drop4 <- fc4_300
I0409 20:01:12.498505  9650 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 20:01:12.498553  9650 net.cpp:150] Setting up drop4
I0409 20:01:12.498570  9650 net.cpp:157] Top shape: 1024 300 (307200)
I0409 20:01:12.498579  9650 net.cpp:165] Memory required for data: 2188546048
I0409 20:01:12.498584  9650 layer_factory.hpp:77] Creating layer fc5_67
I0409 20:01:12.498594  9650 net.cpp:100] Creating Layer fc5_67
I0409 20:01:12.498602  9650 net.cpp:434] fc5_67 <- fc4_300
I0409 20:01:12.498611  9650 net.cpp:408] fc5_67 -> fc5_classes
I0409 20:01:12.500653  9650 net.cpp:150] Setting up fc5_67
I0409 20:01:12.500674  9650 net.cpp:157] Top shape: 1024 67 (68608)
I0409 20:01:12.500682  9650 net.cpp:165] Memory required for data: 2188820480
I0409 20:01:12.500700  9650 layer_factory.hpp:77] Creating layer loss
I0409 20:01:12.500715  9650 net.cpp:100] Creating Layer loss
I0409 20:01:12.500722  9650 net.cpp:434] loss <- fc5_classes
I0409 20:01:12.500730  9650 net.cpp:434] loss <- label
I0409 20:01:12.500742  9650 net.cpp:408] loss -> loss
I0409 20:01:12.500763  9650 layer_factory.hpp:77] Creating layer loss
I0409 20:01:12.501292  9650 net.cpp:150] Setting up loss
I0409 20:01:12.501310  9650 net.cpp:157] Top shape: (1)
I0409 20:01:12.501318  9650 net.cpp:160]     with loss weight 1
I0409 20:01:12.501349  9650 net.cpp:165] Memory required for data: 2188820484
I0409 20:01:12.501358  9650 net.cpp:226] loss needs backward computation.
I0409 20:01:12.501370  9650 net.cpp:226] fc5_67 needs backward computation.
I0409 20:01:12.501376  9650 net.cpp:226] drop4 needs backward computation.
I0409 20:01:12.501384  9650 net.cpp:226] fc4_sTanH needs backward computation.
I0409 20:01:12.501390  9650 net.cpp:226] fc4_300 needs backward computation.
I0409 20:01:12.501395  9650 net.cpp:226] pool3 needs backward computation.
I0409 20:01:12.501401  9650 net.cpp:226] conv3_sTanH needs backward computation.
I0409 20:01:12.501406  9650 net.cpp:226] conv3 needs backward computation.
I0409 20:01:12.501411  9650 net.cpp:226] pool2 needs backward computation.
I0409 20:01:12.501417  9650 net.cpp:226] conv2_sTanH needs backward computation.
I0409 20:01:12.501428  9650 net.cpp:226] conv2 needs backward computation.
I0409 20:01:12.501435  9650 net.cpp:226] pool1 needs backward computation.
I0409 20:01:12.501440  9650 net.cpp:226] conv1_sTanH needs backward computation.
I0409 20:01:12.501444  9650 net.cpp:226] conv1 needs backward computation.
I0409 20:01:12.501451  9650 net.cpp:228] data does not need backward computation.
I0409 20:01:12.501459  9650 net.cpp:270] This network produces output loss
I0409 20:01:12.501479  9650 net.cpp:283] Network initialization done.
I0409 20:01:12.501791  9650 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/test.prototxt
I0409 20:01:12.502013  9650 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 133
    mean_value: 133
    mean_value: 132
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0409 20:01:12.502162  9650 layer_factory.hpp:77] Creating layer data
I0409 20:01:12.503196  9650 net.cpp:100] Creating Layer data
I0409 20:01:12.503216  9650 net.cpp:408] data -> data
I0409 20:01:12.503233  9650 net.cpp:408] data -> label
I0409 20:01:12.504483  9746 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0409 20:01:12.504670  9650 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 20:01:12.549897  9650 net.cpp:150] Setting up data
I0409 20:01:12.549926  9650 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 20:01:12.549932  9650 net.cpp:157] Top shape: 1024 (1024)
I0409 20:01:12.549935  9650 net.cpp:165] Memory required for data: 28315648
I0409 20:01:12.549943  9650 layer_factory.hpp:77] Creating layer label_data_1_split
I0409 20:01:12.549957  9650 net.cpp:100] Creating Layer label_data_1_split
I0409 20:01:12.549962  9650 net.cpp:434] label_data_1_split <- label
I0409 20:01:12.549969  9650 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0409 20:01:12.549989  9650 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0409 20:01:12.549998  9650 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0409 20:01:12.550127  9650 net.cpp:150] Setting up label_data_1_split
I0409 20:01:12.550137  9650 net.cpp:157] Top shape: 1024 (1024)
I0409 20:01:12.550142  9650 net.cpp:157] Top shape: 1024 (1024)
I0409 20:01:12.550145  9650 net.cpp:157] Top shape: 1024 (1024)
I0409 20:01:12.550148  9650 net.cpp:165] Memory required for data: 28327936
I0409 20:01:12.550151  9650 layer_factory.hpp:77] Creating layer conv1
I0409 20:01:12.550165  9650 net.cpp:100] Creating Layer conv1
I0409 20:01:12.550170  9650 net.cpp:434] conv1 <- data
I0409 20:01:12.550178  9650 net.cpp:408] conv1 -> conv1
I0409 20:01:12.554173  9650 net.cpp:150] Setting up conv1
I0409 20:01:12.554193  9650 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 20:01:12.554200  9650 net.cpp:165] Memory required for data: 750862336
I0409 20:01:12.554214  9650 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 20:01:12.554222  9650 net.cpp:100] Creating Layer conv1_sTanH
I0409 20:01:12.554226  9650 net.cpp:434] conv1_sTanH <- conv1
I0409 20:01:12.554231  9650 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 20:01:12.554437  9650 net.cpp:150] Setting up conv1_sTanH
I0409 20:01:12.554452  9650 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 20:01:12.554456  9650 net.cpp:165] Memory required for data: 1473396736
I0409 20:01:12.554460  9650 layer_factory.hpp:77] Creating layer pool1
I0409 20:01:12.554468  9650 net.cpp:100] Creating Layer pool1
I0409 20:01:12.554472  9650 net.cpp:434] pool1 <- conv1
I0409 20:01:12.554479  9650 net.cpp:408] pool1 -> pool1
I0409 20:01:12.554529  9650 net.cpp:150] Setting up pool1
I0409 20:01:12.554538  9650 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 20:01:12.554540  9650 net.cpp:165] Memory required for data: 1654030336
I0409 20:01:12.554543  9650 layer_factory.hpp:77] Creating layer conv2
I0409 20:01:12.554555  9650 net.cpp:100] Creating Layer conv2
I0409 20:01:12.554559  9650 net.cpp:434] conv2 <- pool1
I0409 20:01:12.554564  9650 net.cpp:408] conv2 -> conv2
I0409 20:01:12.558491  9650 net.cpp:150] Setting up conv2
I0409 20:01:12.558511  9650 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 20:01:12.558514  9650 net.cpp:165] Memory required for data: 1853095936
I0409 20:01:12.558524  9650 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 20:01:12.558531  9650 net.cpp:100] Creating Layer conv2_sTanH
I0409 20:01:12.558534  9650 net.cpp:434] conv2_sTanH <- conv2
I0409 20:01:12.558540  9650 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 20:01:12.559319  9650 net.cpp:150] Setting up conv2_sTanH
I0409 20:01:12.559335  9650 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 20:01:12.559339  9650 net.cpp:165] Memory required for data: 2052161536
I0409 20:01:12.559342  9650 layer_factory.hpp:77] Creating layer pool2
I0409 20:01:12.559350  9650 net.cpp:100] Creating Layer pool2
I0409 20:01:12.559353  9650 net.cpp:434] pool2 <- conv2
I0409 20:01:12.559370  9650 net.cpp:408] pool2 -> pool2
I0409 20:01:12.559427  9650 net.cpp:150] Setting up pool2
I0409 20:01:12.559437  9650 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 20:01:12.559440  9650 net.cpp:165] Memory required for data: 2101927936
I0409 20:01:12.559443  9650 layer_factory.hpp:77] Creating layer conv3
I0409 20:01:12.559454  9650 net.cpp:100] Creating Layer conv3
I0409 20:01:12.559460  9650 net.cpp:434] conv3 <- pool2
I0409 20:01:12.559466  9650 net.cpp:408] conv3 -> conv3
I0409 20:01:12.565140  9650 net.cpp:150] Setting up conv3
I0409 20:01:12.565157  9650 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 20:01:12.565161  9650 net.cpp:165] Memory required for data: 2138791936
I0409 20:01:12.565171  9650 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 20:01:12.565188  9650 net.cpp:100] Creating Layer conv3_sTanH
I0409 20:01:12.565192  9650 net.cpp:434] conv3_sTanH <- conv3
I0409 20:01:12.565199  9650 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 20:01:12.566023  9650 net.cpp:150] Setting up conv3_sTanH
I0409 20:01:12.566038  9650 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 20:01:12.566058  9650 net.cpp:165] Memory required for data: 2175655936
I0409 20:01:12.566062  9650 layer_factory.hpp:77] Creating layer pool3
I0409 20:01:12.566071  9650 net.cpp:100] Creating Layer pool3
I0409 20:01:12.566076  9650 net.cpp:434] pool3 <- conv3
I0409 20:01:12.566082  9650 net.cpp:408] pool3 -> pool3
I0409 20:01:12.566135  9650 net.cpp:150] Setting up pool3
I0409 20:01:12.566149  9650 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 20:01:12.566153  9650 net.cpp:165] Memory required for data: 2184871936
I0409 20:01:12.566155  9650 layer_factory.hpp:77] Creating layer fc4_300
I0409 20:01:12.566162  9650 net.cpp:100] Creating Layer fc4_300
I0409 20:01:12.566165  9650 net.cpp:434] fc4_300 <- pool3
I0409 20:01:12.566174  9650 net.cpp:408] fc4_300 -> fc4_300
I0409 20:01:12.571602  9650 net.cpp:150] Setting up fc4_300
I0409 20:01:12.571619  9650 net.cpp:157] Top shape: 1024 300 (307200)
I0409 20:01:12.571621  9650 net.cpp:165] Memory required for data: 2186100736
I0409 20:01:12.571637  9650 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 20:01:12.571643  9650 net.cpp:100] Creating Layer fc4_sTanH
I0409 20:01:12.571647  9650 net.cpp:434] fc4_sTanH <- fc4_300
I0409 20:01:12.571656  9650 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 20:01:12.571857  9650 net.cpp:150] Setting up fc4_sTanH
I0409 20:01:12.571869  9650 net.cpp:157] Top shape: 1024 300 (307200)
I0409 20:01:12.571872  9650 net.cpp:165] Memory required for data: 2187329536
I0409 20:01:12.571887  9650 layer_factory.hpp:77] Creating layer drop4
I0409 20:01:12.571903  9650 net.cpp:100] Creating Layer drop4
I0409 20:01:12.571907  9650 net.cpp:434] drop4 <- fc4_300
I0409 20:01:12.571914  9650 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 20:01:12.571950  9650 net.cpp:150] Setting up drop4
I0409 20:01:12.571959  9650 net.cpp:157] Top shape: 1024 300 (307200)
I0409 20:01:12.571961  9650 net.cpp:165] Memory required for data: 2188558336
I0409 20:01:12.571964  9650 layer_factory.hpp:77] Creating layer fc5_67
I0409 20:01:12.571970  9650 net.cpp:100] Creating Layer fc5_67
I0409 20:01:12.571974  9650 net.cpp:434] fc5_67 <- fc4_300
I0409 20:01:12.571985  9650 net.cpp:408] fc5_67 -> fc5_classes
I0409 20:01:12.572240  9650 net.cpp:150] Setting up fc5_67
I0409 20:01:12.572249  9650 net.cpp:157] Top shape: 1024 67 (68608)
I0409 20:01:12.572252  9650 net.cpp:165] Memory required for data: 2188832768
I0409 20:01:12.572263  9650 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0409 20:01:12.572270  9650 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0409 20:01:12.572274  9650 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0409 20:01:12.572281  9650 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0409 20:01:12.572288  9650 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0409 20:01:12.572294  9650 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0409 20:01:12.572350  9650 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0409 20:01:12.572356  9650 net.cpp:157] Top shape: 1024 67 (68608)
I0409 20:01:12.572360  9650 net.cpp:157] Top shape: 1024 67 (68608)
I0409 20:01:12.572365  9650 net.cpp:157] Top shape: 1024 67 (68608)
I0409 20:01:12.572367  9650 net.cpp:165] Memory required for data: 2189656064
I0409 20:01:12.572371  9650 layer_factory.hpp:77] Creating layer loss
I0409 20:01:12.572378  9650 net.cpp:100] Creating Layer loss
I0409 20:01:12.572381  9650 net.cpp:434] loss <- fc5_classes_fc5_67_0_split_0
I0409 20:01:12.572386  9650 net.cpp:434] loss <- label_data_1_split_0
I0409 20:01:12.572391  9650 net.cpp:408] loss -> loss
I0409 20:01:12.572404  9650 layer_factory.hpp:77] Creating layer loss
I0409 20:01:12.572744  9650 net.cpp:150] Setting up loss
I0409 20:01:12.572757  9650 net.cpp:157] Top shape: (1)
I0409 20:01:12.572760  9650 net.cpp:160]     with loss weight 1
I0409 20:01:12.572769  9650 net.cpp:165] Memory required for data: 2189656068
I0409 20:01:12.572778  9650 layer_factory.hpp:77] Creating layer accuracy_1
I0409 20:01:12.572793  9650 net.cpp:100] Creating Layer accuracy_1
I0409 20:01:12.572811  9650 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0409 20:01:12.572816  9650 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0409 20:01:12.572824  9650 net.cpp:408] accuracy_1 -> accuracy_1
I0409 20:01:12.572834  9650 net.cpp:150] Setting up accuracy_1
I0409 20:01:12.572851  9650 net.cpp:157] Top shape: (1)
I0409 20:01:12.572854  9650 net.cpp:165] Memory required for data: 2189656072
I0409 20:01:12.572857  9650 layer_factory.hpp:77] Creating layer accuracy_5
I0409 20:01:12.572862  9650 net.cpp:100] Creating Layer accuracy_5
I0409 20:01:12.572866  9650 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0409 20:01:12.572870  9650 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0409 20:01:12.572878  9650 net.cpp:408] accuracy_5 -> accuracy_5
I0409 20:01:12.572885  9650 net.cpp:150] Setting up accuracy_5
I0409 20:01:12.572890  9650 net.cpp:157] Top shape: (1)
I0409 20:01:12.572891  9650 net.cpp:165] Memory required for data: 2189656076
I0409 20:01:12.572895  9650 net.cpp:228] accuracy_5 does not need backward computation.
I0409 20:01:12.572898  9650 net.cpp:228] accuracy_1 does not need backward computation.
I0409 20:01:12.572902  9650 net.cpp:226] loss needs backward computation.
I0409 20:01:12.572907  9650 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0409 20:01:12.572911  9650 net.cpp:226] fc5_67 needs backward computation.
I0409 20:01:12.572913  9650 net.cpp:226] drop4 needs backward computation.
I0409 20:01:12.572916  9650 net.cpp:226] fc4_sTanH needs backward computation.
I0409 20:01:12.572919  9650 net.cpp:226] fc4_300 needs backward computation.
I0409 20:01:12.572922  9650 net.cpp:226] pool3 needs backward computation.
I0409 20:01:12.572926  9650 net.cpp:226] conv3_sTanH needs backward computation.
I0409 20:01:12.572928  9650 net.cpp:226] conv3 needs backward computation.
I0409 20:01:12.572932  9650 net.cpp:226] pool2 needs backward computation.
I0409 20:01:12.572935  9650 net.cpp:226] conv2_sTanH needs backward computation.
I0409 20:01:12.572937  9650 net.cpp:226] conv2 needs backward computation.
I0409 20:01:12.572940  9650 net.cpp:226] pool1 needs backward computation.
I0409 20:01:12.572943  9650 net.cpp:226] conv1_sTanH needs backward computation.
I0409 20:01:12.572947  9650 net.cpp:226] conv1 needs backward computation.
I0409 20:01:12.572950  9650 net.cpp:228] label_data_1_split does not need backward computation.
I0409 20:01:12.572954  9650 net.cpp:228] data does not need backward computation.
I0409 20:01:12.572963  9650 net.cpp:270] This network produces output accuracy_1
I0409 20:01:12.572968  9650 net.cpp:270] This network produces output accuracy_5
I0409 20:01:12.572971  9650 net.cpp:270] This network produces output loss
I0409 20:01:12.572989  9650 net.cpp:283] Network initialization done.
I0409 20:01:12.573043  9650 solver.cpp:72] Solver scaffolding done.
I0409 20:01:12.573563  9650 caffe.cpp:251] Starting Optimization
I0409 20:01:12.573571  9650 solver.cpp:291] Solving 
I0409 20:01:12.573575  9650 solver.cpp:292] Learning Rate Policy: step
I0409 20:01:12.576573  9650 solver.cpp:349] Iteration 0, Testing net (#0)
I0409 20:01:12.578092  9650 blocking_queue.cpp:50] Data layer prefetch queue empty
I0409 20:01:13.383407  9650 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0137939
I0409 20:01:13.383436  9650 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0584717
I0409 20:01:13.383446  9650 solver.cpp:416]     Test net output #2: loss = 4.32837 (* 1 = 4.32837 loss)
I0409 20:01:13.488276  9650 solver.cpp:240] Iteration 0, loss = 4.35798
I0409 20:01:13.488322  9650 solver.cpp:256]     Train net output #0: loss = 4.35798 (* 1 = 4.35798 loss)
I0409 20:01:13.488344  9650 sgd_solver.cpp:106] Iteration 0, lr = 1
I0409 20:01:13.799320  9650 solver.cpp:240] Iteration 1, loss = 37.596
I0409 20:01:13.799362  9650 solver.cpp:256]     Train net output #0: loss = 37.596 (* 1 = 37.596 loss)
I0409 20:01:13.799372  9650 sgd_solver.cpp:106] Iteration 1, lr = 1
I0409 20:01:14.101761  9650 solver.cpp:240] Iteration 2, loss = 82.603
I0409 20:01:14.101832  9650 solver.cpp:256]     Train net output #0: loss = 82.603 (* 1 = 82.603 loss)
I0409 20:01:14.101841  9650 sgd_solver.cpp:106] Iteration 2, lr = 1
I0409 20:01:14.404132  9650 solver.cpp:240] Iteration 3, loss = 83.7354
I0409 20:01:14.404168  9650 solver.cpp:256]     Train net output #0: loss = 83.7354 (* 1 = 83.7354 loss)
I0409 20:01:14.404177  9650 sgd_solver.cpp:106] Iteration 3, lr = 1
I0409 20:01:14.704547  9650 solver.cpp:240] Iteration 4, loss = 86.4477
I0409 20:01:14.704592  9650 solver.cpp:256]     Train net output #0: loss = 86.4477 (* 1 = 86.4477 loss)
I0409 20:01:14.704601  9650 sgd_solver.cpp:106] Iteration 4, lr = 1
I0409 20:01:15.013270  9650 solver.cpp:240] Iteration 5, loss = 86.6695
I0409 20:01:15.013308  9650 solver.cpp:256]     Train net output #0: loss = 86.6695 (* 1 = 86.6695 loss)
I0409 20:01:15.013315  9650 sgd_solver.cpp:106] Iteration 5, lr = 1
I0409 20:01:15.315629  9650 solver.cpp:240] Iteration 6, loss = 85.4188
I0409 20:01:15.315665  9650 solver.cpp:256]     Train net output #0: loss = 85.4188 (* 1 = 85.4188 loss)
I0409 20:01:15.315673  9650 sgd_solver.cpp:106] Iteration 6, lr = 1
I0409 20:01:15.619035  9650 solver.cpp:240] Iteration 7, loss = 85.723
I0409 20:01:15.619069  9650 solver.cpp:256]     Train net output #0: loss = 85.723 (* 1 = 85.723 loss)
I0409 20:01:15.619077  9650 sgd_solver.cpp:106] Iteration 7, lr = 1
I0409 20:01:15.920922  9650 solver.cpp:240] Iteration 8, loss = 83.5473
I0409 20:01:15.920958  9650 solver.cpp:256]     Train net output #0: loss = 83.5473 (* 1 = 83.5473 loss)
I0409 20:01:15.920966  9650 sgd_solver.cpp:106] Iteration 8, lr = 1
I0409 20:01:16.226152  9650 solver.cpp:240] Iteration 9, loss = 85.2315
I0409 20:01:16.226197  9650 solver.cpp:256]     Train net output #0: loss = 85.2315 (* 1 = 85.2315 loss)
I0409 20:01:16.226205  9650 sgd_solver.cpp:106] Iteration 9, lr = 1
I0409 20:01:16.531147  9650 solver.cpp:240] Iteration 10, loss = 85.339
I0409 20:01:16.531195  9650 solver.cpp:256]     Train net output #0: loss = 85.339 (* 1 = 85.339 loss)
I0409 20:01:16.531204  9650 sgd_solver.cpp:106] Iteration 10, lr = 1
I0409 20:01:16.836536  9650 solver.cpp:240] Iteration 11, loss = 84.2767
I0409 20:01:16.836581  9650 solver.cpp:256]     Train net output #0: loss = 84.2767 (* 1 = 84.2767 loss)
I0409 20:01:16.836590  9650 sgd_solver.cpp:106] Iteration 11, lr = 1
I0409 20:01:17.138882  9650 solver.cpp:240] Iteration 12, loss = 84.1004
I0409 20:01:17.138926  9650 solver.cpp:256]     Train net output #0: loss = 84.1004 (* 1 = 84.1004 loss)
I0409 20:01:17.138936  9650 sgd_solver.cpp:106] Iteration 12, lr = 1
I0409 20:01:17.441098  9650 solver.cpp:240] Iteration 13, loss = 80.8058
I0409 20:01:17.441143  9650 solver.cpp:256]     Train net output #0: loss = 80.8058 (* 1 = 80.8058 loss)
I0409 20:01:17.441150  9650 sgd_solver.cpp:106] Iteration 13, lr = 1
I0409 20:01:17.743854  9650 solver.cpp:240] Iteration 14, loss = 79.8222
I0409 20:01:17.743911  9650 solver.cpp:256]     Train net output #0: loss = 79.8222 (* 1 = 79.8222 loss)
I0409 20:01:17.743918  9650 sgd_solver.cpp:106] Iteration 14, lr = 1
I0409 20:01:18.047091  9650 solver.cpp:240] Iteration 15, loss = 67.7273
I0409 20:01:18.047137  9650 solver.cpp:256]     Train net output #0: loss = 67.7273 (* 1 = 67.7273 loss)
I0409 20:01:18.047143  9650 sgd_solver.cpp:106] Iteration 15, lr = 1
I0409 20:01:18.351018  9650 solver.cpp:240] Iteration 16, loss = 66.9689
I0409 20:01:18.351053  9650 solver.cpp:256]     Train net output #0: loss = 66.9689 (* 1 = 66.9689 loss)
I0409 20:01:18.351061  9650 sgd_solver.cpp:106] Iteration 16, lr = 1
