I0409 19:42:38.624367  2560 caffe.cpp:217] Using GPUs 1
I0409 19:42:38.925820  2560 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0409 19:42:39.613392  2560 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/test.prototxt"
test_iter: 8
test_interval: 25
base_lr: 1e-05
display: 1
max_iter: 2500
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 250
snapshot_prefix: "./snapshots/experiment_7/rtsd-r1/CoNorm/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0409 19:42:39.613529  2560 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/train.prototxt
I0409 19:42:39.613840  2560 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0409 19:42:39.613852  2560 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0409 19:42:39.613991  2560 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 132
    mean_value: 132
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
I0409 19:42:39.614109  2560 layer_factory.hpp:77] Creating layer data
I0409 19:42:39.615170  2560 net.cpp:100] Creating Layer data
I0409 19:42:39.615195  2560 net.cpp:408] data -> data
I0409 19:42:39.615217  2560 net.cpp:408] data -> label
I0409 19:42:39.616554  2660 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0409 19:42:39.633693  2560 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 19:42:39.678738  2560 net.cpp:150] Setting up data
I0409 19:42:39.678771  2560 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 19:42:39.678776  2560 net.cpp:157] Top shape: 1024 (1024)
I0409 19:42:39.678778  2560 net.cpp:165] Memory required for data: 28315648
I0409 19:42:39.678788  2560 layer_factory.hpp:77] Creating layer conv1
I0409 19:42:39.678809  2560 net.cpp:100] Creating Layer conv1
I0409 19:42:39.678828  2560 net.cpp:434] conv1 <- data
I0409 19:42:39.678839  2560 net.cpp:408] conv1 -> conv1
I0409 19:42:39.955901  2560 net.cpp:150] Setting up conv1
I0409 19:42:39.955932  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:39.955937  2560 net.cpp:165] Memory required for data: 750850048
I0409 19:42:39.955960  2560 layer_factory.hpp:77] Creating layer conv1_prescale
I0409 19:42:39.955973  2560 net.cpp:100] Creating Layer conv1_prescale
I0409 19:42:39.955981  2560 net.cpp:434] conv1_prescale <- conv1
I0409 19:42:39.955987  2560 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0409 19:42:39.956097  2560 net.cpp:150] Setting up conv1_prescale
I0409 19:42:39.956106  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:39.956110  2560 net.cpp:165] Memory required for data: 1473384448
I0409 19:42:39.956116  2560 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 19:42:39.956123  2560 net.cpp:100] Creating Layer conv1_sTanH
I0409 19:42:39.956126  2560 net.cpp:434] conv1_sTanH <- conv1
I0409 19:42:39.956130  2560 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 19:42:39.956321  2560 net.cpp:150] Setting up conv1_sTanH
I0409 19:42:39.956332  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:39.956336  2560 net.cpp:165] Memory required for data: 2195918848
I0409 19:42:39.956339  2560 layer_factory.hpp:77] Creating layer conv1_postscale
I0409 19:42:39.956347  2560 net.cpp:100] Creating Layer conv1_postscale
I0409 19:42:39.956351  2560 net.cpp:434] conv1_postscale <- conv1
I0409 19:42:39.956356  2560 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0409 19:42:39.956449  2560 net.cpp:150] Setting up conv1_postscale
I0409 19:42:39.956459  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:39.956461  2560 net.cpp:165] Memory required for data: 2918453248
I0409 19:42:39.956466  2560 layer_factory.hpp:77] Creating layer pool1
I0409 19:42:39.956472  2560 net.cpp:100] Creating Layer pool1
I0409 19:42:39.956475  2560 net.cpp:434] pool1 <- conv1
I0409 19:42:39.956480  2560 net.cpp:408] pool1 -> pool1
I0409 19:42:39.956526  2560 net.cpp:150] Setting up pool1
I0409 19:42:39.956535  2560 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 19:42:39.956538  2560 net.cpp:165] Memory required for data: 3099086848
I0409 19:42:39.956562  2560 layer_factory.hpp:77] Creating layer conv2
I0409 19:42:39.956573  2560 net.cpp:100] Creating Layer conv2
I0409 19:42:39.956578  2560 net.cpp:434] conv2 <- pool1
I0409 19:42:39.956583  2560 net.cpp:408] conv2 -> conv2
I0409 19:42:39.960938  2560 net.cpp:150] Setting up conv2
I0409 19:42:39.960957  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:39.960960  2560 net.cpp:165] Memory required for data: 3298152448
I0409 19:42:39.960983  2560 layer_factory.hpp:77] Creating layer conv2_prescale
I0409 19:42:39.960993  2560 net.cpp:100] Creating Layer conv2_prescale
I0409 19:42:39.960995  2560 net.cpp:434] conv2_prescale <- conv2
I0409 19:42:39.961001  2560 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0409 19:42:39.961107  2560 net.cpp:150] Setting up conv2_prescale
I0409 19:42:39.961117  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:39.961119  2560 net.cpp:165] Memory required for data: 3497218048
I0409 19:42:39.961124  2560 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 19:42:39.961130  2560 net.cpp:100] Creating Layer conv2_sTanH
I0409 19:42:39.961134  2560 net.cpp:434] conv2_sTanH <- conv2
I0409 19:42:39.961138  2560 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 19:42:39.961884  2560 net.cpp:150] Setting up conv2_sTanH
I0409 19:42:39.961900  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:39.961904  2560 net.cpp:165] Memory required for data: 3696283648
I0409 19:42:39.961907  2560 layer_factory.hpp:77] Creating layer conv2_postscale
I0409 19:42:39.961915  2560 net.cpp:100] Creating Layer conv2_postscale
I0409 19:42:39.961918  2560 net.cpp:434] conv2_postscale <- conv2
I0409 19:42:39.961925  2560 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0409 19:42:39.962018  2560 net.cpp:150] Setting up conv2_postscale
I0409 19:42:39.962026  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:39.962029  2560 net.cpp:165] Memory required for data: 3895349248
I0409 19:42:39.962034  2560 layer_factory.hpp:77] Creating layer pool2
I0409 19:42:39.962040  2560 net.cpp:100] Creating Layer pool2
I0409 19:42:39.962044  2560 net.cpp:434] pool2 <- conv2
I0409 19:42:39.962049  2560 net.cpp:408] pool2 -> pool2
I0409 19:42:39.962086  2560 net.cpp:150] Setting up pool2
I0409 19:42:39.962095  2560 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 19:42:39.962097  2560 net.cpp:165] Memory required for data: 3945115648
I0409 19:42:39.962100  2560 layer_factory.hpp:77] Creating layer conv3
I0409 19:42:39.962108  2560 net.cpp:100] Creating Layer conv3
I0409 19:42:39.962111  2560 net.cpp:434] conv3 <- pool2
I0409 19:42:39.962116  2560 net.cpp:408] conv3 -> conv3
I0409 19:42:39.967516  2560 net.cpp:150] Setting up conv3
I0409 19:42:39.967535  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:39.967537  2560 net.cpp:165] Memory required for data: 3981979648
I0409 19:42:39.967547  2560 layer_factory.hpp:77] Creating layer conv3_prescale
I0409 19:42:39.967557  2560 net.cpp:100] Creating Layer conv3_prescale
I0409 19:42:39.967561  2560 net.cpp:434] conv3_prescale <- conv3
I0409 19:42:39.967566  2560 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0409 19:42:39.967672  2560 net.cpp:150] Setting up conv3_prescale
I0409 19:42:39.967680  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:39.967684  2560 net.cpp:165] Memory required for data: 4018843648
I0409 19:42:39.967689  2560 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 19:42:39.967694  2560 net.cpp:100] Creating Layer conv3_sTanH
I0409 19:42:39.967696  2560 net.cpp:434] conv3_sTanH <- conv3
I0409 19:42:39.967700  2560 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 19:42:39.968485  2560 net.cpp:150] Setting up conv3_sTanH
I0409 19:42:39.968502  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:39.968507  2560 net.cpp:165] Memory required for data: 4055707648
I0409 19:42:39.968510  2560 layer_factory.hpp:77] Creating layer conv3_postscale
I0409 19:42:39.968518  2560 net.cpp:100] Creating Layer conv3_postscale
I0409 19:42:39.968536  2560 net.cpp:434] conv3_postscale <- conv3
I0409 19:42:39.968544  2560 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0409 19:42:39.968643  2560 net.cpp:150] Setting up conv3_postscale
I0409 19:42:39.968652  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:39.968655  2560 net.cpp:165] Memory required for data: 4092571648
I0409 19:42:39.968660  2560 layer_factory.hpp:77] Creating layer pool3
I0409 19:42:39.968667  2560 net.cpp:100] Creating Layer pool3
I0409 19:42:39.968669  2560 net.cpp:434] pool3 <- conv3
I0409 19:42:39.968674  2560 net.cpp:408] pool3 -> pool3
I0409 19:42:39.968711  2560 net.cpp:150] Setting up pool3
I0409 19:42:39.968719  2560 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 19:42:39.968721  2560 net.cpp:165] Memory required for data: 4101787648
I0409 19:42:39.968724  2560 layer_factory.hpp:77] Creating layer fc4_300
I0409 19:42:39.968734  2560 net.cpp:100] Creating Layer fc4_300
I0409 19:42:39.968737  2560 net.cpp:434] fc4_300 <- pool3
I0409 19:42:39.968742  2560 net.cpp:408] fc4_300 -> fc4_300
I0409 19:42:39.974078  2560 net.cpp:150] Setting up fc4_300
I0409 19:42:39.974095  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:39.974098  2560 net.cpp:165] Memory required for data: 4103016448
I0409 19:42:39.974107  2560 layer_factory.hpp:77] Creating layer fc4_prescale
I0409 19:42:39.974113  2560 net.cpp:100] Creating Layer fc4_prescale
I0409 19:42:39.974119  2560 net.cpp:434] fc4_prescale <- fc4_300
I0409 19:42:39.974124  2560 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0409 19:42:39.974222  2560 net.cpp:150] Setting up fc4_prescale
I0409 19:42:39.974231  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:39.974234  2560 net.cpp:165] Memory required for data: 4104245248
I0409 19:42:39.974238  2560 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 19:42:39.974244  2560 net.cpp:100] Creating Layer fc4_sTanH
I0409 19:42:39.974247  2560 net.cpp:434] fc4_sTanH <- fc4_300
I0409 19:42:39.974251  2560 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 19:42:39.974436  2560 net.cpp:150] Setting up fc4_sTanH
I0409 19:42:39.974447  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:39.974450  2560 net.cpp:165] Memory required for data: 4105474048
I0409 19:42:39.974453  2560 layer_factory.hpp:77] Creating layer fc4_postscale
I0409 19:42:39.974460  2560 net.cpp:100] Creating Layer fc4_postscale
I0409 19:42:39.974463  2560 net.cpp:434] fc4_postscale <- fc4_300
I0409 19:42:39.974468  2560 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0409 19:42:39.974560  2560 net.cpp:150] Setting up fc4_postscale
I0409 19:42:39.974570  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:39.974572  2560 net.cpp:165] Memory required for data: 4106702848
I0409 19:42:39.974576  2560 layer_factory.hpp:77] Creating layer drop4
I0409 19:42:39.974583  2560 net.cpp:100] Creating Layer drop4
I0409 19:42:39.974586  2560 net.cpp:434] drop4 <- fc4_300
I0409 19:42:39.974591  2560 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 19:42:39.974617  2560 net.cpp:150] Setting up drop4
I0409 19:42:39.974623  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:39.974627  2560 net.cpp:165] Memory required for data: 4107931648
I0409 19:42:39.974630  2560 layer_factory.hpp:77] Creating layer fc5_67
I0409 19:42:39.974635  2560 net.cpp:100] Creating Layer fc5_67
I0409 19:42:39.974638  2560 net.cpp:434] fc5_67 <- fc4_300
I0409 19:42:39.974643  2560 net.cpp:408] fc5_67 -> fc5_classes
I0409 19:42:39.975888  2560 net.cpp:150] Setting up fc5_67
I0409 19:42:39.975904  2560 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:42:39.975908  2560 net.cpp:165] Memory required for data: 4108206080
I0409 19:42:39.975919  2560 layer_factory.hpp:77] Creating layer loss
I0409 19:42:39.975925  2560 net.cpp:100] Creating Layer loss
I0409 19:42:39.975929  2560 net.cpp:434] loss <- fc5_classes
I0409 19:42:39.975934  2560 net.cpp:434] loss <- label
I0409 19:42:39.975939  2560 net.cpp:408] loss -> loss
I0409 19:42:39.975951  2560 layer_factory.hpp:77] Creating layer loss
I0409 19:42:39.976303  2560 net.cpp:150] Setting up loss
I0409 19:42:39.976328  2560 net.cpp:157] Top shape: (1)
I0409 19:42:39.976332  2560 net.cpp:160]     with loss weight 1
I0409 19:42:39.976361  2560 net.cpp:165] Memory required for data: 4108206084
I0409 19:42:39.976366  2560 net.cpp:226] loss needs backward computation.
I0409 19:42:39.976373  2560 net.cpp:226] fc5_67 needs backward computation.
I0409 19:42:39.976377  2560 net.cpp:226] drop4 needs backward computation.
I0409 19:42:39.976379  2560 net.cpp:226] fc4_postscale needs backward computation.
I0409 19:42:39.976382  2560 net.cpp:226] fc4_sTanH needs backward computation.
I0409 19:42:39.976385  2560 net.cpp:226] fc4_prescale needs backward computation.
I0409 19:42:39.976387  2560 net.cpp:226] fc4_300 needs backward computation.
I0409 19:42:39.976392  2560 net.cpp:226] pool3 needs backward computation.
I0409 19:42:39.976394  2560 net.cpp:226] conv3_postscale needs backward computation.
I0409 19:42:39.976397  2560 net.cpp:226] conv3_sTanH needs backward computation.
I0409 19:42:39.976400  2560 net.cpp:226] conv3_prescale needs backward computation.
I0409 19:42:39.976402  2560 net.cpp:226] conv3 needs backward computation.
I0409 19:42:39.976407  2560 net.cpp:226] pool2 needs backward computation.
I0409 19:42:39.976409  2560 net.cpp:226] conv2_postscale needs backward computation.
I0409 19:42:39.976413  2560 net.cpp:226] conv2_sTanH needs backward computation.
I0409 19:42:39.976415  2560 net.cpp:226] conv2_prescale needs backward computation.
I0409 19:42:39.976418  2560 net.cpp:226] conv2 needs backward computation.
I0409 19:42:39.976421  2560 net.cpp:226] pool1 needs backward computation.
I0409 19:42:39.976423  2560 net.cpp:226] conv1_postscale needs backward computation.
I0409 19:42:39.976426  2560 net.cpp:226] conv1_sTanH needs backward computation.
I0409 19:42:39.976429  2560 net.cpp:226] conv1_prescale needs backward computation.
I0409 19:42:39.976433  2560 net.cpp:226] conv1 needs backward computation.
I0409 19:42:39.976436  2560 net.cpp:228] data does not need backward computation.
I0409 19:42:39.976439  2560 net.cpp:270] This network produces output loss
I0409 19:42:39.976454  2560 net.cpp:283] Network initialization done.
I0409 19:42:39.976716  2560 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_7/rtsd-r1/CoNorm/trial_1/test.prototxt
I0409 19:42:39.976897  2560 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 133
    mean_value: 133
    mean_value: 132
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0409 19:42:39.977008  2560 layer_factory.hpp:77] Creating layer data
I0409 19:42:39.977808  2560 net.cpp:100] Creating Layer data
I0409 19:42:39.977819  2560 net.cpp:408] data -> data
I0409 19:42:39.977828  2560 net.cpp:408] data -> label
I0409 19:42:39.979439  2681 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0409 19:42:39.979688  2560 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 19:42:40.036885  2560 net.cpp:150] Setting up data
I0409 19:42:40.036913  2560 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 19:42:40.036919  2560 net.cpp:157] Top shape: 1024 (1024)
I0409 19:42:40.036922  2560 net.cpp:165] Memory required for data: 28315648
I0409 19:42:40.036928  2560 layer_factory.hpp:77] Creating layer label_data_1_split
I0409 19:42:40.036942  2560 net.cpp:100] Creating Layer label_data_1_split
I0409 19:42:40.036947  2560 net.cpp:434] label_data_1_split <- label
I0409 19:42:40.036953  2560 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0409 19:42:40.036963  2560 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0409 19:42:40.036969  2560 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0409 19:42:40.037099  2560 net.cpp:150] Setting up label_data_1_split
I0409 19:42:40.037109  2560 net.cpp:157] Top shape: 1024 (1024)
I0409 19:42:40.037113  2560 net.cpp:157] Top shape: 1024 (1024)
I0409 19:42:40.037117  2560 net.cpp:157] Top shape: 1024 (1024)
I0409 19:42:40.037120  2560 net.cpp:165] Memory required for data: 28327936
I0409 19:42:40.037142  2560 layer_factory.hpp:77] Creating layer conv1
I0409 19:42:40.037156  2560 net.cpp:100] Creating Layer conv1
I0409 19:42:40.037161  2560 net.cpp:434] conv1 <- data
I0409 19:42:40.037168  2560 net.cpp:408] conv1 -> conv1
I0409 19:42:40.039265  2560 net.cpp:150] Setting up conv1
I0409 19:42:40.039284  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:40.039288  2560 net.cpp:165] Memory required for data: 750862336
I0409 19:42:40.039300  2560 layer_factory.hpp:77] Creating layer conv1_prescale
I0409 19:42:40.039309  2560 net.cpp:100] Creating Layer conv1_prescale
I0409 19:42:40.039314  2560 net.cpp:434] conv1_prescale <- conv1
I0409 19:42:40.039319  2560 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0409 19:42:40.041616  2560 net.cpp:150] Setting up conv1_prescale
I0409 19:42:40.041637  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:40.041642  2560 net.cpp:165] Memory required for data: 1473396736
I0409 19:42:40.041651  2560 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 19:42:40.041661  2560 net.cpp:100] Creating Layer conv1_sTanH
I0409 19:42:40.041666  2560 net.cpp:434] conv1_sTanH <- conv1
I0409 19:42:40.041671  2560 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 19:42:40.041875  2560 net.cpp:150] Setting up conv1_sTanH
I0409 19:42:40.041888  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:40.041893  2560 net.cpp:165] Memory required for data: 2195931136
I0409 19:42:40.041895  2560 layer_factory.hpp:77] Creating layer conv1_postscale
I0409 19:42:40.041903  2560 net.cpp:100] Creating Layer conv1_postscale
I0409 19:42:40.041908  2560 net.cpp:434] conv1_postscale <- conv1
I0409 19:42:40.041913  2560 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0409 19:42:40.042017  2560 net.cpp:150] Setting up conv1_postscale
I0409 19:42:40.042026  2560 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 19:42:40.042031  2560 net.cpp:165] Memory required for data: 2918465536
I0409 19:42:40.042035  2560 layer_factory.hpp:77] Creating layer pool1
I0409 19:42:40.042042  2560 net.cpp:100] Creating Layer pool1
I0409 19:42:40.042045  2560 net.cpp:434] pool1 <- conv1
I0409 19:42:40.042052  2560 net.cpp:408] pool1 -> pool1
I0409 19:42:40.042093  2560 net.cpp:150] Setting up pool1
I0409 19:42:40.042100  2560 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 19:42:40.042104  2560 net.cpp:165] Memory required for data: 3099099136
I0409 19:42:40.042106  2560 layer_factory.hpp:77] Creating layer conv2
I0409 19:42:40.042114  2560 net.cpp:100] Creating Layer conv2
I0409 19:42:40.042117  2560 net.cpp:434] conv2 <- pool1
I0409 19:42:40.042124  2560 net.cpp:408] conv2 -> conv2
I0409 19:42:40.046674  2560 net.cpp:150] Setting up conv2
I0409 19:42:40.046694  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:40.046697  2560 net.cpp:165] Memory required for data: 3298164736
I0409 19:42:40.046708  2560 layer_factory.hpp:77] Creating layer conv2_prescale
I0409 19:42:40.046718  2560 net.cpp:100] Creating Layer conv2_prescale
I0409 19:42:40.046721  2560 net.cpp:434] conv2_prescale <- conv2
I0409 19:42:40.046727  2560 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0409 19:42:40.046838  2560 net.cpp:150] Setting up conv2_prescale
I0409 19:42:40.046847  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:40.046851  2560 net.cpp:165] Memory required for data: 3497230336
I0409 19:42:40.046856  2560 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 19:42:40.046862  2560 net.cpp:100] Creating Layer conv2_sTanH
I0409 19:42:40.046866  2560 net.cpp:434] conv2_sTanH <- conv2
I0409 19:42:40.046870  2560 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 19:42:40.048671  2560 net.cpp:150] Setting up conv2_sTanH
I0409 19:42:40.048687  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:40.048691  2560 net.cpp:165] Memory required for data: 3696295936
I0409 19:42:40.048694  2560 layer_factory.hpp:77] Creating layer conv2_postscale
I0409 19:42:40.048703  2560 net.cpp:100] Creating Layer conv2_postscale
I0409 19:42:40.048722  2560 net.cpp:434] conv2_postscale <- conv2
I0409 19:42:40.048729  2560 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0409 19:42:40.048833  2560 net.cpp:150] Setting up conv2_postscale
I0409 19:42:40.048843  2560 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 19:42:40.048846  2560 net.cpp:165] Memory required for data: 3895361536
I0409 19:42:40.048852  2560 layer_factory.hpp:77] Creating layer pool2
I0409 19:42:40.048858  2560 net.cpp:100] Creating Layer pool2
I0409 19:42:40.048861  2560 net.cpp:434] pool2 <- conv2
I0409 19:42:40.048867  2560 net.cpp:408] pool2 -> pool2
I0409 19:42:40.048910  2560 net.cpp:150] Setting up pool2
I0409 19:42:40.048918  2560 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 19:42:40.048923  2560 net.cpp:165] Memory required for data: 3945127936
I0409 19:42:40.048925  2560 layer_factory.hpp:77] Creating layer conv3
I0409 19:42:40.048934  2560 net.cpp:100] Creating Layer conv3
I0409 19:42:40.048940  2560 net.cpp:434] conv3 <- pool2
I0409 19:42:40.048945  2560 net.cpp:408] conv3 -> conv3
I0409 19:42:40.054656  2560 net.cpp:150] Setting up conv3
I0409 19:42:40.054677  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:40.054680  2560 net.cpp:165] Memory required for data: 3981991936
I0409 19:42:40.054692  2560 layer_factory.hpp:77] Creating layer conv3_prescale
I0409 19:42:40.054699  2560 net.cpp:100] Creating Layer conv3_prescale
I0409 19:42:40.054703  2560 net.cpp:434] conv3_prescale <- conv3
I0409 19:42:40.054708  2560 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0409 19:42:40.054803  2560 net.cpp:150] Setting up conv3_prescale
I0409 19:42:40.054813  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:40.054816  2560 net.cpp:165] Memory required for data: 4018855936
I0409 19:42:40.054821  2560 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 19:42:40.054826  2560 net.cpp:100] Creating Layer conv3_sTanH
I0409 19:42:40.054831  2560 net.cpp:434] conv3_sTanH <- conv3
I0409 19:42:40.054836  2560 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 19:42:40.056311  2560 net.cpp:150] Setting up conv3_sTanH
I0409 19:42:40.056329  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:40.056331  2560 net.cpp:165] Memory required for data: 4055719936
I0409 19:42:40.056336  2560 layer_factory.hpp:77] Creating layer conv3_postscale
I0409 19:42:40.056344  2560 net.cpp:100] Creating Layer conv3_postscale
I0409 19:42:40.056349  2560 net.cpp:434] conv3_postscale <- conv3
I0409 19:42:40.056354  2560 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0409 19:42:40.056453  2560 net.cpp:150] Setting up conv3_postscale
I0409 19:42:40.056463  2560 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 19:42:40.056465  2560 net.cpp:165] Memory required for data: 4092583936
I0409 19:42:40.056471  2560 layer_factory.hpp:77] Creating layer pool3
I0409 19:42:40.056479  2560 net.cpp:100] Creating Layer pool3
I0409 19:42:40.056484  2560 net.cpp:434] pool3 <- conv3
I0409 19:42:40.056490  2560 net.cpp:408] pool3 -> pool3
I0409 19:42:40.056529  2560 net.cpp:150] Setting up pool3
I0409 19:42:40.056537  2560 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 19:42:40.056540  2560 net.cpp:165] Memory required for data: 4101799936
I0409 19:42:40.056543  2560 layer_factory.hpp:77] Creating layer fc4_300
I0409 19:42:40.056550  2560 net.cpp:100] Creating Layer fc4_300
I0409 19:42:40.056553  2560 net.cpp:434] fc4_300 <- pool3
I0409 19:42:40.056560  2560 net.cpp:408] fc4_300 -> fc4_300
I0409 19:42:40.062489  2560 net.cpp:150] Setting up fc4_300
I0409 19:42:40.062505  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:40.062510  2560 net.cpp:165] Memory required for data: 4103028736
I0409 19:42:40.062516  2560 layer_factory.hpp:77] Creating layer fc4_prescale
I0409 19:42:40.062525  2560 net.cpp:100] Creating Layer fc4_prescale
I0409 19:42:40.062527  2560 net.cpp:434] fc4_prescale <- fc4_300
I0409 19:42:40.062535  2560 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0409 19:42:40.062628  2560 net.cpp:150] Setting up fc4_prescale
I0409 19:42:40.062650  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:40.062654  2560 net.cpp:165] Memory required for data: 4104257536
I0409 19:42:40.062659  2560 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 19:42:40.062664  2560 net.cpp:100] Creating Layer fc4_sTanH
I0409 19:42:40.062669  2560 net.cpp:434] fc4_sTanH <- fc4_300
I0409 19:42:40.062674  2560 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 19:42:40.062866  2560 net.cpp:150] Setting up fc4_sTanH
I0409 19:42:40.062880  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:40.062882  2560 net.cpp:165] Memory required for data: 4105486336
I0409 19:42:40.062886  2560 layer_factory.hpp:77] Creating layer fc4_postscale
I0409 19:42:40.062893  2560 net.cpp:100] Creating Layer fc4_postscale
I0409 19:42:40.062896  2560 net.cpp:434] fc4_postscale <- fc4_300
I0409 19:42:40.062901  2560 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0409 19:42:40.063000  2560 net.cpp:150] Setting up fc4_postscale
I0409 19:42:40.063009  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:40.063012  2560 net.cpp:165] Memory required for data: 4106715136
I0409 19:42:40.063017  2560 layer_factory.hpp:77] Creating layer drop4
I0409 19:42:40.063024  2560 net.cpp:100] Creating Layer drop4
I0409 19:42:40.063030  2560 net.cpp:434] drop4 <- fc4_300
I0409 19:42:40.063035  2560 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 19:42:40.063060  2560 net.cpp:150] Setting up drop4
I0409 19:42:40.063066  2560 net.cpp:157] Top shape: 1024 300 (307200)
I0409 19:42:40.063069  2560 net.cpp:165] Memory required for data: 4107943936
I0409 19:42:40.063072  2560 layer_factory.hpp:77] Creating layer fc5_67
I0409 19:42:40.063078  2560 net.cpp:100] Creating Layer fc5_67
I0409 19:42:40.063081  2560 net.cpp:434] fc5_67 <- fc4_300
I0409 19:42:40.063086  2560 net.cpp:408] fc5_67 -> fc5_classes
I0409 19:42:40.063329  2560 net.cpp:150] Setting up fc5_67
I0409 19:42:40.063338  2560 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:42:40.063341  2560 net.cpp:165] Memory required for data: 4108218368
I0409 19:42:40.063351  2560 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0409 19:42:40.063359  2560 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0409 19:42:40.063362  2560 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0409 19:42:40.063367  2560 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0409 19:42:40.063375  2560 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0409 19:42:40.063381  2560 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0409 19:42:40.063434  2560 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0409 19:42:40.063441  2560 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:42:40.063446  2560 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:42:40.063448  2560 net.cpp:157] Top shape: 1024 67 (68608)
I0409 19:42:40.063452  2560 net.cpp:165] Memory required for data: 4109041664
I0409 19:42:40.063454  2560 layer_factory.hpp:77] Creating layer loss
I0409 19:42:40.063460  2560 net.cpp:100] Creating Layer loss
I0409 19:42:40.063463  2560 net.cpp:434] loss <- fc5_classes_fc5_67_0_split_0
I0409 19:42:40.063467  2560 net.cpp:434] loss <- label_data_1_split_0
I0409 19:42:40.063472  2560 net.cpp:408] loss -> loss
I0409 19:42:40.063483  2560 layer_factory.hpp:77] Creating layer loss
I0409 19:42:40.063818  2560 net.cpp:150] Setting up loss
I0409 19:42:40.063830  2560 net.cpp:157] Top shape: (1)
I0409 19:42:40.063833  2560 net.cpp:160]     with loss weight 1
I0409 19:42:40.063844  2560 net.cpp:165] Memory required for data: 4109041668
I0409 19:42:40.063848  2560 layer_factory.hpp:77] Creating layer accuracy_1
I0409 19:42:40.063855  2560 net.cpp:100] Creating Layer accuracy_1
I0409 19:42:40.063859  2560 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0409 19:42:40.063863  2560 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0409 19:42:40.063869  2560 net.cpp:408] accuracy_1 -> accuracy_1
I0409 19:42:40.063885  2560 net.cpp:150] Setting up accuracy_1
I0409 19:42:40.063902  2560 net.cpp:157] Top shape: (1)
I0409 19:42:40.063905  2560 net.cpp:165] Memory required for data: 4109041672
I0409 19:42:40.063910  2560 layer_factory.hpp:77] Creating layer accuracy_5
I0409 19:42:40.063915  2560 net.cpp:100] Creating Layer accuracy_5
I0409 19:42:40.063920  2560 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0409 19:42:40.063923  2560 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0409 19:42:40.063928  2560 net.cpp:408] accuracy_5 -> accuracy_5
I0409 19:42:40.063935  2560 net.cpp:150] Setting up accuracy_5
I0409 19:42:40.063940  2560 net.cpp:157] Top shape: (1)
I0409 19:42:40.063942  2560 net.cpp:165] Memory required for data: 4109041676
I0409 19:42:40.063946  2560 net.cpp:228] accuracy_5 does not need backward computation.
I0409 19:42:40.063949  2560 net.cpp:228] accuracy_1 does not need backward computation.
I0409 19:42:40.063953  2560 net.cpp:226] loss needs backward computation.
I0409 19:42:40.063957  2560 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0409 19:42:40.063973  2560 net.cpp:226] fc5_67 needs backward computation.
I0409 19:42:40.063977  2560 net.cpp:226] drop4 needs backward computation.
I0409 19:42:40.063979  2560 net.cpp:226] fc4_postscale needs backward computation.
I0409 19:42:40.063982  2560 net.cpp:226] fc4_sTanH needs backward computation.
I0409 19:42:40.063985  2560 net.cpp:226] fc4_prescale needs backward computation.
I0409 19:42:40.063988  2560 net.cpp:226] fc4_300 needs backward computation.
I0409 19:42:40.063992  2560 net.cpp:226] pool3 needs backward computation.
I0409 19:42:40.063994  2560 net.cpp:226] conv3_postscale needs backward computation.
I0409 19:42:40.063997  2560 net.cpp:226] conv3_sTanH needs backward computation.
I0409 19:42:40.064000  2560 net.cpp:226] conv3_prescale needs backward computation.
I0409 19:42:40.064003  2560 net.cpp:226] conv3 needs backward computation.
I0409 19:42:40.064007  2560 net.cpp:226] pool2 needs backward computation.
I0409 19:42:40.064009  2560 net.cpp:226] conv2_postscale needs backward computation.
I0409 19:42:40.064013  2560 net.cpp:226] conv2_sTanH needs backward computation.
I0409 19:42:40.064015  2560 net.cpp:226] conv2_prescale needs backward computation.
I0409 19:42:40.064018  2560 net.cpp:226] conv2 needs backward computation.
I0409 19:42:40.064021  2560 net.cpp:226] pool1 needs backward computation.
I0409 19:42:40.064024  2560 net.cpp:226] conv1_postscale needs backward computation.
I0409 19:42:40.064026  2560 net.cpp:226] conv1_sTanH needs backward computation.
I0409 19:42:40.064029  2560 net.cpp:226] conv1_prescale needs backward computation.
I0409 19:42:40.064033  2560 net.cpp:226] conv1 needs backward computation.
I0409 19:42:40.064036  2560 net.cpp:228] label_data_1_split does not need backward computation.
I0409 19:42:40.064040  2560 net.cpp:228] data does not need backward computation.
I0409 19:42:40.064043  2560 net.cpp:270] This network produces output accuracy_1
I0409 19:42:40.064047  2560 net.cpp:270] This network produces output accuracy_5
I0409 19:42:40.064061  2560 net.cpp:270] This network produces output loss
I0409 19:42:40.064080  2560 net.cpp:283] Network initialization done.
I0409 19:42:40.064152  2560 solver.cpp:72] Solver scaffolding done.
I0409 19:42:40.065057  2560 caffe.cpp:251] Starting Optimization
I0409 19:42:40.065068  2560 solver.cpp:291] Solving 
I0409 19:42:40.065070  2560 solver.cpp:292] Learning Rate Policy: step
I0409 19:42:40.067229  2560 solver.cpp:349] Iteration 0, Testing net (#0)
I0409 19:42:40.068629  2560 blocking_queue.cpp:50] Data layer prefetch queue empty
I0409 19:42:41.181187  2560 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0090332
I0409 19:42:41.181221  2560 solver.cpp:416]     Test net output #1: accuracy_5 = 0.120972
I0409 19:42:41.181244  2560 solver.cpp:416]     Test net output #2: loss = 4.52556 (* 1 = 4.52556 loss)
I0409 19:42:41.332466  2560 solver.cpp:240] Iteration 0, loss = 4.76829
I0409 19:42:41.332514  2560 solver.cpp:256]     Train net output #0: loss = 4.76829 (* 1 = 4.76829 loss)
I0409 19:42:41.332526  2560 sgd_solver.cpp:106] Iteration 0, lr = 1e-05
I0409 19:42:41.708313  2560 solver.cpp:240] Iteration 1, loss = 4.75818
I0409 19:42:41.708349  2560 solver.cpp:256]     Train net output #0: loss = 4.75818 (* 1 = 4.75818 loss)
I0409 19:42:41.708359  2560 sgd_solver.cpp:106] Iteration 1, lr = 1e-05
I0409 19:42:42.075425  2560 solver.cpp:240] Iteration 2, loss = 4.8071
I0409 19:42:42.075477  2560 solver.cpp:256]     Train net output #0: loss = 4.8071 (* 1 = 4.8071 loss)
I0409 19:42:42.075487  2560 sgd_solver.cpp:106] Iteration 2, lr = 1e-05
I0409 19:42:42.448734  2560 solver.cpp:240] Iteration 3, loss = 4.79075
I0409 19:42:42.448781  2560 solver.cpp:256]     Train net output #0: loss = 4.79075 (* 1 = 4.79075 loss)
I0409 19:42:42.448791  2560 sgd_solver.cpp:106] Iteration 3, lr = 1e-05
I0409 19:42:42.827463  2560 solver.cpp:240] Iteration 4, loss = 4.73169
I0409 19:42:42.827498  2560 solver.cpp:256]     Train net output #0: loss = 4.73169 (* 1 = 4.73169 loss)
I0409 19:42:42.827514  2560 sgd_solver.cpp:106] Iteration 4, lr = 1e-05
I0409 19:42:43.201542  2560 solver.cpp:240] Iteration 5, loss = 4.83306
I0409 19:42:43.201581  2560 solver.cpp:256]     Train net output #0: loss = 4.83306 (* 1 = 4.83306 loss)
I0409 19:42:43.201589  2560 sgd_solver.cpp:106] Iteration 5, lr = 1e-05
I0409 19:42:43.575392  2560 solver.cpp:240] Iteration 6, loss = 4.81744
I0409 19:42:43.575428  2560 solver.cpp:256]     Train net output #0: loss = 4.81744 (* 1 = 4.81744 loss)
I0409 19:42:43.575436  2560 sgd_solver.cpp:106] Iteration 6, lr = 1e-05
I0409 19:42:43.954644  2560 solver.cpp:240] Iteration 7, loss = 4.81749
I0409 19:42:43.954686  2560 solver.cpp:256]     Train net output #0: loss = 4.81749 (* 1 = 4.81749 loss)
I0409 19:42:43.954695  2560 sgd_solver.cpp:106] Iteration 7, lr = 1e-05
I0409 19:42:44.332736  2560 solver.cpp:240] Iteration 8, loss = 4.82881
I0409 19:42:44.332774  2560 solver.cpp:256]     Train net output #0: loss = 4.82881 (* 1 = 4.82881 loss)
I0409 19:42:44.332782  2560 sgd_solver.cpp:106] Iteration 8, lr = 1e-05
I0409 19:42:44.707782  2560 solver.cpp:240] Iteration 9, loss = 4.84546
I0409 19:42:44.707818  2560 solver.cpp:256]     Train net output #0: loss = 4.84546 (* 1 = 4.84546 loss)
I0409 19:42:44.707826  2560 sgd_solver.cpp:106] Iteration 9, lr = 1e-05
I0409 19:42:45.084419  2560 solver.cpp:240] Iteration 10, loss = 4.89031
I0409 19:42:45.084455  2560 solver.cpp:256]     Train net output #0: loss = 4.89031 (* 1 = 4.89031 loss)
I0409 19:42:45.084463  2560 sgd_solver.cpp:106] Iteration 10, lr = 1e-05
I0409 19:42:45.458432  2560 solver.cpp:240] Iteration 11, loss = 4.86982
I0409 19:42:45.458472  2560 solver.cpp:256]     Train net output #0: loss = 4.86982 (* 1 = 4.86982 loss)
I0409 19:42:45.458479  2560 sgd_solver.cpp:106] Iteration 11, lr = 1e-05
I0409 19:42:45.837255  2560 solver.cpp:240] Iteration 12, loss = 4.83779
I0409 19:42:45.837291  2560 solver.cpp:256]     Train net output #0: loss = 4.83779 (* 1 = 4.83779 loss)
I0409 19:42:45.837297  2560 sgd_solver.cpp:106] Iteration 12, lr = 1e-05
I0409 19:42:46.213973  2560 solver.cpp:240] Iteration 13, loss = 4.93591
I0409 19:42:46.214010  2560 solver.cpp:256]     Train net output #0: loss = 4.93591 (* 1 = 4.93591 loss)
I0409 19:42:46.214017  2560 sgd_solver.cpp:106] Iteration 13, lr = 1e-05
I0409 19:42:46.590685  2560 solver.cpp:240] Iteration 14, loss = 4.93207
I0409 19:42:46.590720  2560 solver.cpp:256]     Train net output #0: loss = 4.93207 (* 1 = 4.93207 loss)
I0409 19:42:46.590728  2560 sgd_solver.cpp:106] Iteration 14, lr = 1e-05
I0409 19:42:46.964371  2560 solver.cpp:240] Iteration 15, loss = 4.93878
I0409 19:42:46.964407  2560 solver.cpp:256]     Train net output #0: loss = 4.93878 (* 1 = 4.93878 loss)
I0409 19:42:46.964416  2560 sgd_solver.cpp:106] Iteration 15, lr = 1e-05
I0409 19:42:47.344012  2560 solver.cpp:240] Iteration 16, loss = 4.95941
I0409 19:42:47.344048  2560 solver.cpp:256]     Train net output #0: loss = 4.95941 (* 1 = 4.95941 loss)
I0409 19:42:47.344055  2560 sgd_solver.cpp:106] Iteration 16, lr = 1e-05
I0409 19:42:47.720772  2560 solver.cpp:240] Iteration 17, loss = 4.92721
I0409 19:42:47.720825  2560 solver.cpp:256]     Train net output #0: loss = 4.92721 (* 1 = 4.92721 loss)
I0409 19:42:47.720839  2560 sgd_solver.cpp:106] Iteration 17, lr = 1e-05
I0409 19:42:48.093487  2560 solver.cpp:240] Iteration 18, loss = 4.96345
I0409 19:42:48.093524  2560 solver.cpp:256]     Train net output #0: loss = 4.96345 (* 1 = 4.96345 loss)
I0409 19:42:48.093533  2560 sgd_solver.cpp:106] Iteration 18, lr = 1e-05
I0409 19:42:48.466297  2560 solver.cpp:240] Iteration 19, loss = 4.99603
I0409 19:42:48.466336  2560 solver.cpp:256]     Train net output #0: loss = 4.99603 (* 1 = 4.99603 loss)
I0409 19:42:48.466346  2560 sgd_solver.cpp:106] Iteration 19, lr = 1e-05
I0409 19:42:48.847512  2560 solver.cpp:240] Iteration 20, loss = 5.04388
I0409 19:42:48.847548  2560 solver.cpp:256]     Train net output #0: loss = 5.04388 (* 1 = 5.04388 loss)
I0409 19:42:48.847556  2560 sgd_solver.cpp:106] Iteration 20, lr = 1e-05
I0409 19:42:49.224006  2560 solver.cpp:240] Iteration 21, loss = 4.95861
I0409 19:42:49.224041  2560 solver.cpp:256]     Train net output #0: loss = 4.95861 (* 1 = 4.95861 loss)
I0409 19:42:49.224050  2560 sgd_solver.cpp:106] Iteration 21, lr = 1e-05
I0409 19:42:49.598796  2560 solver.cpp:240] Iteration 22, loss = 5.03716
I0409 19:42:49.598845  2560 solver.cpp:256]     Train net output #0: loss = 5.03716 (* 1 = 5.03716 loss)
I0409 19:42:49.598852  2560 sgd_solver.cpp:106] Iteration 22, lr = 1e-05
I0409 19:42:49.970093  2560 solver.cpp:240] Iteration 23, loss = 4.98646
I0409 19:42:49.970129  2560 solver.cpp:256]     Train net output #0: loss = 4.98646 (* 1 = 4.98646 loss)
I0409 19:42:49.970137  2560 sgd_solver.cpp:106] Iteration 23, lr = 1e-05
I0409 19:42:50.349925  2560 solver.cpp:240] Iteration 24, loss = 5.08424
I0409 19:42:50.349975  2560 solver.cpp:256]     Train net output #0: loss = 5.08424 (* 1 = 5.08424 loss)
I0409 19:42:50.349984  2560 sgd_solver.cpp:106] Iteration 24, lr = 1e-05
I0409 19:42:50.350312  2560 solver.cpp:349] Iteration 25, Testing net (#0)
I0409 19:42:51.649271  2560 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00354004
I0409 19:42:51.649298  2560 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0748291
I0409 19:42:51.649319  2560 solver.cpp:416]     Test net output #2: loss = 4.82209 (* 1 = 4.82209 loss)
I0409 19:42:51.778426  2560 solver.cpp:240] Iteration 25, loss = 5.10578
I0409 19:42:51.778475  2560 solver.cpp:256]     Train net output #0: loss = 5.10578 (* 1 = 5.10578 loss)
I0409 19:42:51.778483  2560 sgd_solver.cpp:106] Iteration 25, lr = 1e-05
I0409 19:42:52.149524  2560 solver.cpp:240] Iteration 26, loss = 5.11862
I0409 19:42:52.149564  2560 solver.cpp:256]     Train net output #0: loss = 5.11862 (* 1 = 5.11862 loss)
I0409 19:42:52.149577  2560 sgd_solver.cpp:106] Iteration 26, lr = 1e-05
I0409 19:42:52.529433  2560 solver.cpp:240] Iteration 27, loss = 5.06471
I0409 19:42:52.529467  2560 solver.cpp:256]     Train net output #0: loss = 5.06471 (* 1 = 5.06471 loss)
I0409 19:42:52.529490  2560 sgd_solver.cpp:106] Iteration 27, lr = 1e-05
I0409 19:42:52.905077  2560 solver.cpp:240] Iteration 28, loss = 5.15511
I0409 19:42:52.905113  2560 solver.cpp:256]     Train net output #0: loss = 5.15511 (* 1 = 5.15511 loss)
I0409 19:42:52.905136  2560 sgd_solver.cpp:106] Iteration 28, lr = 1e-05
I0409 19:42:53.277726  2560 solver.cpp:240] Iteration 29, loss = 5.03747
I0409 19:42:53.277761  2560 solver.cpp:256]     Train net output #0: loss = 5.03747 (* 1 = 5.03747 loss)
I0409 19:42:53.277773  2560 sgd_solver.cpp:106] Iteration 29, lr = 1e-05
I0409 19:42:53.659540  2560 solver.cpp:240] Iteration 30, loss = 5.13525
I0409 19:42:53.659586  2560 solver.cpp:256]     Train net output #0: loss = 5.13525 (* 1 = 5.13525 loss)
I0409 19:42:53.659598  2560 sgd_solver.cpp:106] Iteration 30, lr = 1e-05
I0409 19:42:54.035512  2560 solver.cpp:240] Iteration 31, loss = 5.08982
I0409 19:42:54.035548  2560 solver.cpp:256]     Train net output #0: loss = 5.08982 (* 1 = 5.08982 loss)
I0409 19:42:54.035557  2560 sgd_solver.cpp:106] Iteration 31, lr = 1e-05
I0409 19:42:54.409624  2560 solver.cpp:240] Iteration 32, loss = 5.12904
I0409 19:42:54.409677  2560 solver.cpp:256]     Train net output #0: loss = 5.12904 (* 1 = 5.12904 loss)
I0409 19:42:54.409687  2560 sgd_solver.cpp:106] Iteration 32, lr = 1e-05
I0409 19:42:54.782166  2560 solver.cpp:240] Iteration 33, loss = 5.17914
I0409 19:42:54.782200  2560 solver.cpp:256]     Train net output #0: loss = 5.17914 (* 1 = 5.17914 loss)
I0409 19:42:54.782208  2560 sgd_solver.cpp:106] Iteration 33, lr = 1e-05
I0409 19:42:55.165163  2560 solver.cpp:240] Iteration 34, loss = 5.1147
I0409 19:42:55.165197  2560 solver.cpp:256]     Train net output #0: loss = 5.1147 (* 1 = 5.1147 loss)
I0409 19:42:55.165205  2560 sgd_solver.cpp:106] Iteration 34, lr = 1e-05
I0409 19:42:55.542735  2560 solver.cpp:240] Iteration 35, loss = 5.17583
I0409 19:42:55.542770  2560 solver.cpp:256]     Train net output #0: loss = 5.17583 (* 1 = 5.17583 loss)
I0409 19:42:55.542779  2560 sgd_solver.cpp:106] Iteration 35, lr = 1e-05
I0409 19:42:55.917783  2560 solver.cpp:240] Iteration 36, loss = 5.25027
I0409 19:42:55.917819  2560 solver.cpp:256]     Train net output #0: loss = 5.25027 (* 1 = 5.25027 loss)
I0409 19:42:55.917827  2560 sgd_solver.cpp:106] Iteration 36, lr = 1e-05
I0409 19:42:56.292764  2560 solver.cpp:240] Iteration 37, loss = 5.21856
I0409 19:42:56.292798  2560 solver.cpp:256]     Train net output #0: loss = 5.21856 (* 1 = 5.21856 loss)
I0409 19:42:56.292806  2560 sgd_solver.cpp:106] Iteration 37, lr = 1e-05
I0409 19:42:56.664304  2560 solver.cpp:240] Iteration 38, loss = 5.20544
I0409 19:42:56.664338  2560 solver.cpp:256]     Train net output #0: loss = 5.20544 (* 1 = 5.20544 loss)
I0409 19:42:56.664347  2560 sgd_solver.cpp:106] Iteration 38, lr = 1e-05
I0409 19:42:57.042088  2560 solver.cpp:240] Iteration 39, loss = 5.29383
I0409 19:42:57.042124  2560 solver.cpp:256]     Train net output #0: loss = 5.29383 (* 1 = 5.29383 loss)
I0409 19:42:57.042134  2560 sgd_solver.cpp:106] Iteration 39, lr = 1e-05
I0409 19:42:57.417135  2560 solver.cpp:240] Iteration 40, loss = 5.15333
I0409 19:42:57.417168  2560 solver.cpp:256]     Train net output #0: loss = 5.15333 (* 1 = 5.15333 loss)
I0409 19:42:57.417176  2560 sgd_solver.cpp:106] Iteration 40, lr = 1e-05
I0409 19:42:57.790558  2560 solver.cpp:240] Iteration 41, loss = 5.28957
I0409 19:42:57.790603  2560 solver.cpp:256]     Train net output #0: loss = 5.28957 (* 1 = 5.28957 loss)
I0409 19:42:57.790614  2560 sgd_solver.cpp:106] Iteration 41, lr = 1e-05
I0409 19:42:58.171634  2560 solver.cpp:240] Iteration 42, loss = 5.25542
I0409 19:42:58.171671  2560 solver.cpp:256]     Train net output #0: loss = 5.25542 (* 1 = 5.25542 loss)
I0409 19:42:58.171680  2560 sgd_solver.cpp:106] Iteration 42, lr = 1e-05
I0409 19:42:58.547965  2560 solver.cpp:240] Iteration 43, loss = 5.32017
I0409 19:42:58.548002  2560 solver.cpp:256]     Train net output #0: loss = 5.32017 (* 1 = 5.32017 loss)
I0409 19:42:58.548010  2560 sgd_solver.cpp:106] Iteration 43, lr = 1e-05
I0409 19:42:58.922328  2560 solver.cpp:240] Iteration 44, loss = 5.3218
I0409 19:42:58.922365  2560 solver.cpp:256]     Train net output #0: loss = 5.3218 (* 1 = 5.3218 loss)
I0409 19:42:58.922375  2560 sgd_solver.cpp:106] Iteration 44, lr = 1e-05
I0409 19:42:59.294677  2560 solver.cpp:240] Iteration 45, loss = 5.29359
I0409 19:42:59.294711  2560 solver.cpp:256]     Train net output #0: loss = 5.29359 (* 1 = 5.29359 loss)
I0409 19:42:59.294719  2560 sgd_solver.cpp:106] Iteration 45, lr = 1e-05
I0409 19:42:59.675290  2560 solver.cpp:240] Iteration 46, loss = 5.26763
I0409 19:42:59.675328  2560 solver.cpp:256]     Train net output #0: loss = 5.26763 (* 1 = 5.26763 loss)
I0409 19:42:59.675336  2560 sgd_solver.cpp:106] Iteration 46, lr = 1e-05
I0409 19:43:00.052877  2560 solver.cpp:240] Iteration 47, loss = 5.40346
I0409 19:43:00.052923  2560 solver.cpp:256]     Train net output #0: loss = 5.40346 (* 1 = 5.40346 loss)
I0409 19:43:00.052932  2560 sgd_solver.cpp:106] Iteration 47, lr = 1e-05
I0409 19:43:00.427572  2560 solver.cpp:240] Iteration 48, loss = 5.2892
I0409 19:43:00.427608  2560 solver.cpp:256]     Train net output #0: loss = 5.2892 (* 1 = 5.2892 loss)
I0409 19:43:00.427634  2560 sgd_solver.cpp:106] Iteration 48, lr = 1e-05
I0409 19:43:00.802501  2560 solver.cpp:240] Iteration 49, loss = 5.42569
I0409 19:43:00.802549  2560 solver.cpp:256]     Train net output #0: loss = 5.42569 (* 1 = 5.42569 loss)
I0409 19:43:00.802567  2560 sgd_solver.cpp:106] Iteration 49, lr = 1e-05
I0409 19:43:00.803081  2560 solver.cpp:349] Iteration 50, Testing net (#0)
I0409 19:43:02.107641  2560 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00354004
I0409 19:43:02.107672  2560 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0388184
I0409 19:43:02.107682  2560 solver.cpp:416]     Test net output #2: loss = 5.09804 (* 1 = 5.09804 loss)
I0409 19:43:02.237637  2560 solver.cpp:240] Iteration 50, loss = 5.35167
I0409 19:43:02.237673  2560 solver.cpp:256]     Train net output #0: loss = 5.35167 (* 1 = 5.35167 loss)
I0409 19:43:02.237681  2560 sgd_solver.cpp:106] Iteration 50, lr = 1e-05
I0409 19:43:02.613497  2560 solver.cpp:240] Iteration 51, loss = 5.42554
I0409 19:43:02.613535  2560 solver.cpp:256]     Train net output #0: loss = 5.42554 (* 1 = 5.42554 loss)
I0409 19:43:02.613545  2560 sgd_solver.cpp:106] Iteration 51, lr = 1e-05
I0409 19:43:02.990902  2560 solver.cpp:240] Iteration 52, loss = 5.44139
I0409 19:43:02.990937  2560 solver.cpp:256]     Train net output #0: loss = 5.44139 (* 1 = 5.44139 loss)
I0409 19:43:02.990945  2560 sgd_solver.cpp:106] Iteration 52, lr = 1e-05
I0409 19:43:03.364401  2560 solver.cpp:240] Iteration 53, loss = 5.4222
I0409 19:43:03.364436  2560 solver.cpp:256]     Train net output #0: loss = 5.4222 (* 1 = 5.4222 loss)
I0409 19:43:03.364445  2560 sgd_solver.cpp:106] Iteration 53, lr = 1e-05
I0409 19:43:03.743691  2560 solver.cpp:240] Iteration 54, loss = 5.382
I0409 19:43:03.743726  2560 solver.cpp:256]     Train net output #0: loss = 5.382 (* 1 = 5.382 loss)
I0409 19:43:03.743736  2560 sgd_solver.cpp:106] Iteration 54, lr = 1e-05
I0409 19:43:04.120658  2560 solver.cpp:240] Iteration 55, loss = 5.44491
I0409 19:43:04.120694  2560 solver.cpp:256]     Train net output #0: loss = 5.44491 (* 1 = 5.44491 loss)
I0409 19:43:04.120702  2560 sgd_solver.cpp:106] Iteration 55, lr = 1e-05
I0409 19:43:04.497318  2560 solver.cpp:240] Iteration 56, loss = 5.40857
I0409 19:43:04.497357  2560 solver.cpp:256]     Train net output #0: loss = 5.40857 (* 1 = 5.40857 loss)
I0409 19:43:04.497365  2560 sgd_solver.cpp:106] Iteration 56, lr = 1e-05
I0409 19:43:04.867902  2560 solver.cpp:240] Iteration 57, loss = 5.41167
I0409 19:43:04.867935  2560 solver.cpp:256]     Train net output #0: loss = 5.41167 (* 1 = 5.41167 loss)
I0409 19:43:04.867944  2560 sgd_solver.cpp:106] Iteration 57, lr = 1e-05
I0409 19:43:05.246362  2560 solver.cpp:240] Iteration 58, loss = 5.38801
I0409 19:43:05.246397  2560 solver.cpp:256]     Train net output #0: loss = 5.38801 (* 1 = 5.38801 loss)
I0409 19:43:05.246407  2560 sgd_solver.cpp:106] Iteration 58, lr = 1e-05
I0409 19:43:05.623163  2560 solver.cpp:240] Iteration 59, loss = 5.42308
I0409 19:43:05.623203  2560 solver.cpp:256]     Train net output #0: loss = 5.42308 (* 1 = 5.42308 loss)
I0409 19:43:05.623211  2560 sgd_solver.cpp:106] Iteration 59, lr = 1e-05
I0409 19:43:05.998723  2560 solver.cpp:240] Iteration 60, loss = 5.39192
I0409 19:43:05.998759  2560 solver.cpp:256]     Train net output #0: loss = 5.39192 (* 1 = 5.39192 loss)
I0409 19:43:05.998766  2560 sgd_solver.cpp:106] Iteration 60, lr = 1e-05
I0409 19:43:06.372416  2560 solver.cpp:240] Iteration 61, loss = 5.51443
I0409 19:43:06.372453  2560 solver.cpp:256]     Train net output #0: loss = 5.51443 (* 1 = 5.51443 loss)
I0409 19:43:06.372462  2560 sgd_solver.cpp:106] Iteration 61, lr = 1e-05
I0409 19:43:06.752468  2560 solver.cpp:240] Iteration 62, loss = 5.43781
I0409 19:43:06.752506  2560 solver.cpp:256]     Train net output #0: loss = 5.43781 (* 1 = 5.43781 loss)
I0409 19:43:06.752513  2560 sgd_solver.cpp:106] Iteration 62, lr = 1e-05
I0409 19:43:07.132184  2560 solver.cpp:240] Iteration 63, loss = 5.52711
I0409 19:43:07.132248  2560 solver.cpp:256]     Train net output #0: loss = 5.52711 (* 1 = 5.52711 loss)
I0409 19:43:07.132261  2560 sgd_solver.cpp:106] Iteration 63, lr = 1e-05
I0409 19:43:07.507084  2560 solver.cpp:240] Iteration 64, loss = 5.38378
I0409 19:43:07.507133  2560 solver.cpp:256]     Train net output #0: loss = 5.38378 (* 1 = 5.38378 loss)
I0409 19:43:07.507141  2560 sgd_solver.cpp:106] Iteration 64, lr = 1e-05
I0409 19:43:07.877205  2560 solver.cpp:240] Iteration 65, loss = 5.43099
I0409 19:43:07.877241  2560 solver.cpp:256]     Train net output #0: loss = 5.43099 (* 1 = 5.43099 loss)
I0409 19:43:07.877249  2560 sgd_solver.cpp:106] Iteration 65, lr = 1e-05
I0409 19:43:08.255318  2560 solver.cpp:240] Iteration 66, loss = 5.56494
I0409 19:43:08.255357  2560 solver.cpp:256]     Train net output #0: loss = 5.56494 (* 1 = 5.56494 loss)
I0409 19:43:08.255365  2560 sgd_solver.cpp:106] Iteration 66, lr = 1e-05
I0409 19:43:08.632251  2560 solver.cpp:240] Iteration 67, loss = 5.46399
I0409 19:43:08.632418  2560 solver.cpp:256]     Train net output #0: loss = 5.46399 (* 1 = 5.46399 loss)
I0409 19:43:08.632431  2560 sgd_solver.cpp:106] Iteration 67, lr = 1e-05
I0409 19:43:09.008708  2560 solver.cpp:240] Iteration 68, loss = 5.52359
I0409 19:43:09.008746  2560 solver.cpp:256]     Train net output #0: loss = 5.52359 (* 1 = 5.52359 loss)
I0409 19:43:09.008754  2560 sgd_solver.cpp:106] Iteration 68, lr = 1e-05
I0409 19:43:09.391312  2560 solver.cpp:240] Iteration 69, loss = 5.4785
I0409 19:43:09.391353  2560 solver.cpp:256]     Train net output #0: loss = 5.4785 (* 1 = 5.4785 loss)
I0409 19:43:09.391361  2560 sgd_solver.cpp:106] Iteration 69, lr = 1e-05
I0409 19:43:09.769724  2560 solver.cpp:240] Iteration 70, loss = 5.45623
I0409 19:43:09.769760  2560 solver.cpp:256]     Train net output #0: loss = 5.45623 (* 1 = 5.45623 loss)
I0409 19:43:09.769768  2560 sgd_solver.cpp:106] Iteration 70, lr = 1e-05
I0409 19:43:10.143663  2560 solver.cpp:240] Iteration 71, loss = 5.43999
I0409 19:43:10.143697  2560 solver.cpp:256]     Train net output #0: loss = 5.43999 (* 1 = 5.43999 loss)
I0409 19:43:10.143704  2560 sgd_solver.cpp:106] Iteration 71, lr = 1e-05
I0409 19:43:10.520596  2560 solver.cpp:240] Iteration 72, loss = 5.53652
I0409 19:43:10.520630  2560 solver.cpp:256]     Train net output #0: loss = 5.53652 (* 1 = 5.53652 loss)
I0409 19:43:10.520638  2560 sgd_solver.cpp:106] Iteration 72, lr = 1e-05
I0409 19:43:10.902096  2560 solver.cpp:240] Iteration 73, loss = 5.52503
I0409 19:43:10.902127  2560 solver.cpp:256]     Train net output #0: loss = 5.52503 (* 1 = 5.52503 loss)
I0409 19:43:10.902137  2560 sgd_solver.cpp:106] Iteration 73, lr = 1e-05
I0409 19:43:11.280165  2560 solver.cpp:240] Iteration 74, loss = 5.62096
I0409 19:43:11.280201  2560 solver.cpp:256]     Train net output #0: loss = 5.62096 (* 1 = 5.62096 loss)
I0409 19:43:11.280208  2560 sgd_solver.cpp:106] Iteration 74, lr = 1e-05
I0409 19:43:11.280531  2560 solver.cpp:349] Iteration 75, Testing net (#0)
I0409 19:43:12.584461  2560 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00341797
I0409 19:43:12.584489  2560 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0524902
I0409 19:43:12.584499  2560 solver.cpp:416]     Test net output #2: loss = 5.26298 (* 1 = 5.26298 loss)
I0409 19:43:12.713716  2560 solver.cpp:240] Iteration 75, loss = 5.61442
I0409 19:43:12.713749  2560 solver.cpp:256]     Train net output #0: loss = 5.61442 (* 1 = 5.61442 loss)
I0409 19:43:12.713757  2560 sgd_solver.cpp:106] Iteration 75, lr = 1e-05
I0409 19:43:13.087642  2560 solver.cpp:240] Iteration 76, loss = 5.56612
I0409 19:43:13.087676  2560 solver.cpp:256]     Train net output #0: loss = 5.56612 (* 1 = 5.56612 loss)
I0409 19:43:13.087683  2560 sgd_solver.cpp:106] Iteration 76, lr = 1e-05
I0409 19:43:13.465960  2560 solver.cpp:240] Iteration 77, loss = 5.51575
I0409 19:43:13.465993  2560 solver.cpp:256]     Train net output #0: loss = 5.51575 (* 1 = 5.51575 loss)
I0409 19:43:13.466001  2560 sgd_solver.cpp:106] Iteration 77, lr = 1e-05
I0409 19:43:13.842901  2560 solver.cpp:240] Iteration 78, loss = 5.553
I0409 19:43:13.842932  2560 solver.cpp:256]     Train net output #0: loss = 5.553 (* 1 = 5.553 loss)
I0409 19:43:13.842942  2560 sgd_solver.cpp:106] Iteration 78, lr = 1e-05
I0409 19:43:14.225670  2560 solver.cpp:240] Iteration 79, loss = 5.48324
I0409 19:43:14.225703  2560 solver.cpp:256]     Train net output #0: loss = 5.48324 (* 1 = 5.48324 loss)
I0409 19:43:14.225710  2560 sgd_solver.cpp:106] Iteration 79, lr = 1e-05
I0409 19:43:14.606084  2560 solver.cpp:240] Iteration 80, loss = 5.5085
I0409 19:43:14.606117  2560 solver.cpp:256]     Train net output #0: loss = 5.5085 (* 1 = 5.5085 loss)
I0409 19:43:14.606127  2560 sgd_solver.cpp:106] Iteration 80, lr = 1e-05
I0409 19:43:14.982579  2560 solver.cpp:240] Iteration 81, loss = 5.51845
I0409 19:43:14.982614  2560 solver.cpp:256]     Train net output #0: loss = 5.51845 (* 1 = 5.51845 loss)
I0409 19:43:14.982622  2560 sgd_solver.cpp:106] Iteration 81, lr = 1e-05
I0409 19:43:15.358000  2560 solver.cpp:240] Iteration 82, loss = 5.48655
I0409 19:43:15.358058  2560 solver.cpp:256]     Train net output #0: loss = 5.48655 (* 1 = 5.48655 loss)
I0409 19:43:15.358067  2560 sgd_solver.cpp:106] Iteration 82, lr = 1e-05
I0409 19:43:15.736703  2560 solver.cpp:240] Iteration 83, loss = 5.5381
I0409 19:43:15.736747  2560 solver.cpp:256]     Train net output #0: loss = 5.5381 (* 1 = 5.5381 loss)
I0409 19:43:15.736758  2560 sgd_solver.cpp:106] Iteration 83, lr = 1e-05
I0409 19:43:16.117770  2560 solver.cpp:240] Iteration 84, loss = 5.52793
I0409 19:43:16.117811  2560 solver.cpp:256]     Train net output #0: loss = 5.52793 (* 1 = 5.52793 loss)
I0409 19:43:16.117822  2560 sgd_solver.cpp:106] Iteration 84, lr = 1e-05
I0409 19:43:16.494280  2560 solver.cpp:240] Iteration 85, loss = 5.48208
I0409 19:43:16.494316  2560 solver.cpp:256]     Train net output #0: loss = 5.48208 (* 1 = 5.48208 loss)
I0409 19:43:16.494324  2560 sgd_solver.cpp:106] Iteration 85, lr = 1e-05
I0409 19:43:16.870934  2560 solver.cpp:240] Iteration 86, loss = 5.54556
I0409 19:43:16.870968  2560 solver.cpp:256]     Train net output #0: loss = 5.54556 (* 1 = 5.54556 loss)
I0409 19:43:16.870977  2560 sgd_solver.cpp:106] Iteration 86, lr = 1e-05
I0409 19:43:17.253633  2560 solver.cpp:240] Iteration 87, loss = 5.5339
I0409 19:43:17.253669  2560 solver.cpp:256]     Train net output #0: loss = 5.5339 (* 1 = 5.5339 loss)
I0409 19:43:17.253675  2560 sgd_solver.cpp:106] Iteration 87, lr = 1e-05
I0409 19:43:17.632284  2560 solver.cpp:240] Iteration 88, loss = 5.55737
I0409 19:43:17.632318  2560 solver.cpp:256]     Train net output #0: loss = 5.55737 (* 1 = 5.55737 loss)
I0409 19:43:17.632326  2560 sgd_solver.cpp:106] Iteration 88, lr = 1e-05
I0409 19:43:18.007505  2560 solver.cpp:240] Iteration 89, loss = 5.46425
I0409 19:43:18.007540  2560 solver.cpp:256]     Train net output #0: loss = 5.46425 (* 1 = 5.46425 loss)
I0409 19:43:18.007550  2560 sgd_solver.cpp:106] Iteration 89, lr = 1e-05
I0409 19:43:18.381898  2560 solver.cpp:240] Iteration 90, loss = 5.54927
I0409 19:43:18.381932  2560 solver.cpp:256]     Train net output #0: loss = 5.54927 (* 1 = 5.54927 loss)
I0409 19:43:18.381940  2560 sgd_solver.cpp:106] Iteration 90, lr = 1e-05
I0409 19:43:18.764621  2560 solver.cpp:240] Iteration 91, loss = 5.53904
I0409 19:43:18.764657  2560 solver.cpp:256]     Train net output #0: loss = 5.53904 (* 1 = 5.53904 loss)
I0409 19:43:18.764665  2560 sgd_solver.cpp:106] Iteration 91, lr = 1e-05
I0409 19:43:19.140074  2560 solver.cpp:240] Iteration 92, loss = 5.51556
I0409 19:43:19.140107  2560 solver.cpp:256]     Train net output #0: loss = 5.51556 (* 1 = 5.51556 loss)
I0409 19:43:19.140116  2560 sgd_solver.cpp:106] Iteration 92, lr = 1e-05
I0409 19:43:19.516759  2560 solver.cpp:240] Iteration 93, loss = 5.52652
I0409 19:43:19.516794  2560 solver.cpp:256]     Train net output #0: loss = 5.52652 (* 1 = 5.52652 loss)
I0409 19:43:19.516803  2560 sgd_solver.cpp:106] Iteration 93, lr = 1e-05
I0409 19:43:19.893390  2560 solver.cpp:240] Iteration 94, loss = 5.52935
I0409 19:43:19.893425  2560 solver.cpp:256]     Train net output #0: loss = 5.52935 (* 1 = 5.52935 loss)
I0409 19:43:19.893434  2560 sgd_solver.cpp:106] Iteration 94, lr = 1e-05
I0409 19:43:20.266683  2560 solver.cpp:240] Iteration 95, loss = 5.49064
I0409 19:43:20.266719  2560 solver.cpp:256]     Train net output #0: loss = 5.49064 (* 1 = 5.49064 loss)
I0409 19:43:20.266727  2560 sgd_solver.cpp:106] Iteration 95, lr = 1e-05
I0409 19:43:20.646656  2560 solver.cpp:240] Iteration 96, loss = 5.44211
I0409 19:43:20.646692  2560 solver.cpp:256]     Train net output #0: loss = 5.44211 (* 1 = 5.44211 loss)
I0409 19:43:20.646702  2560 sgd_solver.cpp:106] Iteration 96, lr = 1e-05
I0409 19:43:21.023562  2560 solver.cpp:240] Iteration 97, loss = 5.50772
I0409 19:43:21.023598  2560 solver.cpp:256]     Train net output #0: loss = 5.50772 (* 1 = 5.50772 loss)
I0409 19:43:21.023607  2560 sgd_solver.cpp:106] Iteration 97, lr = 1e-05
I0409 19:43:21.400063  2560 solver.cpp:240] Iteration 98, loss = 5.4951
I0409 19:43:21.400102  2560 solver.cpp:256]     Train net output #0: loss = 5.4951 (* 1 = 5.4951 loss)
I0409 19:43:21.400140  2560 sgd_solver.cpp:106] Iteration 98, lr = 1e-05
I0409 19:43:21.770925  2560 solver.cpp:240] Iteration 99, loss = 5.52373
I0409 19:43:21.770959  2560 solver.cpp:256]     Train net output #0: loss = 5.52373 (* 1 = 5.52373 loss)
I0409 19:43:21.770968  2560 sgd_solver.cpp:106] Iteration 99, lr = 1e-05
I0409 19:43:21.771293  2560 solver.cpp:349] Iteration 100, Testing net (#0)
I0409 19:43:23.078788  2560 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00378418
I0409 19:43:23.078819  2560 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0721436
I0409 19:43:23.078830  2560 solver.cpp:416]     Test net output #2: loss = 5.19938 (* 1 = 5.19938 loss)
I0409 19:43:23.207833  2560 solver.cpp:240] Iteration 100, loss = 5.5745
I0409 19:43:23.207867  2560 solver.cpp:256]     Train net output #0: loss = 5.5745 (* 1 = 5.5745 loss)
I0409 19:43:23.207876  2560 sgd_solver.cpp:106] Iteration 100, lr = 1e-05
I0409 19:43:23.585065  2560 solver.cpp:240] Iteration 101, loss = 5.46813
I0409 19:43:23.585100  2560 solver.cpp:256]     Train net output #0: loss = 5.46813 (* 1 = 5.46813 loss)
I0409 19:43:23.585109  2560 sgd_solver.cpp:106] Iteration 101, lr = 1e-05
I0409 19:43:23.966954  2560 solver.cpp:240] Iteration 102, loss = 5.47713
I0409 19:43:23.966990  2560 solver.cpp:256]     Train net output #0: loss = 5.47713 (* 1 = 5.47713 loss)
I0409 19:43:23.966998  2560 sgd_solver.cpp:106] Iteration 102, lr = 1e-05
I0409 19:43:24.345582  2560 solver.cpp:240] Iteration 103, loss = 5.41155
I0409 19:43:24.345618  2560 solver.cpp:256]     Train net output #0: loss = 5.41155 (* 1 = 5.41155 loss)
I0409 19:43:24.345628  2560 sgd_solver.cpp:106] Iteration 103, lr = 1e-05
I0409 19:43:24.721554  2560 solver.cpp:240] Iteration 104, loss = 5.414
I0409 19:43:24.721587  2560 solver.cpp:256]     Train net output #0: loss = 5.414 (* 1 = 5.414 loss)
I0409 19:43:24.721596  2560 sgd_solver.cpp:106] Iteration 104, lr = 1e-05
I0409 19:43:25.099870  2560 solver.cpp:240] Iteration 105, loss = 5.49733
I0409 19:43:25.099917  2560 solver.cpp:256]     Train net output #0: loss = 5.49733 (* 1 = 5.49733 loss)
I0409 19:43:25.099926  2560 sgd_solver.cpp:106] Iteration 105, lr = 1e-05
I0409 19:43:25.480320  2560 solver.cpp:240] Iteration 106, loss = 5.43912
I0409 19:43:25.480355  2560 solver.cpp:256]     Train net output #0: loss = 5.43912 (* 1 = 5.43912 loss)
I0409 19:43:25.480363  2560 sgd_solver.cpp:106] Iteration 106, lr = 1e-05
I0409 19:43:25.858839  2560 solver.cpp:240] Iteration 107, loss = 5.42113
I0409 19:43:25.858875  2560 solver.cpp:256]     Train net output #0: loss = 5.42113 (* 1 = 5.42113 loss)
I0409 19:43:25.858883  2560 sgd_solver.cpp:106] Iteration 107, lr = 1e-05
I0409 19:43:26.237229  2560 solver.cpp:240] Iteration 108, loss = 5.49446
I0409 19:43:26.237265  2560 solver.cpp:256]     Train net output #0: loss = 5.49446 (* 1 = 5.49446 loss)
I0409 19:43:26.237274  2560 sgd_solver.cpp:106] Iteration 108, lr = 1e-05
I0409 19:43:26.619828  2560 solver.cpp:240] Iteration 109, loss = 5.41898
I0409 19:43:26.619863  2560 solver.cpp:256]     Train net output #0: loss = 5.41898 (* 1 = 5.41898 loss)
I0409 19:43:26.619873  2560 sgd_solver.cpp:106] Iteration 109, lr = 1e-05
I0409 19:43:27.000397  2560 solver.cpp:240] Iteration 110, loss = 5.44779
I0409 19:43:27.000433  2560 solver.cpp:256]     Train net output #0: loss = 5.44779 (* 1 = 5.44779 loss)
I0409 19:43:27.000442  2560 sgd_solver.cpp:106] Iteration 110, lr = 1e-05
I0409 19:43:27.378674  2560 solver.cpp:240] Iteration 111, loss = 5.47581
I0409 19:43:27.378710  2560 solver.cpp:256]     Train net output #0: loss = 5.47581 (* 1 = 5.47581 loss)
I0409 19:43:27.378717  2560 sgd_solver.cpp:106] Iteration 111, lr = 1e-05
I0409 19:43:27.756091  2560 solver.cpp:240] Iteration 112, loss = 5.43098
I0409 19:43:27.756129  2560 solver.cpp:256]     Train net output #0: loss = 5.43098 (* 1 = 5.43098 loss)
I0409 19:43:27.756136  2560 sgd_solver.cpp:106] Iteration 112, lr = 1e-05
I0409 19:43:28.128732  2560 solver.cpp:240] Iteration 113, loss = 5.48365
I0409 19:43:28.128767  2560 solver.cpp:256]     Train net output #0: loss = 5.48365 (* 1 = 5.48365 loss)
I0409 19:43:28.128799  2560 sgd_solver.cpp:106] Iteration 113, lr = 1e-05
I0409 19:43:28.508410  2560 solver.cpp:240] Iteration 114, loss = 5.41956
I0409 19:43:28.508446  2560 solver.cpp:256]     Train net output #0: loss = 5.41956 (* 1 = 5.41956 loss)
I0409 19:43:28.508455  2560 sgd_solver.cpp:106] Iteration 114, lr = 1e-05
