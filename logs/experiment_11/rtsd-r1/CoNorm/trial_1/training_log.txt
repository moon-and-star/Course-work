I0414 03:08:35.225284 16767 caffe.cpp:217] Using GPUs 3
I0414 03:08:35.386211 16767 caffe.cpp:222] GPU 3: GeForce GTX 1070
I0414 03:08:36.332473 16767 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_11/rtsd-r1/CoNorm/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_11/rtsd-r1/CoNorm/trial_1/test.prototxt"
test_iter: 8
test_interval: 25
base_lr: 0.0001
display: 1
max_iter: 2500
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 125
snapshot: 250
snapshot_prefix: "./snapshots/experiment_11/rtsd-r1/CoNorm/trial_1/snap"
solver_mode: GPU
device_id: 3
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0414 03:08:36.332617 16767 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_11/rtsd-r1/CoNorm/trial_1/train.prototxt
I0414 03:08:36.333076 16767 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: false
    crop_size: 48
    mean_value: 132
    mean_value: 132
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "fc5_classes"
  top: "softmax"
}
layer {
  name: "loss"
  type: "MultinomialLogisticLoss"
  bottom: "softmax"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "accuracy_1"
  bottom: "accuracy_5"
}
I0414 03:08:36.333230 16767 layer_factory.hpp:77] Creating layer data
I0414 03:08:36.334300 16767 net.cpp:100] Creating Layer data
I0414 03:08:36.334318 16767 net.cpp:408] data -> data
I0414 03:08:36.334343 16767 net.cpp:408] data -> label
I0414 03:08:36.335346 16882 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0414 03:08:36.352784 16767 data_layer.cpp:41] output data size: 1024,3,48,48
I0414 03:08:36.414093 16767 net.cpp:150] Setting up data
I0414 03:08:36.414121 16767 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0414 03:08:36.414127 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.414130 16767 net.cpp:165] Memory required for data: 28315648
I0414 03:08:36.414142 16767 layer_factory.hpp:77] Creating layer label_data_1_split
I0414 03:08:36.414155 16767 net.cpp:100] Creating Layer label_data_1_split
I0414 03:08:36.414161 16767 net.cpp:434] label_data_1_split <- label
I0414 03:08:36.414175 16767 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0414 03:08:36.414187 16767 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0414 03:08:36.414199 16767 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0414 03:08:36.414269 16767 net.cpp:150] Setting up label_data_1_split
I0414 03:08:36.414278 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.414281 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.414285 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.414288 16767 net.cpp:165] Memory required for data: 28327936
I0414 03:08:36.414291 16767 layer_factory.hpp:77] Creating layer conv1
I0414 03:08:36.414309 16767 net.cpp:100] Creating Layer conv1
I0414 03:08:36.414314 16767 net.cpp:434] conv1 <- data
I0414 03:08:36.414321 16767 net.cpp:408] conv1 -> conv1
I0414 03:08:36.740031 16767 net.cpp:150] Setting up conv1
I0414 03:08:36.740061 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.740064 16767 net.cpp:165] Memory required for data: 750862336
I0414 03:08:36.740087 16767 layer_factory.hpp:77] Creating layer conv1_prescale
I0414 03:08:36.740101 16767 net.cpp:100] Creating Layer conv1_prescale
I0414 03:08:36.740108 16767 net.cpp:434] conv1_prescale <- conv1
I0414 03:08:36.740114 16767 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0414 03:08:36.740226 16767 net.cpp:150] Setting up conv1_prescale
I0414 03:08:36.740236 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.740239 16767 net.cpp:165] Memory required for data: 1473396736
I0414 03:08:36.740247 16767 layer_factory.hpp:77] Creating layer conv1_sTanH
I0414 03:08:36.740255 16767 net.cpp:100] Creating Layer conv1_sTanH
I0414 03:08:36.740260 16767 net.cpp:434] conv1_sTanH <- conv1
I0414 03:08:36.740264 16767 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0414 03:08:36.740458 16767 net.cpp:150] Setting up conv1_sTanH
I0414 03:08:36.740491 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.740495 16767 net.cpp:165] Memory required for data: 2195931136
I0414 03:08:36.740499 16767 layer_factory.hpp:77] Creating layer conv1_postscale
I0414 03:08:36.740506 16767 net.cpp:100] Creating Layer conv1_postscale
I0414 03:08:36.740511 16767 net.cpp:434] conv1_postscale <- conv1
I0414 03:08:36.740517 16767 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0414 03:08:36.740615 16767 net.cpp:150] Setting up conv1_postscale
I0414 03:08:36.740623 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.740628 16767 net.cpp:165] Memory required for data: 2918465536
I0414 03:08:36.740633 16767 layer_factory.hpp:77] Creating layer pool1
I0414 03:08:36.740641 16767 net.cpp:100] Creating Layer pool1
I0414 03:08:36.740645 16767 net.cpp:434] pool1 <- conv1
I0414 03:08:36.740650 16767 net.cpp:408] pool1 -> pool1
I0414 03:08:36.740698 16767 net.cpp:150] Setting up pool1
I0414 03:08:36.740707 16767 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0414 03:08:36.740710 16767 net.cpp:165] Memory required for data: 3099099136
I0414 03:08:36.740715 16767 layer_factory.hpp:77] Creating layer conv2
I0414 03:08:36.740725 16767 net.cpp:100] Creating Layer conv2
I0414 03:08:36.740728 16767 net.cpp:434] conv2 <- pool1
I0414 03:08:36.740733 16767 net.cpp:408] conv2 -> conv2
I0414 03:08:36.748486 16767 net.cpp:150] Setting up conv2
I0414 03:08:36.748503 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.748508 16767 net.cpp:165] Memory required for data: 3298164736
I0414 03:08:36.748518 16767 layer_factory.hpp:77] Creating layer conv2_prescale
I0414 03:08:36.748529 16767 net.cpp:100] Creating Layer conv2_prescale
I0414 03:08:36.748535 16767 net.cpp:434] conv2_prescale <- conv2
I0414 03:08:36.748540 16767 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0414 03:08:36.748647 16767 net.cpp:150] Setting up conv2_prescale
I0414 03:08:36.748656 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.748661 16767 net.cpp:165] Memory required for data: 3497230336
I0414 03:08:36.748666 16767 layer_factory.hpp:77] Creating layer conv2_sTanH
I0414 03:08:36.748672 16767 net.cpp:100] Creating Layer conv2_sTanH
I0414 03:08:36.748675 16767 net.cpp:434] conv2_sTanH <- conv2
I0414 03:08:36.748680 16767 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0414 03:08:36.749538 16767 net.cpp:150] Setting up conv2_sTanH
I0414 03:08:36.749554 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.749559 16767 net.cpp:165] Memory required for data: 3696295936
I0414 03:08:36.749563 16767 layer_factory.hpp:77] Creating layer conv2_postscale
I0414 03:08:36.749570 16767 net.cpp:100] Creating Layer conv2_postscale
I0414 03:08:36.749575 16767 net.cpp:434] conv2_postscale <- conv2
I0414 03:08:36.749581 16767 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0414 03:08:36.749678 16767 net.cpp:150] Setting up conv2_postscale
I0414 03:08:36.749687 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.749691 16767 net.cpp:165] Memory required for data: 3895361536
I0414 03:08:36.749697 16767 layer_factory.hpp:77] Creating layer pool2
I0414 03:08:36.749706 16767 net.cpp:100] Creating Layer pool2
I0414 03:08:36.749711 16767 net.cpp:434] pool2 <- conv2
I0414 03:08:36.749716 16767 net.cpp:408] pool2 -> pool2
I0414 03:08:36.749757 16767 net.cpp:150] Setting up pool2
I0414 03:08:36.749765 16767 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0414 03:08:36.749769 16767 net.cpp:165] Memory required for data: 3945127936
I0414 03:08:36.749773 16767 layer_factory.hpp:77] Creating layer conv3
I0414 03:08:36.749781 16767 net.cpp:100] Creating Layer conv3
I0414 03:08:36.749786 16767 net.cpp:434] conv3 <- pool2
I0414 03:08:36.749791 16767 net.cpp:408] conv3 -> conv3
I0414 03:08:36.755692 16767 net.cpp:150] Setting up conv3
I0414 03:08:36.755710 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.755714 16767 net.cpp:165] Memory required for data: 3981991936
I0414 03:08:36.755724 16767 layer_factory.hpp:77] Creating layer conv3_prescale
I0414 03:08:36.755748 16767 net.cpp:100] Creating Layer conv3_prescale
I0414 03:08:36.755753 16767 net.cpp:434] conv3_prescale <- conv3
I0414 03:08:36.755759 16767 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0414 03:08:36.755856 16767 net.cpp:150] Setting up conv3_prescale
I0414 03:08:36.755864 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.755867 16767 net.cpp:165] Memory required for data: 4018855936
I0414 03:08:36.755872 16767 layer_factory.hpp:77] Creating layer conv3_sTanH
I0414 03:08:36.755887 16767 net.cpp:100] Creating Layer conv3_sTanH
I0414 03:08:36.755890 16767 net.cpp:434] conv3_sTanH <- conv3
I0414 03:08:36.755895 16767 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0414 03:08:36.757874 16767 net.cpp:150] Setting up conv3_sTanH
I0414 03:08:36.757891 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.757895 16767 net.cpp:165] Memory required for data: 4055719936
I0414 03:08:36.757899 16767 layer_factory.hpp:77] Creating layer conv3_postscale
I0414 03:08:36.757907 16767 net.cpp:100] Creating Layer conv3_postscale
I0414 03:08:36.757912 16767 net.cpp:434] conv3_postscale <- conv3
I0414 03:08:36.757918 16767 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0414 03:08:36.758016 16767 net.cpp:150] Setting up conv3_postscale
I0414 03:08:36.758025 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.758028 16767 net.cpp:165] Memory required for data: 4092583936
I0414 03:08:36.758033 16767 layer_factory.hpp:77] Creating layer pool3
I0414 03:08:36.758044 16767 net.cpp:100] Creating Layer pool3
I0414 03:08:36.758047 16767 net.cpp:434] pool3 <- conv3
I0414 03:08:36.758052 16767 net.cpp:408] pool3 -> pool3
I0414 03:08:36.758090 16767 net.cpp:150] Setting up pool3
I0414 03:08:36.758097 16767 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0414 03:08:36.758100 16767 net.cpp:165] Memory required for data: 4101799936
I0414 03:08:36.758103 16767 layer_factory.hpp:77] Creating layer fc4_300
I0414 03:08:36.758111 16767 net.cpp:100] Creating Layer fc4_300
I0414 03:08:36.758114 16767 net.cpp:434] fc4_300 <- pool3
I0414 03:08:36.758119 16767 net.cpp:408] fc4_300 -> fc4_300
I0414 03:08:36.769899 16767 net.cpp:150] Setting up fc4_300
I0414 03:08:36.769932 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.769940 16767 net.cpp:165] Memory required for data: 4103028736
I0414 03:08:36.769955 16767 layer_factory.hpp:77] Creating layer fc4_prescale
I0414 03:08:36.769970 16767 net.cpp:100] Creating Layer fc4_prescale
I0414 03:08:36.769979 16767 net.cpp:434] fc4_prescale <- fc4_300
I0414 03:08:36.769991 16767 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0414 03:08:36.770148 16767 net.cpp:150] Setting up fc4_prescale
I0414 03:08:36.770161 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.770169 16767 net.cpp:165] Memory required for data: 4104257536
I0414 03:08:36.770176 16767 layer_factory.hpp:77] Creating layer fc4_sTanH
I0414 03:08:36.770187 16767 net.cpp:100] Creating Layer fc4_sTanH
I0414 03:08:36.770195 16767 net.cpp:434] fc4_sTanH <- fc4_300
I0414 03:08:36.770202 16767 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0414 03:08:36.770539 16767 net.cpp:150] Setting up fc4_sTanH
I0414 03:08:36.770558 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.770565 16767 net.cpp:165] Memory required for data: 4105486336
I0414 03:08:36.770571 16767 layer_factory.hpp:77] Creating layer fc4_postscale
I0414 03:08:36.770584 16767 net.cpp:100] Creating Layer fc4_postscale
I0414 03:08:36.770592 16767 net.cpp:434] fc4_postscale <- fc4_300
I0414 03:08:36.770603 16767 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0414 03:08:36.770766 16767 net.cpp:150] Setting up fc4_postscale
I0414 03:08:36.770777 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.770784 16767 net.cpp:165] Memory required for data: 4106715136
I0414 03:08:36.770792 16767 layer_factory.hpp:77] Creating layer fc5_67
I0414 03:08:36.770804 16767 net.cpp:100] Creating Layer fc5_67
I0414 03:08:36.770812 16767 net.cpp:434] fc5_67 <- fc4_300
I0414 03:08:36.770820 16767 net.cpp:408] fc5_67 -> fc5_classes
I0414 03:08:36.773591 16767 net.cpp:150] Setting up fc5_67
I0414 03:08:36.773622 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.773632 16767 net.cpp:165] Memory required for data: 4106989568
I0414 03:08:36.773654 16767 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0414 03:08:36.773671 16767 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0414 03:08:36.773680 16767 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0414 03:08:36.773694 16767 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0414 03:08:36.773711 16767 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0414 03:08:36.773727 16767 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0414 03:08:36.773826 16767 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0414 03:08:36.773839 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.773849 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.773857 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.773864 16767 net.cpp:165] Memory required for data: 4107812864
I0414 03:08:36.773872 16767 layer_factory.hpp:77] Creating layer softmax
I0414 03:08:36.773885 16767 net.cpp:100] Creating Layer softmax
I0414 03:08:36.773895 16767 net.cpp:434] softmax <- fc5_classes_fc5_67_0_split_0
I0414 03:08:36.773906 16767 net.cpp:408] softmax -> softmax
I0414 03:08:36.774415 16767 net.cpp:150] Setting up softmax
I0414 03:08:36.774438 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.774446 16767 net.cpp:165] Memory required for data: 4108087296
I0414 03:08:36.774456 16767 layer_factory.hpp:77] Creating layer loss
I0414 03:08:36.774469 16767 net.cpp:100] Creating Layer loss
I0414 03:08:36.774478 16767 net.cpp:434] loss <- softmax
I0414 03:08:36.774489 16767 net.cpp:434] loss <- label_data_1_split_0
I0414 03:08:36.774502 16767 net.cpp:408] loss -> loss
I0414 03:08:36.774561 16767 net.cpp:150] Setting up loss
I0414 03:08:36.774574 16767 net.cpp:157] Top shape: (1)
I0414 03:08:36.774582 16767 net.cpp:160]     with loss weight 1
I0414 03:08:36.774621 16767 net.cpp:165] Memory required for data: 4108087300
I0414 03:08:36.774631 16767 layer_factory.hpp:77] Creating layer accuracy_1
I0414 03:08:36.774646 16767 net.cpp:100] Creating Layer accuracy_1
I0414 03:08:36.774654 16767 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0414 03:08:36.774665 16767 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0414 03:08:36.774677 16767 net.cpp:408] accuracy_1 -> accuracy_1
I0414 03:08:36.774699 16767 net.cpp:150] Setting up accuracy_1
I0414 03:08:36.774711 16767 net.cpp:157] Top shape: (1)
I0414 03:08:36.774718 16767 net.cpp:165] Memory required for data: 4108087304
I0414 03:08:36.774725 16767 layer_factory.hpp:77] Creating layer accuracy_5
I0414 03:08:36.774736 16767 net.cpp:100] Creating Layer accuracy_5
I0414 03:08:36.774745 16767 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0414 03:08:36.774755 16767 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0414 03:08:36.774770 16767 net.cpp:408] accuracy_5 -> accuracy_5
I0414 03:08:36.774785 16767 net.cpp:150] Setting up accuracy_5
I0414 03:08:36.774796 16767 net.cpp:157] Top shape: (1)
I0414 03:08:36.774802 16767 net.cpp:165] Memory required for data: 4108087308
I0414 03:08:36.774811 16767 layer_factory.hpp:77] Creating layer silence
I0414 03:08:36.774822 16767 net.cpp:100] Creating Layer silence
I0414 03:08:36.774830 16767 net.cpp:434] silence <- accuracy_1
I0414 03:08:36.774840 16767 net.cpp:434] silence <- accuracy_5
I0414 03:08:36.774849 16767 net.cpp:150] Setting up silence
I0414 03:08:36.774857 16767 net.cpp:165] Memory required for data: 4108087308
I0414 03:08:36.774863 16767 net.cpp:228] silence does not need backward computation.
I0414 03:08:36.774878 16767 net.cpp:228] accuracy_5 does not need backward computation.
I0414 03:08:36.774888 16767 net.cpp:228] accuracy_1 does not need backward computation.
I0414 03:08:36.774899 16767 net.cpp:226] loss needs backward computation.
I0414 03:08:36.774909 16767 net.cpp:226] softmax needs backward computation.
I0414 03:08:36.774942 16767 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0414 03:08:36.774951 16767 net.cpp:226] fc5_67 needs backward computation.
I0414 03:08:36.774960 16767 net.cpp:226] fc4_postscale needs backward computation.
I0414 03:08:36.774968 16767 net.cpp:226] fc4_sTanH needs backward computation.
I0414 03:08:36.774976 16767 net.cpp:226] fc4_prescale needs backward computation.
I0414 03:08:36.774983 16767 net.cpp:226] fc4_300 needs backward computation.
I0414 03:08:36.774992 16767 net.cpp:226] pool3 needs backward computation.
I0414 03:08:36.775001 16767 net.cpp:226] conv3_postscale needs backward computation.
I0414 03:08:36.775008 16767 net.cpp:226] conv3_sTanH needs backward computation.
I0414 03:08:36.775017 16767 net.cpp:226] conv3_prescale needs backward computation.
I0414 03:08:36.775024 16767 net.cpp:226] conv3 needs backward computation.
I0414 03:08:36.775033 16767 net.cpp:226] pool2 needs backward computation.
I0414 03:08:36.775041 16767 net.cpp:226] conv2_postscale needs backward computation.
I0414 03:08:36.775049 16767 net.cpp:226] conv2_sTanH needs backward computation.
I0414 03:08:36.775058 16767 net.cpp:226] conv2_prescale needs backward computation.
I0414 03:08:36.775063 16767 net.cpp:226] conv2 needs backward computation.
I0414 03:08:36.775073 16767 net.cpp:226] pool1 needs backward computation.
I0414 03:08:36.775080 16767 net.cpp:226] conv1_postscale needs backward computation.
I0414 03:08:36.775089 16767 net.cpp:226] conv1_sTanH needs backward computation.
I0414 03:08:36.775095 16767 net.cpp:226] conv1_prescale needs backward computation.
I0414 03:08:36.775104 16767 net.cpp:226] conv1 needs backward computation.
I0414 03:08:36.775120 16767 net.cpp:228] label_data_1_split does not need backward computation.
I0414 03:08:36.775130 16767 net.cpp:228] data does not need backward computation.
I0414 03:08:36.775138 16767 net.cpp:270] This network produces output loss
I0414 03:08:36.775192 16767 net.cpp:283] Network initialization done.
I0414 03:08:36.775704 16767 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_11/rtsd-r1/CoNorm/trial_1/test.prototxt
I0414 03:08:36.776094 16767 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: false
    crop_size: 48
    mean_value: 133
    mean_value: 133
    mean_value: 132
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "fc5_classes"
  top: "softmax"
}
layer {
  name: "loss"
  type: "MultinomialLogisticLoss"
  bottom: "softmax"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0414 03:08:36.776317 16767 layer_factory.hpp:77] Creating layer data
I0414 03:08:36.777642 16767 net.cpp:100] Creating Layer data
I0414 03:08:36.777662 16767 net.cpp:408] data -> data
I0414 03:08:36.777678 16767 net.cpp:408] data -> label
I0414 03:08:36.780237 16930 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0414 03:08:36.780418 16767 data_layer.cpp:41] output data size: 1024,3,48,48
I0414 03:08:36.841373 16767 net.cpp:150] Setting up data
I0414 03:08:36.841404 16767 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0414 03:08:36.841413 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.841418 16767 net.cpp:165] Memory required for data: 28315648
I0414 03:08:36.841425 16767 layer_factory.hpp:77] Creating layer label_data_1_split
I0414 03:08:36.841444 16767 net.cpp:100] Creating Layer label_data_1_split
I0414 03:08:36.841452 16767 net.cpp:434] label_data_1_split <- label
I0414 03:08:36.841465 16767 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0414 03:08:36.841485 16767 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0414 03:08:36.841496 16767 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0414 03:08:36.841589 16767 net.cpp:150] Setting up label_data_1_split
I0414 03:08:36.841600 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.841606 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.841614 16767 net.cpp:157] Top shape: 1024 (1024)
I0414 03:08:36.841619 16767 net.cpp:165] Memory required for data: 28327936
I0414 03:08:36.841647 16767 layer_factory.hpp:77] Creating layer conv1
I0414 03:08:36.841666 16767 net.cpp:100] Creating Layer conv1
I0414 03:08:36.841672 16767 net.cpp:434] conv1 <- data
I0414 03:08:36.841682 16767 net.cpp:408] conv1 -> conv1
I0414 03:08:36.848369 16767 net.cpp:150] Setting up conv1
I0414 03:08:36.848387 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.848394 16767 net.cpp:165] Memory required for data: 750862336
I0414 03:08:36.848412 16767 layer_factory.hpp:77] Creating layer conv1_prescale
I0414 03:08:36.848428 16767 net.cpp:100] Creating Layer conv1_prescale
I0414 03:08:36.848435 16767 net.cpp:434] conv1_prescale <- conv1
I0414 03:08:36.848448 16767 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0414 03:08:36.848565 16767 net.cpp:150] Setting up conv1_prescale
I0414 03:08:36.848577 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.848583 16767 net.cpp:165] Memory required for data: 1473396736
I0414 03:08:36.848597 16767 layer_factory.hpp:77] Creating layer conv1_sTanH
I0414 03:08:36.848608 16767 net.cpp:100] Creating Layer conv1_sTanH
I0414 03:08:36.848616 16767 net.cpp:434] conv1_sTanH <- conv1
I0414 03:08:36.848629 16767 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0414 03:08:36.848830 16767 net.cpp:150] Setting up conv1_sTanH
I0414 03:08:36.848845 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.848850 16767 net.cpp:165] Memory required for data: 2195931136
I0414 03:08:36.848856 16767 layer_factory.hpp:77] Creating layer conv1_postscale
I0414 03:08:36.848868 16767 net.cpp:100] Creating Layer conv1_postscale
I0414 03:08:36.848876 16767 net.cpp:434] conv1_postscale <- conv1
I0414 03:08:36.848886 16767 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0414 03:08:36.851377 16767 net.cpp:150] Setting up conv1_postscale
I0414 03:08:36.851392 16767 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0414 03:08:36.851397 16767 net.cpp:165] Memory required for data: 2918465536
I0414 03:08:36.851407 16767 layer_factory.hpp:77] Creating layer pool1
I0414 03:08:36.851420 16767 net.cpp:100] Creating Layer pool1
I0414 03:08:36.851428 16767 net.cpp:434] pool1 <- conv1
I0414 03:08:36.851436 16767 net.cpp:408] pool1 -> pool1
I0414 03:08:36.851492 16767 net.cpp:150] Setting up pool1
I0414 03:08:36.851505 16767 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0414 03:08:36.851510 16767 net.cpp:165] Memory required for data: 3099099136
I0414 03:08:36.851516 16767 layer_factory.hpp:77] Creating layer conv2
I0414 03:08:36.851529 16767 net.cpp:100] Creating Layer conv2
I0414 03:08:36.851536 16767 net.cpp:434] conv2 <- pool1
I0414 03:08:36.851549 16767 net.cpp:408] conv2 -> conv2
I0414 03:08:36.855933 16767 net.cpp:150] Setting up conv2
I0414 03:08:36.855955 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.855962 16767 net.cpp:165] Memory required for data: 3298164736
I0414 03:08:36.855978 16767 layer_factory.hpp:77] Creating layer conv2_prescale
I0414 03:08:36.855995 16767 net.cpp:100] Creating Layer conv2_prescale
I0414 03:08:36.856014 16767 net.cpp:434] conv2_prescale <- conv2
I0414 03:08:36.856025 16767 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0414 03:08:36.856154 16767 net.cpp:150] Setting up conv2_prescale
I0414 03:08:36.856168 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.856173 16767 net.cpp:165] Memory required for data: 3497230336
I0414 03:08:36.856181 16767 layer_factory.hpp:77] Creating layer conv2_sTanH
I0414 03:08:36.856192 16767 net.cpp:100] Creating Layer conv2_sTanH
I0414 03:08:36.856200 16767 net.cpp:434] conv2_sTanH <- conv2
I0414 03:08:36.856217 16767 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0414 03:08:36.857072 16767 net.cpp:150] Setting up conv2_sTanH
I0414 03:08:36.857091 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.857097 16767 net.cpp:165] Memory required for data: 3696295936
I0414 03:08:36.857103 16767 layer_factory.hpp:77] Creating layer conv2_postscale
I0414 03:08:36.857116 16767 net.cpp:100] Creating Layer conv2_postscale
I0414 03:08:36.857136 16767 net.cpp:434] conv2_postscale <- conv2
I0414 03:08:36.857147 16767 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0414 03:08:36.857265 16767 net.cpp:150] Setting up conv2_postscale
I0414 03:08:36.857278 16767 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0414 03:08:36.857286 16767 net.cpp:165] Memory required for data: 3895361536
I0414 03:08:36.857298 16767 layer_factory.hpp:77] Creating layer pool2
I0414 03:08:36.857311 16767 net.cpp:100] Creating Layer pool2
I0414 03:08:36.857319 16767 net.cpp:434] pool2 <- conv2
I0414 03:08:36.857327 16767 net.cpp:408] pool2 -> pool2
I0414 03:08:36.857383 16767 net.cpp:150] Setting up pool2
I0414 03:08:36.857395 16767 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0414 03:08:36.857401 16767 net.cpp:165] Memory required for data: 3945127936
I0414 03:08:36.857406 16767 layer_factory.hpp:77] Creating layer conv3
I0414 03:08:36.857420 16767 net.cpp:100] Creating Layer conv3
I0414 03:08:36.857427 16767 net.cpp:434] conv3 <- pool2
I0414 03:08:36.857439 16767 net.cpp:408] conv3 -> conv3
I0414 03:08:36.867388 16767 net.cpp:150] Setting up conv3
I0414 03:08:36.867408 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.867415 16767 net.cpp:165] Memory required for data: 3981991936
I0414 03:08:36.867430 16767 layer_factory.hpp:77] Creating layer conv3_prescale
I0414 03:08:36.867445 16767 net.cpp:100] Creating Layer conv3_prescale
I0414 03:08:36.867453 16767 net.cpp:434] conv3_prescale <- conv3
I0414 03:08:36.867465 16767 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0414 03:08:36.867576 16767 net.cpp:150] Setting up conv3_prescale
I0414 03:08:36.867589 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.867594 16767 net.cpp:165] Memory required for data: 4018855936
I0414 03:08:36.867607 16767 layer_factory.hpp:77] Creating layer conv3_sTanH
I0414 03:08:36.867620 16767 net.cpp:100] Creating Layer conv3_sTanH
I0414 03:08:36.867627 16767 net.cpp:434] conv3_sTanH <- conv3
I0414 03:08:36.867636 16767 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0414 03:08:36.871736 16767 net.cpp:150] Setting up conv3_sTanH
I0414 03:08:36.871762 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.871767 16767 net.cpp:165] Memory required for data: 4055719936
I0414 03:08:36.871773 16767 layer_factory.hpp:77] Creating layer conv3_postscale
I0414 03:08:36.871783 16767 net.cpp:100] Creating Layer conv3_postscale
I0414 03:08:36.871790 16767 net.cpp:434] conv3_postscale <- conv3
I0414 03:08:36.871800 16767 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0414 03:08:36.871969 16767 net.cpp:150] Setting up conv3_postscale
I0414 03:08:36.871985 16767 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0414 03:08:36.871989 16767 net.cpp:165] Memory required for data: 4092583936
I0414 03:08:36.871996 16767 layer_factory.hpp:77] Creating layer pool3
I0414 03:08:36.872022 16767 net.cpp:100] Creating Layer pool3
I0414 03:08:36.872028 16767 net.cpp:434] pool3 <- conv3
I0414 03:08:36.872035 16767 net.cpp:408] pool3 -> pool3
I0414 03:08:36.872094 16767 net.cpp:150] Setting up pool3
I0414 03:08:36.872104 16767 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0414 03:08:36.872114 16767 net.cpp:165] Memory required for data: 4101799936
I0414 03:08:36.872118 16767 layer_factory.hpp:77] Creating layer fc4_300
I0414 03:08:36.872129 16767 net.cpp:100] Creating Layer fc4_300
I0414 03:08:36.872135 16767 net.cpp:434] fc4_300 <- pool3
I0414 03:08:36.872144 16767 net.cpp:408] fc4_300 -> fc4_300
I0414 03:08:36.879075 16767 net.cpp:150] Setting up fc4_300
I0414 03:08:36.879096 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.879101 16767 net.cpp:165] Memory required for data: 4103028736
I0414 03:08:36.879108 16767 layer_factory.hpp:77] Creating layer fc4_prescale
I0414 03:08:36.879122 16767 net.cpp:100] Creating Layer fc4_prescale
I0414 03:08:36.879128 16767 net.cpp:434] fc4_prescale <- fc4_300
I0414 03:08:36.879135 16767 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0414 03:08:36.879258 16767 net.cpp:150] Setting up fc4_prescale
I0414 03:08:36.879271 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.879297 16767 net.cpp:165] Memory required for data: 4104257536
I0414 03:08:36.879304 16767 layer_factory.hpp:77] Creating layer fc4_sTanH
I0414 03:08:36.879313 16767 net.cpp:100] Creating Layer fc4_sTanH
I0414 03:08:36.879318 16767 net.cpp:434] fc4_sTanH <- fc4_300
I0414 03:08:36.879326 16767 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0414 03:08:36.879576 16767 net.cpp:150] Setting up fc4_sTanH
I0414 03:08:36.879591 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.879596 16767 net.cpp:165] Memory required for data: 4105486336
I0414 03:08:36.879601 16767 layer_factory.hpp:77] Creating layer fc4_postscale
I0414 03:08:36.879611 16767 net.cpp:100] Creating Layer fc4_postscale
I0414 03:08:36.879617 16767 net.cpp:434] fc4_postscale <- fc4_300
I0414 03:08:36.879624 16767 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0414 03:08:36.879758 16767 net.cpp:150] Setting up fc4_postscale
I0414 03:08:36.879778 16767 net.cpp:157] Top shape: 1024 300 (307200)
I0414 03:08:36.879783 16767 net.cpp:165] Memory required for data: 4106715136
I0414 03:08:36.879789 16767 layer_factory.hpp:77] Creating layer fc5_67
I0414 03:08:36.879801 16767 net.cpp:100] Creating Layer fc5_67
I0414 03:08:36.879806 16767 net.cpp:434] fc5_67 <- fc4_300
I0414 03:08:36.879813 16767 net.cpp:408] fc5_67 -> fc5_classes
I0414 03:08:36.882293 16767 net.cpp:150] Setting up fc5_67
I0414 03:08:36.882313 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.882318 16767 net.cpp:165] Memory required for data: 4106989568
I0414 03:08:36.882333 16767 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0414 03:08:36.882344 16767 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0414 03:08:36.882349 16767 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0414 03:08:36.882361 16767 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0414 03:08:36.882375 16767 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0414 03:08:36.882385 16767 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0414 03:08:36.882454 16767 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0414 03:08:36.882465 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.882472 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.882475 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.882479 16767 net.cpp:165] Memory required for data: 4107812864
I0414 03:08:36.882483 16767 layer_factory.hpp:77] Creating layer softmax
I0414 03:08:36.882494 16767 net.cpp:100] Creating Layer softmax
I0414 03:08:36.882500 16767 net.cpp:434] softmax <- fc5_classes_fc5_67_0_split_0
I0414 03:08:36.882506 16767 net.cpp:408] softmax -> softmax
I0414 03:08:36.882832 16767 net.cpp:150] Setting up softmax
I0414 03:08:36.882849 16767 net.cpp:157] Top shape: 1024 67 (68608)
I0414 03:08:36.882854 16767 net.cpp:165] Memory required for data: 4108087296
I0414 03:08:36.882859 16767 layer_factory.hpp:77] Creating layer loss
I0414 03:08:36.882868 16767 net.cpp:100] Creating Layer loss
I0414 03:08:36.882874 16767 net.cpp:434] loss <- softmax
I0414 03:08:36.882879 16767 net.cpp:434] loss <- label_data_1_split_0
I0414 03:08:36.882889 16767 net.cpp:408] loss -> loss
I0414 03:08:36.882927 16767 net.cpp:150] Setting up loss
I0414 03:08:36.882937 16767 net.cpp:157] Top shape: (1)
I0414 03:08:36.882941 16767 net.cpp:160]     with loss weight 1
I0414 03:08:36.882953 16767 net.cpp:165] Memory required for data: 4108087300
I0414 03:08:36.882957 16767 layer_factory.hpp:77] Creating layer accuracy_1
I0414 03:08:36.882966 16767 net.cpp:100] Creating Layer accuracy_1
I0414 03:08:36.882975 16767 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0414 03:08:36.882987 16767 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0414 03:08:36.882998 16767 net.cpp:408] accuracy_1 -> accuracy_1
I0414 03:08:36.883015 16767 net.cpp:150] Setting up accuracy_1
I0414 03:08:36.883025 16767 net.cpp:157] Top shape: (1)
I0414 03:08:36.883033 16767 net.cpp:165] Memory required for data: 4108087304
I0414 03:08:36.883059 16767 layer_factory.hpp:77] Creating layer accuracy_5
I0414 03:08:36.883074 16767 net.cpp:100] Creating Layer accuracy_5
I0414 03:08:36.883083 16767 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0414 03:08:36.883093 16767 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0414 03:08:36.883106 16767 net.cpp:408] accuracy_5 -> accuracy_5
I0414 03:08:36.883121 16767 net.cpp:150] Setting up accuracy_5
I0414 03:08:36.883131 16767 net.cpp:157] Top shape: (1)
I0414 03:08:36.883138 16767 net.cpp:165] Memory required for data: 4108087308
I0414 03:08:36.883144 16767 net.cpp:228] accuracy_5 does not need backward computation.
I0414 03:08:36.883154 16767 net.cpp:228] accuracy_1 does not need backward computation.
I0414 03:08:36.883163 16767 net.cpp:226] loss needs backward computation.
I0414 03:08:36.883172 16767 net.cpp:226] softmax needs backward computation.
I0414 03:08:36.883182 16767 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0414 03:08:36.883191 16767 net.cpp:226] fc5_67 needs backward computation.
I0414 03:08:36.883203 16767 net.cpp:226] fc4_postscale needs backward computation.
I0414 03:08:36.883210 16767 net.cpp:226] fc4_sTanH needs backward computation.
I0414 03:08:36.883219 16767 net.cpp:226] fc4_prescale needs backward computation.
I0414 03:08:36.883224 16767 net.cpp:226] fc4_300 needs backward computation.
I0414 03:08:36.883232 16767 net.cpp:226] pool3 needs backward computation.
I0414 03:08:36.883239 16767 net.cpp:226] conv3_postscale needs backward computation.
I0414 03:08:36.883246 16767 net.cpp:226] conv3_sTanH needs backward computation.
I0414 03:08:36.883257 16767 net.cpp:226] conv3_prescale needs backward computation.
I0414 03:08:36.883265 16767 net.cpp:226] conv3 needs backward computation.
I0414 03:08:36.883272 16767 net.cpp:226] pool2 needs backward computation.
I0414 03:08:36.883280 16767 net.cpp:226] conv2_postscale needs backward computation.
I0414 03:08:36.883287 16767 net.cpp:226] conv2_sTanH needs backward computation.
I0414 03:08:36.883293 16767 net.cpp:226] conv2_prescale needs backward computation.
I0414 03:08:36.883299 16767 net.cpp:226] conv2 needs backward computation.
I0414 03:08:36.883311 16767 net.cpp:226] pool1 needs backward computation.
I0414 03:08:36.883319 16767 net.cpp:226] conv1_postscale needs backward computation.
I0414 03:08:36.883327 16767 net.cpp:226] conv1_sTanH needs backward computation.
I0414 03:08:36.883335 16767 net.cpp:226] conv1_prescale needs backward computation.
I0414 03:08:36.883342 16767 net.cpp:226] conv1 needs backward computation.
I0414 03:08:36.883350 16767 net.cpp:228] label_data_1_split does not need backward computation.
I0414 03:08:36.883359 16767 net.cpp:228] data does not need backward computation.
I0414 03:08:36.883368 16767 net.cpp:270] This network produces output accuracy_1
I0414 03:08:36.883375 16767 net.cpp:270] This network produces output accuracy_5
I0414 03:08:36.883383 16767 net.cpp:270] This network produces output loss
I0414 03:08:36.883419 16767 net.cpp:283] Network initialization done.
I0414 03:08:36.883539 16767 solver.cpp:72] Solver scaffolding done.
I0414 03:08:36.885105 16767 caffe.cpp:251] Starting Optimization
I0414 03:08:36.885123 16767 solver.cpp:291] Solving 
I0414 03:08:36.885129 16767 solver.cpp:292] Learning Rate Policy: step
I0414 03:08:36.892915 16767 solver.cpp:349] Iteration 0, Testing net (#0)
I0414 03:08:36.898279 16767 net.cpp:693] Ignoring source layer silence
I0414 03:08:38.026489 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0032959
I0414 03:08:38.026516 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.020874
I0414 03:08:38.026526 16767 solver.cpp:416]     Test net output #2: loss = 4.38532 (* 1 = 4.38532 loss)
I0414 03:08:38.198813 16767 solver.cpp:240] Iteration 0, loss = 4.36903
I0414 03:08:38.198849 16767 solver.cpp:256]     Train net output #0: loss = 4.36903 (* 1 = 4.36903 loss)
I0414 03:08:38.198868 16767 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0414 03:08:38.576586 16767 solver.cpp:240] Iteration 1, loss = 3.98315
I0414 03:08:38.576653 16767 solver.cpp:256]     Train net output #0: loss = 3.98315 (* 1 = 3.98315 loss)
I0414 03:08:38.576661 16767 sgd_solver.cpp:106] Iteration 1, lr = 0.0001
I0414 03:08:38.959077 16767 solver.cpp:240] Iteration 2, loss = 3.7395
I0414 03:08:38.959106 16767 solver.cpp:256]     Train net output #0: loss = 3.7395 (* 1 = 3.7395 loss)
I0414 03:08:38.959115 16767 sgd_solver.cpp:106] Iteration 2, lr = 0.0001
I0414 03:08:39.340358 16767 solver.cpp:240] Iteration 3, loss = 3.63383
I0414 03:08:39.340394 16767 solver.cpp:256]     Train net output #0: loss = 3.63383 (* 1 = 3.63383 loss)
I0414 03:08:39.340402 16767 sgd_solver.cpp:106] Iteration 3, lr = 0.0001
I0414 03:08:39.719991 16767 solver.cpp:240] Iteration 4, loss = 3.54805
I0414 03:08:39.720026 16767 solver.cpp:256]     Train net output #0: loss = 3.54805 (* 1 = 3.54805 loss)
I0414 03:08:39.720034 16767 sgd_solver.cpp:106] Iteration 4, lr = 0.0001
I0414 03:08:40.101552 16767 solver.cpp:240] Iteration 5, loss = 3.56216
I0414 03:08:40.101593 16767 solver.cpp:256]     Train net output #0: loss = 3.56216 (* 1 = 3.56216 loss)
I0414 03:08:40.101601 16767 sgd_solver.cpp:106] Iteration 5, lr = 0.0001
I0414 03:08:40.485430 16767 solver.cpp:240] Iteration 6, loss = 3.42397
I0414 03:08:40.485465 16767 solver.cpp:256]     Train net output #0: loss = 3.42397 (* 1 = 3.42397 loss)
I0414 03:08:40.485473 16767 sgd_solver.cpp:106] Iteration 6, lr = 0.0001
I0414 03:08:40.869086 16767 solver.cpp:240] Iteration 7, loss = 3.41214
I0414 03:08:40.869123 16767 solver.cpp:256]     Train net output #0: loss = 3.41214 (* 1 = 3.41214 loss)
I0414 03:08:40.869132 16767 sgd_solver.cpp:106] Iteration 7, lr = 0.0001
I0414 03:08:41.253794 16767 solver.cpp:240] Iteration 8, loss = 3.33311
I0414 03:08:41.253825 16767 solver.cpp:256]     Train net output #0: loss = 3.33311 (* 1 = 3.33311 loss)
I0414 03:08:41.253834 16767 sgd_solver.cpp:106] Iteration 8, lr = 0.0001
I0414 03:08:41.643970 16767 solver.cpp:240] Iteration 9, loss = 3.36255
I0414 03:08:41.644013 16767 solver.cpp:256]     Train net output #0: loss = 3.36255 (* 1 = 3.36255 loss)
I0414 03:08:41.644022 16767 sgd_solver.cpp:106] Iteration 9, lr = 0.0001
I0414 03:08:42.026684 16767 solver.cpp:240] Iteration 10, loss = 3.3797
I0414 03:08:42.026718 16767 solver.cpp:256]     Train net output #0: loss = 3.3797 (* 1 = 3.3797 loss)
I0414 03:08:42.026726 16767 sgd_solver.cpp:106] Iteration 10, lr = 0.0001
I0414 03:08:42.407979 16767 solver.cpp:240] Iteration 11, loss = 3.29117
I0414 03:08:42.408015 16767 solver.cpp:256]     Train net output #0: loss = 3.29117 (* 1 = 3.29117 loss)
I0414 03:08:42.408023 16767 sgd_solver.cpp:106] Iteration 11, lr = 0.0001
I0414 03:08:42.787909 16767 solver.cpp:240] Iteration 12, loss = 3.21036
I0414 03:08:42.787945 16767 solver.cpp:256]     Train net output #0: loss = 3.21036 (* 1 = 3.21036 loss)
I0414 03:08:42.787952 16767 sgd_solver.cpp:106] Iteration 12, lr = 0.0001
I0414 03:08:43.171166 16767 solver.cpp:240] Iteration 13, loss = 3.24548
I0414 03:08:43.171205 16767 solver.cpp:256]     Train net output #0: loss = 3.24548 (* 1 = 3.24548 loss)
I0414 03:08:43.171213 16767 sgd_solver.cpp:106] Iteration 13, lr = 0.0001
I0414 03:08:43.554329 16767 solver.cpp:240] Iteration 14, loss = 3.2309
I0414 03:08:43.554366 16767 solver.cpp:256]     Train net output #0: loss = 3.2309 (* 1 = 3.2309 loss)
I0414 03:08:43.554374 16767 sgd_solver.cpp:106] Iteration 14, lr = 0.0001
I0414 03:08:43.939323 16767 solver.cpp:240] Iteration 15, loss = 3.12957
I0414 03:08:43.939362 16767 solver.cpp:256]     Train net output #0: loss = 3.12957 (* 1 = 3.12957 loss)
I0414 03:08:43.939369 16767 sgd_solver.cpp:106] Iteration 15, lr = 0.0001
I0414 03:08:44.336840 16767 solver.cpp:240] Iteration 16, loss = 3.12863
I0414 03:08:44.336872 16767 solver.cpp:256]     Train net output #0: loss = 3.12863 (* 1 = 3.12863 loss)
I0414 03:08:44.336880 16767 sgd_solver.cpp:106] Iteration 16, lr = 0.0001
I0414 03:08:44.730727 16767 solver.cpp:240] Iteration 17, loss = 3.00951
I0414 03:08:44.730759 16767 solver.cpp:256]     Train net output #0: loss = 3.00951 (* 1 = 3.00951 loss)
I0414 03:08:44.730794 16767 sgd_solver.cpp:106] Iteration 17, lr = 0.0001
I0414 03:08:45.121338 16767 solver.cpp:240] Iteration 18, loss = 2.99483
I0414 03:08:45.121374 16767 solver.cpp:256]     Train net output #0: loss = 2.99483 (* 1 = 2.99483 loss)
I0414 03:08:45.121383 16767 sgd_solver.cpp:106] Iteration 18, lr = 0.0001
I0414 03:08:45.516016 16767 solver.cpp:240] Iteration 19, loss = 2.92619
I0414 03:08:45.516057 16767 solver.cpp:256]     Train net output #0: loss = 2.92619 (* 1 = 2.92619 loss)
I0414 03:08:45.516065 16767 sgd_solver.cpp:106] Iteration 19, lr = 0.0001
I0414 03:08:45.904850 16767 solver.cpp:240] Iteration 20, loss = 2.94786
I0414 03:08:45.904884 16767 solver.cpp:256]     Train net output #0: loss = 2.94786 (* 1 = 2.94786 loss)
I0414 03:08:45.904892 16767 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
I0414 03:08:46.296962 16767 solver.cpp:240] Iteration 21, loss = 2.90138
I0414 03:08:46.296993 16767 solver.cpp:256]     Train net output #0: loss = 2.90138 (* 1 = 2.90138 loss)
I0414 03:08:46.297001 16767 sgd_solver.cpp:106] Iteration 21, lr = 0.0001
I0414 03:08:46.690517 16767 solver.cpp:240] Iteration 22, loss = 2.99664
I0414 03:08:46.690549 16767 solver.cpp:256]     Train net output #0: loss = 2.99664 (* 1 = 2.99664 loss)
I0414 03:08:46.690557 16767 sgd_solver.cpp:106] Iteration 22, lr = 0.0001
I0414 03:08:47.086928 16767 solver.cpp:240] Iteration 23, loss = 2.88233
I0414 03:08:47.086964 16767 solver.cpp:256]     Train net output #0: loss = 2.88233 (* 1 = 2.88233 loss)
I0414 03:08:47.086973 16767 sgd_solver.cpp:106] Iteration 23, lr = 0.0001
I0414 03:08:47.480566 16767 solver.cpp:240] Iteration 24, loss = 2.89316
I0414 03:08:47.480602 16767 solver.cpp:256]     Train net output #0: loss = 2.89316 (* 1 = 2.89316 loss)
I0414 03:08:47.480612 16767 sgd_solver.cpp:106] Iteration 24, lr = 0.0001
I0414 03:08:47.480924 16767 solver.cpp:349] Iteration 25, Testing net (#0)
I0414 03:08:47.480947 16767 net.cpp:693] Ignoring source layer silence
I0414 03:08:48.850641 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.36499
I0414 03:08:48.850677 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.578247
I0414 03:08:48.850687 16767 solver.cpp:416]     Test net output #2: loss = 2.89186 (* 1 = 2.89186 loss)
I0414 03:08:48.991227 16767 solver.cpp:240] Iteration 25, loss = 2.80922
I0414 03:08:48.991266 16767 solver.cpp:256]     Train net output #0: loss = 2.80922 (* 1 = 2.80922 loss)
I0414 03:08:48.991276 16767 sgd_solver.cpp:106] Iteration 25, lr = 0.0001
I0414 03:08:49.395985 16767 solver.cpp:240] Iteration 26, loss = 2.74087
I0414 03:08:49.396021 16767 solver.cpp:256]     Train net output #0: loss = 2.74087 (* 1 = 2.74087 loss)
I0414 03:08:49.396031 16767 sgd_solver.cpp:106] Iteration 26, lr = 0.0001
I0414 03:08:49.800758 16767 solver.cpp:240] Iteration 27, loss = 2.67959
I0414 03:08:49.800804 16767 solver.cpp:256]     Train net output #0: loss = 2.67959 (* 1 = 2.67959 loss)
I0414 03:08:49.800812 16767 sgd_solver.cpp:106] Iteration 27, lr = 0.0001
I0414 03:08:50.204557 16767 solver.cpp:240] Iteration 28, loss = 2.69263
I0414 03:08:50.204596 16767 solver.cpp:256]     Train net output #0: loss = 2.69263 (* 1 = 2.69263 loss)
I0414 03:08:50.204604 16767 sgd_solver.cpp:106] Iteration 28, lr = 0.0001
I0414 03:08:50.608129 16767 solver.cpp:240] Iteration 29, loss = 2.65028
I0414 03:08:50.608175 16767 solver.cpp:256]     Train net output #0: loss = 2.65028 (* 1 = 2.65028 loss)
I0414 03:08:50.608184 16767 sgd_solver.cpp:106] Iteration 29, lr = 0.0001
I0414 03:08:51.009912 16767 solver.cpp:240] Iteration 30, loss = 2.66028
I0414 03:08:51.009944 16767 solver.cpp:256]     Train net output #0: loss = 2.66028 (* 1 = 2.66028 loss)
I0414 03:08:51.009953 16767 sgd_solver.cpp:106] Iteration 30, lr = 0.0001
I0414 03:08:51.415568 16767 solver.cpp:240] Iteration 31, loss = 2.5112
I0414 03:08:51.415607 16767 solver.cpp:256]     Train net output #0: loss = 2.5112 (* 1 = 2.5112 loss)
I0414 03:08:51.415617 16767 sgd_solver.cpp:106] Iteration 31, lr = 0.0001
I0414 03:08:51.820885 16767 solver.cpp:240] Iteration 32, loss = 2.56238
I0414 03:08:51.820951 16767 solver.cpp:256]     Train net output #0: loss = 2.56238 (* 1 = 2.56238 loss)
I0414 03:08:51.820961 16767 sgd_solver.cpp:106] Iteration 32, lr = 0.0001
I0414 03:08:52.226814 16767 solver.cpp:240] Iteration 33, loss = 2.48761
I0414 03:08:52.226853 16767 solver.cpp:256]     Train net output #0: loss = 2.48761 (* 1 = 2.48761 loss)
I0414 03:08:52.226862 16767 sgd_solver.cpp:106] Iteration 33, lr = 0.0001
I0414 03:08:52.633184 16767 solver.cpp:240] Iteration 34, loss = 2.54507
I0414 03:08:52.633222 16767 solver.cpp:256]     Train net output #0: loss = 2.54507 (* 1 = 2.54507 loss)
I0414 03:08:52.633230 16767 sgd_solver.cpp:106] Iteration 34, lr = 0.0001
I0414 03:08:53.039029 16767 solver.cpp:240] Iteration 35, loss = 2.47918
I0414 03:08:53.039063 16767 solver.cpp:256]     Train net output #0: loss = 2.47918 (* 1 = 2.47918 loss)
I0414 03:08:53.039072 16767 sgd_solver.cpp:106] Iteration 35, lr = 0.0001
I0414 03:08:53.444279 16767 solver.cpp:240] Iteration 36, loss = 2.42434
I0414 03:08:53.444316 16767 solver.cpp:256]     Train net output #0: loss = 2.42434 (* 1 = 2.42434 loss)
I0414 03:08:53.444325 16767 sgd_solver.cpp:106] Iteration 36, lr = 0.0001
I0414 03:08:53.846388 16767 solver.cpp:240] Iteration 37, loss = 2.35739
I0414 03:08:53.846424 16767 solver.cpp:256]     Train net output #0: loss = 2.35739 (* 1 = 2.35739 loss)
I0414 03:08:53.846433 16767 sgd_solver.cpp:106] Iteration 37, lr = 0.0001
I0414 03:08:54.253022 16767 solver.cpp:240] Iteration 38, loss = 2.39776
I0414 03:08:54.253067 16767 solver.cpp:256]     Train net output #0: loss = 2.39776 (* 1 = 2.39776 loss)
I0414 03:08:54.253077 16767 sgd_solver.cpp:106] Iteration 38, lr = 0.0001
I0414 03:08:54.658427 16767 solver.cpp:240] Iteration 39, loss = 2.34866
I0414 03:08:54.658457 16767 solver.cpp:256]     Train net output #0: loss = 2.34866 (* 1 = 2.34866 loss)
I0414 03:08:54.658465 16767 sgd_solver.cpp:106] Iteration 39, lr = 0.0001
I0414 03:08:55.064956 16767 solver.cpp:240] Iteration 40, loss = 2.25512
I0414 03:08:55.064996 16767 solver.cpp:256]     Train net output #0: loss = 2.25512 (* 1 = 2.25512 loss)
I0414 03:08:55.065006 16767 sgd_solver.cpp:106] Iteration 40, lr = 0.0001
I0414 03:08:55.472632 16767 solver.cpp:240] Iteration 41, loss = 2.25133
I0414 03:08:55.472667 16767 solver.cpp:256]     Train net output #0: loss = 2.25133 (* 1 = 2.25133 loss)
I0414 03:08:55.472676 16767 sgd_solver.cpp:106] Iteration 41, lr = 0.0001
I0414 03:08:55.878852 16767 solver.cpp:240] Iteration 42, loss = 2.19319
I0414 03:08:55.878891 16767 solver.cpp:256]     Train net output #0: loss = 2.19319 (* 1 = 2.19319 loss)
I0414 03:08:55.878900 16767 sgd_solver.cpp:106] Iteration 42, lr = 0.0001
I0414 03:08:56.282554 16767 solver.cpp:240] Iteration 43, loss = 2.09257
I0414 03:08:56.282588 16767 solver.cpp:256]     Train net output #0: loss = 2.09257 (* 1 = 2.09257 loss)
I0414 03:08:56.282598 16767 sgd_solver.cpp:106] Iteration 43, lr = 0.0001
I0414 03:08:56.684415 16767 solver.cpp:240] Iteration 44, loss = 2.1226
I0414 03:08:56.684455 16767 solver.cpp:256]     Train net output #0: loss = 2.1226 (* 1 = 2.1226 loss)
I0414 03:08:56.684464 16767 sgd_solver.cpp:106] Iteration 44, lr = 0.0001
I0414 03:08:57.090338 16767 solver.cpp:240] Iteration 45, loss = 2.06543
I0414 03:08:57.090371 16767 solver.cpp:256]     Train net output #0: loss = 2.06543 (* 1 = 2.06543 loss)
I0414 03:08:57.090379 16767 sgd_solver.cpp:106] Iteration 45, lr = 0.0001
I0414 03:08:57.496126 16767 solver.cpp:240] Iteration 46, loss = 2.10269
I0414 03:08:57.496166 16767 solver.cpp:256]     Train net output #0: loss = 2.10269 (* 1 = 2.10269 loss)
I0414 03:08:57.496175 16767 sgd_solver.cpp:106] Iteration 46, lr = 0.0001
I0414 03:08:57.901857 16767 solver.cpp:240] Iteration 47, loss = 2.11255
I0414 03:08:57.901895 16767 solver.cpp:256]     Train net output #0: loss = 2.11255 (* 1 = 2.11255 loss)
I0414 03:08:57.901903 16767 sgd_solver.cpp:106] Iteration 47, lr = 0.0001
I0414 03:08:58.305995 16767 solver.cpp:240] Iteration 48, loss = 2.14215
I0414 03:08:58.306031 16767 solver.cpp:256]     Train net output #0: loss = 2.14215 (* 1 = 2.14215 loss)
I0414 03:08:58.306073 16767 sgd_solver.cpp:106] Iteration 48, lr = 0.0001
I0414 03:08:58.708066 16767 solver.cpp:240] Iteration 49, loss = 2.11665
I0414 03:08:58.708098 16767 solver.cpp:256]     Train net output #0: loss = 2.11665 (* 1 = 2.11665 loss)
I0414 03:08:58.708106 16767 sgd_solver.cpp:106] Iteration 49, lr = 0.0001
I0414 03:08:58.708420 16767 solver.cpp:349] Iteration 50, Testing net (#0)
I0414 03:08:58.708437 16767 net.cpp:693] Ignoring source layer silence
I0414 03:09:00.089943 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.537964
I0414 03:09:00.089974 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.69458
I0414 03:09:00.089984 16767 solver.cpp:416]     Test net output #2: loss = 2.15201 (* 1 = 2.15201 loss)
I0414 03:09:00.230381 16767 solver.cpp:240] Iteration 50, loss = 1.95144
I0414 03:09:00.230414 16767 solver.cpp:256]     Train net output #0: loss = 1.95144 (* 1 = 1.95144 loss)
I0414 03:09:00.230423 16767 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I0414 03:09:00.636349 16767 solver.cpp:240] Iteration 51, loss = 1.98613
I0414 03:09:00.636384 16767 solver.cpp:256]     Train net output #0: loss = 1.98613 (* 1 = 1.98613 loss)
I0414 03:09:00.636394 16767 sgd_solver.cpp:106] Iteration 51, lr = 0.0001
I0414 03:09:01.042098 16767 solver.cpp:240] Iteration 52, loss = 1.92427
I0414 03:09:01.042134 16767 solver.cpp:256]     Train net output #0: loss = 1.92427 (* 1 = 1.92427 loss)
I0414 03:09:01.042141 16767 sgd_solver.cpp:106] Iteration 52, lr = 0.0001
I0414 03:09:01.447727 16767 solver.cpp:240] Iteration 53, loss = 1.93391
I0414 03:09:01.447764 16767 solver.cpp:256]     Train net output #0: loss = 1.93391 (* 1 = 1.93391 loss)
I0414 03:09:01.447772 16767 sgd_solver.cpp:106] Iteration 53, lr = 0.0001
I0414 03:09:01.853116 16767 solver.cpp:240] Iteration 54, loss = 1.91912
I0414 03:09:01.853150 16767 solver.cpp:256]     Train net output #0: loss = 1.91912 (* 1 = 1.91912 loss)
I0414 03:09:01.853159 16767 sgd_solver.cpp:106] Iteration 54, lr = 0.0001
I0414 03:09:02.259265 16767 solver.cpp:240] Iteration 55, loss = 1.94512
I0414 03:09:02.259306 16767 solver.cpp:256]     Train net output #0: loss = 1.94512 (* 1 = 1.94512 loss)
I0414 03:09:02.259315 16767 sgd_solver.cpp:106] Iteration 55, lr = 0.0001
I0414 03:09:02.665472 16767 solver.cpp:240] Iteration 56, loss = 1.85734
I0414 03:09:02.665510 16767 solver.cpp:256]     Train net output #0: loss = 1.85734 (* 1 = 1.85734 loss)
I0414 03:09:02.665518 16767 sgd_solver.cpp:106] Iteration 56, lr = 0.0001
I0414 03:09:03.071184 16767 solver.cpp:240] Iteration 57, loss = 1.872
I0414 03:09:03.071215 16767 solver.cpp:256]     Train net output #0: loss = 1.872 (* 1 = 1.872 loss)
I0414 03:09:03.071223 16767 sgd_solver.cpp:106] Iteration 57, lr = 0.0001
I0414 03:09:03.475798 16767 solver.cpp:240] Iteration 58, loss = 1.83561
I0414 03:09:03.475834 16767 solver.cpp:256]     Train net output #0: loss = 1.83561 (* 1 = 1.83561 loss)
I0414 03:09:03.475842 16767 sgd_solver.cpp:106] Iteration 58, lr = 0.0001
I0414 03:09:03.881650 16767 solver.cpp:240] Iteration 59, loss = 1.87785
I0414 03:09:03.881687 16767 solver.cpp:256]     Train net output #0: loss = 1.87785 (* 1 = 1.87785 loss)
I0414 03:09:03.881695 16767 sgd_solver.cpp:106] Iteration 59, lr = 0.0001
I0414 03:09:04.287617 16767 solver.cpp:240] Iteration 60, loss = 1.88056
I0414 03:09:04.287654 16767 solver.cpp:256]     Train net output #0: loss = 1.88056 (* 1 = 1.88056 loss)
I0414 03:09:04.287662 16767 sgd_solver.cpp:106] Iteration 60, lr = 0.0001
I0414 03:09:04.693856 16767 solver.cpp:240] Iteration 61, loss = 1.81884
I0414 03:09:04.693886 16767 solver.cpp:256]     Train net output #0: loss = 1.81884 (* 1 = 1.81884 loss)
I0414 03:09:04.693894 16767 sgd_solver.cpp:106] Iteration 61, lr = 0.0001
I0414 03:09:05.099468 16767 solver.cpp:240] Iteration 62, loss = 1.7412
I0414 03:09:05.099506 16767 solver.cpp:256]     Train net output #0: loss = 1.7412 (* 1 = 1.7412 loss)
I0414 03:09:05.099514 16767 sgd_solver.cpp:106] Iteration 62, lr = 0.0001
I0414 03:09:05.506191 16767 solver.cpp:240] Iteration 63, loss = 1.83822
I0414 03:09:05.506345 16767 solver.cpp:256]     Train net output #0: loss = 1.83822 (* 1 = 1.83822 loss)
I0414 03:09:05.506357 16767 sgd_solver.cpp:106] Iteration 63, lr = 0.0001
I0414 03:09:05.912542 16767 solver.cpp:240] Iteration 64, loss = 1.75825
I0414 03:09:05.912576 16767 solver.cpp:256]     Train net output #0: loss = 1.75825 (* 1 = 1.75825 loss)
I0414 03:09:05.912585 16767 sgd_solver.cpp:106] Iteration 64, lr = 0.0001
I0414 03:09:06.318743 16767 solver.cpp:240] Iteration 65, loss = 1.79314
I0414 03:09:06.318780 16767 solver.cpp:256]     Train net output #0: loss = 1.79314 (* 1 = 1.79314 loss)
I0414 03:09:06.318789 16767 sgd_solver.cpp:106] Iteration 65, lr = 0.0001
I0414 03:09:06.727300 16767 solver.cpp:240] Iteration 66, loss = 1.67623
I0414 03:09:06.727362 16767 solver.cpp:256]     Train net output #0: loss = 1.67623 (* 1 = 1.67623 loss)
I0414 03:09:06.727375 16767 sgd_solver.cpp:106] Iteration 66, lr = 0.0001
I0414 03:09:07.133785 16767 solver.cpp:240] Iteration 67, loss = 1.60227
I0414 03:09:07.133819 16767 solver.cpp:256]     Train net output #0: loss = 1.60227 (* 1 = 1.60227 loss)
I0414 03:09:07.133829 16767 sgd_solver.cpp:106] Iteration 67, lr = 0.0001
I0414 03:09:07.540439 16767 solver.cpp:240] Iteration 68, loss = 1.69319
I0414 03:09:07.540477 16767 solver.cpp:256]     Train net output #0: loss = 1.69319 (* 1 = 1.69319 loss)
I0414 03:09:07.540485 16767 sgd_solver.cpp:106] Iteration 68, lr = 0.0001
I0414 03:09:07.946338 16767 solver.cpp:240] Iteration 69, loss = 1.64701
I0414 03:09:07.946373 16767 solver.cpp:256]     Train net output #0: loss = 1.64701 (* 1 = 1.64701 loss)
I0414 03:09:07.946382 16767 sgd_solver.cpp:106] Iteration 69, lr = 0.0001
I0414 03:09:08.351119 16767 solver.cpp:240] Iteration 70, loss = 1.5471
I0414 03:09:08.351152 16767 solver.cpp:256]     Train net output #0: loss = 1.5471 (* 1 = 1.5471 loss)
I0414 03:09:08.351161 16767 sgd_solver.cpp:106] Iteration 70, lr = 0.0001
I0414 03:09:08.755833 16767 solver.cpp:240] Iteration 71, loss = 1.71725
I0414 03:09:08.755867 16767 solver.cpp:256]     Train net output #0: loss = 1.71725 (* 1 = 1.71725 loss)
I0414 03:09:08.755875 16767 sgd_solver.cpp:106] Iteration 71, lr = 0.0001
I0414 03:09:09.162410 16767 solver.cpp:240] Iteration 72, loss = 1.64387
I0414 03:09:09.162446 16767 solver.cpp:256]     Train net output #0: loss = 1.64387 (* 1 = 1.64387 loss)
I0414 03:09:09.162454 16767 sgd_solver.cpp:106] Iteration 72, lr = 0.0001
I0414 03:09:09.568316 16767 solver.cpp:240] Iteration 73, loss = 1.70636
I0414 03:09:09.568351 16767 solver.cpp:256]     Train net output #0: loss = 1.70636 (* 1 = 1.70636 loss)
I0414 03:09:09.568358 16767 sgd_solver.cpp:106] Iteration 73, lr = 0.0001
I0414 03:09:09.973886 16767 solver.cpp:240] Iteration 74, loss = 1.73615
I0414 03:09:09.973917 16767 solver.cpp:256]     Train net output #0: loss = 1.73615 (* 1 = 1.73615 loss)
I0414 03:09:09.973927 16767 sgd_solver.cpp:106] Iteration 74, lr = 0.0001
I0414 03:09:09.974251 16767 solver.cpp:349] Iteration 75, Testing net (#0)
I0414 03:09:09.974269 16767 net.cpp:693] Ignoring source layer silence
I0414 03:09:11.359356 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.596436
I0414 03:09:11.359387 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.756348
I0414 03:09:11.359397 16767 solver.cpp:416]     Test net output #2: loss = 1.80726 (* 1 = 1.80726 loss)
I0414 03:09:11.499294 16767 solver.cpp:240] Iteration 75, loss = 1.53158
I0414 03:09:11.499326 16767 solver.cpp:256]     Train net output #0: loss = 1.53158 (* 1 = 1.53158 loss)
I0414 03:09:11.499335 16767 sgd_solver.cpp:106] Iteration 75, lr = 0.0001
I0414 03:09:11.905297 16767 solver.cpp:240] Iteration 76, loss = 1.57421
I0414 03:09:11.905334 16767 solver.cpp:256]     Train net output #0: loss = 1.57421 (* 1 = 1.57421 loss)
I0414 03:09:11.905344 16767 sgd_solver.cpp:106] Iteration 76, lr = 0.0001
I0414 03:09:12.312062 16767 solver.cpp:240] Iteration 77, loss = 1.56489
I0414 03:09:12.312103 16767 solver.cpp:256]     Train net output #0: loss = 1.56489 (* 1 = 1.56489 loss)
I0414 03:09:12.312110 16767 sgd_solver.cpp:106] Iteration 77, lr = 0.0001
I0414 03:09:12.718109 16767 solver.cpp:240] Iteration 78, loss = 1.58149
I0414 03:09:12.718138 16767 solver.cpp:256]     Train net output #0: loss = 1.58149 (* 1 = 1.58149 loss)
I0414 03:09:12.718147 16767 sgd_solver.cpp:106] Iteration 78, lr = 0.0001
I0414 03:09:13.125087 16767 solver.cpp:240] Iteration 79, loss = 1.57311
I0414 03:09:13.125123 16767 solver.cpp:256]     Train net output #0: loss = 1.57311 (* 1 = 1.57311 loss)
I0414 03:09:13.125129 16767 sgd_solver.cpp:106] Iteration 79, lr = 0.0001
I0414 03:09:13.530982 16767 solver.cpp:240] Iteration 80, loss = 1.55368
I0414 03:09:13.531014 16767 solver.cpp:256]     Train net output #0: loss = 1.55368 (* 1 = 1.55368 loss)
I0414 03:09:13.531023 16767 sgd_solver.cpp:106] Iteration 80, lr = 0.0001
I0414 03:09:13.937254 16767 solver.cpp:240] Iteration 81, loss = 1.54172
I0414 03:09:13.937296 16767 solver.cpp:256]     Train net output #0: loss = 1.54172 (* 1 = 1.54172 loss)
I0414 03:09:13.937307 16767 sgd_solver.cpp:106] Iteration 81, lr = 0.0001
I0414 03:09:14.341799 16767 solver.cpp:240] Iteration 82, loss = 1.42806
I0414 03:09:14.341832 16767 solver.cpp:256]     Train net output #0: loss = 1.42806 (* 1 = 1.42806 loss)
I0414 03:09:14.341841 16767 sgd_solver.cpp:106] Iteration 82, lr = 0.0001
I0414 03:09:14.746933 16767 solver.cpp:240] Iteration 83, loss = 1.52728
I0414 03:09:14.746968 16767 solver.cpp:256]     Train net output #0: loss = 1.52728 (* 1 = 1.52728 loss)
I0414 03:09:14.746978 16767 sgd_solver.cpp:106] Iteration 83, lr = 0.0001
I0414 03:09:15.152773 16767 solver.cpp:240] Iteration 84, loss = 1.5162
I0414 03:09:15.152808 16767 solver.cpp:256]     Train net output #0: loss = 1.5162 (* 1 = 1.5162 loss)
I0414 03:09:15.152817 16767 sgd_solver.cpp:106] Iteration 84, lr = 0.0001
I0414 03:09:15.558110 16767 solver.cpp:240] Iteration 85, loss = 1.49961
I0414 03:09:15.558143 16767 solver.cpp:256]     Train net output #0: loss = 1.49961 (* 1 = 1.49961 loss)
I0414 03:09:15.558151 16767 sgd_solver.cpp:106] Iteration 85, lr = 0.0001
I0414 03:09:15.963611 16767 solver.cpp:240] Iteration 86, loss = 1.46989
I0414 03:09:15.963649 16767 solver.cpp:256]     Train net output #0: loss = 1.46989 (* 1 = 1.46989 loss)
I0414 03:09:15.963656 16767 sgd_solver.cpp:106] Iteration 86, lr = 0.0001
I0414 03:09:16.367887 16767 solver.cpp:240] Iteration 87, loss = 1.46246
I0414 03:09:16.367918 16767 solver.cpp:256]     Train net output #0: loss = 1.46246 (* 1 = 1.46246 loss)
I0414 03:09:16.367926 16767 sgd_solver.cpp:106] Iteration 87, lr = 0.0001
I0414 03:09:16.772572 16767 solver.cpp:240] Iteration 88, loss = 1.49605
I0414 03:09:16.772608 16767 solver.cpp:256]     Train net output #0: loss = 1.49605 (* 1 = 1.49605 loss)
I0414 03:09:16.772616 16767 sgd_solver.cpp:106] Iteration 88, lr = 0.0001
I0414 03:09:17.178186 16767 solver.cpp:240] Iteration 89, loss = 1.4129
I0414 03:09:17.178220 16767 solver.cpp:256]     Train net output #0: loss = 1.4129 (* 1 = 1.4129 loss)
I0414 03:09:17.178230 16767 sgd_solver.cpp:106] Iteration 89, lr = 0.0001
I0414 03:09:17.583508 16767 solver.cpp:240] Iteration 90, loss = 1.46411
I0414 03:09:17.583546 16767 solver.cpp:256]     Train net output #0: loss = 1.46411 (* 1 = 1.46411 loss)
I0414 03:09:17.583555 16767 sgd_solver.cpp:106] Iteration 90, lr = 0.0001
I0414 03:09:17.988479 16767 solver.cpp:240] Iteration 91, loss = 1.36185
I0414 03:09:17.988509 16767 solver.cpp:256]     Train net output #0: loss = 1.36185 (* 1 = 1.36185 loss)
I0414 03:09:17.988517 16767 sgd_solver.cpp:106] Iteration 91, lr = 0.0001
I0414 03:09:18.394264 16767 solver.cpp:240] Iteration 92, loss = 1.36502
I0414 03:09:18.394309 16767 solver.cpp:256]     Train net output #0: loss = 1.36502 (* 1 = 1.36502 loss)
I0414 03:09:18.394317 16767 sgd_solver.cpp:106] Iteration 92, lr = 0.0001
I0414 03:09:18.799258 16767 solver.cpp:240] Iteration 93, loss = 1.38027
I0414 03:09:18.799293 16767 solver.cpp:256]     Train net output #0: loss = 1.38027 (* 1 = 1.38027 loss)
I0414 03:09:18.799302 16767 sgd_solver.cpp:106] Iteration 93, lr = 0.0001
I0414 03:09:19.204252 16767 solver.cpp:240] Iteration 94, loss = 1.31451
I0414 03:09:19.204322 16767 solver.cpp:256]     Train net output #0: loss = 1.31451 (* 1 = 1.31451 loss)
I0414 03:09:19.204334 16767 sgd_solver.cpp:106] Iteration 94, lr = 0.0001
I0414 03:09:19.609942 16767 solver.cpp:240] Iteration 95, loss = 1.29017
I0414 03:09:19.609979 16767 solver.cpp:256]     Train net output #0: loss = 1.29017 (* 1 = 1.29017 loss)
I0414 03:09:19.609992 16767 sgd_solver.cpp:106] Iteration 95, lr = 0.0001
I0414 03:09:20.015233 16767 solver.cpp:240] Iteration 96, loss = 1.41159
I0414 03:09:20.015277 16767 solver.cpp:256]     Train net output #0: loss = 1.41159 (* 1 = 1.41159 loss)
I0414 03:09:20.015290 16767 sgd_solver.cpp:106] Iteration 96, lr = 0.0001
I0414 03:09:20.421079 16767 solver.cpp:240] Iteration 97, loss = 1.34045
I0414 03:09:20.421116 16767 solver.cpp:256]     Train net output #0: loss = 1.34045 (* 1 = 1.34045 loss)
I0414 03:09:20.421128 16767 sgd_solver.cpp:106] Iteration 97, lr = 0.0001
I0414 03:09:20.826047 16767 solver.cpp:240] Iteration 98, loss = 1.44599
I0414 03:09:20.826086 16767 solver.cpp:256]     Train net output #0: loss = 1.44599 (* 1 = 1.44599 loss)
I0414 03:09:20.826097 16767 sgd_solver.cpp:106] Iteration 98, lr = 0.0001
I0414 03:09:21.231554 16767 solver.cpp:240] Iteration 99, loss = 1.38579
I0414 03:09:21.231590 16767 solver.cpp:256]     Train net output #0: loss = 1.38579 (* 1 = 1.38579 loss)
I0414 03:09:21.231601 16767 sgd_solver.cpp:106] Iteration 99, lr = 0.0001
I0414 03:09:21.231931 16767 solver.cpp:349] Iteration 100, Testing net (#0)
I0414 03:09:21.231953 16767 net.cpp:693] Ignoring source layer silence
I0414 03:09:22.614562 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.640869
I0414 03:09:22.614594 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.796753
I0414 03:09:22.614609 16767 solver.cpp:416]     Test net output #2: loss = 1.59067 (* 1 = 1.59067 loss)
I0414 03:09:22.754681 16767 solver.cpp:240] Iteration 100, loss = 1.29087
I0414 03:09:22.754719 16767 solver.cpp:256]     Train net output #0: loss = 1.29087 (* 1 = 1.29087 loss)
I0414 03:09:22.754730 16767 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0414 03:09:23.159654 16767 solver.cpp:240] Iteration 101, loss = 1.24099
I0414 03:09:23.159693 16767 solver.cpp:256]     Train net output #0: loss = 1.24099 (* 1 = 1.24099 loss)
I0414 03:09:23.159703 16767 sgd_solver.cpp:106] Iteration 101, lr = 0.0001
I0414 03:09:23.565659 16767 solver.cpp:240] Iteration 102, loss = 1.34892
I0414 03:09:23.565697 16767 solver.cpp:256]     Train net output #0: loss = 1.34892 (* 1 = 1.34892 loss)
I0414 03:09:23.565706 16767 sgd_solver.cpp:106] Iteration 102, lr = 0.0001
I0414 03:09:23.971791 16767 solver.cpp:240] Iteration 103, loss = 1.28368
I0414 03:09:23.971823 16767 solver.cpp:256]     Train net output #0: loss = 1.28368 (* 1 = 1.28368 loss)
I0414 03:09:23.971832 16767 sgd_solver.cpp:106] Iteration 103, lr = 0.0001
I0414 03:09:24.378311 16767 solver.cpp:240] Iteration 104, loss = 1.33813
I0414 03:09:24.378350 16767 solver.cpp:256]     Train net output #0: loss = 1.33813 (* 1 = 1.33813 loss)
I0414 03:09:24.378360 16767 sgd_solver.cpp:106] Iteration 104, lr = 0.0001
I0414 03:09:24.783509 16767 solver.cpp:240] Iteration 105, loss = 1.28115
I0414 03:09:24.783548 16767 solver.cpp:256]     Train net output #0: loss = 1.28115 (* 1 = 1.28115 loss)
I0414 03:09:24.783557 16767 sgd_solver.cpp:106] Iteration 105, lr = 0.0001
I0414 03:09:25.188580 16767 solver.cpp:240] Iteration 106, loss = 1.29553
I0414 03:09:25.188616 16767 solver.cpp:256]     Train net output #0: loss = 1.29553 (* 1 = 1.29553 loss)
I0414 03:09:25.188623 16767 sgd_solver.cpp:106] Iteration 106, lr = 0.0001
I0414 03:09:25.594157 16767 solver.cpp:240] Iteration 107, loss = 1.19669
I0414 03:09:25.594194 16767 solver.cpp:256]     Train net output #0: loss = 1.19669 (* 1 = 1.19669 loss)
I0414 03:09:25.594203 16767 sgd_solver.cpp:106] Iteration 107, lr = 0.0001
I0414 03:09:26.000269 16767 solver.cpp:240] Iteration 108, loss = 1.29158
I0414 03:09:26.000299 16767 solver.cpp:256]     Train net output #0: loss = 1.29158 (* 1 = 1.29158 loss)
I0414 03:09:26.000332 16767 sgd_solver.cpp:106] Iteration 108, lr = 0.0001
I0414 03:09:26.405748 16767 solver.cpp:240] Iteration 109, loss = 1.29305
I0414 03:09:26.405788 16767 solver.cpp:256]     Train net output #0: loss = 1.29305 (* 1 = 1.29305 loss)
I0414 03:09:26.405797 16767 sgd_solver.cpp:106] Iteration 109, lr = 0.0001
I0414 03:09:26.811342 16767 solver.cpp:240] Iteration 110, loss = 1.25013
I0414 03:09:26.811377 16767 solver.cpp:256]     Train net output #0: loss = 1.25013 (* 1 = 1.25013 loss)
I0414 03:09:26.811384 16767 sgd_solver.cpp:106] Iteration 110, lr = 0.0001
I0414 03:09:27.217020 16767 solver.cpp:240] Iteration 111, loss = 1.20451
I0414 03:09:27.217057 16767 solver.cpp:256]     Train net output #0: loss = 1.20451 (* 1 = 1.20451 loss)
I0414 03:09:27.217066 16767 sgd_solver.cpp:106] Iteration 111, lr = 0.0001
I0414 03:09:27.623760 16767 solver.cpp:240] Iteration 112, loss = 1.23811
I0414 03:09:27.623790 16767 solver.cpp:256]     Train net output #0: loss = 1.23811 (* 1 = 1.23811 loss)
I0414 03:09:27.623798 16767 sgd_solver.cpp:106] Iteration 112, lr = 0.0001
I0414 03:09:28.029310 16767 solver.cpp:240] Iteration 113, loss = 1.22341
I0414 03:09:28.029345 16767 solver.cpp:256]     Train net output #0: loss = 1.22341 (* 1 = 1.22341 loss)
I0414 03:09:28.029353 16767 sgd_solver.cpp:106] Iteration 113, lr = 0.0001
I0414 03:09:28.435055 16767 solver.cpp:240] Iteration 114, loss = 1.17212
I0414 03:09:28.435097 16767 solver.cpp:256]     Train net output #0: loss = 1.17212 (* 1 = 1.17212 loss)
I0414 03:09:28.435106 16767 sgd_solver.cpp:106] Iteration 114, lr = 0.0001
I0414 03:09:28.841117 16767 solver.cpp:240] Iteration 115, loss = 1.22262
I0414 03:09:28.841156 16767 solver.cpp:256]     Train net output #0: loss = 1.22262 (* 1 = 1.22262 loss)
I0414 03:09:28.841164 16767 sgd_solver.cpp:106] Iteration 115, lr = 0.0001
I0414 03:09:29.247684 16767 solver.cpp:240] Iteration 116, loss = 1.13415
I0414 03:09:29.247723 16767 solver.cpp:256]     Train net output #0: loss = 1.13415 (* 1 = 1.13415 loss)
I0414 03:09:29.247732 16767 sgd_solver.cpp:106] Iteration 116, lr = 0.0001
I0414 03:09:29.652822 16767 solver.cpp:240] Iteration 117, loss = 1.08891
I0414 03:09:29.652858 16767 solver.cpp:256]     Train net output #0: loss = 1.08891 (* 1 = 1.08891 loss)
I0414 03:09:29.652868 16767 sgd_solver.cpp:106] Iteration 117, lr = 0.0001
I0414 03:09:30.058032 16767 solver.cpp:240] Iteration 118, loss = 1.1674
I0414 03:09:30.058069 16767 solver.cpp:256]     Train net output #0: loss = 1.1674 (* 1 = 1.1674 loss)
I0414 03:09:30.058079 16767 sgd_solver.cpp:106] Iteration 118, lr = 0.0001
I0414 03:09:30.463804 16767 solver.cpp:240] Iteration 119, loss = 1.1219
I0414 03:09:30.463840 16767 solver.cpp:256]     Train net output #0: loss = 1.1219 (* 1 = 1.1219 loss)
I0414 03:09:30.463848 16767 sgd_solver.cpp:106] Iteration 119, lr = 0.0001
I0414 03:09:30.869269 16767 solver.cpp:240] Iteration 120, loss = 1.09684
I0414 03:09:30.869307 16767 solver.cpp:256]     Train net output #0: loss = 1.09684 (* 1 = 1.09684 loss)
I0414 03:09:30.869318 16767 sgd_solver.cpp:106] Iteration 120, lr = 0.0001
I0414 03:09:31.274719 16767 solver.cpp:240] Iteration 121, loss = 1.21575
I0414 03:09:31.274755 16767 solver.cpp:256]     Train net output #0: loss = 1.21575 (* 1 = 1.21575 loss)
I0414 03:09:31.274762 16767 sgd_solver.cpp:106] Iteration 121, lr = 0.0001
I0414 03:09:31.680829 16767 solver.cpp:240] Iteration 122, loss = 1.13045
I0414 03:09:31.680866 16767 solver.cpp:256]     Train net output #0: loss = 1.13045 (* 1 = 1.13045 loss)
I0414 03:09:31.680876 16767 sgd_solver.cpp:106] Iteration 122, lr = 0.0001
I0414 03:09:32.085374 16767 solver.cpp:240] Iteration 123, loss = 1.23935
I0414 03:09:32.085409 16767 solver.cpp:256]     Train net output #0: loss = 1.23935 (* 1 = 1.23935 loss)
I0414 03:09:32.085418 16767 sgd_solver.cpp:106] Iteration 123, lr = 0.0001
I0414 03:09:32.490566 16767 solver.cpp:240] Iteration 124, loss = 1.12869
I0414 03:09:32.490599 16767 solver.cpp:256]     Train net output #0: loss = 1.12869 (* 1 = 1.12869 loss)
I0414 03:09:32.490607 16767 sgd_solver.cpp:106] Iteration 124, lr = 0.0001
I0414 03:09:32.490944 16767 solver.cpp:349] Iteration 125, Testing net (#0)
I0414 03:09:32.490963 16767 net.cpp:693] Ignoring source layer silence
I0414 03:09:33.871261 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.688965
I0414 03:09:33.871294 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.831299
I0414 03:09:33.871304 16767 solver.cpp:416]     Test net output #2: loss = 1.40971 (* 1 = 1.40971 loss)
I0414 03:09:34.011677 16767 solver.cpp:240] Iteration 125, loss = 1.07019
I0414 03:09:34.011705 16767 solver.cpp:256]     Train net output #0: loss = 1.07019 (* 1 = 1.07019 loss)
I0414 03:09:34.011713 16767 sgd_solver.cpp:106] Iteration 125, lr = 5e-05
I0414 03:09:34.417516 16767 solver.cpp:240] Iteration 126, loss = 1.04418
I0414 03:09:34.417552 16767 solver.cpp:256]     Train net output #0: loss = 1.04418 (* 1 = 1.04418 loss)
I0414 03:09:34.417560 16767 sgd_solver.cpp:106] Iteration 126, lr = 5e-05
I0414 03:09:34.823129 16767 solver.cpp:240] Iteration 127, loss = 1.17706
I0414 03:09:34.823163 16767 solver.cpp:256]     Train net output #0: loss = 1.17706 (* 1 = 1.17706 loss)
I0414 03:09:34.823173 16767 sgd_solver.cpp:106] Iteration 127, lr = 5e-05
I0414 03:09:35.230973 16767 solver.cpp:240] Iteration 128, loss = 1.08028
I0414 03:09:35.231024 16767 solver.cpp:256]     Train net output #0: loss = 1.08028 (* 1 = 1.08028 loss)
I0414 03:09:35.231039 16767 sgd_solver.cpp:106] Iteration 128, lr = 5e-05
I0414 03:09:35.636281 16767 solver.cpp:240] Iteration 129, loss = 1.15295
I0414 03:09:35.636632 16767 solver.cpp:256]     Train net output #0: loss = 1.15295 (* 1 = 1.15295 loss)
I0414 03:09:35.636642 16767 sgd_solver.cpp:106] Iteration 129, lr = 5e-05
I0414 03:09:36.041465 16767 solver.cpp:240] Iteration 130, loss = 1.08108
I0414 03:09:36.041501 16767 solver.cpp:256]     Train net output #0: loss = 1.08108 (* 1 = 1.08108 loss)
I0414 03:09:36.041508 16767 sgd_solver.cpp:106] Iteration 130, lr = 5e-05
I0414 03:09:36.447053 16767 solver.cpp:240] Iteration 131, loss = 1.13468
I0414 03:09:36.447088 16767 solver.cpp:256]     Train net output #0: loss = 1.13468 (* 1 = 1.13468 loss)
I0414 03:09:36.447096 16767 sgd_solver.cpp:106] Iteration 131, lr = 5e-05
I0414 03:09:36.852157 16767 solver.cpp:240] Iteration 132, loss = 1.0079
I0414 03:09:36.852193 16767 solver.cpp:256]     Train net output #0: loss = 1.0079 (* 1 = 1.0079 loss)
I0414 03:09:36.852201 16767 sgd_solver.cpp:106] Iteration 132, lr = 5e-05
I0414 03:09:37.257292 16767 solver.cpp:240] Iteration 133, loss = 1.10114
I0414 03:09:37.257325 16767 solver.cpp:256]     Train net output #0: loss = 1.10114 (* 1 = 1.10114 loss)
I0414 03:09:37.257333 16767 sgd_solver.cpp:106] Iteration 133, lr = 5e-05
I0414 03:09:37.663008 16767 solver.cpp:240] Iteration 134, loss = 1.17521
I0414 03:09:37.663048 16767 solver.cpp:256]     Train net output #0: loss = 1.17521 (* 1 = 1.17521 loss)
I0414 03:09:37.663056 16767 sgd_solver.cpp:106] Iteration 134, lr = 5e-05
I0414 03:09:38.069005 16767 solver.cpp:240] Iteration 135, loss = 1.0307
I0414 03:09:38.069036 16767 solver.cpp:256]     Train net output #0: loss = 1.0307 (* 1 = 1.0307 loss)
I0414 03:09:38.069046 16767 sgd_solver.cpp:106] Iteration 135, lr = 5e-05
I0414 03:09:38.474467 16767 solver.cpp:240] Iteration 136, loss = 1.02481
I0414 03:09:38.474506 16767 solver.cpp:256]     Train net output #0: loss = 1.02481 (* 1 = 1.02481 loss)
I0414 03:09:38.474514 16767 sgd_solver.cpp:106] Iteration 136, lr = 5e-05
I0414 03:09:38.879977 16767 solver.cpp:240] Iteration 137, loss = 1.09687
I0414 03:09:38.880008 16767 solver.cpp:256]     Train net output #0: loss = 1.09687 (* 1 = 1.09687 loss)
I0414 03:09:38.880017 16767 sgd_solver.cpp:106] Iteration 137, lr = 5e-05
I0414 03:09:39.285325 16767 solver.cpp:240] Iteration 138, loss = 1.05175
I0414 03:09:39.285362 16767 solver.cpp:256]     Train net output #0: loss = 1.05175 (* 1 = 1.05175 loss)
I0414 03:09:39.285369 16767 sgd_solver.cpp:106] Iteration 138, lr = 5e-05
I0414 03:09:39.690713 16767 solver.cpp:240] Iteration 139, loss = 1.1182
I0414 03:09:39.690740 16767 solver.cpp:256]     Train net output #0: loss = 1.1182 (* 1 = 1.1182 loss)
I0414 03:09:39.690747 16767 sgd_solver.cpp:106] Iteration 139, lr = 5e-05
I0414 03:09:40.096190 16767 solver.cpp:240] Iteration 140, loss = 1.02638
I0414 03:09:40.096223 16767 solver.cpp:256]     Train net output #0: loss = 1.02638 (* 1 = 1.02638 loss)
I0414 03:09:40.096231 16767 sgd_solver.cpp:106] Iteration 140, lr = 5e-05
I0414 03:09:40.501983 16767 solver.cpp:240] Iteration 141, loss = 1.01354
I0414 03:09:40.502013 16767 solver.cpp:256]     Train net output #0: loss = 1.01354 (* 1 = 1.01354 loss)
I0414 03:09:40.502022 16767 sgd_solver.cpp:106] Iteration 141, lr = 5e-05
I0414 03:09:40.907229 16767 solver.cpp:240] Iteration 142, loss = 1.03669
I0414 03:09:40.907263 16767 solver.cpp:256]     Train net output #0: loss = 1.03669 (* 1 = 1.03669 loss)
I0414 03:09:40.907271 16767 sgd_solver.cpp:106] Iteration 142, lr = 5e-05
I0414 03:09:41.312494 16767 solver.cpp:240] Iteration 143, loss = 1.04753
I0414 03:09:41.312527 16767 solver.cpp:256]     Train net output #0: loss = 1.04753 (* 1 = 1.04753 loss)
I0414 03:09:41.312536 16767 sgd_solver.cpp:106] Iteration 143, lr = 5e-05
I0414 03:09:41.714968 16767 solver.cpp:240] Iteration 144, loss = 0.983113
I0414 03:09:41.715003 16767 solver.cpp:256]     Train net output #0: loss = 0.983113 (* 1 = 0.983113 loss)
I0414 03:09:41.715010 16767 sgd_solver.cpp:106] Iteration 144, lr = 5e-05
I0414 03:09:42.120381 16767 solver.cpp:240] Iteration 145, loss = 1.03532
I0414 03:09:42.120414 16767 solver.cpp:256]     Train net output #0: loss = 1.03532 (* 1 = 1.03532 loss)
I0414 03:09:42.120448 16767 sgd_solver.cpp:106] Iteration 145, lr = 5e-05
I0414 03:09:42.525732 16767 solver.cpp:240] Iteration 146, loss = 1.06643
I0414 03:09:42.525769 16767 solver.cpp:256]     Train net output #0: loss = 1.06643 (* 1 = 1.06643 loss)
I0414 03:09:42.525779 16767 sgd_solver.cpp:106] Iteration 146, lr = 5e-05
I0414 03:09:42.931401 16767 solver.cpp:240] Iteration 147, loss = 1.09469
I0414 03:09:42.931435 16767 solver.cpp:256]     Train net output #0: loss = 1.09469 (* 1 = 1.09469 loss)
I0414 03:09:42.931444 16767 sgd_solver.cpp:106] Iteration 147, lr = 5e-05
I0414 03:09:43.336956 16767 solver.cpp:240] Iteration 148, loss = 1.1078
I0414 03:09:43.336989 16767 solver.cpp:256]     Train net output #0: loss = 1.1078 (* 1 = 1.1078 loss)
I0414 03:09:43.336997 16767 sgd_solver.cpp:106] Iteration 148, lr = 5e-05
I0414 03:09:43.742974 16767 solver.cpp:240] Iteration 149, loss = 1.03992
I0414 03:09:43.743010 16767 solver.cpp:256]     Train net output #0: loss = 1.03992 (* 1 = 1.03992 loss)
I0414 03:09:43.743017 16767 sgd_solver.cpp:106] Iteration 149, lr = 5e-05
I0414 03:09:43.743333 16767 solver.cpp:349] Iteration 150, Testing net (#0)
I0414 03:09:43.743351 16767 net.cpp:693] Ignoring source layer silence
I0414 03:09:45.125315 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.712402
I0414 03:09:45.125341 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.845825
I0414 03:09:45.125351 16767 solver.cpp:416]     Test net output #2: loss = 1.2987 (* 1 = 1.2987 loss)
I0414 03:09:45.265341 16767 solver.cpp:240] Iteration 150, loss = 0.982821
I0414 03:09:45.265374 16767 solver.cpp:256]     Train net output #0: loss = 0.982821 (* 1 = 0.982821 loss)
I0414 03:09:45.265383 16767 sgd_solver.cpp:106] Iteration 150, lr = 5e-05
I0414 03:09:45.670924 16767 solver.cpp:240] Iteration 151, loss = 0.992764
I0414 03:09:45.670960 16767 solver.cpp:256]     Train net output #0: loss = 0.992764 (* 1 = 0.992764 loss)
I0414 03:09:45.670969 16767 sgd_solver.cpp:106] Iteration 151, lr = 5e-05
I0414 03:09:46.076551 16767 solver.cpp:240] Iteration 152, loss = 1.02556
I0414 03:09:46.076589 16767 solver.cpp:256]     Train net output #0: loss = 1.02556 (* 1 = 1.02556 loss)
I0414 03:09:46.076597 16767 sgd_solver.cpp:106] Iteration 152, lr = 5e-05
I0414 03:09:46.481076 16767 solver.cpp:240] Iteration 153, loss = 1.03338
I0414 03:09:46.481111 16767 solver.cpp:256]     Train net output #0: loss = 1.03338 (* 1 = 1.03338 loss)
I0414 03:09:46.481119 16767 sgd_solver.cpp:106] Iteration 153, lr = 5e-05
I0414 03:09:46.886490 16767 solver.cpp:240] Iteration 154, loss = 1.0283
I0414 03:09:46.886528 16767 solver.cpp:256]     Train net output #0: loss = 1.0283 (* 1 = 1.0283 loss)
I0414 03:09:46.886535 16767 sgd_solver.cpp:106] Iteration 154, lr = 5e-05
I0414 03:09:47.291774 16767 solver.cpp:240] Iteration 155, loss = 1.01825
I0414 03:09:47.291806 16767 solver.cpp:256]     Train net output #0: loss = 1.01825 (* 1 = 1.01825 loss)
I0414 03:09:47.291815 16767 sgd_solver.cpp:106] Iteration 155, lr = 5e-05
I0414 03:09:47.697181 16767 solver.cpp:240] Iteration 156, loss = 1.04654
I0414 03:09:47.697214 16767 solver.cpp:256]     Train net output #0: loss = 1.04654 (* 1 = 1.04654 loss)
I0414 03:09:47.697222 16767 sgd_solver.cpp:106] Iteration 156, lr = 5e-05
I0414 03:09:48.102870 16767 solver.cpp:240] Iteration 157, loss = 0.967554
I0414 03:09:48.102910 16767 solver.cpp:256]     Train net output #0: loss = 0.967554 (* 1 = 0.967554 loss)
I0414 03:09:48.102916 16767 sgd_solver.cpp:106] Iteration 157, lr = 5e-05
I0414 03:09:48.508215 16767 solver.cpp:240] Iteration 158, loss = 1.01523
I0414 03:09:48.508254 16767 solver.cpp:256]     Train net output #0: loss = 1.01523 (* 1 = 1.01523 loss)
I0414 03:09:48.508262 16767 sgd_solver.cpp:106] Iteration 158, lr = 5e-05
I0414 03:09:48.913307 16767 solver.cpp:240] Iteration 159, loss = 1.10619
I0414 03:09:48.913341 16767 solver.cpp:256]     Train net output #0: loss = 1.10619 (* 1 = 1.10619 loss)
I0414 03:09:48.913350 16767 sgd_solver.cpp:106] Iteration 159, lr = 5e-05
I0414 03:09:49.318698 16767 solver.cpp:240] Iteration 160, loss = 0.978647
I0414 03:09:49.318733 16767 solver.cpp:256]     Train net output #0: loss = 0.978647 (* 1 = 0.978647 loss)
I0414 03:09:49.318742 16767 sgd_solver.cpp:106] Iteration 160, lr = 5e-05
I0414 03:09:49.724202 16767 solver.cpp:240] Iteration 161, loss = 0.954411
I0414 03:09:49.724231 16767 solver.cpp:256]     Train net output #0: loss = 0.954411 (* 1 = 0.954411 loss)
I0414 03:09:49.724239 16767 sgd_solver.cpp:106] Iteration 161, lr = 5e-05
I0414 03:09:50.130230 16767 solver.cpp:240] Iteration 162, loss = 1.02611
I0414 03:09:50.130265 16767 solver.cpp:256]     Train net output #0: loss = 1.02611 (* 1 = 1.02611 loss)
I0414 03:09:50.130273 16767 sgd_solver.cpp:106] Iteration 162, lr = 5e-05
I0414 03:09:50.535873 16767 solver.cpp:240] Iteration 163, loss = 1.02543
I0414 03:09:50.535920 16767 solver.cpp:256]     Train net output #0: loss = 1.02543 (* 1 = 1.02543 loss)
I0414 03:09:50.535928 16767 sgd_solver.cpp:106] Iteration 163, lr = 5e-05
I0414 03:09:50.941471 16767 solver.cpp:240] Iteration 164, loss = 0.970004
I0414 03:09:50.941507 16767 solver.cpp:256]     Train net output #0: loss = 0.970004 (* 1 = 0.970004 loss)
I0414 03:09:50.941515 16767 sgd_solver.cpp:106] Iteration 164, lr = 5e-05
I0414 03:09:51.347029 16767 solver.cpp:240] Iteration 165, loss = 0.99486
I0414 03:09:51.347064 16767 solver.cpp:256]     Train net output #0: loss = 0.99486 (* 1 = 0.99486 loss)
I0414 03:09:51.347072 16767 sgd_solver.cpp:106] Iteration 165, lr = 5e-05
I0414 03:09:51.752315 16767 solver.cpp:240] Iteration 166, loss = 0.920273
I0414 03:09:51.752347 16767 solver.cpp:256]     Train net output #0: loss = 0.920273 (* 1 = 0.920273 loss)
I0414 03:09:51.752355 16767 sgd_solver.cpp:106] Iteration 166, lr = 5e-05
I0414 03:09:52.158161 16767 solver.cpp:240] Iteration 167, loss = 0.958945
I0414 03:09:52.158195 16767 solver.cpp:256]     Train net output #0: loss = 0.958945 (* 1 = 0.958945 loss)
I0414 03:09:52.158202 16767 sgd_solver.cpp:106] Iteration 167, lr = 5e-05
I0414 03:09:52.563971 16767 solver.cpp:240] Iteration 168, loss = 0.93893
I0414 03:09:52.564007 16767 solver.cpp:256]     Train net output #0: loss = 0.93893 (* 1 = 0.93893 loss)
I0414 03:09:52.564015 16767 sgd_solver.cpp:106] Iteration 168, lr = 5e-05
I0414 03:09:52.969307 16767 solver.cpp:240] Iteration 169, loss = 0.93849
I0414 03:09:52.969344 16767 solver.cpp:256]     Train net output #0: loss = 0.93849 (* 1 = 0.93849 loss)
I0414 03:09:52.969353 16767 sgd_solver.cpp:106] Iteration 169, lr = 5e-05
I0414 03:09:53.374754 16767 solver.cpp:240] Iteration 170, loss = 0.94688
I0414 03:09:53.374790 16767 solver.cpp:256]     Train net output #0: loss = 0.94688 (* 1 = 0.94688 loss)
I0414 03:09:53.374799 16767 sgd_solver.cpp:106] Iteration 170, lr = 5e-05
I0414 03:09:53.780014 16767 solver.cpp:240] Iteration 171, loss = 1.01852
I0414 03:09:53.780047 16767 solver.cpp:256]     Train net output #0: loss = 1.01852 (* 1 = 1.01852 loss)
I0414 03:09:53.780055 16767 sgd_solver.cpp:106] Iteration 171, lr = 5e-05
I0414 03:09:54.184805 16767 solver.cpp:240] Iteration 172, loss = 1.01545
I0414 03:09:54.184842 16767 solver.cpp:256]     Train net output #0: loss = 1.01545 (* 1 = 1.01545 loss)
I0414 03:09:54.184849 16767 sgd_solver.cpp:106] Iteration 172, lr = 5e-05
I0414 03:09:54.589664 16767 solver.cpp:240] Iteration 173, loss = 1.05293
I0414 03:09:54.589701 16767 solver.cpp:256]     Train net output #0: loss = 1.05293 (* 1 = 1.05293 loss)
I0414 03:09:54.589709 16767 sgd_solver.cpp:106] Iteration 173, lr = 5e-05
I0414 03:09:54.994210 16767 solver.cpp:240] Iteration 174, loss = 0.983588
I0414 03:09:54.994237 16767 solver.cpp:256]     Train net output #0: loss = 0.983588 (* 1 = 0.983588 loss)
I0414 03:09:54.994246 16767 sgd_solver.cpp:106] Iteration 174, lr = 5e-05
I0414 03:09:54.994557 16767 solver.cpp:349] Iteration 175, Testing net (#0)
I0414 03:09:54.994575 16767 net.cpp:693] Ignoring source layer silence
I0414 03:09:56.377370 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.725586
I0414 03:09:56.377400 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.854614
I0414 03:09:56.377436 16767 solver.cpp:416]     Test net output #2: loss = 1.2384 (* 1 = 1.2384 loss)
I0414 03:09:56.517918 16767 solver.cpp:240] Iteration 175, loss = 0.893521
I0414 03:09:56.517951 16767 solver.cpp:256]     Train net output #0: loss = 0.893521 (* 1 = 0.893521 loss)
I0414 03:09:56.517958 16767 sgd_solver.cpp:106] Iteration 175, lr = 5e-05
I0414 03:09:56.923172 16767 solver.cpp:240] Iteration 176, loss = 0.976915
I0414 03:09:56.923207 16767 solver.cpp:256]     Train net output #0: loss = 0.976915 (* 1 = 0.976915 loss)
I0414 03:09:56.923214 16767 sgd_solver.cpp:106] Iteration 176, lr = 5e-05
I0414 03:09:57.328945 16767 solver.cpp:240] Iteration 177, loss = 0.938697
I0414 03:09:57.328984 16767 solver.cpp:256]     Train net output #0: loss = 0.938697 (* 1 = 0.938697 loss)
I0414 03:09:57.328994 16767 sgd_solver.cpp:106] Iteration 177, lr = 5e-05
I0414 03:09:57.733836 16767 solver.cpp:240] Iteration 178, loss = 0.92584
I0414 03:09:57.733865 16767 solver.cpp:256]     Train net output #0: loss = 0.92584 (* 1 = 0.92584 loss)
I0414 03:09:57.733872 16767 sgd_solver.cpp:106] Iteration 178, lr = 5e-05
I0414 03:09:58.139252 16767 solver.cpp:240] Iteration 179, loss = 1.00229
I0414 03:09:58.139295 16767 solver.cpp:256]     Train net output #0: loss = 1.00229 (* 1 = 1.00229 loss)
I0414 03:09:58.139303 16767 sgd_solver.cpp:106] Iteration 179, lr = 5e-05
I0414 03:09:58.544682 16767 solver.cpp:240] Iteration 180, loss = 0.89911
I0414 03:09:58.544716 16767 solver.cpp:256]     Train net output #0: loss = 0.89911 (* 1 = 0.89911 loss)
I0414 03:09:58.544723 16767 sgd_solver.cpp:106] Iteration 180, lr = 5e-05
I0414 03:09:58.950444 16767 solver.cpp:240] Iteration 181, loss = 0.973726
I0414 03:09:58.950484 16767 solver.cpp:256]     Train net output #0: loss = 0.973726 (* 1 = 0.973726 loss)
I0414 03:09:58.950490 16767 sgd_solver.cpp:106] Iteration 181, lr = 5e-05
I0414 03:09:59.355949 16767 solver.cpp:240] Iteration 182, loss = 0.904831
I0414 03:09:59.355986 16767 solver.cpp:256]     Train net output #0: loss = 0.904831 (* 1 = 0.904831 loss)
I0414 03:09:59.355994 16767 sgd_solver.cpp:106] Iteration 182, lr = 5e-05
I0414 03:09:59.761035 16767 solver.cpp:240] Iteration 183, loss = 0.947984
I0414 03:09:59.761068 16767 solver.cpp:256]     Train net output #0: loss = 0.947984 (* 1 = 0.947984 loss)
I0414 03:09:59.761076 16767 sgd_solver.cpp:106] Iteration 183, lr = 5e-05
I0414 03:10:00.166205 16767 solver.cpp:240] Iteration 184, loss = 0.996732
I0414 03:10:00.166239 16767 solver.cpp:256]     Train net output #0: loss = 0.996732 (* 1 = 0.996732 loss)
I0414 03:10:00.166246 16767 sgd_solver.cpp:106] Iteration 184, lr = 5e-05
I0414 03:10:00.571715 16767 solver.cpp:240] Iteration 185, loss = 0.950692
I0414 03:10:00.571753 16767 solver.cpp:256]     Train net output #0: loss = 0.950692 (* 1 = 0.950692 loss)
I0414 03:10:00.571761 16767 sgd_solver.cpp:106] Iteration 185, lr = 5e-05
I0414 03:10:00.977032 16767 solver.cpp:240] Iteration 186, loss = 0.906545
I0414 03:10:00.977067 16767 solver.cpp:256]     Train net output #0: loss = 0.906545 (* 1 = 0.906545 loss)
I0414 03:10:00.977075 16767 sgd_solver.cpp:106] Iteration 186, lr = 5e-05
I0414 03:10:01.381835 16767 solver.cpp:240] Iteration 187, loss = 0.944486
I0414 03:10:01.381863 16767 solver.cpp:256]     Train net output #0: loss = 0.944486 (* 1 = 0.944486 loss)
I0414 03:10:01.381871 16767 sgd_solver.cpp:106] Iteration 187, lr = 5e-05
I0414 03:10:01.787134 16767 solver.cpp:240] Iteration 188, loss = 0.96632
I0414 03:10:01.787163 16767 solver.cpp:256]     Train net output #0: loss = 0.96632 (* 1 = 0.96632 loss)
I0414 03:10:01.787171 16767 sgd_solver.cpp:106] Iteration 188, lr = 5e-05
I0414 03:10:02.191692 16767 solver.cpp:240] Iteration 189, loss = 0.929528
I0414 03:10:02.191727 16767 solver.cpp:256]     Train net output #0: loss = 0.929528 (* 1 = 0.929528 loss)
I0414 03:10:02.191735 16767 sgd_solver.cpp:106] Iteration 189, lr = 5e-05
I0414 03:10:02.597232 16767 solver.cpp:240] Iteration 190, loss = 0.920671
I0414 03:10:02.597267 16767 solver.cpp:256]     Train net output #0: loss = 0.920671 (* 1 = 0.920671 loss)
I0414 03:10:02.597301 16767 sgd_solver.cpp:106] Iteration 190, lr = 5e-05
I0414 03:10:03.002378 16767 solver.cpp:240] Iteration 191, loss = 0.873775
I0414 03:10:03.002413 16767 solver.cpp:256]     Train net output #0: loss = 0.873775 (* 1 = 0.873775 loss)
I0414 03:10:03.002420 16767 sgd_solver.cpp:106] Iteration 191, lr = 5e-05
I0414 03:10:03.407343 16767 solver.cpp:240] Iteration 192, loss = 0.903556
I0414 03:10:03.407372 16767 solver.cpp:256]     Train net output #0: loss = 0.903556 (* 1 = 0.903556 loss)
I0414 03:10:03.407378 16767 sgd_solver.cpp:106] Iteration 192, lr = 5e-05
I0414 03:10:03.812898 16767 solver.cpp:240] Iteration 193, loss = 0.890016
I0414 03:10:03.812937 16767 solver.cpp:256]     Train net output #0: loss = 0.890016 (* 1 = 0.890016 loss)
I0414 03:10:03.812945 16767 sgd_solver.cpp:106] Iteration 193, lr = 5e-05
I0414 03:10:04.218571 16767 solver.cpp:240] Iteration 194, loss = 0.839532
I0414 03:10:04.218605 16767 solver.cpp:256]     Train net output #0: loss = 0.839532 (* 1 = 0.839532 loss)
I0414 03:10:04.218612 16767 sgd_solver.cpp:106] Iteration 194, lr = 5e-05
I0414 03:10:04.624102 16767 solver.cpp:240] Iteration 195, loss = 0.912951
I0414 03:10:04.624142 16767 solver.cpp:256]     Train net output #0: loss = 0.912951 (* 1 = 0.912951 loss)
I0414 03:10:04.624151 16767 sgd_solver.cpp:106] Iteration 195, lr = 5e-05
I0414 03:10:05.029393 16767 solver.cpp:240] Iteration 196, loss = 0.977028
I0414 03:10:05.029427 16767 solver.cpp:256]     Train net output #0: loss = 0.977028 (* 1 = 0.977028 loss)
I0414 03:10:05.029434 16767 sgd_solver.cpp:106] Iteration 196, lr = 5e-05
I0414 03:10:05.434769 16767 solver.cpp:240] Iteration 197, loss = 0.931336
I0414 03:10:05.434806 16767 solver.cpp:256]     Train net output #0: loss = 0.931336 (* 1 = 0.931336 loss)
I0414 03:10:05.434814 16767 sgd_solver.cpp:106] Iteration 197, lr = 5e-05
I0414 03:10:05.840219 16767 solver.cpp:240] Iteration 198, loss = 0.989595
I0414 03:10:05.840363 16767 solver.cpp:256]     Train net output #0: loss = 0.989595 (* 1 = 0.989595 loss)
I0414 03:10:05.840374 16767 sgd_solver.cpp:106] Iteration 198, lr = 5e-05
I0414 03:10:06.245744 16767 solver.cpp:240] Iteration 199, loss = 0.848794
I0414 03:10:06.245784 16767 solver.cpp:256]     Train net output #0: loss = 0.848794 (* 1 = 0.848794 loss)
I0414 03:10:06.245791 16767 sgd_solver.cpp:106] Iteration 199, lr = 5e-05
I0414 03:10:06.246103 16767 solver.cpp:349] Iteration 200, Testing net (#0)
I0414 03:10:06.246119 16767 net.cpp:693] Ignoring source layer silence
I0414 03:10:07.628638 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.738159
I0414 03:10:07.628665 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.862427
I0414 03:10:07.628675 16767 solver.cpp:416]     Test net output #2: loss = 1.17475 (* 1 = 1.17475 loss)
I0414 03:10:07.768918 16767 solver.cpp:240] Iteration 200, loss = 0.86746
I0414 03:10:07.768949 16767 solver.cpp:256]     Train net output #0: loss = 0.86746 (* 1 = 0.86746 loss)
I0414 03:10:07.768955 16767 sgd_solver.cpp:106] Iteration 200, lr = 5e-05
I0414 03:10:08.174365 16767 solver.cpp:240] Iteration 201, loss = 0.885687
I0414 03:10:08.174394 16767 solver.cpp:256]     Train net output #0: loss = 0.885687 (* 1 = 0.885687 loss)
I0414 03:10:08.174402 16767 sgd_solver.cpp:106] Iteration 201, lr = 5e-05
I0414 03:10:08.579386 16767 solver.cpp:240] Iteration 202, loss = 0.879649
I0414 03:10:08.579422 16767 solver.cpp:256]     Train net output #0: loss = 0.879649 (* 1 = 0.879649 loss)
I0414 03:10:08.579430 16767 sgd_solver.cpp:106] Iteration 202, lr = 5e-05
I0414 03:10:08.984741 16767 solver.cpp:240] Iteration 203, loss = 0.925265
I0414 03:10:08.984776 16767 solver.cpp:256]     Train net output #0: loss = 0.925265 (* 1 = 0.925265 loss)
I0414 03:10:08.984783 16767 sgd_solver.cpp:106] Iteration 203, lr = 5e-05
I0414 03:10:09.389499 16767 solver.cpp:240] Iteration 204, loss = 0.911088
I0414 03:10:09.389536 16767 solver.cpp:256]     Train net output #0: loss = 0.911088 (* 1 = 0.911088 loss)
I0414 03:10:09.389544 16767 sgd_solver.cpp:106] Iteration 204, lr = 5e-05
I0414 03:10:09.794977 16767 solver.cpp:240] Iteration 205, loss = 0.919598
I0414 03:10:09.795009 16767 solver.cpp:256]     Train net output #0: loss = 0.919598 (* 1 = 0.919598 loss)
I0414 03:10:09.795017 16767 sgd_solver.cpp:106] Iteration 205, lr = 5e-05
I0414 03:10:10.200219 16767 solver.cpp:240] Iteration 206, loss = 0.878187
I0414 03:10:10.200260 16767 solver.cpp:256]     Train net output #0: loss = 0.878187 (* 1 = 0.878187 loss)
I0414 03:10:10.200268 16767 sgd_solver.cpp:106] Iteration 206, lr = 5e-05
I0414 03:10:10.605259 16767 solver.cpp:240] Iteration 207, loss = 0.855215
I0414 03:10:10.605293 16767 solver.cpp:256]     Train net output #0: loss = 0.855215 (* 1 = 0.855215 loss)
I0414 03:10:10.605300 16767 sgd_solver.cpp:106] Iteration 207, lr = 5e-05
I0414 03:10:11.010558 16767 solver.cpp:240] Iteration 208, loss = 0.896635
I0414 03:10:11.010594 16767 solver.cpp:256]     Train net output #0: loss = 0.896635 (* 1 = 0.896635 loss)
I0414 03:10:11.010602 16767 sgd_solver.cpp:106] Iteration 208, lr = 5e-05
I0414 03:10:11.414710 16767 solver.cpp:240] Iteration 209, loss = 0.927975
I0414 03:10:11.414746 16767 solver.cpp:256]     Train net output #0: loss = 0.927975 (* 1 = 0.927975 loss)
I0414 03:10:11.414753 16767 sgd_solver.cpp:106] Iteration 209, lr = 5e-05
I0414 03:10:11.818418 16767 solver.cpp:240] Iteration 210, loss = 0.894896
I0414 03:10:11.818454 16767 solver.cpp:256]     Train net output #0: loss = 0.894896 (* 1 = 0.894896 loss)
I0414 03:10:11.818460 16767 sgd_solver.cpp:106] Iteration 210, lr = 5e-05
I0414 03:10:12.224059 16767 solver.cpp:240] Iteration 211, loss = 0.854174
I0414 03:10:12.224095 16767 solver.cpp:256]     Train net output #0: loss = 0.854174 (* 1 = 0.854174 loss)
I0414 03:10:12.224103 16767 sgd_solver.cpp:106] Iteration 211, lr = 5e-05
I0414 03:10:12.629034 16767 solver.cpp:240] Iteration 212, loss = 0.900384
I0414 03:10:12.629070 16767 solver.cpp:256]     Train net output #0: loss = 0.900384 (* 1 = 0.900384 loss)
I0414 03:10:12.629104 16767 sgd_solver.cpp:106] Iteration 212, lr = 5e-05
I0414 03:10:13.034674 16767 solver.cpp:240] Iteration 213, loss = 0.868471
I0414 03:10:13.034703 16767 solver.cpp:256]     Train net output #0: loss = 0.868471 (* 1 = 0.868471 loss)
I0414 03:10:13.034711 16767 sgd_solver.cpp:106] Iteration 213, lr = 5e-05
I0414 03:10:13.439965 16767 solver.cpp:240] Iteration 214, loss = 0.908148
I0414 03:10:13.439999 16767 solver.cpp:256]     Train net output #0: loss = 0.908148 (* 1 = 0.908148 loss)
I0414 03:10:13.440007 16767 sgd_solver.cpp:106] Iteration 214, lr = 5e-05
I0414 03:10:13.846035 16767 solver.cpp:240] Iteration 215, loss = 0.834349
I0414 03:10:13.846074 16767 solver.cpp:256]     Train net output #0: loss = 0.834349 (* 1 = 0.834349 loss)
I0414 03:10:13.846082 16767 sgd_solver.cpp:106] Iteration 215, lr = 5e-05
I0414 03:10:14.251379 16767 solver.cpp:240] Iteration 216, loss = 0.793947
I0414 03:10:14.251415 16767 solver.cpp:256]     Train net output #0: loss = 0.793947 (* 1 = 0.793947 loss)
I0414 03:10:14.251422 16767 sgd_solver.cpp:106] Iteration 216, lr = 5e-05
I0414 03:10:14.656972 16767 solver.cpp:240] Iteration 217, loss = 0.864058
I0414 03:10:14.657006 16767 solver.cpp:256]     Train net output #0: loss = 0.864058 (* 1 = 0.864058 loss)
I0414 03:10:14.657014 16767 sgd_solver.cpp:106] Iteration 217, lr = 5e-05
I0414 03:10:15.061811 16767 solver.cpp:240] Iteration 218, loss = 0.795218
I0414 03:10:15.061847 16767 solver.cpp:256]     Train net output #0: loss = 0.795218 (* 1 = 0.795218 loss)
I0414 03:10:15.061856 16767 sgd_solver.cpp:106] Iteration 218, lr = 5e-05
I0414 03:10:15.466995 16767 solver.cpp:240] Iteration 219, loss = 0.812059
I0414 03:10:15.467027 16767 solver.cpp:256]     Train net output #0: loss = 0.812059 (* 1 = 0.812059 loss)
I0414 03:10:15.467034 16767 sgd_solver.cpp:106] Iteration 219, lr = 5e-05
I0414 03:10:15.872308 16767 solver.cpp:240] Iteration 220, loss = 0.858573
I0414 03:10:15.872340 16767 solver.cpp:256]     Train net output #0: loss = 0.858573 (* 1 = 0.858573 loss)
I0414 03:10:15.872349 16767 sgd_solver.cpp:106] Iteration 220, lr = 5e-05
I0414 03:10:16.277851 16767 solver.cpp:240] Iteration 221, loss = 0.877352
I0414 03:10:16.277886 16767 solver.cpp:256]     Train net output #0: loss = 0.877352 (* 1 = 0.877352 loss)
I0414 03:10:16.277894 16767 sgd_solver.cpp:106] Iteration 221, lr = 5e-05
I0414 03:10:16.683024 16767 solver.cpp:240] Iteration 222, loss = 0.92903
I0414 03:10:16.683058 16767 solver.cpp:256]     Train net output #0: loss = 0.92903 (* 1 = 0.92903 loss)
I0414 03:10:16.683065 16767 sgd_solver.cpp:106] Iteration 222, lr = 5e-05
I0414 03:10:17.090366 16767 solver.cpp:240] Iteration 223, loss = 0.933051
I0414 03:10:17.090414 16767 solver.cpp:256]     Train net output #0: loss = 0.933051 (* 1 = 0.933051 loss)
I0414 03:10:17.090430 16767 sgd_solver.cpp:106] Iteration 223, lr = 5e-05
I0414 03:10:17.495609 16767 solver.cpp:240] Iteration 224, loss = 0.791324
I0414 03:10:17.495645 16767 solver.cpp:256]     Train net output #0: loss = 0.791324 (* 1 = 0.791324 loss)
I0414 03:10:17.495652 16767 sgd_solver.cpp:106] Iteration 224, lr = 5e-05
I0414 03:10:17.495962 16767 solver.cpp:349] Iteration 225, Testing net (#0)
I0414 03:10:17.495981 16767 net.cpp:693] Ignoring source layer silence
I0414 03:10:18.877012 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.746094
I0414 03:10:18.877040 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.875977
I0414 03:10:18.877050 16767 solver.cpp:416]     Test net output #2: loss = 1.11803 (* 1 = 1.11803 loss)
I0414 03:10:19.017200 16767 solver.cpp:240] Iteration 225, loss = 0.782677
I0414 03:10:19.017235 16767 solver.cpp:256]     Train net output #0: loss = 0.782677 (* 1 = 0.782677 loss)
I0414 03:10:19.017243 16767 sgd_solver.cpp:106] Iteration 225, lr = 5e-05
I0414 03:10:19.423036 16767 solver.cpp:240] Iteration 226, loss = 0.82138
I0414 03:10:19.423075 16767 solver.cpp:256]     Train net output #0: loss = 0.82138 (* 1 = 0.82138 loss)
I0414 03:10:19.423084 16767 sgd_solver.cpp:106] Iteration 226, lr = 5e-05
I0414 03:10:19.828747 16767 solver.cpp:240] Iteration 227, loss = 0.839368
I0414 03:10:19.828783 16767 solver.cpp:256]     Train net output #0: loss = 0.839368 (* 1 = 0.839368 loss)
I0414 03:10:19.828790 16767 sgd_solver.cpp:106] Iteration 227, lr = 5e-05
I0414 03:10:20.234009 16767 solver.cpp:240] Iteration 228, loss = 0.882619
I0414 03:10:20.234042 16767 solver.cpp:256]     Train net output #0: loss = 0.882619 (* 1 = 0.882619 loss)
I0414 03:10:20.234050 16767 sgd_solver.cpp:106] Iteration 228, lr = 5e-05
I0414 03:10:20.639806 16767 solver.cpp:240] Iteration 229, loss = 0.824059
I0414 03:10:20.639842 16767 solver.cpp:256]     Train net output #0: loss = 0.824059 (* 1 = 0.824059 loss)
I0414 03:10:20.639849 16767 sgd_solver.cpp:106] Iteration 229, lr = 5e-05
I0414 03:10:21.045974 16767 solver.cpp:240] Iteration 230, loss = 0.857753
I0414 03:10:21.046008 16767 solver.cpp:256]     Train net output #0: loss = 0.857753 (* 1 = 0.857753 loss)
I0414 03:10:21.046016 16767 sgd_solver.cpp:106] Iteration 230, lr = 5e-05
I0414 03:10:21.451138 16767 solver.cpp:240] Iteration 231, loss = 0.779133
I0414 03:10:21.451169 16767 solver.cpp:256]     Train net output #0: loss = 0.779133 (* 1 = 0.779133 loss)
I0414 03:10:21.451177 16767 sgd_solver.cpp:106] Iteration 231, lr = 5e-05
I0414 03:10:21.856640 16767 solver.cpp:240] Iteration 232, loss = 0.784771
I0414 03:10:21.856680 16767 solver.cpp:256]     Train net output #0: loss = 0.784771 (* 1 = 0.784771 loss)
I0414 03:10:21.856688 16767 sgd_solver.cpp:106] Iteration 232, lr = 5e-05
I0414 03:10:22.262158 16767 solver.cpp:240] Iteration 233, loss = 0.897138
I0414 03:10:22.262192 16767 solver.cpp:256]     Train net output #0: loss = 0.897138 (* 1 = 0.897138 loss)
I0414 03:10:22.262200 16767 sgd_solver.cpp:106] Iteration 233, lr = 5e-05
I0414 03:10:22.667276 16767 solver.cpp:240] Iteration 234, loss = 0.859487
I0414 03:10:22.667311 16767 solver.cpp:256]     Train net output #0: loss = 0.859487 (* 1 = 0.859487 loss)
I0414 03:10:22.667320 16767 sgd_solver.cpp:106] Iteration 234, lr = 5e-05
I0414 03:10:23.072620 16767 solver.cpp:240] Iteration 235, loss = 0.795535
I0414 03:10:23.072654 16767 solver.cpp:256]     Train net output #0: loss = 0.795535 (* 1 = 0.795535 loss)
I0414 03:10:23.072662 16767 sgd_solver.cpp:106] Iteration 235, lr = 5e-05
I0414 03:10:23.478124 16767 solver.cpp:240] Iteration 236, loss = 0.792624
I0414 03:10:23.478159 16767 solver.cpp:256]     Train net output #0: loss = 0.792624 (* 1 = 0.792624 loss)
I0414 03:10:23.478168 16767 sgd_solver.cpp:106] Iteration 236, lr = 5e-05
I0414 03:10:23.884886 16767 solver.cpp:240] Iteration 237, loss = 0.821859
I0414 03:10:23.884924 16767 solver.cpp:256]     Train net output #0: loss = 0.821859 (* 1 = 0.821859 loss)
I0414 03:10:23.884933 16767 sgd_solver.cpp:106] Iteration 237, lr = 5e-05
I0414 03:10:24.291476 16767 solver.cpp:240] Iteration 238, loss = 0.802598
I0414 03:10:24.291518 16767 solver.cpp:256]     Train net output #0: loss = 0.802598 (* 1 = 0.802598 loss)
I0414 03:10:24.291527 16767 sgd_solver.cpp:106] Iteration 238, lr = 5e-05
I0414 03:10:24.696004 16767 solver.cpp:240] Iteration 239, loss = 0.855455
I0414 03:10:24.696038 16767 solver.cpp:256]     Train net output #0: loss = 0.855455 (* 1 = 0.855455 loss)
I0414 03:10:24.696046 16767 sgd_solver.cpp:106] Iteration 239, lr = 5e-05
I0414 03:10:25.100800 16767 solver.cpp:240] Iteration 240, loss = 0.736996
I0414 03:10:25.100829 16767 solver.cpp:256]     Train net output #0: loss = 0.736996 (* 1 = 0.736996 loss)
I0414 03:10:25.100836 16767 sgd_solver.cpp:106] Iteration 240, lr = 5e-05
I0414 03:10:25.510432 16767 solver.cpp:240] Iteration 241, loss = 0.794047
I0414 03:10:25.510486 16767 solver.cpp:256]     Train net output #0: loss = 0.794047 (* 1 = 0.794047 loss)
I0414 03:10:25.510500 16767 sgd_solver.cpp:106] Iteration 241, lr = 5e-05
I0414 03:10:25.915786 16767 solver.cpp:240] Iteration 242, loss = 0.816468
I0414 03:10:25.915823 16767 solver.cpp:256]     Train net output #0: loss = 0.816468 (* 1 = 0.816468 loss)
I0414 03:10:25.915832 16767 sgd_solver.cpp:106] Iteration 242, lr = 5e-05
I0414 03:10:26.320425 16767 solver.cpp:240] Iteration 243, loss = 0.751237
I0414 03:10:26.320458 16767 solver.cpp:256]     Train net output #0: loss = 0.751237 (* 1 = 0.751237 loss)
I0414 03:10:26.320467 16767 sgd_solver.cpp:106] Iteration 243, lr = 5e-05
I0414 03:10:26.725347 16767 solver.cpp:240] Iteration 244, loss = 0.744775
I0414 03:10:26.725376 16767 solver.cpp:256]     Train net output #0: loss = 0.744775 (* 1 = 0.744775 loss)
I0414 03:10:26.725384 16767 sgd_solver.cpp:106] Iteration 244, lr = 5e-05
I0414 03:10:27.130689 16767 solver.cpp:240] Iteration 245, loss = 0.868249
I0414 03:10:27.130725 16767 solver.cpp:256]     Train net output #0: loss = 0.868249 (* 1 = 0.868249 loss)
I0414 03:10:27.130733 16767 sgd_solver.cpp:106] Iteration 245, lr = 5e-05
I0414 03:10:27.536545 16767 solver.cpp:240] Iteration 246, loss = 0.791288
I0414 03:10:27.536586 16767 solver.cpp:256]     Train net output #0: loss = 0.791288 (* 1 = 0.791288 loss)
I0414 03:10:27.536594 16767 sgd_solver.cpp:106] Iteration 246, lr = 5e-05
I0414 03:10:27.941489 16767 solver.cpp:240] Iteration 247, loss = 0.883388
I0414 03:10:27.941526 16767 solver.cpp:256]     Train net output #0: loss = 0.883388 (* 1 = 0.883388 loss)
I0414 03:10:27.941534 16767 sgd_solver.cpp:106] Iteration 247, lr = 5e-05
I0414 03:10:28.346979 16767 solver.cpp:240] Iteration 248, loss = 0.832774
I0414 03:10:28.347013 16767 solver.cpp:256]     Train net output #0: loss = 0.832774 (* 1 = 0.832774 loss)
I0414 03:10:28.347021 16767 sgd_solver.cpp:106] Iteration 248, lr = 5e-05
I0414 03:10:28.752043 16767 solver.cpp:240] Iteration 249, loss = 0.767649
I0414 03:10:28.752076 16767 solver.cpp:256]     Train net output #0: loss = 0.767649 (* 1 = 0.767649 loss)
I0414 03:10:28.752084 16767 sgd_solver.cpp:106] Iteration 249, lr = 5e-05
I0414 03:10:28.752315 16767 solver.cpp:466] Snapshotting to binary proto file ./snapshots/experiment_11/rtsd-r1/CoNorm/trial_1/snap_iter_250.caffemodel
I0414 03:10:29.064707 16767 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./snapshots/experiment_11/rtsd-r1/CoNorm/trial_1/snap_iter_250.solverstate
I0414 03:10:29.092195 16767 solver.cpp:349] Iteration 250, Testing net (#0)
I0414 03:10:29.092226 16767 net.cpp:693] Ignoring source layer silence
I0414 03:10:30.207538 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.763916
I0414 03:10:30.207571 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.888062
I0414 03:10:30.207581 16767 solver.cpp:416]     Test net output #2: loss = 1.05404 (* 1 = 1.05404 loss)
I0414 03:10:30.347506 16767 solver.cpp:240] Iteration 250, loss = 0.716608
I0414 03:10:30.347537 16767 solver.cpp:256]     Train net output #0: loss = 0.716608 (* 1 = 0.716608 loss)
I0414 03:10:30.347543 16767 sgd_solver.cpp:106] Iteration 250, lr = 2.5e-05
I0414 03:10:30.751488 16767 solver.cpp:240] Iteration 251, loss = 0.827489
I0414 03:10:30.751523 16767 solver.cpp:256]     Train net output #0: loss = 0.827489 (* 1 = 0.827489 loss)
I0414 03:10:30.751530 16767 sgd_solver.cpp:106] Iteration 251, lr = 2.5e-05
I0414 03:10:31.156782 16767 solver.cpp:240] Iteration 252, loss = 0.784522
I0414 03:10:31.156821 16767 solver.cpp:256]     Train net output #0: loss = 0.784522 (* 1 = 0.784522 loss)
I0414 03:10:31.156828 16767 sgd_solver.cpp:106] Iteration 252, lr = 2.5e-05
I0414 03:10:31.561156 16767 solver.cpp:240] Iteration 253, loss = 0.791676
I0414 03:10:31.561192 16767 solver.cpp:256]     Train net output #0: loss = 0.791676 (* 1 = 0.791676 loss)
I0414 03:10:31.561200 16767 sgd_solver.cpp:106] Iteration 253, lr = 2.5e-05
I0414 03:10:31.966173 16767 solver.cpp:240] Iteration 254, loss = 0.787172
I0414 03:10:31.966212 16767 solver.cpp:256]     Train net output #0: loss = 0.787172 (* 1 = 0.787172 loss)
I0414 03:10:31.966222 16767 sgd_solver.cpp:106] Iteration 254, lr = 2.5e-05
I0414 03:10:32.371587 16767 solver.cpp:240] Iteration 255, loss = 0.870694
I0414 03:10:32.371624 16767 solver.cpp:256]     Train net output #0: loss = 0.870694 (* 1 = 0.870694 loss)
I0414 03:10:32.371634 16767 sgd_solver.cpp:106] Iteration 255, lr = 2.5e-05
I0414 03:10:32.776880 16767 solver.cpp:240] Iteration 256, loss = 0.738638
I0414 03:10:32.776924 16767 solver.cpp:256]     Train net output #0: loss = 0.738638 (* 1 = 0.738638 loss)
I0414 03:10:32.776933 16767 sgd_solver.cpp:106] Iteration 256, lr = 2.5e-05
I0414 03:10:33.182471 16767 solver.cpp:240] Iteration 257, loss = 0.809595
I0414 03:10:33.182510 16767 solver.cpp:256]     Train net output #0: loss = 0.809595 (* 1 = 0.809595 loss)
I0414 03:10:33.182518 16767 sgd_solver.cpp:106] Iteration 257, lr = 2.5e-05
I0414 03:10:33.587630 16767 solver.cpp:240] Iteration 258, loss = 0.825702
I0414 03:10:33.587664 16767 solver.cpp:256]     Train net output #0: loss = 0.825702 (* 1 = 0.825702 loss)
I0414 03:10:33.587672 16767 sgd_solver.cpp:106] Iteration 258, lr = 2.5e-05
I0414 03:10:33.992475 16767 solver.cpp:240] Iteration 259, loss = 0.799283
I0414 03:10:33.992511 16767 solver.cpp:256]     Train net output #0: loss = 0.799283 (* 1 = 0.799283 loss)
I0414 03:10:33.992519 16767 sgd_solver.cpp:106] Iteration 259, lr = 2.5e-05
I0414 03:10:34.397935 16767 solver.cpp:240] Iteration 260, loss = 0.789029
I0414 03:10:34.397970 16767 solver.cpp:256]     Train net output #0: loss = 0.789029 (* 1 = 0.789029 loss)
I0414 03:10:34.397979 16767 sgd_solver.cpp:106] Iteration 260, lr = 2.5e-05
I0414 03:10:34.803776 16767 solver.cpp:240] Iteration 261, loss = 0.792909
I0414 03:10:34.803812 16767 solver.cpp:256]     Train net output #0: loss = 0.792909 (* 1 = 0.792909 loss)
I0414 03:10:34.803819 16767 sgd_solver.cpp:106] Iteration 261, lr = 2.5e-05
I0414 03:10:35.209131 16767 solver.cpp:240] Iteration 262, loss = 0.786634
I0414 03:10:35.209169 16767 solver.cpp:256]     Train net output #0: loss = 0.786634 (* 1 = 0.786634 loss)
I0414 03:10:35.209178 16767 sgd_solver.cpp:106] Iteration 262, lr = 2.5e-05
I0414 03:10:35.614245 16767 solver.cpp:240] Iteration 263, loss = 0.765321
I0414 03:10:35.614284 16767 solver.cpp:256]     Train net output #0: loss = 0.765321 (* 1 = 0.765321 loss)
I0414 03:10:35.614292 16767 sgd_solver.cpp:106] Iteration 263, lr = 2.5e-05
I0414 03:10:36.019707 16767 solver.cpp:240] Iteration 264, loss = 0.796818
I0414 03:10:36.022121 16767 solver.cpp:256]     Train net output #0: loss = 0.796818 (* 1 = 0.796818 loss)
I0414 03:10:36.022132 16767 sgd_solver.cpp:106] Iteration 264, lr = 2.5e-05
I0414 03:10:36.424728 16767 solver.cpp:240] Iteration 265, loss = 0.746915
I0414 03:10:36.424762 16767 solver.cpp:256]     Train net output #0: loss = 0.746915 (* 1 = 0.746915 loss)
I0414 03:10:36.424770 16767 sgd_solver.cpp:106] Iteration 265, lr = 2.5e-05
I0414 03:10:36.829872 16767 solver.cpp:240] Iteration 266, loss = 0.739812
I0414 03:10:36.829906 16767 solver.cpp:256]     Train net output #0: loss = 0.739812 (* 1 = 0.739812 loss)
I0414 03:10:36.829915 16767 sgd_solver.cpp:106] Iteration 266, lr = 2.5e-05
I0414 03:10:37.235952 16767 solver.cpp:240] Iteration 267, loss = 0.775105
I0414 03:10:37.235986 16767 solver.cpp:256]     Train net output #0: loss = 0.775105 (* 1 = 0.775105 loss)
I0414 03:10:37.235994 16767 sgd_solver.cpp:106] Iteration 267, lr = 2.5e-05
I0414 03:10:37.641413 16767 solver.cpp:240] Iteration 268, loss = 0.728835
I0414 03:10:37.641448 16767 solver.cpp:256]     Train net output #0: loss = 0.728835 (* 1 = 0.728835 loss)
I0414 03:10:37.641458 16767 sgd_solver.cpp:106] Iteration 268, lr = 2.5e-05
I0414 03:10:38.046756 16767 solver.cpp:240] Iteration 269, loss = 0.76326
I0414 03:10:38.046792 16767 solver.cpp:256]     Train net output #0: loss = 0.76326 (* 1 = 0.76326 loss)
I0414 03:10:38.046799 16767 sgd_solver.cpp:106] Iteration 269, lr = 2.5e-05
I0414 03:10:38.452294 16767 solver.cpp:240] Iteration 270, loss = 0.845557
I0414 03:10:38.452333 16767 solver.cpp:256]     Train net output #0: loss = 0.845557 (* 1 = 0.845557 loss)
I0414 03:10:38.452342 16767 sgd_solver.cpp:106] Iteration 270, lr = 2.5e-05
I0414 03:10:38.857830 16767 solver.cpp:240] Iteration 271, loss = 0.756396
I0414 03:10:38.857864 16767 solver.cpp:256]     Train net output #0: loss = 0.756396 (* 1 = 0.756396 loss)
I0414 03:10:38.857873 16767 sgd_solver.cpp:106] Iteration 271, lr = 2.5e-05
I0414 03:10:39.264804 16767 solver.cpp:240] Iteration 272, loss = 0.833054
I0414 03:10:39.264840 16767 solver.cpp:256]     Train net output #0: loss = 0.833054 (* 1 = 0.833054 loss)
I0414 03:10:39.264848 16767 sgd_solver.cpp:106] Iteration 272, lr = 2.5e-05
I0414 03:10:39.670356 16767 solver.cpp:240] Iteration 273, loss = 0.779363
I0414 03:10:39.670392 16767 solver.cpp:256]     Train net output #0: loss = 0.779363 (* 1 = 0.779363 loss)
I0414 03:10:39.670399 16767 sgd_solver.cpp:106] Iteration 273, lr = 2.5e-05
I0414 03:10:40.075229 16767 solver.cpp:240] Iteration 274, loss = 0.723627
I0414 03:10:40.075265 16767 solver.cpp:256]     Train net output #0: loss = 0.723627 (* 1 = 0.723627 loss)
I0414 03:10:40.075273 16767 sgd_solver.cpp:106] Iteration 274, lr = 2.5e-05
I0414 03:10:40.075579 16767 solver.cpp:349] Iteration 275, Testing net (#0)
I0414 03:10:40.075598 16767 net.cpp:693] Ignoring source layer silence
I0414 03:10:41.459152 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.763916
I0414 03:10:41.459183 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.894897
I0414 03:10:41.459193 16767 solver.cpp:416]     Test net output #2: loss = 1.02927 (* 1 = 1.02927 loss)
I0414 03:10:41.599256 16767 solver.cpp:240] Iteration 275, loss = 0.716832
I0414 03:10:41.599289 16767 solver.cpp:256]     Train net output #0: loss = 0.716832 (* 1 = 0.716832 loss)
I0414 03:10:41.599298 16767 sgd_solver.cpp:106] Iteration 275, lr = 2.5e-05
I0414 03:10:42.004781 16767 solver.cpp:240] Iteration 276, loss = 0.835684
I0414 03:10:42.004812 16767 solver.cpp:256]     Train net output #0: loss = 0.835684 (* 1 = 0.835684 loss)
I0414 03:10:42.004820 16767 sgd_solver.cpp:106] Iteration 276, lr = 2.5e-05
I0414 03:10:42.410209 16767 solver.cpp:240] Iteration 277, loss = 0.743503
I0414 03:10:42.410244 16767 solver.cpp:256]     Train net output #0: loss = 0.743503 (* 1 = 0.743503 loss)
I0414 03:10:42.410254 16767 sgd_solver.cpp:106] Iteration 277, lr = 2.5e-05
I0414 03:10:42.815253 16767 solver.cpp:240] Iteration 278, loss = 0.798019
I0414 03:10:42.815285 16767 solver.cpp:256]     Train net output #0: loss = 0.798019 (* 1 = 0.798019 loss)
I0414 03:10:42.815312 16767 sgd_solver.cpp:106] Iteration 278, lr = 2.5e-05
I0414 03:10:43.220580 16767 solver.cpp:240] Iteration 279, loss = 0.752353
I0414 03:10:43.220614 16767 solver.cpp:256]     Train net output #0: loss = 0.752353 (* 1 = 0.752353 loss)
I0414 03:10:43.220623 16767 sgd_solver.cpp:106] Iteration 279, lr = 2.5e-05
I0414 03:10:43.625537 16767 solver.cpp:240] Iteration 280, loss = 0.803586
I0414 03:10:43.625576 16767 solver.cpp:256]     Train net output #0: loss = 0.803586 (* 1 = 0.803586 loss)
I0414 03:10:43.625584 16767 sgd_solver.cpp:106] Iteration 280, lr = 2.5e-05
I0414 03:10:44.032618 16767 solver.cpp:240] Iteration 281, loss = 0.711083
I0414 03:10:44.032657 16767 solver.cpp:256]     Train net output #0: loss = 0.711083 (* 1 = 0.711083 loss)
I0414 03:10:44.032666 16767 sgd_solver.cpp:106] Iteration 281, lr = 2.5e-05
I0414 03:10:44.438076 16767 solver.cpp:240] Iteration 282, loss = 0.761007
I0414 03:10:44.438107 16767 solver.cpp:256]     Train net output #0: loss = 0.761007 (* 1 = 0.761007 loss)
I0414 03:10:44.438115 16767 sgd_solver.cpp:106] Iteration 282, lr = 2.5e-05
I0414 03:10:44.843875 16767 solver.cpp:240] Iteration 283, loss = 0.799298
I0414 03:10:44.843914 16767 solver.cpp:256]     Train net output #0: loss = 0.799298 (* 1 = 0.799298 loss)
I0414 03:10:44.843922 16767 sgd_solver.cpp:106] Iteration 283, lr = 2.5e-05
I0414 03:10:45.249536 16767 solver.cpp:240] Iteration 284, loss = 0.748216
I0414 03:10:45.249572 16767 solver.cpp:256]     Train net output #0: loss = 0.748216 (* 1 = 0.748216 loss)
I0414 03:10:45.249580 16767 sgd_solver.cpp:106] Iteration 284, lr = 2.5e-05
I0414 03:10:45.655642 16767 solver.cpp:240] Iteration 285, loss = 0.729318
I0414 03:10:45.655679 16767 solver.cpp:256]     Train net output #0: loss = 0.729318 (* 1 = 0.729318 loss)
I0414 03:10:45.655688 16767 sgd_solver.cpp:106] Iteration 285, lr = 2.5e-05
I0414 03:10:46.061378 16767 solver.cpp:240] Iteration 286, loss = 0.779599
I0414 03:10:46.061408 16767 solver.cpp:256]     Train net output #0: loss = 0.779599 (* 1 = 0.779599 loss)
I0414 03:10:46.061415 16767 sgd_solver.cpp:106] Iteration 286, lr = 2.5e-05
I0414 03:10:46.466400 16767 solver.cpp:240] Iteration 287, loss = 0.762251
I0414 03:10:46.466433 16767 solver.cpp:256]     Train net output #0: loss = 0.762251 (* 1 = 0.762251 loss)
I0414 03:10:46.466440 16767 sgd_solver.cpp:106] Iteration 287, lr = 2.5e-05
I0414 03:10:46.871579 16767 solver.cpp:240] Iteration 288, loss = 0.77338
I0414 03:10:46.871618 16767 solver.cpp:256]     Train net output #0: loss = 0.77338 (* 1 = 0.77338 loss)
I0414 03:10:46.871625 16767 sgd_solver.cpp:106] Iteration 288, lr = 2.5e-05
I0414 03:10:47.277269 16767 solver.cpp:240] Iteration 289, loss = 0.765905
I0414 03:10:47.277305 16767 solver.cpp:256]     Train net output #0: loss = 0.765905 (* 1 = 0.765905 loss)
I0414 03:10:47.277314 16767 sgd_solver.cpp:106] Iteration 289, lr = 2.5e-05
I0414 03:10:47.682857 16767 solver.cpp:240] Iteration 290, loss = 0.730048
I0414 03:10:47.682893 16767 solver.cpp:256]     Train net output #0: loss = 0.730048 (* 1 = 0.730048 loss)
I0414 03:10:47.682901 16767 sgd_solver.cpp:106] Iteration 290, lr = 2.5e-05
I0414 03:10:48.088745 16767 solver.cpp:240] Iteration 291, loss = 0.714435
I0414 03:10:48.088778 16767 solver.cpp:256]     Train net output #0: loss = 0.714435 (* 1 = 0.714435 loss)
I0414 03:10:48.088786 16767 sgd_solver.cpp:106] Iteration 291, lr = 2.5e-05
I0414 03:10:48.493909 16767 solver.cpp:240] Iteration 292, loss = 0.747101
I0414 03:10:48.493945 16767 solver.cpp:256]     Train net output #0: loss = 0.747101 (* 1 = 0.747101 loss)
I0414 03:10:48.493953 16767 sgd_solver.cpp:106] Iteration 292, lr = 2.5e-05
I0414 03:10:48.899313 16767 solver.cpp:240] Iteration 293, loss = 0.696988
I0414 03:10:48.899348 16767 solver.cpp:256]     Train net output #0: loss = 0.696988 (* 1 = 0.696988 loss)
I0414 03:10:48.899358 16767 sgd_solver.cpp:106] Iteration 293, lr = 2.5e-05
I0414 03:10:49.304803 16767 solver.cpp:240] Iteration 294, loss = 0.804586
I0414 03:10:49.304846 16767 solver.cpp:256]     Train net output #0: loss = 0.804586 (* 1 = 0.804586 loss)
I0414 03:10:49.304883 16767 sgd_solver.cpp:106] Iteration 294, lr = 2.5e-05
I0414 03:10:49.710007 16767 solver.cpp:240] Iteration 295, loss = 0.758478
I0414 03:10:49.710041 16767 solver.cpp:256]     Train net output #0: loss = 0.758478 (* 1 = 0.758478 loss)
I0414 03:10:49.710049 16767 sgd_solver.cpp:106] Iteration 295, lr = 2.5e-05
I0414 03:10:50.115486 16767 solver.cpp:240] Iteration 296, loss = 0.783365
I0414 03:10:50.115530 16767 solver.cpp:256]     Train net output #0: loss = 0.783365 (* 1 = 0.783365 loss)
I0414 03:10:50.115538 16767 sgd_solver.cpp:106] Iteration 296, lr = 2.5e-05
I0414 03:10:50.520814 16767 solver.cpp:240] Iteration 297, loss = 0.804507
I0414 03:10:50.520848 16767 solver.cpp:256]     Train net output #0: loss = 0.804507 (* 1 = 0.804507 loss)
I0414 03:10:50.520858 16767 sgd_solver.cpp:106] Iteration 297, lr = 2.5e-05
I0414 03:10:50.926198 16767 solver.cpp:240] Iteration 298, loss = 0.742378
I0414 03:10:50.926234 16767 solver.cpp:256]     Train net output #0: loss = 0.742378 (* 1 = 0.742378 loss)
I0414 03:10:50.926242 16767 sgd_solver.cpp:106] Iteration 298, lr = 2.5e-05
I0414 03:10:51.333119 16767 solver.cpp:240] Iteration 299, loss = 0.699668
I0414 03:10:51.333163 16767 solver.cpp:256]     Train net output #0: loss = 0.699668 (* 1 = 0.699668 loss)
I0414 03:10:51.333173 16767 sgd_solver.cpp:106] Iteration 299, lr = 2.5e-05
I0414 03:10:51.333611 16767 solver.cpp:349] Iteration 300, Testing net (#0)
I0414 03:10:51.333632 16767 net.cpp:693] Ignoring source layer silence
I0414 03:10:52.712435 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.770996
I0414 03:10:52.712466 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.901123
I0414 03:10:52.712476 16767 solver.cpp:416]     Test net output #2: loss = 0.99771 (* 1 = 0.99771 loss)
I0414 03:10:52.852424 16767 solver.cpp:240] Iteration 300, loss = 0.736807
I0414 03:10:52.852453 16767 solver.cpp:256]     Train net output #0: loss = 0.736807 (* 1 = 0.736807 loss)
I0414 03:10:52.852461 16767 sgd_solver.cpp:106] Iteration 300, lr = 2.5e-05
I0414 03:10:53.257638 16767 solver.cpp:240] Iteration 301, loss = 0.753352
I0414 03:10:53.257676 16767 solver.cpp:256]     Train net output #0: loss = 0.753352 (* 1 = 0.753352 loss)
I0414 03:10:53.257685 16767 sgd_solver.cpp:106] Iteration 301, lr = 2.5e-05
I0414 03:10:53.663280 16767 solver.cpp:240] Iteration 302, loss = 0.755724
I0414 03:10:53.663316 16767 solver.cpp:256]     Train net output #0: loss = 0.755724 (* 1 = 0.755724 loss)
I0414 03:10:53.663326 16767 sgd_solver.cpp:106] Iteration 302, lr = 2.5e-05
I0414 03:10:54.068617 16767 solver.cpp:240] Iteration 303, loss = 0.748116
I0414 03:10:54.068647 16767 solver.cpp:256]     Train net output #0: loss = 0.748116 (* 1 = 0.748116 loss)
I0414 03:10:54.068655 16767 sgd_solver.cpp:106] Iteration 303, lr = 2.5e-05
I0414 03:10:54.474071 16767 solver.cpp:240] Iteration 304, loss = 0.716789
I0414 03:10:54.474102 16767 solver.cpp:256]     Train net output #0: loss = 0.716789 (* 1 = 0.716789 loss)
I0414 03:10:54.474109 16767 sgd_solver.cpp:106] Iteration 304, lr = 2.5e-05
I0414 03:10:54.879259 16767 solver.cpp:240] Iteration 305, loss = 0.769649
I0414 03:10:54.879295 16767 solver.cpp:256]     Train net output #0: loss = 0.769649 (* 1 = 0.769649 loss)
I0414 03:10:54.879303 16767 sgd_solver.cpp:106] Iteration 305, lr = 2.5e-05
I0414 03:10:55.284788 16767 solver.cpp:240] Iteration 306, loss = 0.685278
I0414 03:10:55.284823 16767 solver.cpp:256]     Train net output #0: loss = 0.685278 (* 1 = 0.685278 loss)
I0414 03:10:55.284832 16767 sgd_solver.cpp:106] Iteration 306, lr = 2.5e-05
I0414 03:10:55.690312 16767 solver.cpp:240] Iteration 307, loss = 0.770141
I0414 03:10:55.690347 16767 solver.cpp:256]     Train net output #0: loss = 0.770141 (* 1 = 0.770141 loss)
I0414 03:10:55.690356 16767 sgd_solver.cpp:106] Iteration 307, lr = 2.5e-05
I0414 03:10:56.096264 16767 solver.cpp:240] Iteration 308, loss = 0.789493
I0414 03:10:56.096298 16767 solver.cpp:256]     Train net output #0: loss = 0.789493 (* 1 = 0.789493 loss)
I0414 03:10:56.096328 16767 sgd_solver.cpp:106] Iteration 308, lr = 2.5e-05
I0414 03:10:56.502286 16767 solver.cpp:240] Iteration 309, loss = 0.737869
I0414 03:10:56.502321 16767 solver.cpp:256]     Train net output #0: loss = 0.737869 (* 1 = 0.737869 loss)
I0414 03:10:56.502328 16767 sgd_solver.cpp:106] Iteration 309, lr = 2.5e-05
I0414 03:10:56.908351 16767 solver.cpp:240] Iteration 310, loss = 0.720996
I0414 03:10:56.908387 16767 solver.cpp:256]     Train net output #0: loss = 0.720996 (* 1 = 0.720996 loss)
I0414 03:10:56.908396 16767 sgd_solver.cpp:106] Iteration 310, lr = 2.5e-05
I0414 03:10:57.314152 16767 solver.cpp:240] Iteration 311, loss = 0.727233
I0414 03:10:57.314188 16767 solver.cpp:256]     Train net output #0: loss = 0.727233 (* 1 = 0.727233 loss)
I0414 03:10:57.314198 16767 sgd_solver.cpp:106] Iteration 311, lr = 2.5e-05
I0414 03:10:57.719269 16767 solver.cpp:240] Iteration 312, loss = 0.790279
I0414 03:10:57.719301 16767 solver.cpp:256]     Train net output #0: loss = 0.790279 (* 1 = 0.790279 loss)
I0414 03:10:57.719310 16767 sgd_solver.cpp:106] Iteration 312, lr = 2.5e-05
I0414 03:10:58.124773 16767 solver.cpp:240] Iteration 313, loss = 0.738244
I0414 03:10:58.124807 16767 solver.cpp:256]     Train net output #0: loss = 0.738244 (* 1 = 0.738244 loss)
I0414 03:10:58.124816 16767 sgd_solver.cpp:106] Iteration 313, lr = 2.5e-05
I0414 03:10:58.530395 16767 solver.cpp:240] Iteration 314, loss = 0.759109
I0414 03:10:58.530441 16767 solver.cpp:256]     Train net output #0: loss = 0.759109 (* 1 = 0.759109 loss)
I0414 03:10:58.530449 16767 sgd_solver.cpp:106] Iteration 314, lr = 2.5e-05
I0414 03:10:58.934912 16767 solver.cpp:240] Iteration 315, loss = 0.689009
I0414 03:10:58.934948 16767 solver.cpp:256]     Train net output #0: loss = 0.689009 (* 1 = 0.689009 loss)
I0414 03:10:58.934957 16767 sgd_solver.cpp:106] Iteration 315, lr = 2.5e-05
I0414 03:10:59.340126 16767 solver.cpp:240] Iteration 316, loss = 0.692838
I0414 03:10:59.340167 16767 solver.cpp:256]     Train net output #0: loss = 0.692838 (* 1 = 0.692838 loss)
I0414 03:10:59.340175 16767 sgd_solver.cpp:106] Iteration 316, lr = 2.5e-05
I0414 03:10:59.744848 16767 solver.cpp:240] Iteration 317, loss = 0.726877
I0414 03:10:59.744882 16767 solver.cpp:256]     Train net output #0: loss = 0.726877 (* 1 = 0.726877 loss)
I0414 03:10:59.744890 16767 sgd_solver.cpp:106] Iteration 317, lr = 2.5e-05
I0414 03:11:00.150924 16767 solver.cpp:240] Iteration 318, loss = 0.714251
I0414 03:11:00.150959 16767 solver.cpp:256]     Train net output #0: loss = 0.714251 (* 1 = 0.714251 loss)
I0414 03:11:00.150967 16767 sgd_solver.cpp:106] Iteration 318, lr = 2.5e-05
I0414 03:11:00.556653 16767 solver.cpp:240] Iteration 319, loss = 0.710545
I0414 03:11:00.556687 16767 solver.cpp:256]     Train net output #0: loss = 0.710545 (* 1 = 0.710545 loss)
I0414 03:11:00.556695 16767 sgd_solver.cpp:106] Iteration 319, lr = 2.5e-05
I0414 03:11:00.961987 16767 solver.cpp:240] Iteration 320, loss = 0.796663
I0414 03:11:00.962024 16767 solver.cpp:256]     Train net output #0: loss = 0.796663 (* 1 = 0.796663 loss)
I0414 03:11:00.962033 16767 sgd_solver.cpp:106] Iteration 320, lr = 2.5e-05
I0414 03:11:01.367180 16767 solver.cpp:240] Iteration 321, loss = 0.72046
I0414 03:11:01.367215 16767 solver.cpp:256]     Train net output #0: loss = 0.72046 (* 1 = 0.72046 loss)
I0414 03:11:01.367223 16767 sgd_solver.cpp:106] Iteration 321, lr = 2.5e-05
I0414 03:11:01.772387 16767 solver.cpp:240] Iteration 322, loss = 0.792954
I0414 03:11:01.772421 16767 solver.cpp:256]     Train net output #0: loss = 0.792954 (* 1 = 0.792954 loss)
I0414 03:11:01.772429 16767 sgd_solver.cpp:106] Iteration 322, lr = 2.5e-05
I0414 03:11:02.177676 16767 solver.cpp:240] Iteration 323, loss = 0.729806
I0414 03:11:02.177712 16767 solver.cpp:256]     Train net output #0: loss = 0.729806 (* 1 = 0.729806 loss)
I0414 03:11:02.177721 16767 sgd_solver.cpp:106] Iteration 323, lr = 2.5e-05
I0414 03:11:02.583003 16767 solver.cpp:240] Iteration 324, loss = 0.673739
I0414 03:11:02.583037 16767 solver.cpp:256]     Train net output #0: loss = 0.673739 (* 1 = 0.673739 loss)
I0414 03:11:02.583068 16767 sgd_solver.cpp:106] Iteration 324, lr = 2.5e-05
I0414 03:11:02.583377 16767 solver.cpp:349] Iteration 325, Testing net (#0)
I0414 03:11:02.583395 16767 net.cpp:693] Ignoring source layer silence
I0414 03:11:03.964207 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.773682
I0414 03:11:03.964238 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.904907
I0414 03:11:03.964247 16767 solver.cpp:416]     Test net output #2: loss = 0.973912 (* 1 = 0.973912 loss)
I0414 03:11:04.104419 16767 solver.cpp:240] Iteration 325, loss = 0.728316
I0414 03:11:04.104457 16767 solver.cpp:256]     Train net output #0: loss = 0.728316 (* 1 = 0.728316 loss)
I0414 03:11:04.104466 16767 sgd_solver.cpp:106] Iteration 325, lr = 2.5e-05
I0414 03:11:04.509454 16767 solver.cpp:240] Iteration 326, loss = 0.732875
I0414 03:11:04.509490 16767 solver.cpp:256]     Train net output #0: loss = 0.732875 (* 1 = 0.732875 loss)
I0414 03:11:04.509497 16767 sgd_solver.cpp:106] Iteration 326, lr = 2.5e-05
I0414 03:11:04.914921 16767 solver.cpp:240] Iteration 327, loss = 0.724369
I0414 03:11:04.914957 16767 solver.cpp:256]     Train net output #0: loss = 0.724369 (* 1 = 0.724369 loss)
I0414 03:11:04.914964 16767 sgd_solver.cpp:106] Iteration 327, lr = 2.5e-05
I0414 03:11:05.320392 16767 solver.cpp:240] Iteration 328, loss = 0.728359
I0414 03:11:05.320430 16767 solver.cpp:256]     Train net output #0: loss = 0.728359 (* 1 = 0.728359 loss)
I0414 03:11:05.320437 16767 sgd_solver.cpp:106] Iteration 328, lr = 2.5e-05
I0414 03:11:05.726554 16767 solver.cpp:240] Iteration 329, loss = 0.691291
I0414 03:11:05.726590 16767 solver.cpp:256]     Train net output #0: loss = 0.691291 (* 1 = 0.691291 loss)
I0414 03:11:05.726598 16767 sgd_solver.cpp:106] Iteration 329, lr = 2.5e-05
I0414 03:11:06.132040 16767 solver.cpp:240] Iteration 330, loss = 0.752564
I0414 03:11:06.132164 16767 solver.cpp:256]     Train net output #0: loss = 0.752564 (* 1 = 0.752564 loss)
I0414 03:11:06.132174 16767 sgd_solver.cpp:106] Iteration 330, lr = 2.5e-05
I0414 03:11:06.536092 16767 solver.cpp:240] Iteration 331, loss = 0.677339
I0414 03:11:06.536134 16767 solver.cpp:256]     Train net output #0: loss = 0.677339 (* 1 = 0.677339 loss)
I0414 03:11:06.536144 16767 sgd_solver.cpp:106] Iteration 331, lr = 2.5e-05
I0414 03:11:06.941674 16767 solver.cpp:240] Iteration 332, loss = 0.706343
I0414 03:11:06.941714 16767 solver.cpp:256]     Train net output #0: loss = 0.706343 (* 1 = 0.706343 loss)
I0414 03:11:06.941723 16767 sgd_solver.cpp:106] Iteration 332, lr = 2.5e-05
I0414 03:11:07.347100 16767 solver.cpp:240] Iteration 333, loss = 0.776817
I0414 03:11:07.347138 16767 solver.cpp:256]     Train net output #0: loss = 0.776817 (* 1 = 0.776817 loss)
I0414 03:11:07.347148 16767 sgd_solver.cpp:106] Iteration 333, lr = 2.5e-05
I0414 03:11:07.752593 16767 solver.cpp:240] Iteration 334, loss = 0.699605
I0414 03:11:07.752630 16767 solver.cpp:256]     Train net output #0: loss = 0.699605 (* 1 = 0.699605 loss)
I0414 03:11:07.752638 16767 sgd_solver.cpp:106] Iteration 334, lr = 2.5e-05
I0414 03:11:08.158524 16767 solver.cpp:240] Iteration 335, loss = 0.704339
I0414 03:11:08.158558 16767 solver.cpp:256]     Train net output #0: loss = 0.704339 (* 1 = 0.704339 loss)
I0414 03:11:08.158566 16767 sgd_solver.cpp:106] Iteration 335, lr = 2.5e-05
I0414 03:11:08.563956 16767 solver.cpp:240] Iteration 336, loss = 0.702267
I0414 03:11:08.563992 16767 solver.cpp:256]     Train net output #0: loss = 0.702267 (* 1 = 0.702267 loss)
I0414 03:11:08.564000 16767 sgd_solver.cpp:106] Iteration 336, lr = 2.5e-05
I0414 03:11:08.969902 16767 solver.cpp:240] Iteration 337, loss = 0.756639
I0414 03:11:08.969941 16767 solver.cpp:256]     Train net output #0: loss = 0.756639 (* 1 = 0.756639 loss)
I0414 03:11:08.969949 16767 sgd_solver.cpp:106] Iteration 337, lr = 2.5e-05
I0414 03:11:09.375927 16767 solver.cpp:240] Iteration 338, loss = 0.722019
I0414 03:11:09.375963 16767 solver.cpp:256]     Train net output #0: loss = 0.722019 (* 1 = 0.722019 loss)
I0414 03:11:09.375972 16767 sgd_solver.cpp:106] Iteration 338, lr = 2.5e-05
I0414 03:11:09.781302 16767 solver.cpp:240] Iteration 339, loss = 0.713601
I0414 03:11:09.781348 16767 solver.cpp:256]     Train net output #0: loss = 0.713601 (* 1 = 0.713601 loss)
I0414 03:11:09.781358 16767 sgd_solver.cpp:106] Iteration 339, lr = 2.5e-05
I0414 03:11:10.186539 16767 solver.cpp:240] Iteration 340, loss = 0.636916
I0414 03:11:10.186573 16767 solver.cpp:256]     Train net output #0: loss = 0.636916 (* 1 = 0.636916 loss)
I0414 03:11:10.186583 16767 sgd_solver.cpp:106] Iteration 340, lr = 2.5e-05
I0414 03:11:10.591995 16767 solver.cpp:240] Iteration 341, loss = 0.681483
I0414 03:11:10.592033 16767 solver.cpp:256]     Train net output #0: loss = 0.681483 (* 1 = 0.681483 loss)
I0414 03:11:10.592041 16767 sgd_solver.cpp:106] Iteration 341, lr = 2.5e-05
I0414 03:11:10.996997 16767 solver.cpp:240] Iteration 342, loss = 0.713951
I0414 03:11:10.997031 16767 solver.cpp:256]     Train net output #0: loss = 0.713951 (* 1 = 0.713951 loss)
I0414 03:11:10.997040 16767 sgd_solver.cpp:106] Iteration 342, lr = 2.5e-05
I0414 03:11:11.402683 16767 solver.cpp:240] Iteration 343, loss = 0.64371
I0414 03:11:11.402722 16767 solver.cpp:256]     Train net output #0: loss = 0.64371 (* 1 = 0.64371 loss)
I0414 03:11:11.402731 16767 sgd_solver.cpp:106] Iteration 343, lr = 2.5e-05
I0414 03:11:11.808001 16767 solver.cpp:240] Iteration 344, loss = 0.772744
I0414 03:11:11.808040 16767 solver.cpp:256]     Train net output #0: loss = 0.772744 (* 1 = 0.772744 loss)
I0414 03:11:11.808048 16767 sgd_solver.cpp:106] Iteration 344, lr = 2.5e-05
I0414 03:11:12.213516 16767 solver.cpp:240] Iteration 345, loss = 0.761834
I0414 03:11:12.213558 16767 solver.cpp:256]     Train net output #0: loss = 0.761834 (* 1 = 0.761834 loss)
I0414 03:11:12.213567 16767 sgd_solver.cpp:106] Iteration 345, lr = 2.5e-05
I0414 03:11:12.617727 16767 solver.cpp:240] Iteration 346, loss = 0.745285
I0414 03:11:12.617790 16767 solver.cpp:256]     Train net output #0: loss = 0.745285 (* 1 = 0.745285 loss)
I0414 03:11:12.617800 16767 sgd_solver.cpp:106] Iteration 346, lr = 2.5e-05
I0414 03:11:13.023200 16767 solver.cpp:240] Iteration 347, loss = 0.75955
I0414 03:11:13.023236 16767 solver.cpp:256]     Train net output #0: loss = 0.75955 (* 1 = 0.75955 loss)
I0414 03:11:13.023244 16767 sgd_solver.cpp:106] Iteration 347, lr = 2.5e-05
I0414 03:11:13.428794 16767 solver.cpp:240] Iteration 348, loss = 0.654868
I0414 03:11:13.428823 16767 solver.cpp:256]     Train net output #0: loss = 0.654868 (* 1 = 0.654868 loss)
I0414 03:11:13.428830 16767 sgd_solver.cpp:106] Iteration 348, lr = 2.5e-05
I0414 03:11:13.835023 16767 solver.cpp:240] Iteration 349, loss = 0.655241
I0414 03:11:13.835057 16767 solver.cpp:256]     Train net output #0: loss = 0.655241 (* 1 = 0.655241 loss)
I0414 03:11:13.835064 16767 sgd_solver.cpp:106] Iteration 349, lr = 2.5e-05
I0414 03:11:13.835376 16767 solver.cpp:349] Iteration 350, Testing net (#0)
I0414 03:11:13.835396 16767 net.cpp:693] Ignoring source layer silence
I0414 03:11:15.216152 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.777588
I0414 03:11:15.216188 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.908813
I0414 03:11:15.216202 16767 solver.cpp:416]     Test net output #2: loss = 0.962189 (* 1 = 0.962189 loss)
I0414 03:11:15.356214 16767 solver.cpp:240] Iteration 350, loss = 0.717741
I0414 03:11:15.356247 16767 solver.cpp:256]     Train net output #0: loss = 0.717741 (* 1 = 0.717741 loss)
I0414 03:11:15.356256 16767 sgd_solver.cpp:106] Iteration 350, lr = 2.5e-05
I0414 03:11:15.761052 16767 solver.cpp:240] Iteration 351, loss = 0.686552
I0414 03:11:15.761080 16767 solver.cpp:256]     Train net output #0: loss = 0.686552 (* 1 = 0.686552 loss)
I0414 03:11:15.761088 16767 sgd_solver.cpp:106] Iteration 351, lr = 2.5e-05
I0414 03:11:16.166499 16767 solver.cpp:240] Iteration 352, loss = 0.732335
I0414 03:11:16.166537 16767 solver.cpp:256]     Train net output #0: loss = 0.732335 (* 1 = 0.732335 loss)
I0414 03:11:16.166545 16767 sgd_solver.cpp:106] Iteration 352, lr = 2.5e-05
I0414 03:11:16.571696 16767 solver.cpp:240] Iteration 353, loss = 0.656758
I0414 03:11:16.571732 16767 solver.cpp:256]     Train net output #0: loss = 0.656758 (* 1 = 0.656758 loss)
I0414 03:11:16.571741 16767 sgd_solver.cpp:106] Iteration 353, lr = 2.5e-05
I0414 03:11:16.977042 16767 solver.cpp:240] Iteration 354, loss = 0.700867
I0414 03:11:16.977077 16767 solver.cpp:256]     Train net output #0: loss = 0.700867 (* 1 = 0.700867 loss)
I0414 03:11:16.977085 16767 sgd_solver.cpp:106] Iteration 354, lr = 2.5e-05
I0414 03:11:17.383205 16767 solver.cpp:240] Iteration 355, loss = 0.684649
I0414 03:11:17.383241 16767 solver.cpp:256]     Train net output #0: loss = 0.684649 (* 1 = 0.684649 loss)
I0414 03:11:17.383250 16767 sgd_solver.cpp:106] Iteration 355, lr = 2.5e-05
I0414 03:11:17.789145 16767 solver.cpp:240] Iteration 356, loss = 0.684887
I0414 03:11:17.789183 16767 solver.cpp:256]     Train net output #0: loss = 0.684887 (* 1 = 0.684887 loss)
I0414 03:11:17.789192 16767 sgd_solver.cpp:106] Iteration 356, lr = 2.5e-05
I0414 03:11:18.194454 16767 solver.cpp:240] Iteration 357, loss = 0.703176
I0414 03:11:18.194483 16767 solver.cpp:256]     Train net output #0: loss = 0.703176 (* 1 = 0.703176 loss)
I0414 03:11:18.194491 16767 sgd_solver.cpp:106] Iteration 357, lr = 2.5e-05
I0414 03:11:18.599792 16767 solver.cpp:240] Iteration 358, loss = 0.732414
I0414 03:11:18.599831 16767 solver.cpp:256]     Train net output #0: loss = 0.732414 (* 1 = 0.732414 loss)
I0414 03:11:18.599839 16767 sgd_solver.cpp:106] Iteration 358, lr = 2.5e-05
I0414 03:11:19.004814 16767 solver.cpp:240] Iteration 359, loss = 0.701542
I0414 03:11:19.004849 16767 solver.cpp:256]     Train net output #0: loss = 0.701542 (* 1 = 0.701542 loss)
I0414 03:11:19.004858 16767 sgd_solver.cpp:106] Iteration 359, lr = 2.5e-05
I0414 03:11:19.410436 16767 solver.cpp:240] Iteration 360, loss = 0.684652
I0414 03:11:19.410473 16767 solver.cpp:256]     Train net output #0: loss = 0.684652 (* 1 = 0.684652 loss)
I0414 03:11:19.410508 16767 sgd_solver.cpp:106] Iteration 360, lr = 2.5e-05
I0414 03:11:19.815843 16767 solver.cpp:240] Iteration 361, loss = 0.733407
I0414 03:11:19.815873 16767 solver.cpp:256]     Train net output #0: loss = 0.733407 (* 1 = 0.733407 loss)
I0414 03:11:19.815887 16767 sgd_solver.cpp:106] Iteration 361, lr = 2.5e-05
I0414 03:11:20.221308 16767 solver.cpp:240] Iteration 362, loss = 0.707073
I0414 03:11:20.221344 16767 solver.cpp:256]     Train net output #0: loss = 0.707073 (* 1 = 0.707073 loss)
I0414 03:11:20.221354 16767 sgd_solver.cpp:106] Iteration 362, lr = 2.5e-05
I0414 03:11:20.626688 16767 solver.cpp:240] Iteration 363, loss = 0.712048
I0414 03:11:20.626724 16767 solver.cpp:256]     Train net output #0: loss = 0.712048 (* 1 = 0.712048 loss)
I0414 03:11:20.626732 16767 sgd_solver.cpp:106] Iteration 363, lr = 2.5e-05
I0414 03:11:21.032337 16767 solver.cpp:240] Iteration 364, loss = 0.67022
I0414 03:11:21.032376 16767 solver.cpp:256]     Train net output #0: loss = 0.67022 (* 1 = 0.67022 loss)
I0414 03:11:21.032384 16767 sgd_solver.cpp:106] Iteration 364, lr = 2.5e-05
I0414 03:11:21.437517 16767 solver.cpp:240] Iteration 365, loss = 0.645083
I0414 03:11:21.437552 16767 solver.cpp:256]     Train net output #0: loss = 0.645083 (* 1 = 0.645083 loss)
I0414 03:11:21.437561 16767 sgd_solver.cpp:106] Iteration 365, lr = 2.5e-05
I0414 03:11:21.842728 16767 solver.cpp:240] Iteration 366, loss = 0.704673
I0414 03:11:21.842766 16767 solver.cpp:256]     Train net output #0: loss = 0.704673 (* 1 = 0.704673 loss)
I0414 03:11:21.842775 16767 sgd_solver.cpp:106] Iteration 366, lr = 2.5e-05
I0414 03:11:22.248445 16767 solver.cpp:240] Iteration 367, loss = 0.637779
I0414 03:11:22.248481 16767 solver.cpp:256]     Train net output #0: loss = 0.637779 (* 1 = 0.637779 loss)
I0414 03:11:22.248488 16767 sgd_solver.cpp:106] Iteration 367, lr = 2.5e-05
I0414 03:11:22.653836 16767 solver.cpp:240] Iteration 368, loss = 0.659888
I0414 03:11:22.653869 16767 solver.cpp:256]     Train net output #0: loss = 0.659888 (* 1 = 0.659888 loss)
I0414 03:11:22.653877 16767 sgd_solver.cpp:106] Iteration 368, lr = 2.5e-05
I0414 03:11:23.059162 16767 solver.cpp:240] Iteration 369, loss = 0.725782
I0414 03:11:23.059207 16767 solver.cpp:256]     Train net output #0: loss = 0.725782 (* 1 = 0.725782 loss)
I0414 03:11:23.059216 16767 sgd_solver.cpp:106] Iteration 369, lr = 2.5e-05
I0414 03:11:23.464524 16767 solver.cpp:240] Iteration 370, loss = 0.706151
I0414 03:11:23.464562 16767 solver.cpp:256]     Train net output #0: loss = 0.706151 (* 1 = 0.706151 loss)
I0414 03:11:23.464570 16767 sgd_solver.cpp:106] Iteration 370, lr = 2.5e-05
I0414 03:11:23.869747 16767 solver.cpp:240] Iteration 371, loss = 0.728437
I0414 03:11:23.869781 16767 solver.cpp:256]     Train net output #0: loss = 0.728437 (* 1 = 0.728437 loss)
I0414 03:11:23.869789 16767 sgd_solver.cpp:106] Iteration 371, lr = 2.5e-05
I0414 03:11:24.275346 16767 solver.cpp:240] Iteration 372, loss = 0.795088
I0414 03:11:24.275382 16767 solver.cpp:256]     Train net output #0: loss = 0.795088 (* 1 = 0.795088 loss)
I0414 03:11:24.275390 16767 sgd_solver.cpp:106] Iteration 372, lr = 2.5e-05
I0414 03:11:24.680878 16767 solver.cpp:240] Iteration 373, loss = 0.626388
I0414 03:11:24.680912 16767 solver.cpp:256]     Train net output #0: loss = 0.626388 (* 1 = 0.626388 loss)
I0414 03:11:24.680920 16767 sgd_solver.cpp:106] Iteration 373, lr = 2.5e-05
I0414 03:11:25.086459 16767 solver.cpp:240] Iteration 374, loss = 0.664292
I0414 03:11:25.086490 16767 solver.cpp:256]     Train net output #0: loss = 0.664292 (* 1 = 0.664292 loss)
I0414 03:11:25.086498 16767 sgd_solver.cpp:106] Iteration 374, lr = 2.5e-05
I0414 03:11:25.086802 16767 solver.cpp:349] Iteration 375, Testing net (#0)
I0414 03:11:25.086819 16767 net.cpp:693] Ignoring source layer silence
I0414 03:11:26.466722 16767 solver.cpp:416]     Test net output #0: accuracy_1 = 0.778931
I0414 03:11:26.466761 16767 solver.cpp:416]     Test net output #1: accuracy_5 = 0.912476
I0414 03:11:26.466771 16767 solver.cpp:416]     Test net output #2: loss = 0.942523 (* 1 = 0.942523 loss)
I0414 03:11:26.607065 16767 solver.cpp:240] Iteration 375, loss = 0.707351
I0414 03:11:26.607100 16767 solver.cpp:256]     Train net output #0: loss = 0.707351 (* 1 = 0.707351 loss)
I0414 03:11:26.607108 16767 sgd_solver.cpp:106] Iteration 375, lr = 1.25e-05
I0414 03:11:27.012758 16767 solver.cpp:240] Iteration 376, loss = 0.684739
I0414 03:11:27.012792 16767 solver.cpp:256]     Train net output #0: loss = 0.684739 (* 1 = 0.684739 loss)
I0414 03:11:27.012801 16767 sgd_solver.cpp:106] Iteration 376, lr = 1.25e-05
I0414 03:11:27.418532 16767 solver.cpp:240] Iteration 377, loss = 0.719652
I0414 03:11:27.418566 16767 solver.cpp:256]     Train net output #0: loss = 0.719652 (* 1 = 0.719652 loss)
I0414 03:11:27.418575 16767 sgd_solver.cpp:106] Iteration 377, lr = 1.25e-05
I0414 03:11:27.823295 16767 solver.cpp:240] Iteration 378, loss = 0.664796
I0414 03:11:27.823328 16767 solver.cpp:256]     Train net output #0: loss = 0.664796 (* 1 = 0.664796 loss)
I0414 03:11:27.823336 16767 sgd_solver.cpp:106] Iteration 378, lr = 1.25e-05
I0414 03:11:28.228350 16767 solver.cpp:240] Iteration 379, loss = 0.712195
I0414 03:11:28.228385 16767 solver.cpp:256]     Train net output #0: loss = 0.712195 (* 1 = 0.712195 loss)
I0414 03:11:28.228394 16767 sgd_solver.cpp:106] Iteration 379, lr = 1.25e-05
I0414 03:11:28.633446 16767 solver.cpp:240] Iteration 380, loss = 0.653277
I0414 03:11:28.633481 16767 solver.cpp:256]     Train net output #0: loss = 0.653277 (* 1 = 0.653277 loss)
I0414 03:11:28.633491 16767 sgd_solver.cpp:106] Iteration 380, lr = 1.25e-05
I0414 03:11:29.039371 16767 solver.cpp:240] Iteration 381, loss = 0.652731
I0414 03:11:29.039408 16767 solver.cpp:256]     Train net output #0: loss = 0.652731 (* 1 = 0.652731 loss)
I0414 03:11:29.039417 16767 sgd_solver.cpp:106] Iteration 381, lr = 1.25e-05
I0414 03:11:29.444779 16767 solver.cpp:240] Iteration 382, loss = 0.695888
I0414 03:11:29.444813 16767 solver.cpp:256]     Train net output #0: loss = 0.695888 (* 1 = 0.695888 loss)
I0414 03:11:29.444821 16767 sgd_solver.cpp:106] Iteration 382, lr = 1.25e-05
I0414 03:11:29.850512 16767 solver.cpp:240] Iteration 383, loss = 0.733603
I0414 03:11:29.850540 16767 solver.cpp:256]     Train net output #0: loss = 0.733603 (* 1 = 0.733603 loss)
I0414 03:11:29.850548 16767 sgd_solver.cpp:106] Iteration 383, lr = 1.25e-05
I0414 03:11:30.256180 16767 solver.cpp:240] Iteration 384, loss = 0.666652
I0414 03:11:30.256216 16767 solver.cpp:256]     Train net output #0: loss = 0.666652 (* 1 = 0.666652 loss)
I0414 03:11:30.256224 16767 sgd_solver.cpp:106] Iteration 384, lr = 1.25e-05
