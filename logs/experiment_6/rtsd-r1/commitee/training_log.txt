I0408 21:11:58.734639  9048 caffe.cpp:217] Using GPUs 0
I0408 21:11:58.988415  9048 caffe.cpp:222] GPU 0: GeForce GTX 1070
I0408 21:11:59.711546  9048 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_6/rtsd-r1/commitee/train.prototxt"
test_net: "./Prototxt/experiment_6/rtsd-r1/commitee/test.prototxt"
test_iter: 504
test_interval: 16960
base_lr: 0.01
display: 1
max_iter: 84800
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 33920
snapshot: 16960
snapshot_prefix: "./snapshots/experiment_6/rtsd-r1/commitee/snap"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0408 21:11:59.711680  9048 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_6/rtsd-r1/commitee/train.prototxt
I0408 21:11:59.712594  9048 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0408 21:11:59.712605  9048 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0408 21:11:59.713160  9048 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data_0"
  type: "Data"
  top: "data_0"
  top: "label_0"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 115
    mean_value: 107
    mean_value: 120
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/orig/train/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv0_0"
  type: "Convolution"
  bottom: "data_0"
  top: "conv0_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv0_0_prescale"
  type: "Scale"
  bottom: "conv0_0"
  top: "conv0_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv0_0_sTanH"
  type: "TanH"
  bottom: "conv0_0"
  top: "conv0_0"
}
layer {
  name: "conv0_0_postscale"
  type: "Scale"
  bottom: "conv0_0"
  top: "conv0_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool0_0"
  type: "Pooling"
  bottom: "conv0_0"
  top: "pool0_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv0_1"
  type: "Convolution"
  bottom: "pool0_0"
  top: "conv0_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv0_1_prescale"
  type: "Scale"
  bottom: "conv0_1"
  top: "conv0_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv0_1_sTanH"
  type: "TanH"
  bottom: "conv0_1"
  top: "conv0_1"
}
layer {
  name: "conv0_1_postscale"
  type: "Scale"
  bottom: "conv0_1"
  top: "conv0_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool0_1"
  type: "Pooling"
  bottom: "conv0_1"
  top: "pool0_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv0_2"
  type: "Convolution"
  bottom: "pool0_1"
  top: "conv0_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv0_2_prescale"
  type: "Scale"
  bottom: "conv0_2"
  top: "conv0_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv0_2_sTanH"
  type: "TanH"
  bottom: "conv0_2"
  top: "conv0_2"
}
layer {
  name: "conv0_2_postscale"
  type: "Scale"
  bottom: "conv0_2"
  top: "conv0_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool0_2"
  type: "Pooling"
  bottom: "conv0_2"
  top: "pool0_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc0_4_300"
  type: "InnerProduct"
  bottom: "pool0_2"
  top: "fc0_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc0_4_prescale"
  type: "Scale"
  bottom: "fc0_4"
  top: "fc0_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc0_4_sTanH"
  type: "TanH"
  bottom: "fc0_4"
  top: "fc0_4"
}
layer {
  name: "fc0_4_postscale"
  type: "Scale"
  bottom: "fc0_4"
  top: "fc0_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop0_4"
  type: "Dropout"
  bottom: "fc0_4"
  top: "fc0_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc0_5_67"
  type: "InnerProduct"
  bottom: "fc0_4"
  top: "fc0_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_0"
  type: "Softmax"
  bottom: "fc0_5"
  top: "softmax_0"
}
layer {
  name: "data_1"
  type: "Data"
  top: "data_1"
  top: "label_1"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 122
    mean_value: 115
    mean_value: 128
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/histeq/train/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "data_1"
  top: "conv1_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_0_prescale"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_0_sTanH"
  type: "TanH"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv1_0_postscale"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1_0"
  type: "Pooling"
  bottom: "conv1_0"
  top: "pool1_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "pool1_0"
  top: "conv1_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_1_prescale"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_1_sTanH"
  type: "TanH"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_1_postscale"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "pool1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_2_prescale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_2_sTanH"
  type: "TanH"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2_postscale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1_2"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1_4_300"
  type: "InnerProduct"
  bottom: "pool1_2"
  top: "fc1_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc1_4_prescale"
  type: "Scale"
  bottom: "fc1_4"
  top: "fc1_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc1_4_sTanH"
  type: "TanH"
  bottom: "fc1_4"
  top: "fc1_4"
}
layer {
  name: "fc1_4_postscale"
  type: "Scale"
  bottom: "fc1_4"
  top: "fc1_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop1_4"
  type: "Dropout"
  bottom: "fc1_4"
  top: "fc1_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc1_5_67"
  type: "InnerProduct"
  bottom: "fc1_4"
  top: "fc1_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_1"
  type: "Softmax"
  bottom: "fc1_5"
  top: "softmax_1"
}
layer {
  name: "data_2"
  type: "Data"
  top: "data_2"
  top: "label_2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 125
    mean_value: 118
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/AHE/train/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv2_0"
  type: "Convolution"
  bottom: "data_2"
  top: "conv2_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_0_prescale"
  type: "Scale"
  bottom: "conv2_0"
  top: "conv2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_0_sTanH"
  type: "TanH"
  bottom: "conv2_0"
  top: "conv2_0"
}
layer {
  name: "conv2_0_postscale"
  type: "Scale"
  bottom: "conv2_0"
  top: "conv2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2_0"
  type: "Pooling"
  bottom: "conv2_0"
  top: "pool2_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_0"
  top: "conv2_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_1_prescale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_1_sTanH"
  type: "TanH"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_postscale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_2_prescale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_2_sTanH"
  type: "TanH"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2_postscale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2_2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc2_4_300"
  type: "InnerProduct"
  bottom: "pool2_2"
  top: "fc2_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc2_4_prescale"
  type: "Scale"
  bottom: "fc2_4"
  top: "fc2_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc2_4_sTanH"
  type: "TanH"
  bottom: "fc2_4"
  top: "fc2_4"
}
layer {
  name: "fc2_4_postscale"
  type: "Scale"
  bottom: "fc2_4"
  top: "fc2_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop2_4"
  type: "Dropout"
  bottom: "fc2_4"
  top: "fc2_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc2_5_67"
  type: "InnerProduct"
  bottom: "fc2_4"
  top: "fc2_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_2"
  type: "Softmax"
  bottom: "fc2_5"
  top: "softmax_2"
}
layer {
  name: "data_3"
  type: "Data"
  top: "data_3"
  top: "label_3"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 108
    mean_value: 101
    mean_value: 114
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/imajust/train/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv3_0"
  type: "Convolution"
  bottom: "data_3"
  top: "conv3_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_0_prescale"
  type: "Scale"
  bottom: "conv3_0"
  top: "conv3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_0_sTanH"
  type: "TanH"
  bottom: "conv3_0"
  top: "conv3_0"
}
layer {
  name: "conv3_0_postscale"
  type: "Scale"
  bottom: "conv3_0"
  top: "conv3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3_0"
  type: "Pooling"
  bottom: "conv3_0"
  top: "pool3_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool3_0"
  top: "conv3_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_1_prescale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_1_sTanH"
  type: "TanH"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_1_postscale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "pool3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_2_prescale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_2_sTanH"
  type: "TanH"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_2_postscale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3_2"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc3_4_300"
  type: "InnerProduct"
  bottom: "pool3_2"
  top: "fc3_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc3_4_prescale"
  type: "Scale"
  bottom: "fc3_4"
  top: "fc3_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc3_4_sTanH"
  type: "TanH"
  bottom: "fc3_4"
  top: "fc3_4"
}
layer {
  name: "fc3_4_postscale"
  type: "Scale"
  bottom: "fc3_4"
  top: "fc3_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop3_4"
  type: "Dropout"
  bottom: "fc3_4"
  top: "fc3_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc3_5_67"
  type: "InnerProduct"
  bottom: "fc3_4"
  top: "fc3_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_3"
  type: "Softmax"
  bottom: "fc3_5"
  top: "softmax_3"
}
layer {
  name: "data_4"
  type: "Data"
  top: "data_4"
  top: "label_4"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 124
    mean_value: 123
    mean_value: 123
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "data_4"
  top: "conv4_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0_prescale"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv4_0_sTanH"
  type: "TanH"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv4_0_postscale"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool4_0"
  type: "Pooling"
  bottom: "conv4_0"
  top: "pool4_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool4_0"
  top: "conv4_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_1_prescale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv4_1_sTanH"
  type: "TanH"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_1_postscale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool4_1"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "pool4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_2_prescale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv4_2_sTanH"
  type: "TanH"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_2_postscale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_4_300"
  type: "InnerProduct"
  bottom: "pool4_2"
  top: "fc4_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_4_prescale"
  type: "Scale"
  bottom: "fc4_4"
  top: "fc4_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_4_sTanH"
  type: "TanH"
  bottom: "fc4_4"
  top: "fc4_4"
}
layer {
  name: "fc4_4_postscale"
  type: "Scale"
  bottom: "fc4_4"
  top: "fc4_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4_4"
  type: "Dropout"
  bottom: "fc4_4"
  top: "fc4_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc4_5_67"
  type: "InnerProduct"
  bottom: "fc4_4"
  top: "fc4_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_4"
  type: "Softmax"
  bottom: "fc4_5"
  top: "softmax_4"
}
layer {
  name: "averaging"
  type: "Eltwise"
  bottom: "softmax_0"
  bottom: "softmax_1"
  bottom: "softmax_2"
  bottom: "softmax_3"
  bottom: "softmax_4"
  top: "eltwize"
  eltwise_param {
    operation: SUM
    coeff: 0.2
    coeff: 0.2
    coeff: 0.2
    coeff: 0.2
    coeff: 0.2
  }
}
layer {
  name: "loss"
  type: "MultinomialLogisticLoss"
  bottom: "eltwize"
  bottom: "label_0"
  top: "loss"
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "label_1"
  bottom: "label_2"
  bottom: "label_3"
  bottom: "label_4"
}
I0408 21:11:59.713506  9048 layer_factory.hpp:77] Creating layer data_0
I0408 21:11:59.714256  9048 net.cpp:100] Creating Layer data_0
I0408 21:11:59.714270  9048 net.cpp:408] data_0 -> data_0
I0408 21:11:59.714293  9048 net.cpp:408] data_0 -> label_0
I0408 21:11:59.715469  9120 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/orig/train/lmdb
I0408 21:11:59.731227  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:11:59.739454  9048 net.cpp:150] Setting up data_0
I0408 21:11:59.739486  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:11:59.739492  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:11:59.739495  9048 net.cpp:165] Memory required for data: 4147800
I0408 21:11:59.739503  9048 layer_factory.hpp:77] Creating layer conv0_0
I0408 21:11:59.739524  9048 net.cpp:100] Creating Layer conv0_0
I0408 21:11:59.739534  9048 net.cpp:434] conv0_0 <- data_0
I0408 21:11:59.739547  9048 net.cpp:408] conv0_0 -> conv0_0
I0408 21:12:00.009639  9048 net.cpp:150] Setting up conv0_0
I0408 21:12:00.009670  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.009675  9048 net.cpp:165] Memory required for data: 109987800
I0408 21:12:00.009696  9048 layer_factory.hpp:77] Creating layer conv0_0_prescale
I0408 21:12:00.009711  9048 net.cpp:100] Creating Layer conv0_0_prescale
I0408 21:12:00.009719  9048 net.cpp:434] conv0_0_prescale <- conv0_0
I0408 21:12:00.009727  9048 net.cpp:395] conv0_0_prescale -> conv0_0 (in-place)
I0408 21:12:00.009842  9048 net.cpp:150] Setting up conv0_0_prescale
I0408 21:12:00.009851  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.009855  9048 net.cpp:165] Memory required for data: 215827800
I0408 21:12:00.009861  9048 layer_factory.hpp:77] Creating layer conv0_0_sTanH
I0408 21:12:00.009867  9048 net.cpp:100] Creating Layer conv0_0_sTanH
I0408 21:12:00.009871  9048 net.cpp:434] conv0_0_sTanH <- conv0_0
I0408 21:12:00.009876  9048 net.cpp:395] conv0_0_sTanH -> conv0_0 (in-place)
I0408 21:12:00.010064  9048 net.cpp:150] Setting up conv0_0_sTanH
I0408 21:12:00.010076  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.010079  9048 net.cpp:165] Memory required for data: 321667800
I0408 21:12:00.010083  9048 layer_factory.hpp:77] Creating layer conv0_0_postscale
I0408 21:12:00.010092  9048 net.cpp:100] Creating Layer conv0_0_postscale
I0408 21:12:00.010095  9048 net.cpp:434] conv0_0_postscale <- conv0_0
I0408 21:12:00.010100  9048 net.cpp:395] conv0_0_postscale -> conv0_0 (in-place)
I0408 21:12:00.010191  9048 net.cpp:150] Setting up conv0_0_postscale
I0408 21:12:00.010200  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.010202  9048 net.cpp:165] Memory required for data: 427507800
I0408 21:12:00.010207  9048 layer_factory.hpp:77] Creating layer pool0_0
I0408 21:12:00.010215  9048 net.cpp:100] Creating Layer pool0_0
I0408 21:12:00.010217  9048 net.cpp:434] pool0_0 <- conv0_0
I0408 21:12:00.010222  9048 net.cpp:408] pool0_0 -> pool0_0
I0408 21:12:00.010267  9048 net.cpp:150] Setting up pool0_0
I0408 21:12:00.010290  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.010293  9048 net.cpp:165] Memory required for data: 453967800
I0408 21:12:00.010298  9048 layer_factory.hpp:77] Creating layer conv0_1
I0408 21:12:00.010308  9048 net.cpp:100] Creating Layer conv0_1
I0408 21:12:00.010310  9048 net.cpp:434] conv0_1 <- pool0_0
I0408 21:12:00.010315  9048 net.cpp:408] conv0_1 -> conv0_1
I0408 21:12:00.015578  9048 net.cpp:150] Setting up conv0_1
I0408 21:12:00.015594  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.015599  9048 net.cpp:165] Memory required for data: 483127800
I0408 21:12:00.015609  9048 layer_factory.hpp:77] Creating layer conv0_1_prescale
I0408 21:12:00.015628  9048 net.cpp:100] Creating Layer conv0_1_prescale
I0408 21:12:00.015635  9048 net.cpp:434] conv0_1_prescale <- conv0_1
I0408 21:12:00.015641  9048 net.cpp:395] conv0_1_prescale -> conv0_1 (in-place)
I0408 21:12:00.015743  9048 net.cpp:150] Setting up conv0_1_prescale
I0408 21:12:00.015751  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.015754  9048 net.cpp:165] Memory required for data: 512287800
I0408 21:12:00.015759  9048 layer_factory.hpp:77] Creating layer conv0_1_sTanH
I0408 21:12:00.015766  9048 net.cpp:100] Creating Layer conv0_1_sTanH
I0408 21:12:00.015770  9048 net.cpp:434] conv0_1_sTanH <- conv0_1
I0408 21:12:00.015774  9048 net.cpp:395] conv0_1_sTanH -> conv0_1 (in-place)
I0408 21:12:00.016530  9048 net.cpp:150] Setting up conv0_1_sTanH
I0408 21:12:00.016544  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.016547  9048 net.cpp:165] Memory required for data: 541447800
I0408 21:12:00.016551  9048 layer_factory.hpp:77] Creating layer conv0_1_postscale
I0408 21:12:00.016558  9048 net.cpp:100] Creating Layer conv0_1_postscale
I0408 21:12:00.016562  9048 net.cpp:434] conv0_1_postscale <- conv0_1
I0408 21:12:00.016567  9048 net.cpp:395] conv0_1_postscale -> conv0_1 (in-place)
I0408 21:12:00.016683  9048 net.cpp:150] Setting up conv0_1_postscale
I0408 21:12:00.016692  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.016695  9048 net.cpp:165] Memory required for data: 570607800
I0408 21:12:00.016700  9048 layer_factory.hpp:77] Creating layer pool0_1
I0408 21:12:00.016705  9048 net.cpp:100] Creating Layer pool0_1
I0408 21:12:00.016722  9048 net.cpp:434] pool0_1 <- conv0_1
I0408 21:12:00.016728  9048 net.cpp:408] pool0_1 -> pool0_1
I0408 21:12:00.016764  9048 net.cpp:150] Setting up pool0_1
I0408 21:12:00.016772  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.016774  9048 net.cpp:165] Memory required for data: 577897800
I0408 21:12:00.016777  9048 layer_factory.hpp:77] Creating layer conv0_2
I0408 21:12:00.016785  9048 net.cpp:100] Creating Layer conv0_2
I0408 21:12:00.016788  9048 net.cpp:434] conv0_2 <- pool0_1
I0408 21:12:00.016793  9048 net.cpp:408] conv0_2 -> conv0_2
I0408 21:12:00.022125  9048 net.cpp:150] Setting up conv0_2
I0408 21:12:00.022140  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.022145  9048 net.cpp:165] Memory required for data: 583297800
I0408 21:12:00.022155  9048 layer_factory.hpp:77] Creating layer conv0_2_prescale
I0408 21:12:00.022162  9048 net.cpp:100] Creating Layer conv0_2_prescale
I0408 21:12:00.022166  9048 net.cpp:434] conv0_2_prescale <- conv0_2
I0408 21:12:00.022171  9048 net.cpp:395] conv0_2_prescale -> conv0_2 (in-place)
I0408 21:12:00.022267  9048 net.cpp:150] Setting up conv0_2_prescale
I0408 21:12:00.022275  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.022279  9048 net.cpp:165] Memory required for data: 588697800
I0408 21:12:00.022284  9048 layer_factory.hpp:77] Creating layer conv0_2_sTanH
I0408 21:12:00.022289  9048 net.cpp:100] Creating Layer conv0_2_sTanH
I0408 21:12:00.022292  9048 net.cpp:434] conv0_2_sTanH <- conv0_2
I0408 21:12:00.022296  9048 net.cpp:395] conv0_2_sTanH -> conv0_2 (in-place)
I0408 21:12:00.023056  9048 net.cpp:150] Setting up conv0_2_sTanH
I0408 21:12:00.023082  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.023120  9048 net.cpp:165] Memory required for data: 594097800
I0408 21:12:00.023125  9048 layer_factory.hpp:77] Creating layer conv0_2_postscale
I0408 21:12:00.023144  9048 net.cpp:100] Creating Layer conv0_2_postscale
I0408 21:12:00.023149  9048 net.cpp:434] conv0_2_postscale <- conv0_2
I0408 21:12:00.023154  9048 net.cpp:395] conv0_2_postscale -> conv0_2 (in-place)
I0408 21:12:00.023247  9048 net.cpp:150] Setting up conv0_2_postscale
I0408 21:12:00.023255  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.023258  9048 net.cpp:165] Memory required for data: 599497800
I0408 21:12:00.023263  9048 layer_factory.hpp:77] Creating layer pool0_2
I0408 21:12:00.023269  9048 net.cpp:100] Creating Layer pool0_2
I0408 21:12:00.023273  9048 net.cpp:434] pool0_2 <- conv0_2
I0408 21:12:00.023278  9048 net.cpp:408] pool0_2 -> pool0_2
I0408 21:12:00.023313  9048 net.cpp:150] Setting up pool0_2
I0408 21:12:00.023319  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.023322  9048 net.cpp:165] Memory required for data: 600847800
I0408 21:12:00.023326  9048 layer_factory.hpp:77] Creating layer fc0_4_300
I0408 21:12:00.023335  9048 net.cpp:100] Creating Layer fc0_4_300
I0408 21:12:00.023339  9048 net.cpp:434] fc0_4_300 <- pool0_2
I0408 21:12:00.023344  9048 net.cpp:408] fc0_4_300 -> fc0_4
I0408 21:12:00.028647  9048 net.cpp:150] Setting up fc0_4_300
I0408 21:12:00.028663  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.028666  9048 net.cpp:165] Memory required for data: 601027800
I0408 21:12:00.028673  9048 layer_factory.hpp:77] Creating layer fc0_4_prescale
I0408 21:12:00.028679  9048 net.cpp:100] Creating Layer fc0_4_prescale
I0408 21:12:00.028683  9048 net.cpp:434] fc0_4_prescale <- fc0_4
I0408 21:12:00.028688  9048 net.cpp:395] fc0_4_prescale -> fc0_4 (in-place)
I0408 21:12:00.028786  9048 net.cpp:150] Setting up fc0_4_prescale
I0408 21:12:00.028795  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.028797  9048 net.cpp:165] Memory required for data: 601207800
I0408 21:12:00.028802  9048 layer_factory.hpp:77] Creating layer fc0_4_sTanH
I0408 21:12:00.028807  9048 net.cpp:100] Creating Layer fc0_4_sTanH
I0408 21:12:00.028810  9048 net.cpp:434] fc0_4_sTanH <- fc0_4
I0408 21:12:00.028815  9048 net.cpp:395] fc0_4_sTanH -> fc0_4 (in-place)
I0408 21:12:00.028988  9048 net.cpp:150] Setting up fc0_4_sTanH
I0408 21:12:00.028998  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.029001  9048 net.cpp:165] Memory required for data: 601387800
I0408 21:12:00.029006  9048 layer_factory.hpp:77] Creating layer fc0_4_postscale
I0408 21:12:00.029011  9048 net.cpp:100] Creating Layer fc0_4_postscale
I0408 21:12:00.029016  9048 net.cpp:434] fc0_4_postscale <- fc0_4
I0408 21:12:00.029021  9048 net.cpp:395] fc0_4_postscale -> fc0_4 (in-place)
I0408 21:12:00.029108  9048 net.cpp:150] Setting up fc0_4_postscale
I0408 21:12:00.029114  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.029117  9048 net.cpp:165] Memory required for data: 601567800
I0408 21:12:00.029122  9048 layer_factory.hpp:77] Creating layer drop0_4
I0408 21:12:00.029129  9048 net.cpp:100] Creating Layer drop0_4
I0408 21:12:00.029131  9048 net.cpp:434] drop0_4 <- fc0_4
I0408 21:12:00.029136  9048 net.cpp:395] drop0_4 -> fc0_4 (in-place)
I0408 21:12:00.029161  9048 net.cpp:150] Setting up drop0_4
I0408 21:12:00.029167  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.029170  9048 net.cpp:165] Memory required for data: 601747800
I0408 21:12:00.029173  9048 layer_factory.hpp:77] Creating layer fc0_5_67
I0408 21:12:00.029180  9048 net.cpp:100] Creating Layer fc0_5_67
I0408 21:12:00.029182  9048 net.cpp:434] fc0_5_67 <- fc0_4
I0408 21:12:00.029186  9048 net.cpp:408] fc0_5_67 -> fc0_5
I0408 21:12:00.030414  9048 net.cpp:150] Setting up fc0_5_67
I0408 21:12:00.030428  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.030432  9048 net.cpp:165] Memory required for data: 601788000
I0408 21:12:00.030442  9048 layer_factory.hpp:77] Creating layer softmax_0
I0408 21:12:00.030449  9048 net.cpp:100] Creating Layer softmax_0
I0408 21:12:00.030465  9048 net.cpp:434] softmax_0 <- fc0_5
I0408 21:12:00.030472  9048 net.cpp:408] softmax_0 -> softmax_0
I0408 21:12:00.030705  9048 net.cpp:150] Setting up softmax_0
I0408 21:12:00.030717  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.030720  9048 net.cpp:165] Memory required for data: 601828200
I0408 21:12:00.030725  9048 layer_factory.hpp:77] Creating layer data_1
I0408 21:12:00.030861  9048 net.cpp:100] Creating Layer data_1
I0408 21:12:00.030884  9048 net.cpp:408] data_1 -> data_1
I0408 21:12:00.030892  9048 net.cpp:408] data_1 -> label_1
I0408 21:12:00.032359  9134 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/histeq/train/lmdb
I0408 21:12:00.032636  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.041200  9048 net.cpp:150] Setting up data_1
I0408 21:12:00.041216  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.041237  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.041240  9048 net.cpp:165] Memory required for data: 605976000
I0408 21:12:00.041244  9048 layer_factory.hpp:77] Creating layer conv1_0
I0408 21:12:00.041255  9048 net.cpp:100] Creating Layer conv1_0
I0408 21:12:00.041260  9048 net.cpp:434] conv1_0 <- data_1
I0408 21:12:00.041266  9048 net.cpp:408] conv1_0 -> conv1_0
I0408 21:12:00.042961  9048 net.cpp:150] Setting up conv1_0
I0408 21:12:00.042978  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.042992  9048 net.cpp:165] Memory required for data: 711816000
I0408 21:12:00.043000  9048 layer_factory.hpp:77] Creating layer conv1_0_prescale
I0408 21:12:00.043009  9048 net.cpp:100] Creating Layer conv1_0_prescale
I0408 21:12:00.043012  9048 net.cpp:434] conv1_0_prescale <- conv1_0
I0408 21:12:00.043018  9048 net.cpp:395] conv1_0_prescale -> conv1_0 (in-place)
I0408 21:12:00.043128  9048 net.cpp:150] Setting up conv1_0_prescale
I0408 21:12:00.043136  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.043139  9048 net.cpp:165] Memory required for data: 817656000
I0408 21:12:00.043144  9048 layer_factory.hpp:77] Creating layer conv1_0_sTanH
I0408 21:12:00.043150  9048 net.cpp:100] Creating Layer conv1_0_sTanH
I0408 21:12:00.043154  9048 net.cpp:434] conv1_0_sTanH <- conv1_0
I0408 21:12:00.043159  9048 net.cpp:395] conv1_0_sTanH -> conv1_0 (in-place)
I0408 21:12:00.043665  9048 net.cpp:150] Setting up conv1_0_sTanH
I0408 21:12:00.043676  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.043679  9048 net.cpp:165] Memory required for data: 923496000
I0408 21:12:00.043684  9048 layer_factory.hpp:77] Creating layer conv1_0_postscale
I0408 21:12:00.043690  9048 net.cpp:100] Creating Layer conv1_0_postscale
I0408 21:12:00.043694  9048 net.cpp:434] conv1_0_postscale <- conv1_0
I0408 21:12:00.043699  9048 net.cpp:395] conv1_0_postscale -> conv1_0 (in-place)
I0408 21:12:00.043795  9048 net.cpp:150] Setting up conv1_0_postscale
I0408 21:12:00.043807  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.043809  9048 net.cpp:165] Memory required for data: 1029336000
I0408 21:12:00.043814  9048 layer_factory.hpp:77] Creating layer pool1_0
I0408 21:12:00.043820  9048 net.cpp:100] Creating Layer pool1_0
I0408 21:12:00.043823  9048 net.cpp:434] pool1_0 <- conv1_0
I0408 21:12:00.043828  9048 net.cpp:408] pool1_0 -> pool1_0
I0408 21:12:00.043866  9048 net.cpp:150] Setting up pool1_0
I0408 21:12:00.043874  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.043887  9048 net.cpp:165] Memory required for data: 1055796000
I0408 21:12:00.043892  9048 layer_factory.hpp:77] Creating layer conv1_1
I0408 21:12:00.043900  9048 net.cpp:100] Creating Layer conv1_1
I0408 21:12:00.043905  9048 net.cpp:434] conv1_1 <- pool1_0
I0408 21:12:00.043910  9048 net.cpp:408] conv1_1 -> conv1_1
I0408 21:12:00.046747  9048 net.cpp:150] Setting up conv1_1
I0408 21:12:00.046764  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.046768  9048 net.cpp:165] Memory required for data: 1084956000
I0408 21:12:00.046775  9048 layer_factory.hpp:77] Creating layer conv1_1_prescale
I0408 21:12:00.046797  9048 net.cpp:100] Creating Layer conv1_1_prescale
I0408 21:12:00.046802  9048 net.cpp:434] conv1_1_prescale <- conv1_1
I0408 21:12:00.046807  9048 net.cpp:395] conv1_1_prescale -> conv1_1 (in-place)
I0408 21:12:00.046903  9048 net.cpp:150] Setting up conv1_1_prescale
I0408 21:12:00.046912  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.046916  9048 net.cpp:165] Memory required for data: 1114116000
I0408 21:12:00.046921  9048 layer_factory.hpp:77] Creating layer conv1_1_sTanH
I0408 21:12:00.046927  9048 net.cpp:100] Creating Layer conv1_1_sTanH
I0408 21:12:00.046931  9048 net.cpp:434] conv1_1_sTanH <- conv1_1
I0408 21:12:00.046936  9048 net.cpp:395] conv1_1_sTanH -> conv1_1 (in-place)
I0408 21:12:00.047694  9048 net.cpp:150] Setting up conv1_1_sTanH
I0408 21:12:00.047710  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.047719  9048 net.cpp:165] Memory required for data: 1143276000
I0408 21:12:00.047722  9048 layer_factory.hpp:77] Creating layer conv1_1_postscale
I0408 21:12:00.047734  9048 net.cpp:100] Creating Layer conv1_1_postscale
I0408 21:12:00.047739  9048 net.cpp:434] conv1_1_postscale <- conv1_1
I0408 21:12:00.047744  9048 net.cpp:395] conv1_1_postscale -> conv1_1 (in-place)
I0408 21:12:00.047852  9048 net.cpp:150] Setting up conv1_1_postscale
I0408 21:12:00.047861  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.047864  9048 net.cpp:165] Memory required for data: 1172436000
I0408 21:12:00.047869  9048 layer_factory.hpp:77] Creating layer pool1_1
I0408 21:12:00.047876  9048 net.cpp:100] Creating Layer pool1_1
I0408 21:12:00.047888  9048 net.cpp:434] pool1_1 <- conv1_1
I0408 21:12:00.047894  9048 net.cpp:408] pool1_1 -> pool1_1
I0408 21:12:00.047936  9048 net.cpp:150] Setting up pool1_1
I0408 21:12:00.047946  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.047950  9048 net.cpp:165] Memory required for data: 1179726000
I0408 21:12:00.047952  9048 layer_factory.hpp:77] Creating layer conv1_2
I0408 21:12:00.047960  9048 net.cpp:100] Creating Layer conv1_2
I0408 21:12:00.047963  9048 net.cpp:434] conv1_2 <- pool1_1
I0408 21:12:00.047968  9048 net.cpp:408] conv1_2 -> conv1_2
I0408 21:12:00.053338  9048 net.cpp:150] Setting up conv1_2
I0408 21:12:00.053366  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.053370  9048 net.cpp:165] Memory required for data: 1185126000
I0408 21:12:00.053377  9048 layer_factory.hpp:77] Creating layer conv1_2_prescale
I0408 21:12:00.053385  9048 net.cpp:100] Creating Layer conv1_2_prescale
I0408 21:12:00.053388  9048 net.cpp:434] conv1_2_prescale <- conv1_2
I0408 21:12:00.053393  9048 net.cpp:395] conv1_2_prescale -> conv1_2 (in-place)
I0408 21:12:00.053484  9048 net.cpp:150] Setting up conv1_2_prescale
I0408 21:12:00.053493  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.053495  9048 net.cpp:165] Memory required for data: 1190526000
I0408 21:12:00.053500  9048 layer_factory.hpp:77] Creating layer conv1_2_sTanH
I0408 21:12:00.053505  9048 net.cpp:100] Creating Layer conv1_2_sTanH
I0408 21:12:00.053509  9048 net.cpp:434] conv1_2_sTanH <- conv1_2
I0408 21:12:00.053522  9048 net.cpp:395] conv1_2_sTanH -> conv1_2 (in-place)
I0408 21:12:00.054425  9048 net.cpp:150] Setting up conv1_2_sTanH
I0408 21:12:00.054446  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.054452  9048 net.cpp:165] Memory required for data: 1195926000
I0408 21:12:00.054458  9048 layer_factory.hpp:77] Creating layer conv1_2_postscale
I0408 21:12:00.054471  9048 net.cpp:100] Creating Layer conv1_2_postscale
I0408 21:12:00.054487  9048 net.cpp:434] conv1_2_postscale <- conv1_2
I0408 21:12:00.054497  9048 net.cpp:395] conv1_2_postscale -> conv1_2 (in-place)
I0408 21:12:00.054639  9048 net.cpp:150] Setting up conv1_2_postscale
I0408 21:12:00.054652  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.054657  9048 net.cpp:165] Memory required for data: 1201326000
I0408 21:12:00.054666  9048 layer_factory.hpp:77] Creating layer pool1_2
I0408 21:12:00.054692  9048 net.cpp:100] Creating Layer pool1_2
I0408 21:12:00.054697  9048 net.cpp:434] pool1_2 <- conv1_2
I0408 21:12:00.054705  9048 net.cpp:408] pool1_2 -> pool1_2
I0408 21:12:00.054762  9048 net.cpp:150] Setting up pool1_2
I0408 21:12:00.054775  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.054780  9048 net.cpp:165] Memory required for data: 1202676000
I0408 21:12:00.054785  9048 layer_factory.hpp:77] Creating layer fc1_4_300
I0408 21:12:00.054795  9048 net.cpp:100] Creating Layer fc1_4_300
I0408 21:12:00.054802  9048 net.cpp:434] fc1_4_300 <- pool1_2
I0408 21:12:00.054810  9048 net.cpp:408] fc1_4_300 -> fc1_4
I0408 21:12:00.060402  9048 net.cpp:150] Setting up fc1_4_300
I0408 21:12:00.060420  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.060423  9048 net.cpp:165] Memory required for data: 1202856000
I0408 21:12:00.060432  9048 layer_factory.hpp:77] Creating layer fc1_4_prescale
I0408 21:12:00.060439  9048 net.cpp:100] Creating Layer fc1_4_prescale
I0408 21:12:00.060443  9048 net.cpp:434] fc1_4_prescale <- fc1_4
I0408 21:12:00.060449  9048 net.cpp:395] fc1_4_prescale -> fc1_4 (in-place)
I0408 21:12:00.060542  9048 net.cpp:150] Setting up fc1_4_prescale
I0408 21:12:00.060555  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.060559  9048 net.cpp:165] Memory required for data: 1203036000
I0408 21:12:00.060569  9048 layer_factory.hpp:77] Creating layer fc1_4_sTanH
I0408 21:12:00.060575  9048 net.cpp:100] Creating Layer fc1_4_sTanH
I0408 21:12:00.060580  9048 net.cpp:434] fc1_4_sTanH <- fc1_4
I0408 21:12:00.060583  9048 net.cpp:395] fc1_4_sTanH -> fc1_4 (in-place)
I0408 21:12:00.060767  9048 net.cpp:150] Setting up fc1_4_sTanH
I0408 21:12:00.060778  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.060781  9048 net.cpp:165] Memory required for data: 1203216000
I0408 21:12:00.060786  9048 layer_factory.hpp:77] Creating layer fc1_4_postscale
I0408 21:12:00.060791  9048 net.cpp:100] Creating Layer fc1_4_postscale
I0408 21:12:00.060796  9048 net.cpp:434] fc1_4_postscale <- fc1_4
I0408 21:12:00.060801  9048 net.cpp:395] fc1_4_postscale -> fc1_4 (in-place)
I0408 21:12:00.060899  9048 net.cpp:150] Setting up fc1_4_postscale
I0408 21:12:00.060914  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.060917  9048 net.cpp:165] Memory required for data: 1203396000
I0408 21:12:00.060922  9048 layer_factory.hpp:77] Creating layer drop1_4
I0408 21:12:00.060930  9048 net.cpp:100] Creating Layer drop1_4
I0408 21:12:00.060932  9048 net.cpp:434] drop1_4 <- fc1_4
I0408 21:12:00.060937  9048 net.cpp:395] drop1_4 -> fc1_4 (in-place)
I0408 21:12:00.060962  9048 net.cpp:150] Setting up drop1_4
I0408 21:12:00.060969  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.060972  9048 net.cpp:165] Memory required for data: 1203576000
I0408 21:12:00.060976  9048 layer_factory.hpp:77] Creating layer fc1_5_67
I0408 21:12:00.060981  9048 net.cpp:100] Creating Layer fc1_5_67
I0408 21:12:00.060984  9048 net.cpp:434] fc1_5_67 <- fc1_4
I0408 21:12:00.060989  9048 net.cpp:408] fc1_5_67 -> fc1_5
I0408 21:12:00.061230  9048 net.cpp:150] Setting up fc1_5_67
I0408 21:12:00.061239  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.061242  9048 net.cpp:165] Memory required for data: 1203616200
I0408 21:12:00.061254  9048 layer_factory.hpp:77] Creating layer softmax_1
I0408 21:12:00.061261  9048 net.cpp:100] Creating Layer softmax_1
I0408 21:12:00.061265  9048 net.cpp:434] softmax_1 <- fc1_5
I0408 21:12:00.061269  9048 net.cpp:408] softmax_1 -> softmax_1
I0408 21:12:00.061497  9048 net.cpp:150] Setting up softmax_1
I0408 21:12:00.061508  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.061511  9048 net.cpp:165] Memory required for data: 1203656400
I0408 21:12:00.061516  9048 layer_factory.hpp:77] Creating layer data_2
I0408 21:12:00.061648  9048 net.cpp:100] Creating Layer data_2
I0408 21:12:00.061660  9048 net.cpp:408] data_2 -> data_2
I0408 21:12:00.061668  9048 net.cpp:408] data_2 -> label_2
I0408 21:12:00.063225  9139 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/AHE/train/lmdb
I0408 21:12:00.063385  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.073941  9048 net.cpp:150] Setting up data_2
I0408 21:12:00.073958  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.073963  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.073966  9048 net.cpp:165] Memory required for data: 1207804200
I0408 21:12:00.073971  9048 layer_factory.hpp:77] Creating layer conv2_0
I0408 21:12:00.073981  9048 net.cpp:100] Creating Layer conv2_0
I0408 21:12:00.073984  9048 net.cpp:434] conv2_0 <- data_2
I0408 21:12:00.073992  9048 net.cpp:408] conv2_0 -> conv2_0
I0408 21:12:00.077123  9048 net.cpp:150] Setting up conv2_0
I0408 21:12:00.077141  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.077144  9048 net.cpp:165] Memory required for data: 1313644200
I0408 21:12:00.077152  9048 layer_factory.hpp:77] Creating layer conv2_0_prescale
I0408 21:12:00.077160  9048 net.cpp:100] Creating Layer conv2_0_prescale
I0408 21:12:00.077163  9048 net.cpp:434] conv2_0_prescale <- conv2_0
I0408 21:12:00.077169  9048 net.cpp:395] conv2_0_prescale -> conv2_0 (in-place)
I0408 21:12:00.077268  9048 net.cpp:150] Setting up conv2_0_prescale
I0408 21:12:00.077277  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.077280  9048 net.cpp:165] Memory required for data: 1419484200
I0408 21:12:00.077286  9048 layer_factory.hpp:77] Creating layer conv2_0_sTanH
I0408 21:12:00.077291  9048 net.cpp:100] Creating Layer conv2_0_sTanH
I0408 21:12:00.077293  9048 net.cpp:434] conv2_0_sTanH <- conv2_0
I0408 21:12:00.077298  9048 net.cpp:395] conv2_0_sTanH -> conv2_0 (in-place)
I0408 21:12:00.077476  9048 net.cpp:150] Setting up conv2_0_sTanH
I0408 21:12:00.077487  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.077491  9048 net.cpp:165] Memory required for data: 1525324200
I0408 21:12:00.077494  9048 layer_factory.hpp:77] Creating layer conv2_0_postscale
I0408 21:12:00.077502  9048 net.cpp:100] Creating Layer conv2_0_postscale
I0408 21:12:00.077505  9048 net.cpp:434] conv2_0_postscale <- conv2_0
I0408 21:12:00.077510  9048 net.cpp:395] conv2_0_postscale -> conv2_0 (in-place)
I0408 21:12:00.077610  9048 net.cpp:150] Setting up conv2_0_postscale
I0408 21:12:00.077617  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.077620  9048 net.cpp:165] Memory required for data: 1631164200
I0408 21:12:00.077625  9048 layer_factory.hpp:77] Creating layer pool2_0
I0408 21:12:00.077632  9048 net.cpp:100] Creating Layer pool2_0
I0408 21:12:00.077636  9048 net.cpp:434] pool2_0 <- conv2_0
I0408 21:12:00.077641  9048 net.cpp:408] pool2_0 -> pool2_0
I0408 21:12:00.077680  9048 net.cpp:150] Setting up pool2_0
I0408 21:12:00.077687  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.077690  9048 net.cpp:165] Memory required for data: 1657624200
I0408 21:12:00.077693  9048 layer_factory.hpp:77] Creating layer conv2_1
I0408 21:12:00.077702  9048 net.cpp:100] Creating Layer conv2_1
I0408 21:12:00.077705  9048 net.cpp:434] conv2_1 <- pool2_0
I0408 21:12:00.077710  9048 net.cpp:408] conv2_1 -> conv2_1
I0408 21:12:00.083039  9048 net.cpp:150] Setting up conv2_1
I0408 21:12:00.083055  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.083060  9048 net.cpp:165] Memory required for data: 1686784200
I0408 21:12:00.083066  9048 layer_factory.hpp:77] Creating layer conv2_1_prescale
I0408 21:12:00.083075  9048 net.cpp:100] Creating Layer conv2_1_prescale
I0408 21:12:00.083078  9048 net.cpp:434] conv2_1_prescale <- conv2_1
I0408 21:12:00.083086  9048 net.cpp:395] conv2_1_prescale -> conv2_1 (in-place)
I0408 21:12:00.083189  9048 net.cpp:150] Setting up conv2_1_prescale
I0408 21:12:00.083199  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.083202  9048 net.cpp:165] Memory required for data: 1715944200
I0408 21:12:00.083207  9048 layer_factory.hpp:77] Creating layer conv2_1_sTanH
I0408 21:12:00.083212  9048 net.cpp:100] Creating Layer conv2_1_sTanH
I0408 21:12:00.083215  9048 net.cpp:434] conv2_1_sTanH <- conv2_1
I0408 21:12:00.083235  9048 net.cpp:395] conv2_1_sTanH -> conv2_1 (in-place)
I0408 21:12:00.084121  9048 net.cpp:150] Setting up conv2_1_sTanH
I0408 21:12:00.084138  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.084142  9048 net.cpp:165] Memory required for data: 1745104200
I0408 21:12:00.084146  9048 layer_factory.hpp:77] Creating layer conv2_1_postscale
I0408 21:12:00.084153  9048 net.cpp:100] Creating Layer conv2_1_postscale
I0408 21:12:00.084157  9048 net.cpp:434] conv2_1_postscale <- conv2_1
I0408 21:12:00.084162  9048 net.cpp:395] conv2_1_postscale -> conv2_1 (in-place)
I0408 21:12:00.084267  9048 net.cpp:150] Setting up conv2_1_postscale
I0408 21:12:00.084276  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.084280  9048 net.cpp:165] Memory required for data: 1774264200
I0408 21:12:00.084285  9048 layer_factory.hpp:77] Creating layer pool2_1
I0408 21:12:00.084290  9048 net.cpp:100] Creating Layer pool2_1
I0408 21:12:00.084295  9048 net.cpp:434] pool2_1 <- conv2_1
I0408 21:12:00.084298  9048 net.cpp:408] pool2_1 -> pool2_1
I0408 21:12:00.084338  9048 net.cpp:150] Setting up pool2_1
I0408 21:12:00.084347  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.084349  9048 net.cpp:165] Memory required for data: 1781554200
I0408 21:12:00.084363  9048 layer_factory.hpp:77] Creating layer conv2_2
I0408 21:12:00.084372  9048 net.cpp:100] Creating Layer conv2_2
I0408 21:12:00.084375  9048 net.cpp:434] conv2_2 <- pool2_1
I0408 21:12:00.084380  9048 net.cpp:408] conv2_2 -> conv2_2
I0408 21:12:00.097498  9048 net.cpp:150] Setting up conv2_2
I0408 21:12:00.097514  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.097518  9048 net.cpp:165] Memory required for data: 1786954200
I0408 21:12:00.097525  9048 layer_factory.hpp:77] Creating layer conv2_2_prescale
I0408 21:12:00.097533  9048 net.cpp:100] Creating Layer conv2_2_prescale
I0408 21:12:00.097537  9048 net.cpp:434] conv2_2_prescale <- conv2_2
I0408 21:12:00.097543  9048 net.cpp:395] conv2_2_prescale -> conv2_2 (in-place)
I0408 21:12:00.097640  9048 net.cpp:150] Setting up conv2_2_prescale
I0408 21:12:00.097648  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.097651  9048 net.cpp:165] Memory required for data: 1792354200
I0408 21:12:00.097656  9048 layer_factory.hpp:77] Creating layer conv2_2_sTanH
I0408 21:12:00.097661  9048 net.cpp:100] Creating Layer conv2_2_sTanH
I0408 21:12:00.097666  9048 net.cpp:434] conv2_2_sTanH <- conv2_2
I0408 21:12:00.097669  9048 net.cpp:395] conv2_2_sTanH -> conv2_2 (in-place)
I0408 21:12:00.098203  9048 net.cpp:150] Setting up conv2_2_sTanH
I0408 21:12:00.098214  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.098218  9048 net.cpp:165] Memory required for data: 1797754200
I0408 21:12:00.098222  9048 layer_factory.hpp:77] Creating layer conv2_2_postscale
I0408 21:12:00.098229  9048 net.cpp:100] Creating Layer conv2_2_postscale
I0408 21:12:00.098232  9048 net.cpp:434] conv2_2_postscale <- conv2_2
I0408 21:12:00.098237  9048 net.cpp:395] conv2_2_postscale -> conv2_2 (in-place)
I0408 21:12:00.098336  9048 net.cpp:150] Setting up conv2_2_postscale
I0408 21:12:00.098345  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.098347  9048 net.cpp:165] Memory required for data: 1803154200
I0408 21:12:00.098352  9048 layer_factory.hpp:77] Creating layer pool2_2
I0408 21:12:00.098358  9048 net.cpp:100] Creating Layer pool2_2
I0408 21:12:00.098361  9048 net.cpp:434] pool2_2 <- conv2_2
I0408 21:12:00.098366  9048 net.cpp:408] pool2_2 -> pool2_2
I0408 21:12:00.098405  9048 net.cpp:150] Setting up pool2_2
I0408 21:12:00.098412  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.098415  9048 net.cpp:165] Memory required for data: 1804504200
I0408 21:12:00.098418  9048 layer_factory.hpp:77] Creating layer fc2_4_300
I0408 21:12:00.098424  9048 net.cpp:100] Creating Layer fc2_4_300
I0408 21:12:00.098428  9048 net.cpp:434] fc2_4_300 <- pool2_2
I0408 21:12:00.098433  9048 net.cpp:408] fc2_4_300 -> fc2_4
I0408 21:12:00.108690  9048 net.cpp:150] Setting up fc2_4_300
I0408 21:12:00.108705  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.108708  9048 net.cpp:165] Memory required for data: 1804684200
I0408 21:12:00.108716  9048 layer_factory.hpp:77] Creating layer fc2_4_prescale
I0408 21:12:00.108722  9048 net.cpp:100] Creating Layer fc2_4_prescale
I0408 21:12:00.108726  9048 net.cpp:434] fc2_4_prescale <- fc2_4
I0408 21:12:00.108732  9048 net.cpp:395] fc2_4_prescale -> fc2_4 (in-place)
I0408 21:12:00.108829  9048 net.cpp:150] Setting up fc2_4_prescale
I0408 21:12:00.108836  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.108839  9048 net.cpp:165] Memory required for data: 1804864200
I0408 21:12:00.108844  9048 layer_factory.hpp:77] Creating layer fc2_4_sTanH
I0408 21:12:00.108857  9048 net.cpp:100] Creating Layer fc2_4_sTanH
I0408 21:12:00.108862  9048 net.cpp:434] fc2_4_sTanH <- fc2_4
I0408 21:12:00.108867  9048 net.cpp:395] fc2_4_sTanH -> fc2_4 (in-place)
I0408 21:12:00.109050  9048 net.cpp:150] Setting up fc2_4_sTanH
I0408 21:12:00.109061  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.109064  9048 net.cpp:165] Memory required for data: 1805044200
I0408 21:12:00.109068  9048 layer_factory.hpp:77] Creating layer fc2_4_postscale
I0408 21:12:00.109074  9048 net.cpp:100] Creating Layer fc2_4_postscale
I0408 21:12:00.109077  9048 net.cpp:434] fc2_4_postscale <- fc2_4
I0408 21:12:00.109082  9048 net.cpp:395] fc2_4_postscale -> fc2_4 (in-place)
I0408 21:12:00.109181  9048 net.cpp:150] Setting up fc2_4_postscale
I0408 21:12:00.109189  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.109192  9048 net.cpp:165] Memory required for data: 1805224200
I0408 21:12:00.109197  9048 layer_factory.hpp:77] Creating layer drop2_4
I0408 21:12:00.109203  9048 net.cpp:100] Creating Layer drop2_4
I0408 21:12:00.109206  9048 net.cpp:434] drop2_4 <- fc2_4
I0408 21:12:00.109210  9048 net.cpp:395] drop2_4 -> fc2_4 (in-place)
I0408 21:12:00.109235  9048 net.cpp:150] Setting up drop2_4
I0408 21:12:00.109241  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.109243  9048 net.cpp:165] Memory required for data: 1805404200
I0408 21:12:00.109246  9048 layer_factory.hpp:77] Creating layer fc2_5_67
I0408 21:12:00.109252  9048 net.cpp:100] Creating Layer fc2_5_67
I0408 21:12:00.109256  9048 net.cpp:434] fc2_5_67 <- fc2_4
I0408 21:12:00.109261  9048 net.cpp:408] fc2_5_67 -> fc2_5
I0408 21:12:00.109508  9048 net.cpp:150] Setting up fc2_5_67
I0408 21:12:00.109516  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.109519  9048 net.cpp:165] Memory required for data: 1805444400
I0408 21:12:00.109525  9048 layer_factory.hpp:77] Creating layer softmax_2
I0408 21:12:00.109531  9048 net.cpp:100] Creating Layer softmax_2
I0408 21:12:00.109534  9048 net.cpp:434] softmax_2 <- fc2_5
I0408 21:12:00.109539  9048 net.cpp:408] softmax_2 -> softmax_2
I0408 21:12:00.109781  9048 net.cpp:150] Setting up softmax_2
I0408 21:12:00.109791  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.109794  9048 net.cpp:165] Memory required for data: 1805484600
I0408 21:12:00.109798  9048 layer_factory.hpp:77] Creating layer data_3
I0408 21:12:00.109930  9048 net.cpp:100] Creating Layer data_3
I0408 21:12:00.109941  9048 net.cpp:408] data_3 -> data_3
I0408 21:12:00.109948  9048 net.cpp:408] data_3 -> label_3
I0408 21:12:00.114430  9144 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/imajust/train/lmdb
I0408 21:12:00.114560  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.127743  9048 net.cpp:150] Setting up data_3
I0408 21:12:00.127760  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.127765  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.127768  9048 net.cpp:165] Memory required for data: 1809632400
I0408 21:12:00.127773  9048 layer_factory.hpp:77] Creating layer conv3_0
I0408 21:12:00.127784  9048 net.cpp:100] Creating Layer conv3_0
I0408 21:12:00.127787  9048 net.cpp:434] conv3_0 <- data_3
I0408 21:12:00.127794  9048 net.cpp:408] conv3_0 -> conv3_0
I0408 21:12:00.130141  9048 net.cpp:150] Setting up conv3_0
I0408 21:12:00.130169  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.130174  9048 net.cpp:165] Memory required for data: 1915472400
I0408 21:12:00.130182  9048 layer_factory.hpp:77] Creating layer conv3_0_prescale
I0408 21:12:00.130190  9048 net.cpp:100] Creating Layer conv3_0_prescale
I0408 21:12:00.130194  9048 net.cpp:434] conv3_0_prescale <- conv3_0
I0408 21:12:00.130200  9048 net.cpp:395] conv3_0_prescale -> conv3_0 (in-place)
I0408 21:12:00.130306  9048 net.cpp:150] Setting up conv3_0_prescale
I0408 21:12:00.130316  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.130318  9048 net.cpp:165] Memory required for data: 2021312400
I0408 21:12:00.130323  9048 layer_factory.hpp:77] Creating layer conv3_0_sTanH
I0408 21:12:00.130328  9048 net.cpp:100] Creating Layer conv3_0_sTanH
I0408 21:12:00.130332  9048 net.cpp:434] conv3_0_sTanH <- conv3_0
I0408 21:12:00.130336  9048 net.cpp:395] conv3_0_sTanH -> conv3_0 (in-place)
I0408 21:12:00.132789  9048 net.cpp:150] Setting up conv3_0_sTanH
I0408 21:12:00.132803  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.132807  9048 net.cpp:165] Memory required for data: 2127152400
I0408 21:12:00.132812  9048 layer_factory.hpp:77] Creating layer conv3_0_postscale
I0408 21:12:00.132818  9048 net.cpp:100] Creating Layer conv3_0_postscale
I0408 21:12:00.132822  9048 net.cpp:434] conv3_0_postscale <- conv3_0
I0408 21:12:00.132828  9048 net.cpp:395] conv3_0_postscale -> conv3_0 (in-place)
I0408 21:12:00.133258  9048 net.cpp:150] Setting up conv3_0_postscale
I0408 21:12:00.133268  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.133271  9048 net.cpp:165] Memory required for data: 2232992400
I0408 21:12:00.133277  9048 layer_factory.hpp:77] Creating layer pool3_0
I0408 21:12:00.133285  9048 net.cpp:100] Creating Layer pool3_0
I0408 21:12:00.133287  9048 net.cpp:434] pool3_0 <- conv3_0
I0408 21:12:00.133292  9048 net.cpp:408] pool3_0 -> pool3_0
I0408 21:12:00.133337  9048 net.cpp:150] Setting up pool3_0
I0408 21:12:00.133345  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.133348  9048 net.cpp:165] Memory required for data: 2259452400
I0408 21:12:00.133352  9048 layer_factory.hpp:77] Creating layer conv3_1
I0408 21:12:00.133359  9048 net.cpp:100] Creating Layer conv3_1
I0408 21:12:00.133363  9048 net.cpp:434] conv3_1 <- pool3_0
I0408 21:12:00.133379  9048 net.cpp:408] conv3_1 -> conv3_1
I0408 21:12:00.135694  9048 net.cpp:150] Setting up conv3_1
I0408 21:12:00.135709  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.135712  9048 net.cpp:165] Memory required for data: 2288612400
I0408 21:12:00.135718  9048 layer_factory.hpp:77] Creating layer conv3_1_prescale
I0408 21:12:00.135727  9048 net.cpp:100] Creating Layer conv3_1_prescale
I0408 21:12:00.135731  9048 net.cpp:434] conv3_1_prescale <- conv3_1
I0408 21:12:00.135737  9048 net.cpp:395] conv3_1_prescale -> conv3_1 (in-place)
I0408 21:12:00.135848  9048 net.cpp:150] Setting up conv3_1_prescale
I0408 21:12:00.135857  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.135860  9048 net.cpp:165] Memory required for data: 2317772400
I0408 21:12:00.135865  9048 layer_factory.hpp:77] Creating layer conv3_1_sTanH
I0408 21:12:00.135871  9048 net.cpp:100] Creating Layer conv3_1_sTanH
I0408 21:12:00.135875  9048 net.cpp:434] conv3_1_sTanH <- conv3_1
I0408 21:12:00.135892  9048 net.cpp:395] conv3_1_sTanH -> conv3_1 (in-place)
I0408 21:12:00.152413  9048 net.cpp:150] Setting up conv3_1_sTanH
I0408 21:12:00.152433  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.152437  9048 net.cpp:165] Memory required for data: 2346932400
I0408 21:12:00.152441  9048 layer_factory.hpp:77] Creating layer conv3_1_postscale
I0408 21:12:00.152448  9048 net.cpp:100] Creating Layer conv3_1_postscale
I0408 21:12:00.152452  9048 net.cpp:434] conv3_1_postscale <- conv3_1
I0408 21:12:00.152459  9048 net.cpp:395] conv3_1_postscale -> conv3_1 (in-place)
I0408 21:12:00.152895  9048 net.cpp:150] Setting up conv3_1_postscale
I0408 21:12:00.152918  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.152921  9048 net.cpp:165] Memory required for data: 2376092400
I0408 21:12:00.152927  9048 layer_factory.hpp:77] Creating layer pool3_1
I0408 21:12:00.152935  9048 net.cpp:100] Creating Layer pool3_1
I0408 21:12:00.152937  9048 net.cpp:434] pool3_1 <- conv3_1
I0408 21:12:00.152945  9048 net.cpp:408] pool3_1 -> pool3_1
I0408 21:12:00.152992  9048 net.cpp:150] Setting up pool3_1
I0408 21:12:00.153002  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.153005  9048 net.cpp:165] Memory required for data: 2383382400
I0408 21:12:00.153008  9048 layer_factory.hpp:77] Creating layer conv3_2
I0408 21:12:00.153017  9048 net.cpp:100] Creating Layer conv3_2
I0408 21:12:00.153023  9048 net.cpp:434] conv3_2 <- pool3_1
I0408 21:12:00.153028  9048 net.cpp:408] conv3_2 -> conv3_2
I0408 21:12:00.160020  9048 net.cpp:150] Setting up conv3_2
I0408 21:12:00.160037  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.160042  9048 net.cpp:165] Memory required for data: 2388782400
I0408 21:12:00.160048  9048 layer_factory.hpp:77] Creating layer conv3_2_prescale
I0408 21:12:00.160058  9048 net.cpp:100] Creating Layer conv3_2_prescale
I0408 21:12:00.160063  9048 net.cpp:434] conv3_2_prescale <- conv3_2
I0408 21:12:00.160068  9048 net.cpp:395] conv3_2_prescale -> conv3_2 (in-place)
I0408 21:12:00.160176  9048 net.cpp:150] Setting up conv3_2_prescale
I0408 21:12:00.160184  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.160187  9048 net.cpp:165] Memory required for data: 2394182400
I0408 21:12:00.160202  9048 layer_factory.hpp:77] Creating layer conv3_2_sTanH
I0408 21:12:00.160212  9048 net.cpp:100] Creating Layer conv3_2_sTanH
I0408 21:12:00.160215  9048 net.cpp:434] conv3_2_sTanH <- conv3_2
I0408 21:12:00.160220  9048 net.cpp:395] conv3_2_sTanH -> conv3_2 (in-place)
I0408 21:12:00.160409  9048 net.cpp:150] Setting up conv3_2_sTanH
I0408 21:12:00.160423  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.160428  9048 net.cpp:165] Memory required for data: 2399582400
I0408 21:12:00.160430  9048 layer_factory.hpp:77] Creating layer conv3_2_postscale
I0408 21:12:00.160439  9048 net.cpp:100] Creating Layer conv3_2_postscale
I0408 21:12:00.160444  9048 net.cpp:434] conv3_2_postscale <- conv3_2
I0408 21:12:00.160449  9048 net.cpp:395] conv3_2_postscale -> conv3_2 (in-place)
I0408 21:12:00.160558  9048 net.cpp:150] Setting up conv3_2_postscale
I0408 21:12:00.160567  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.160570  9048 net.cpp:165] Memory required for data: 2404982400
I0408 21:12:00.160575  9048 layer_factory.hpp:77] Creating layer pool3_2
I0408 21:12:00.160583  9048 net.cpp:100] Creating Layer pool3_2
I0408 21:12:00.160588  9048 net.cpp:434] pool3_2 <- conv3_2
I0408 21:12:00.160593  9048 net.cpp:408] pool3_2 -> pool3_2
I0408 21:12:00.160640  9048 net.cpp:150] Setting up pool3_2
I0408 21:12:00.160647  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.160650  9048 net.cpp:165] Memory required for data: 2406332400
I0408 21:12:00.160653  9048 layer_factory.hpp:77] Creating layer fc3_4_300
I0408 21:12:00.160660  9048 net.cpp:100] Creating Layer fc3_4_300
I0408 21:12:00.160662  9048 net.cpp:434] fc3_4_300 <- pool3_2
I0408 21:12:00.160676  9048 net.cpp:408] fc3_4_300 -> fc3_4
I0408 21:12:00.166085  9048 net.cpp:150] Setting up fc3_4_300
I0408 21:12:00.166100  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.166103  9048 net.cpp:165] Memory required for data: 2406512400
I0408 21:12:00.166110  9048 layer_factory.hpp:77] Creating layer fc3_4_prescale
I0408 21:12:00.166117  9048 net.cpp:100] Creating Layer fc3_4_prescale
I0408 21:12:00.166121  9048 net.cpp:434] fc3_4_prescale <- fc3_4
I0408 21:12:00.166128  9048 net.cpp:395] fc3_4_prescale -> fc3_4 (in-place)
I0408 21:12:00.166234  9048 net.cpp:150] Setting up fc3_4_prescale
I0408 21:12:00.166242  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.166245  9048 net.cpp:165] Memory required for data: 2406692400
I0408 21:12:00.166262  9048 layer_factory.hpp:77] Creating layer fc3_4_sTanH
I0408 21:12:00.166267  9048 net.cpp:100] Creating Layer fc3_4_sTanH
I0408 21:12:00.166271  9048 net.cpp:434] fc3_4_sTanH <- fc3_4
I0408 21:12:00.166275  9048 net.cpp:395] fc3_4_sTanH -> fc3_4 (in-place)
I0408 21:12:00.166471  9048 net.cpp:150] Setting up fc3_4_sTanH
I0408 21:12:00.166482  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.166486  9048 net.cpp:165] Memory required for data: 2406872400
I0408 21:12:00.166488  9048 layer_factory.hpp:77] Creating layer fc3_4_postscale
I0408 21:12:00.166496  9048 net.cpp:100] Creating Layer fc3_4_postscale
I0408 21:12:00.166501  9048 net.cpp:434] fc3_4_postscale <- fc3_4
I0408 21:12:00.166507  9048 net.cpp:395] fc3_4_postscale -> fc3_4 (in-place)
I0408 21:12:00.166617  9048 net.cpp:150] Setting up fc3_4_postscale
I0408 21:12:00.166625  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.166627  9048 net.cpp:165] Memory required for data: 2407052400
I0408 21:12:00.166632  9048 layer_factory.hpp:77] Creating layer drop3_4
I0408 21:12:00.166640  9048 net.cpp:100] Creating Layer drop3_4
I0408 21:12:00.166643  9048 net.cpp:434] drop3_4 <- fc3_4
I0408 21:12:00.166648  9048 net.cpp:395] drop3_4 -> fc3_4 (in-place)
I0408 21:12:00.166676  9048 net.cpp:150] Setting up drop3_4
I0408 21:12:00.166682  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.166685  9048 net.cpp:165] Memory required for data: 2407232400
I0408 21:12:00.166688  9048 layer_factory.hpp:77] Creating layer fc3_5_67
I0408 21:12:00.166694  9048 net.cpp:100] Creating Layer fc3_5_67
I0408 21:12:00.166697  9048 net.cpp:434] fc3_5_67 <- fc3_4
I0408 21:12:00.166703  9048 net.cpp:408] fc3_5_67 -> fc3_5
I0408 21:12:00.166962  9048 net.cpp:150] Setting up fc3_5_67
I0408 21:12:00.166970  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.166973  9048 net.cpp:165] Memory required for data: 2407272600
I0408 21:12:00.166980  9048 layer_factory.hpp:77] Creating layer softmax_3
I0408 21:12:00.166985  9048 net.cpp:100] Creating Layer softmax_3
I0408 21:12:00.166988  9048 net.cpp:434] softmax_3 <- fc3_5
I0408 21:12:00.166995  9048 net.cpp:408] softmax_3 -> softmax_3
I0408 21:12:00.167250  9048 net.cpp:150] Setting up softmax_3
I0408 21:12:00.167260  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.167263  9048 net.cpp:165] Memory required for data: 2407312800
I0408 21:12:00.167268  9048 layer_factory.hpp:77] Creating layer data_4
I0408 21:12:00.167407  9048 net.cpp:100] Creating Layer data_4
I0408 21:12:00.167418  9048 net.cpp:408] data_4 -> data_4
I0408 21:12:00.167429  9048 net.cpp:408] data_4 -> label_4
I0408 21:12:00.168609  9146 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0408 21:12:00.168751  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.177379  9048 net.cpp:150] Setting up data_4
I0408 21:12:00.177395  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.177400  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.177402  9048 net.cpp:165] Memory required for data: 2411460600
I0408 21:12:00.177407  9048 layer_factory.hpp:77] Creating layer conv4_0
I0408 21:12:00.177418  9048 net.cpp:100] Creating Layer conv4_0
I0408 21:12:00.177423  9048 net.cpp:434] conv4_0 <- data_4
I0408 21:12:00.177429  9048 net.cpp:408] conv4_0 -> conv4_0
I0408 21:12:00.179729  9048 net.cpp:150] Setting up conv4_0
I0408 21:12:00.179744  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.179749  9048 net.cpp:165] Memory required for data: 2517300600
I0408 21:12:00.179755  9048 layer_factory.hpp:77] Creating layer conv4_0_prescale
I0408 21:12:00.179764  9048 net.cpp:100] Creating Layer conv4_0_prescale
I0408 21:12:00.179774  9048 net.cpp:434] conv4_0_prescale <- conv4_0
I0408 21:12:00.179781  9048 net.cpp:395] conv4_0_prescale -> conv4_0 (in-place)
I0408 21:12:00.179925  9048 net.cpp:150] Setting up conv4_0_prescale
I0408 21:12:00.179936  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.179939  9048 net.cpp:165] Memory required for data: 2623140600
I0408 21:12:00.179957  9048 layer_factory.hpp:77] Creating layer conv4_0_sTanH
I0408 21:12:00.179968  9048 net.cpp:100] Creating Layer conv4_0_sTanH
I0408 21:12:00.179976  9048 net.cpp:434] conv4_0_sTanH <- conv4_0
I0408 21:12:00.179981  9048 net.cpp:395] conv4_0_sTanH -> conv4_0 (in-place)
I0408 21:12:00.180826  9048 net.cpp:150] Setting up conv4_0_sTanH
I0408 21:12:00.180841  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.180845  9048 net.cpp:165] Memory required for data: 2728980600
I0408 21:12:00.180850  9048 layer_factory.hpp:77] Creating layer conv4_0_postscale
I0408 21:12:00.180856  9048 net.cpp:100] Creating Layer conv4_0_postscale
I0408 21:12:00.180860  9048 net.cpp:434] conv4_0_postscale <- conv4_0
I0408 21:12:00.180867  9048 net.cpp:395] conv4_0_postscale -> conv4_0 (in-place)
I0408 21:12:00.180990  9048 net.cpp:150] Setting up conv4_0_postscale
I0408 21:12:00.180999  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.181002  9048 net.cpp:165] Memory required for data: 2834820600
I0408 21:12:00.181008  9048 layer_factory.hpp:77] Creating layer pool4_0
I0408 21:12:00.181015  9048 net.cpp:100] Creating Layer pool4_0
I0408 21:12:00.181018  9048 net.cpp:434] pool4_0 <- conv4_0
I0408 21:12:00.181030  9048 net.cpp:408] pool4_0 -> pool4_0
I0408 21:12:00.181079  9048 net.cpp:150] Setting up pool4_0
I0408 21:12:00.181087  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.181090  9048 net.cpp:165] Memory required for data: 2861280600
I0408 21:12:00.181094  9048 layer_factory.hpp:77] Creating layer conv4_1
I0408 21:12:00.181105  9048 net.cpp:100] Creating Layer conv4_1
I0408 21:12:00.181110  9048 net.cpp:434] conv4_1 <- pool4_0
I0408 21:12:00.181116  9048 net.cpp:408] conv4_1 -> conv4_1
I0408 21:12:00.185070  9048 net.cpp:150] Setting up conv4_1
I0408 21:12:00.185084  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.185101  9048 net.cpp:165] Memory required for data: 2890440600
I0408 21:12:00.185107  9048 layer_factory.hpp:77] Creating layer conv4_1_prescale
I0408 21:12:00.185114  9048 net.cpp:100] Creating Layer conv4_1_prescale
I0408 21:12:00.185118  9048 net.cpp:434] conv4_1_prescale <- conv4_1
I0408 21:12:00.185125  9048 net.cpp:395] conv4_1_prescale -> conv4_1 (in-place)
I0408 21:12:00.185246  9048 net.cpp:150] Setting up conv4_1_prescale
I0408 21:12:00.185256  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.185258  9048 net.cpp:165] Memory required for data: 2919600600
I0408 21:12:00.185263  9048 layer_factory.hpp:77] Creating layer conv4_1_sTanH
I0408 21:12:00.185269  9048 net.cpp:100] Creating Layer conv4_1_sTanH
I0408 21:12:00.185272  9048 net.cpp:434] conv4_1_sTanH <- conv4_1
I0408 21:12:00.185278  9048 net.cpp:395] conv4_1_sTanH -> conv4_1 (in-place)
I0408 21:12:00.185829  9048 net.cpp:150] Setting up conv4_1_sTanH
I0408 21:12:00.185840  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.185844  9048 net.cpp:165] Memory required for data: 2948760600
I0408 21:12:00.185847  9048 layer_factory.hpp:77] Creating layer conv4_1_postscale
I0408 21:12:00.185855  9048 net.cpp:100] Creating Layer conv4_1_postscale
I0408 21:12:00.185859  9048 net.cpp:434] conv4_1_postscale <- conv4_1
I0408 21:12:00.185866  9048 net.cpp:395] conv4_1_postscale -> conv4_1 (in-place)
I0408 21:12:00.185984  9048 net.cpp:150] Setting up conv4_1_postscale
I0408 21:12:00.185993  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.185997  9048 net.cpp:165] Memory required for data: 2977920600
I0408 21:12:00.186013  9048 layer_factory.hpp:77] Creating layer pool4_1
I0408 21:12:00.186022  9048 net.cpp:100] Creating Layer pool4_1
I0408 21:12:00.186028  9048 net.cpp:434] pool4_1 <- conv4_1
I0408 21:12:00.186033  9048 net.cpp:408] pool4_1 -> pool4_1
I0408 21:12:00.186085  9048 net.cpp:150] Setting up pool4_1
I0408 21:12:00.186094  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.186096  9048 net.cpp:165] Memory required for data: 2985210600
I0408 21:12:00.186100  9048 layer_factory.hpp:77] Creating layer conv4_2
I0408 21:12:00.186121  9048 net.cpp:100] Creating Layer conv4_2
I0408 21:12:00.186128  9048 net.cpp:434] conv4_2 <- pool4_1
I0408 21:12:00.186136  9048 net.cpp:408] conv4_2 -> conv4_2
I0408 21:12:00.192848  9048 net.cpp:150] Setting up conv4_2
I0408 21:12:00.192867  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.192873  9048 net.cpp:165] Memory required for data: 2990610600
I0408 21:12:00.192879  9048 layer_factory.hpp:77] Creating layer conv4_2_prescale
I0408 21:12:00.192886  9048 net.cpp:100] Creating Layer conv4_2_prescale
I0408 21:12:00.192890  9048 net.cpp:434] conv4_2_prescale <- conv4_2
I0408 21:12:00.192898  9048 net.cpp:395] conv4_2_prescale -> conv4_2 (in-place)
I0408 21:12:00.193009  9048 net.cpp:150] Setting up conv4_2_prescale
I0408 21:12:00.193022  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.193024  9048 net.cpp:165] Memory required for data: 2996010600
I0408 21:12:00.193028  9048 layer_factory.hpp:77] Creating layer conv4_2_sTanH
I0408 21:12:00.193034  9048 net.cpp:100] Creating Layer conv4_2_sTanH
I0408 21:12:00.193037  9048 net.cpp:434] conv4_2_sTanH <- conv4_2
I0408 21:12:00.193043  9048 net.cpp:395] conv4_2_sTanH -> conv4_2 (in-place)
I0408 21:12:00.193231  9048 net.cpp:150] Setting up conv4_2_sTanH
I0408 21:12:00.193243  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.193248  9048 net.cpp:165] Memory required for data: 3001410600
I0408 21:12:00.193250  9048 layer_factory.hpp:77] Creating layer conv4_2_postscale
I0408 21:12:00.193259  9048 net.cpp:100] Creating Layer conv4_2_postscale
I0408 21:12:00.193261  9048 net.cpp:434] conv4_2_postscale <- conv4_2
I0408 21:12:00.193266  9048 net.cpp:395] conv4_2_postscale -> conv4_2 (in-place)
I0408 21:12:00.193377  9048 net.cpp:150] Setting up conv4_2_postscale
I0408 21:12:00.193385  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.193388  9048 net.cpp:165] Memory required for data: 3006810600
I0408 21:12:00.193393  9048 layer_factory.hpp:77] Creating layer pool4_2
I0408 21:12:00.193400  9048 net.cpp:100] Creating Layer pool4_2
I0408 21:12:00.193404  9048 net.cpp:434] pool4_2 <- conv4_2
I0408 21:12:00.193408  9048 net.cpp:408] pool4_2 -> pool4_2
I0408 21:12:00.193454  9048 net.cpp:150] Setting up pool4_2
I0408 21:12:00.193465  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.193470  9048 net.cpp:165] Memory required for data: 3008160600
I0408 21:12:00.193473  9048 layer_factory.hpp:77] Creating layer fc4_4_300
I0408 21:12:00.193480  9048 net.cpp:100] Creating Layer fc4_4_300
I0408 21:12:00.193483  9048 net.cpp:434] fc4_4_300 <- pool4_2
I0408 21:12:00.193490  9048 net.cpp:408] fc4_4_300 -> fc4_4
I0408 21:12:00.198931  9048 net.cpp:150] Setting up fc4_4_300
I0408 21:12:00.198946  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.198951  9048 net.cpp:165] Memory required for data: 3008340600
I0408 21:12:00.198957  9048 layer_factory.hpp:77] Creating layer fc4_4_prescale
I0408 21:12:00.198964  9048 net.cpp:100] Creating Layer fc4_4_prescale
I0408 21:12:00.198968  9048 net.cpp:434] fc4_4_prescale <- fc4_4
I0408 21:12:00.198976  9048 net.cpp:395] fc4_4_prescale -> fc4_4 (in-place)
I0408 21:12:00.199084  9048 net.cpp:150] Setting up fc4_4_prescale
I0408 21:12:00.199092  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.199095  9048 net.cpp:165] Memory required for data: 3008520600
I0408 21:12:00.199100  9048 layer_factory.hpp:77] Creating layer fc4_4_sTanH
I0408 21:12:00.199105  9048 net.cpp:100] Creating Layer fc4_4_sTanH
I0408 21:12:00.199108  9048 net.cpp:434] fc4_4_sTanH <- fc4_4
I0408 21:12:00.199115  9048 net.cpp:395] fc4_4_sTanH -> fc4_4 (in-place)
I0408 21:12:00.199311  9048 net.cpp:150] Setting up fc4_4_sTanH
I0408 21:12:00.199321  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.199324  9048 net.cpp:165] Memory required for data: 3008700600
I0408 21:12:00.199327  9048 layer_factory.hpp:77] Creating layer fc4_4_postscale
I0408 21:12:00.199337  9048 net.cpp:100] Creating Layer fc4_4_postscale
I0408 21:12:00.199352  9048 net.cpp:434] fc4_4_postscale <- fc4_4
I0408 21:12:00.199358  9048 net.cpp:395] fc4_4_postscale -> fc4_4 (in-place)
I0408 21:12:00.199476  9048 net.cpp:150] Setting up fc4_4_postscale
I0408 21:12:00.199484  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.199487  9048 net.cpp:165] Memory required for data: 3008880600
I0408 21:12:00.199492  9048 layer_factory.hpp:77] Creating layer drop4_4
I0408 21:12:00.199501  9048 net.cpp:100] Creating Layer drop4_4
I0408 21:12:00.199503  9048 net.cpp:434] drop4_4 <- fc4_4
I0408 21:12:00.199508  9048 net.cpp:395] drop4_4 -> fc4_4 (in-place)
I0408 21:12:00.199537  9048 net.cpp:150] Setting up drop4_4
I0408 21:12:00.199543  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.199545  9048 net.cpp:165] Memory required for data: 3009060600
I0408 21:12:00.199548  9048 layer_factory.hpp:77] Creating layer fc4_5_67
I0408 21:12:00.199554  9048 net.cpp:100] Creating Layer fc4_5_67
I0408 21:12:00.199558  9048 net.cpp:434] fc4_5_67 <- fc4_4
I0408 21:12:00.199564  9048 net.cpp:408] fc4_5_67 -> fc4_5
I0408 21:12:00.199826  9048 net.cpp:150] Setting up fc4_5_67
I0408 21:12:00.199834  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.199837  9048 net.cpp:165] Memory required for data: 3009100800
I0408 21:12:00.199843  9048 layer_factory.hpp:77] Creating layer softmax_4
I0408 21:12:00.199848  9048 net.cpp:100] Creating Layer softmax_4
I0408 21:12:00.199852  9048 net.cpp:434] softmax_4 <- fc4_5
I0408 21:12:00.199856  9048 net.cpp:408] softmax_4 -> softmax_4
I0408 21:12:00.200134  9048 net.cpp:150] Setting up softmax_4
I0408 21:12:00.200146  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.200150  9048 net.cpp:165] Memory required for data: 3009141000
I0408 21:12:00.200153  9048 layer_factory.hpp:77] Creating layer averaging
I0408 21:12:00.200162  9048 net.cpp:100] Creating Layer averaging
I0408 21:12:00.200165  9048 net.cpp:434] averaging <- softmax_0
I0408 21:12:00.200170  9048 net.cpp:434] averaging <- softmax_1
I0408 21:12:00.200175  9048 net.cpp:434] averaging <- softmax_2
I0408 21:12:00.200177  9048 net.cpp:434] averaging <- softmax_3
I0408 21:12:00.200181  9048 net.cpp:434] averaging <- softmax_4
I0408 21:12:00.200187  9048 net.cpp:408] averaging -> eltwize
I0408 21:12:00.200222  9048 net.cpp:150] Setting up averaging
I0408 21:12:00.200228  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.200232  9048 net.cpp:165] Memory required for data: 3009181200
I0408 21:12:00.200234  9048 layer_factory.hpp:77] Creating layer loss
I0408 21:12:00.200242  9048 net.cpp:100] Creating Layer loss
I0408 21:12:00.200245  9048 net.cpp:434] loss <- eltwize
I0408 21:12:00.200249  9048 net.cpp:434] loss <- label_0
I0408 21:12:00.200254  9048 net.cpp:408] loss -> loss
I0408 21:12:00.200285  9048 net.cpp:150] Setting up loss
I0408 21:12:00.200292  9048 net.cpp:157] Top shape: (1)
I0408 21:12:00.200295  9048 net.cpp:160]     with loss weight 1
I0408 21:12:00.200316  9048 net.cpp:165] Memory required for data: 3009181204
I0408 21:12:00.200320  9048 layer_factory.hpp:77] Creating layer silence
I0408 21:12:00.200325  9048 net.cpp:100] Creating Layer silence
I0408 21:12:00.200328  9048 net.cpp:434] silence <- label_1
I0408 21:12:00.200332  9048 net.cpp:434] silence <- label_2
I0408 21:12:00.200336  9048 net.cpp:434] silence <- label_3
I0408 21:12:00.200340  9048 net.cpp:434] silence <- label_4
I0408 21:12:00.200343  9048 net.cpp:150] Setting up silence
I0408 21:12:00.200346  9048 net.cpp:165] Memory required for data: 3009181204
I0408 21:12:00.200350  9048 net.cpp:228] silence does not need backward computation.
I0408 21:12:00.200356  9048 net.cpp:226] loss needs backward computation.
I0408 21:12:00.200362  9048 net.cpp:226] averaging needs backward computation.
I0408 21:12:00.200366  9048 net.cpp:226] softmax_4 needs backward computation.
I0408 21:12:00.200369  9048 net.cpp:226] fc4_5_67 needs backward computation.
I0408 21:12:00.200373  9048 net.cpp:226] drop4_4 needs backward computation.
I0408 21:12:00.200376  9048 net.cpp:226] fc4_4_postscale needs backward computation.
I0408 21:12:00.200389  9048 net.cpp:226] fc4_4_sTanH needs backward computation.
I0408 21:12:00.200392  9048 net.cpp:226] fc4_4_prescale needs backward computation.
I0408 21:12:00.200395  9048 net.cpp:226] fc4_4_300 needs backward computation.
I0408 21:12:00.200398  9048 net.cpp:226] pool4_2 needs backward computation.
I0408 21:12:00.200402  9048 net.cpp:226] conv4_2_postscale needs backward computation.
I0408 21:12:00.200405  9048 net.cpp:226] conv4_2_sTanH needs backward computation.
I0408 21:12:00.200407  9048 net.cpp:226] conv4_2_prescale needs backward computation.
I0408 21:12:00.200410  9048 net.cpp:226] conv4_2 needs backward computation.
I0408 21:12:00.200414  9048 net.cpp:226] pool4_1 needs backward computation.
I0408 21:12:00.200417  9048 net.cpp:226] conv4_1_postscale needs backward computation.
I0408 21:12:00.200420  9048 net.cpp:226] conv4_1_sTanH needs backward computation.
I0408 21:12:00.200423  9048 net.cpp:226] conv4_1_prescale needs backward computation.
I0408 21:12:00.200426  9048 net.cpp:226] conv4_1 needs backward computation.
I0408 21:12:00.200429  9048 net.cpp:226] pool4_0 needs backward computation.
I0408 21:12:00.200433  9048 net.cpp:226] conv4_0_postscale needs backward computation.
I0408 21:12:00.200435  9048 net.cpp:226] conv4_0_sTanH needs backward computation.
I0408 21:12:00.200438  9048 net.cpp:226] conv4_0_prescale needs backward computation.
I0408 21:12:00.200441  9048 net.cpp:226] conv4_0 needs backward computation.
I0408 21:12:00.200445  9048 net.cpp:228] data_4 does not need backward computation.
I0408 21:12:00.200448  9048 net.cpp:226] softmax_3 needs backward computation.
I0408 21:12:00.200453  9048 net.cpp:226] fc3_5_67 needs backward computation.
I0408 21:12:00.200456  9048 net.cpp:226] drop3_4 needs backward computation.
I0408 21:12:00.200459  9048 net.cpp:226] fc3_4_postscale needs backward computation.
I0408 21:12:00.200462  9048 net.cpp:226] fc3_4_sTanH needs backward computation.
I0408 21:12:00.200465  9048 net.cpp:226] fc3_4_prescale needs backward computation.
I0408 21:12:00.200469  9048 net.cpp:226] fc3_4_300 needs backward computation.
I0408 21:12:00.200472  9048 net.cpp:226] pool3_2 needs backward computation.
I0408 21:12:00.200475  9048 net.cpp:226] conv3_2_postscale needs backward computation.
I0408 21:12:00.200479  9048 net.cpp:226] conv3_2_sTanH needs backward computation.
I0408 21:12:00.200482  9048 net.cpp:226] conv3_2_prescale needs backward computation.
I0408 21:12:00.200485  9048 net.cpp:226] conv3_2 needs backward computation.
I0408 21:12:00.200489  9048 net.cpp:226] pool3_1 needs backward computation.
I0408 21:12:00.200492  9048 net.cpp:226] conv3_1_postscale needs backward computation.
I0408 21:12:00.200497  9048 net.cpp:226] conv3_1_sTanH needs backward computation.
I0408 21:12:00.200500  9048 net.cpp:226] conv3_1_prescale needs backward computation.
I0408 21:12:00.200505  9048 net.cpp:226] conv3_1 needs backward computation.
I0408 21:12:00.200507  9048 net.cpp:226] pool3_0 needs backward computation.
I0408 21:12:00.200510  9048 net.cpp:226] conv3_0_postscale needs backward computation.
I0408 21:12:00.200515  9048 net.cpp:226] conv3_0_sTanH needs backward computation.
I0408 21:12:00.200517  9048 net.cpp:226] conv3_0_prescale needs backward computation.
I0408 21:12:00.200520  9048 net.cpp:226] conv3_0 needs backward computation.
I0408 21:12:00.200525  9048 net.cpp:228] data_3 does not need backward computation.
I0408 21:12:00.200527  9048 net.cpp:226] softmax_2 needs backward computation.
I0408 21:12:00.200531  9048 net.cpp:226] fc2_5_67 needs backward computation.
I0408 21:12:00.200534  9048 net.cpp:226] drop2_4 needs backward computation.
I0408 21:12:00.200537  9048 net.cpp:226] fc2_4_postscale needs backward computation.
I0408 21:12:00.200541  9048 net.cpp:226] fc2_4_sTanH needs backward computation.
I0408 21:12:00.200544  9048 net.cpp:226] fc2_4_prescale needs backward computation.
I0408 21:12:00.200547  9048 net.cpp:226] fc2_4_300 needs backward computation.
I0408 21:12:00.200551  9048 net.cpp:226] pool2_2 needs backward computation.
I0408 21:12:00.200561  9048 net.cpp:226] conv2_2_postscale needs backward computation.
I0408 21:12:00.200564  9048 net.cpp:226] conv2_2_sTanH needs backward computation.
I0408 21:12:00.200567  9048 net.cpp:226] conv2_2_prescale needs backward computation.
I0408 21:12:00.200570  9048 net.cpp:226] conv2_2 needs backward computation.
I0408 21:12:00.200574  9048 net.cpp:226] pool2_1 needs backward computation.
I0408 21:12:00.200577  9048 net.cpp:226] conv2_1_postscale needs backward computation.
I0408 21:12:00.200580  9048 net.cpp:226] conv2_1_sTanH needs backward computation.
I0408 21:12:00.200583  9048 net.cpp:226] conv2_1_prescale needs backward computation.
I0408 21:12:00.200587  9048 net.cpp:226] conv2_1 needs backward computation.
I0408 21:12:00.200590  9048 net.cpp:226] pool2_0 needs backward computation.
I0408 21:12:00.200593  9048 net.cpp:226] conv2_0_postscale needs backward computation.
I0408 21:12:00.200597  9048 net.cpp:226] conv2_0_sTanH needs backward computation.
I0408 21:12:00.200599  9048 net.cpp:226] conv2_0_prescale needs backward computation.
I0408 21:12:00.200603  9048 net.cpp:226] conv2_0 needs backward computation.
I0408 21:12:00.200606  9048 net.cpp:228] data_2 does not need backward computation.
I0408 21:12:00.200610  9048 net.cpp:226] softmax_1 needs backward computation.
I0408 21:12:00.200613  9048 net.cpp:226] fc1_5_67 needs backward computation.
I0408 21:12:00.200616  9048 net.cpp:226] drop1_4 needs backward computation.
I0408 21:12:00.200620  9048 net.cpp:226] fc1_4_postscale needs backward computation.
I0408 21:12:00.200623  9048 net.cpp:226] fc1_4_sTanH needs backward computation.
I0408 21:12:00.200626  9048 net.cpp:226] fc1_4_prescale needs backward computation.
I0408 21:12:00.200629  9048 net.cpp:226] fc1_4_300 needs backward computation.
I0408 21:12:00.200634  9048 net.cpp:226] pool1_2 needs backward computation.
I0408 21:12:00.200636  9048 net.cpp:226] conv1_2_postscale needs backward computation.
I0408 21:12:00.200639  9048 net.cpp:226] conv1_2_sTanH needs backward computation.
I0408 21:12:00.200642  9048 net.cpp:226] conv1_2_prescale needs backward computation.
I0408 21:12:00.200645  9048 net.cpp:226] conv1_2 needs backward computation.
I0408 21:12:00.200649  9048 net.cpp:226] pool1_1 needs backward computation.
I0408 21:12:00.200652  9048 net.cpp:226] conv1_1_postscale needs backward computation.
I0408 21:12:00.200655  9048 net.cpp:226] conv1_1_sTanH needs backward computation.
I0408 21:12:00.200659  9048 net.cpp:226] conv1_1_prescale needs backward computation.
I0408 21:12:00.200662  9048 net.cpp:226] conv1_1 needs backward computation.
I0408 21:12:00.200665  9048 net.cpp:226] pool1_0 needs backward computation.
I0408 21:12:00.200669  9048 net.cpp:226] conv1_0_postscale needs backward computation.
I0408 21:12:00.200672  9048 net.cpp:226] conv1_0_sTanH needs backward computation.
I0408 21:12:00.200675  9048 net.cpp:226] conv1_0_prescale needs backward computation.
I0408 21:12:00.200678  9048 net.cpp:226] conv1_0 needs backward computation.
I0408 21:12:00.200682  9048 net.cpp:228] data_1 does not need backward computation.
I0408 21:12:00.200685  9048 net.cpp:226] softmax_0 needs backward computation.
I0408 21:12:00.200688  9048 net.cpp:226] fc0_5_67 needs backward computation.
I0408 21:12:00.200692  9048 net.cpp:226] drop0_4 needs backward computation.
I0408 21:12:00.200695  9048 net.cpp:226] fc0_4_postscale needs backward computation.
I0408 21:12:00.200698  9048 net.cpp:226] fc0_4_sTanH needs backward computation.
I0408 21:12:00.200701  9048 net.cpp:226] fc0_4_prescale needs backward computation.
I0408 21:12:00.200705  9048 net.cpp:226] fc0_4_300 needs backward computation.
I0408 21:12:00.200708  9048 net.cpp:226] pool0_2 needs backward computation.
I0408 21:12:00.200711  9048 net.cpp:226] conv0_2_postscale needs backward computation.
I0408 21:12:00.200716  9048 net.cpp:226] conv0_2_sTanH needs backward computation.
I0408 21:12:00.200718  9048 net.cpp:226] conv0_2_prescale needs backward computation.
I0408 21:12:00.200721  9048 net.cpp:226] conv0_2 needs backward computation.
I0408 21:12:00.200732  9048 net.cpp:226] pool0_1 needs backward computation.
I0408 21:12:00.200736  9048 net.cpp:226] conv0_1_postscale needs backward computation.
I0408 21:12:00.200739  9048 net.cpp:226] conv0_1_sTanH needs backward computation.
I0408 21:12:00.200742  9048 net.cpp:226] conv0_1_prescale needs backward computation.
I0408 21:12:00.200745  9048 net.cpp:226] conv0_1 needs backward computation.
I0408 21:12:00.200748  9048 net.cpp:226] pool0_0 needs backward computation.
I0408 21:12:00.200752  9048 net.cpp:226] conv0_0_postscale needs backward computation.
I0408 21:12:00.200755  9048 net.cpp:226] conv0_0_sTanH needs backward computation.
I0408 21:12:00.200758  9048 net.cpp:226] conv0_0_prescale needs backward computation.
I0408 21:12:00.200762  9048 net.cpp:226] conv0_0 needs backward computation.
I0408 21:12:00.200765  9048 net.cpp:228] data_0 does not need backward computation.
I0408 21:12:00.200768  9048 net.cpp:270] This network produces output loss
I0408 21:12:00.200834  9048 net.cpp:283] Network initialization done.
I0408 21:12:00.201849  9048 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_6/rtsd-r1/commitee/test.prototxt
I0408 21:12:00.202584  9048 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data_0"
  type: "Data"
  top: "data_0"
  top: "label_0"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 106
    mean_value: 103
    mean_value: 123
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/orig/test/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv0_0"
  type: "Convolution"
  bottom: "data_0"
  top: "conv0_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv0_0_prescale"
  type: "Scale"
  bottom: "conv0_0"
  top: "conv0_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv0_0_sTanH"
  type: "TanH"
  bottom: "conv0_0"
  top: "conv0_0"
}
layer {
  name: "conv0_0_postscale"
  type: "Scale"
  bottom: "conv0_0"
  top: "conv0_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool0_0"
  type: "Pooling"
  bottom: "conv0_0"
  top: "pool0_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv0_1"
  type: "Convolution"
  bottom: "pool0_0"
  top: "conv0_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv0_1_prescale"
  type: "Scale"
  bottom: "conv0_1"
  top: "conv0_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv0_1_sTanH"
  type: "TanH"
  bottom: "conv0_1"
  top: "conv0_1"
}
layer {
  name: "conv0_1_postscale"
  type: "Scale"
  bottom: "conv0_1"
  top: "conv0_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool0_1"
  type: "Pooling"
  bottom: "conv0_1"
  top: "pool0_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv0_2"
  type: "Convolution"
  bottom: "pool0_1"
  top: "conv0_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv0_2_prescale"
  type: "Scale"
  bottom: "conv0_2"
  top: "conv0_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv0_2_sTanH"
  type: "TanH"
  bottom: "conv0_2"
  top: "conv0_2"
}
layer {
  name: "conv0_2_postscale"
  type: "Scale"
  bottom: "conv0_2"
  top: "conv0_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool0_2"
  type: "Pooling"
  bottom: "conv0_2"
  top: "pool0_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc0_4_300"
  type: "InnerProduct"
  bottom: "pool0_2"
  top: "fc0_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc0_4_prescale"
  type: "Scale"
  bottom: "fc0_4"
  top: "fc0_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc0_4_sTanH"
  type: "TanH"
  bottom: "fc0_4"
  top: "fc0_4"
}
layer {
  name: "fc0_4_postscale"
  type: "Scale"
  bottom: "fc0_4"
  top: "fc0_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop0_4"
  type: "Dropout"
  bottom: "fc0_4"
  top: "fc0_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc0_5_67"
  type: "InnerProduct"
  bottom: "fc0_4"
  top: "fc0_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_0"
  type: "Softmax"
  bottom: "fc0_5"
  top: "softmax_0"
}
layer {
  name: "data_1"
  type: "Data"
  top: "data_1"
  top: "label_1"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 117
    mean_value: 114
    mean_value: 133
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/histeq/test/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "data_1"
  top: "conv1_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_0_prescale"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_0_sTanH"
  type: "TanH"
  bottom: "conv1_0"
  top: "conv1_0"
}
layer {
  name: "conv1_0_postscale"
  type: "Scale"
  bottom: "conv1_0"
  top: "conv1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1_0"
  type: "Pooling"
  bottom: "conv1_0"
  top: "pool1_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "pool1_0"
  top: "conv1_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_1_prescale"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_1_sTanH"
  type: "TanH"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_1_postscale"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1_1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "pool1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_2_prescale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_2_sTanH"
  type: "TanH"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "conv1_2_postscale"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1_2"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc1_4_300"
  type: "InnerProduct"
  bottom: "pool1_2"
  top: "fc1_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc1_4_prescale"
  type: "Scale"
  bottom: "fc1_4"
  top: "fc1_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc1_4_sTanH"
  type: "TanH"
  bottom: "fc1_4"
  top: "fc1_4"
}
layer {
  name: "fc1_4_postscale"
  type: "Scale"
  bottom: "fc1_4"
  top: "fc1_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop1_4"
  type: "Dropout"
  bottom: "fc1_4"
  top: "fc1_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc1_5_67"
  type: "InnerProduct"
  bottom: "fc1_4"
  top: "fc1_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_1"
  type: "Softmax"
  bottom: "fc1_5"
  top: "softmax_1"
}
layer {
  name: "data_2"
  type: "Data"
  top: "data_2"
  top: "label_2"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 119
    mean_value: 116
    mean_value: 136
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/AHE/test/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv2_0"
  type: "Convolution"
  bottom: "data_2"
  top: "conv2_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_0_prescale"
  type: "Scale"
  bottom: "conv2_0"
  top: "conv2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_0_sTanH"
  type: "TanH"
  bottom: "conv2_0"
  top: "conv2_0"
}
layer {
  name: "conv2_0_postscale"
  type: "Scale"
  bottom: "conv2_0"
  top: "conv2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2_0"
  type: "Pooling"
  bottom: "conv2_0"
  top: "pool2_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool2_0"
  top: "conv2_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_1_prescale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_1_sTanH"
  type: "TanH"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_1_postscale"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_2_prescale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_2_sTanH"
  type: "TanH"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "conv2_2_postscale"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2_2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc2_4_300"
  type: "InnerProduct"
  bottom: "pool2_2"
  top: "fc2_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc2_4_prescale"
  type: "Scale"
  bottom: "fc2_4"
  top: "fc2_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc2_4_sTanH"
  type: "TanH"
  bottom: "fc2_4"
  top: "fc2_4"
}
layer {
  name: "fc2_4_postscale"
  type: "Scale"
  bottom: "fc2_4"
  top: "fc2_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop2_4"
  type: "Dropout"
  bottom: "fc2_4"
  top: "fc2_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc2_5_67"
  type: "InnerProduct"
  bottom: "fc2_4"
  top: "fc2_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_2"
  type: "Softmax"
  bottom: "fc2_5"
  top: "softmax_2"
}
layer {
  name: "data_3"
  type: "Data"
  top: "data_3"
  top: "label_3"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 102
    mean_value: 99
    mean_value: 118
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/imajust/test/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv3_0"
  type: "Convolution"
  bottom: "data_3"
  top: "conv3_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_0_prescale"
  type: "Scale"
  bottom: "conv3_0"
  top: "conv3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_0_sTanH"
  type: "TanH"
  bottom: "conv3_0"
  top: "conv3_0"
}
layer {
  name: "conv3_0_postscale"
  type: "Scale"
  bottom: "conv3_0"
  top: "conv3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3_0"
  type: "Pooling"
  bottom: "conv3_0"
  top: "pool3_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool3_0"
  top: "conv3_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_1_prescale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_1_sTanH"
  type: "TanH"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_1_postscale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "pool3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_2_prescale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_2_sTanH"
  type: "TanH"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_2_postscale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3_2"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc3_4_300"
  type: "InnerProduct"
  bottom: "pool3_2"
  top: "fc3_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc3_4_prescale"
  type: "Scale"
  bottom: "fc3_4"
  top: "fc3_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc3_4_sTanH"
  type: "TanH"
  bottom: "fc3_4"
  top: "fc3_4"
}
layer {
  name: "fc3_4_postscale"
  type: "Scale"
  bottom: "fc3_4"
  top: "fc3_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop3_4"
  type: "Dropout"
  bottom: "fc3_4"
  top: "fc3_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc3_5_67"
  type: "InnerProduct"
  bottom: "fc3_4"
  top: "fc3_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_3"
  type: "Softmax"
  bottom: "fc3_5"
  top: "softmax_3"
}
layer {
  name: "data_4"
  type: "Data"
  top: "data_4"
  top: "label_4"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 124
    mean_value: 124
    mean_value: 124
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 150
    backend: LMDB
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "data_4"
  top: "conv4_0"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_0_prescale"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv4_0_sTanH"
  type: "TanH"
  bottom: "conv4_0"
  top: "conv4_0"
}
layer {
  name: "conv4_0_postscale"
  type: "Scale"
  bottom: "conv4_0"
  top: "conv4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool4_0"
  type: "Pooling"
  bottom: "conv4_0"
  top: "pool4_0"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool4_0"
  top: "conv4_1"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_1_prescale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv4_1_sTanH"
  type: "TanH"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_1_postscale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool4_1"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "pool4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv4_2_prescale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv4_2_sTanH"
  type: "TanH"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_2_postscale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_4_300"
  type: "InnerProduct"
  bottom: "pool4_2"
  top: "fc4_4"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_4_prescale"
  type: "Scale"
  bottom: "fc4_4"
  top: "fc4_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_4_sTanH"
  type: "TanH"
  bottom: "fc4_4"
  top: "fc4_4"
}
layer {
  name: "fc4_4_postscale"
  type: "Scale"
  bottom: "fc4_4"
  top: "fc4_4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4_4"
  type: "Dropout"
  bottom: "fc4_4"
  top: "fc4_4"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc4_5_67"
  type: "InnerProduct"
  bottom: "fc4_4"
  top: "fc4_5"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax_4"
  type: "Softmax"
  bottom: "fc4_5"
  top: "softmax_4"
}
layer {
  name: "averaging"
  type: "Eltwise"
  bottom: "softmax_0"
  bottom: "softmax_1"
  bottom: "softmax_2"
  bottom: "softmax_3"
  bottom: "softmax_4"
  top: "eltwize"
  eltwise_param {
    operation: SUM
    coeff: 0.2
    coeff: 0.2
    coeff: 0.2
    coeff: 0.2
    coeff: 0.2
  }
}
layer {
  name: "loss"
  type: "MultinomialLogisticLoss"
  bottom: "eltwize"
  bottom: "label_0"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "eltwize"
  bottom: "label_0"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "eltwize"
  bottom: "label_0"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "label_1"
  bottom: "label_2"
  bottom: "label_3"
  bottom: "label_4"
}
I0408 21:12:00.202930  9048 layer_factory.hpp:77] Creating layer data_0
I0408 21:12:00.203076  9048 net.cpp:100] Creating Layer data_0
I0408 21:12:00.203094  9048 net.cpp:408] data_0 -> data_0
I0408 21:12:00.203104  9048 net.cpp:408] data_0 -> label_0
I0408 21:12:00.204260  9148 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/orig/test/lmdb
I0408 21:12:00.204407  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.213348  9048 net.cpp:150] Setting up data_0
I0408 21:12:00.213366  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.213372  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.213374  9048 net.cpp:165] Memory required for data: 4147800
I0408 21:12:00.213379  9048 layer_factory.hpp:77] Creating layer label_0_data_0_1_split
I0408 21:12:00.213389  9048 net.cpp:100] Creating Layer label_0_data_0_1_split
I0408 21:12:00.213392  9048 net.cpp:434] label_0_data_0_1_split <- label_0
I0408 21:12:00.213399  9048 net.cpp:408] label_0_data_0_1_split -> label_0_data_0_1_split_0
I0408 21:12:00.213408  9048 net.cpp:408] label_0_data_0_1_split -> label_0_data_0_1_split_1
I0408 21:12:00.213414  9048 net.cpp:408] label_0_data_0_1_split -> label_0_data_0_1_split_2
I0408 21:12:00.213536  9048 net.cpp:150] Setting up label_0_data_0_1_split
I0408 21:12:00.213543  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.213546  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.213551  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.213553  9048 net.cpp:165] Memory required for data: 4149600
I0408 21:12:00.213557  9048 layer_factory.hpp:77] Creating layer conv0_0
I0408 21:12:00.213568  9048 net.cpp:100] Creating Layer conv0_0
I0408 21:12:00.213572  9048 net.cpp:434] conv0_0 <- data_0
I0408 21:12:00.213579  9048 net.cpp:408] conv0_0 -> conv0_0
I0408 21:12:00.216078  9048 net.cpp:150] Setting up conv0_0
I0408 21:12:00.216095  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.216099  9048 net.cpp:165] Memory required for data: 109989600
I0408 21:12:00.216109  9048 layer_factory.hpp:77] Creating layer conv0_0_prescale
I0408 21:12:00.216119  9048 net.cpp:100] Creating Layer conv0_0_prescale
I0408 21:12:00.216125  9048 net.cpp:434] conv0_0_prescale <- conv0_0
I0408 21:12:00.216131  9048 net.cpp:395] conv0_0_prescale -> conv0_0 (in-place)
I0408 21:12:00.216254  9048 net.cpp:150] Setting up conv0_0_prescale
I0408 21:12:00.216262  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.216265  9048 net.cpp:165] Memory required for data: 215829600
I0408 21:12:00.216289  9048 layer_factory.hpp:77] Creating layer conv0_0_sTanH
I0408 21:12:00.216296  9048 net.cpp:100] Creating Layer conv0_0_sTanH
I0408 21:12:00.216300  9048 net.cpp:434] conv0_0_sTanH <- conv0_0
I0408 21:12:00.216305  9048 net.cpp:395] conv0_0_sTanH -> conv0_0 (in-place)
I0408 21:12:00.217471  9048 net.cpp:150] Setting up conv0_0_sTanH
I0408 21:12:00.217484  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.217488  9048 net.cpp:165] Memory required for data: 321669600
I0408 21:12:00.217491  9048 layer_factory.hpp:77] Creating layer conv0_0_postscale
I0408 21:12:00.217499  9048 net.cpp:100] Creating Layer conv0_0_postscale
I0408 21:12:00.217506  9048 net.cpp:434] conv0_0_postscale <- conv0_0
I0408 21:12:00.217514  9048 net.cpp:395] conv0_0_postscale -> conv0_0 (in-place)
I0408 21:12:00.217643  9048 net.cpp:150] Setting up conv0_0_postscale
I0408 21:12:00.217653  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.217656  9048 net.cpp:165] Memory required for data: 427509600
I0408 21:12:00.217661  9048 layer_factory.hpp:77] Creating layer pool0_0
I0408 21:12:00.217667  9048 net.cpp:100] Creating Layer pool0_0
I0408 21:12:00.217670  9048 net.cpp:434] pool0_0 <- conv0_0
I0408 21:12:00.217677  9048 net.cpp:408] pool0_0 -> pool0_0
I0408 21:12:00.217726  9048 net.cpp:150] Setting up pool0_0
I0408 21:12:00.217732  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.217736  9048 net.cpp:165] Memory required for data: 453969600
I0408 21:12:00.217738  9048 layer_factory.hpp:77] Creating layer conv0_1
I0408 21:12:00.217749  9048 net.cpp:100] Creating Layer conv0_1
I0408 21:12:00.217752  9048 net.cpp:434] conv0_1 <- pool0_0
I0408 21:12:00.217758  9048 net.cpp:408] conv0_1 -> conv0_1
I0408 21:12:00.221104  9048 net.cpp:150] Setting up conv0_1
I0408 21:12:00.221122  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.221127  9048 net.cpp:165] Memory required for data: 483129600
I0408 21:12:00.221137  9048 layer_factory.hpp:77] Creating layer conv0_1_prescale
I0408 21:12:00.221151  9048 net.cpp:100] Creating Layer conv0_1_prescale
I0408 21:12:00.221155  9048 net.cpp:434] conv0_1_prescale <- conv0_1
I0408 21:12:00.221161  9048 net.cpp:395] conv0_1_prescale -> conv0_1 (in-place)
I0408 21:12:00.221287  9048 net.cpp:150] Setting up conv0_1_prescale
I0408 21:12:00.221297  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.221300  9048 net.cpp:165] Memory required for data: 512289600
I0408 21:12:00.221305  9048 layer_factory.hpp:77] Creating layer conv0_1_sTanH
I0408 21:12:00.221312  9048 net.cpp:100] Creating Layer conv0_1_sTanH
I0408 21:12:00.221315  9048 net.cpp:434] conv0_1_sTanH <- conv0_1
I0408 21:12:00.221320  9048 net.cpp:395] conv0_1_sTanH -> conv0_1 (in-place)
I0408 21:12:00.221554  9048 net.cpp:150] Setting up conv0_1_sTanH
I0408 21:12:00.221563  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.221566  9048 net.cpp:165] Memory required for data: 541449600
I0408 21:12:00.221570  9048 layer_factory.hpp:77] Creating layer conv0_1_postscale
I0408 21:12:00.221577  9048 net.cpp:100] Creating Layer conv0_1_postscale
I0408 21:12:00.221580  9048 net.cpp:434] conv0_1_postscale <- conv0_1
I0408 21:12:00.221585  9048 net.cpp:395] conv0_1_postscale -> conv0_1 (in-place)
I0408 21:12:00.221709  9048 net.cpp:150] Setting up conv0_1_postscale
I0408 21:12:00.221716  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.221719  9048 net.cpp:165] Memory required for data: 570609600
I0408 21:12:00.221724  9048 layer_factory.hpp:77] Creating layer pool0_1
I0408 21:12:00.221730  9048 net.cpp:100] Creating Layer pool0_1
I0408 21:12:00.221734  9048 net.cpp:434] pool0_1 <- conv0_1
I0408 21:12:00.221738  9048 net.cpp:408] pool0_1 -> pool0_1
I0408 21:12:00.221791  9048 net.cpp:150] Setting up pool0_1
I0408 21:12:00.221796  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.221799  9048 net.cpp:165] Memory required for data: 577899600
I0408 21:12:00.221802  9048 layer_factory.hpp:77] Creating layer conv0_2
I0408 21:12:00.221823  9048 net.cpp:100] Creating Layer conv0_2
I0408 21:12:00.221829  9048 net.cpp:434] conv0_2 <- pool0_1
I0408 21:12:00.221835  9048 net.cpp:408] conv0_2 -> conv0_2
I0408 21:12:00.230238  9048 net.cpp:150] Setting up conv0_2
I0408 21:12:00.230253  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.230257  9048 net.cpp:165] Memory required for data: 583299600
I0408 21:12:00.230268  9048 layer_factory.hpp:77] Creating layer conv0_2_prescale
I0408 21:12:00.230278  9048 net.cpp:100] Creating Layer conv0_2_prescale
I0408 21:12:00.230283  9048 net.cpp:434] conv0_2_prescale <- conv0_2
I0408 21:12:00.230288  9048 net.cpp:395] conv0_2_prescale -> conv0_2 (in-place)
I0408 21:12:00.230432  9048 net.cpp:150] Setting up conv0_2_prescale
I0408 21:12:00.230442  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.230444  9048 net.cpp:165] Memory required for data: 588699600
I0408 21:12:00.230450  9048 layer_factory.hpp:77] Creating layer conv0_2_sTanH
I0408 21:12:00.230455  9048 net.cpp:100] Creating Layer conv0_2_sTanH
I0408 21:12:00.230458  9048 net.cpp:434] conv0_2_sTanH <- conv0_2
I0408 21:12:00.230465  9048 net.cpp:395] conv0_2_sTanH -> conv0_2 (in-place)
I0408 21:12:00.230664  9048 net.cpp:150] Setting up conv0_2_sTanH
I0408 21:12:00.230674  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.230676  9048 net.cpp:165] Memory required for data: 594099600
I0408 21:12:00.230679  9048 layer_factory.hpp:77] Creating layer conv0_2_postscale
I0408 21:12:00.230689  9048 net.cpp:100] Creating Layer conv0_2_postscale
I0408 21:12:00.230692  9048 net.cpp:434] conv0_2_postscale <- conv0_2
I0408 21:12:00.230697  9048 net.cpp:395] conv0_2_postscale -> conv0_2 (in-place)
I0408 21:12:00.230835  9048 net.cpp:150] Setting up conv0_2_postscale
I0408 21:12:00.230842  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.230845  9048 net.cpp:165] Memory required for data: 599499600
I0408 21:12:00.230850  9048 layer_factory.hpp:77] Creating layer pool0_2
I0408 21:12:00.230861  9048 net.cpp:100] Creating Layer pool0_2
I0408 21:12:00.230865  9048 net.cpp:434] pool0_2 <- conv0_2
I0408 21:12:00.230870  9048 net.cpp:408] pool0_2 -> pool0_2
I0408 21:12:00.231228  9048 net.cpp:150] Setting up pool0_2
I0408 21:12:00.231236  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.231240  9048 net.cpp:165] Memory required for data: 600849600
I0408 21:12:00.231245  9048 layer_factory.hpp:77] Creating layer fc0_4_300
I0408 21:12:00.231251  9048 net.cpp:100] Creating Layer fc0_4_300
I0408 21:12:00.231254  9048 net.cpp:434] fc0_4_300 <- pool0_2
I0408 21:12:00.231261  9048 net.cpp:408] fc0_4_300 -> fc0_4
I0408 21:12:00.236845  9048 net.cpp:150] Setting up fc0_4_300
I0408 21:12:00.236860  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.236862  9048 net.cpp:165] Memory required for data: 601029600
I0408 21:12:00.236870  9048 layer_factory.hpp:77] Creating layer fc0_4_prescale
I0408 21:12:00.236876  9048 net.cpp:100] Creating Layer fc0_4_prescale
I0408 21:12:00.236879  9048 net.cpp:434] fc0_4_prescale <- fc0_4
I0408 21:12:00.236886  9048 net.cpp:395] fc0_4_prescale -> fc0_4 (in-place)
I0408 21:12:00.236996  9048 net.cpp:150] Setting up fc0_4_prescale
I0408 21:12:00.237002  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.237005  9048 net.cpp:165] Memory required for data: 601209600
I0408 21:12:00.237010  9048 layer_factory.hpp:77] Creating layer fc0_4_sTanH
I0408 21:12:00.237015  9048 net.cpp:100] Creating Layer fc0_4_sTanH
I0408 21:12:00.237017  9048 net.cpp:434] fc0_4_sTanH <- fc0_4
I0408 21:12:00.237022  9048 net.cpp:395] fc0_4_sTanH -> fc0_4 (in-place)
I0408 21:12:00.237229  9048 net.cpp:150] Setting up fc0_4_sTanH
I0408 21:12:00.237237  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.237241  9048 net.cpp:165] Memory required for data: 601389600
I0408 21:12:00.237244  9048 layer_factory.hpp:77] Creating layer fc0_4_postscale
I0408 21:12:00.237251  9048 net.cpp:100] Creating Layer fc0_4_postscale
I0408 21:12:00.237253  9048 net.cpp:434] fc0_4_postscale <- fc0_4
I0408 21:12:00.237272  9048 net.cpp:395] fc0_4_postscale -> fc0_4 (in-place)
I0408 21:12:00.237406  9048 net.cpp:150] Setting up fc0_4_postscale
I0408 21:12:00.237412  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.237416  9048 net.cpp:165] Memory required for data: 601569600
I0408 21:12:00.237419  9048 layer_factory.hpp:77] Creating layer drop0_4
I0408 21:12:00.237426  9048 net.cpp:100] Creating Layer drop0_4
I0408 21:12:00.237428  9048 net.cpp:434] drop0_4 <- fc0_4
I0408 21:12:00.237433  9048 net.cpp:395] drop0_4 -> fc0_4 (in-place)
I0408 21:12:00.237462  9048 net.cpp:150] Setting up drop0_4
I0408 21:12:00.237468  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.237470  9048 net.cpp:165] Memory required for data: 601749600
I0408 21:12:00.237473  9048 layer_factory.hpp:77] Creating layer fc0_5_67
I0408 21:12:00.237478  9048 net.cpp:100] Creating Layer fc0_5_67
I0408 21:12:00.237481  9048 net.cpp:434] fc0_5_67 <- fc0_4
I0408 21:12:00.237488  9048 net.cpp:408] fc0_5_67 -> fc0_5
I0408 21:12:00.237742  9048 net.cpp:150] Setting up fc0_5_67
I0408 21:12:00.237748  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.237751  9048 net.cpp:165] Memory required for data: 601789800
I0408 21:12:00.237761  9048 layer_factory.hpp:77] Creating layer softmax_0
I0408 21:12:00.237767  9048 net.cpp:100] Creating Layer softmax_0
I0408 21:12:00.237771  9048 net.cpp:434] softmax_0 <- fc0_5
I0408 21:12:00.237774  9048 net.cpp:408] softmax_0 -> softmax_0
I0408 21:12:00.244803  9048 net.cpp:150] Setting up softmax_0
I0408 21:12:00.244815  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.244818  9048 net.cpp:165] Memory required for data: 601830000
I0408 21:12:00.244822  9048 layer_factory.hpp:77] Creating layer data_1
I0408 21:12:00.244964  9048 net.cpp:100] Creating Layer data_1
I0408 21:12:00.244983  9048 net.cpp:408] data_1 -> data_1
I0408 21:12:00.244994  9048 net.cpp:408] data_1 -> label_1
I0408 21:12:00.254863  9153 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/histeq/test/lmdb
I0408 21:12:00.255010  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.265771  9048 net.cpp:150] Setting up data_1
I0408 21:12:00.265789  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.265794  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.265796  9048 net.cpp:165] Memory required for data: 605977800
I0408 21:12:00.265801  9048 layer_factory.hpp:77] Creating layer conv1_0
I0408 21:12:00.265815  9048 net.cpp:100] Creating Layer conv1_0
I0408 21:12:00.265818  9048 net.cpp:434] conv1_0 <- data_1
I0408 21:12:00.265839  9048 net.cpp:408] conv1_0 -> conv1_0
I0408 21:12:00.267124  9048 net.cpp:150] Setting up conv1_0
I0408 21:12:00.267139  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.267143  9048 net.cpp:165] Memory required for data: 711817800
I0408 21:12:00.267149  9048 layer_factory.hpp:77] Creating layer conv1_0_prescale
I0408 21:12:00.267158  9048 net.cpp:100] Creating Layer conv1_0_prescale
I0408 21:12:00.267163  9048 net.cpp:434] conv1_0_prescale <- conv1_0
I0408 21:12:00.267168  9048 net.cpp:395] conv1_0_prescale -> conv1_0 (in-place)
I0408 21:12:00.267302  9048 net.cpp:150] Setting up conv1_0_prescale
I0408 21:12:00.267310  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.267313  9048 net.cpp:165] Memory required for data: 817657800
I0408 21:12:00.267318  9048 layer_factory.hpp:77] Creating layer conv1_0_sTanH
I0408 21:12:00.267325  9048 net.cpp:100] Creating Layer conv1_0_sTanH
I0408 21:12:00.267329  9048 net.cpp:434] conv1_0_sTanH <- conv1_0
I0408 21:12:00.267333  9048 net.cpp:395] conv1_0_sTanH -> conv1_0 (in-place)
I0408 21:12:00.269016  9048 net.cpp:150] Setting up conv1_0_sTanH
I0408 21:12:00.269033  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.269037  9048 net.cpp:165] Memory required for data: 923497800
I0408 21:12:00.269042  9048 layer_factory.hpp:77] Creating layer conv1_0_postscale
I0408 21:12:00.269048  9048 net.cpp:100] Creating Layer conv1_0_postscale
I0408 21:12:00.269065  9048 net.cpp:434] conv1_0_postscale <- conv1_0
I0408 21:12:00.269073  9048 net.cpp:395] conv1_0_postscale -> conv1_0 (in-place)
I0408 21:12:00.269207  9048 net.cpp:150] Setting up conv1_0_postscale
I0408 21:12:00.269217  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.269219  9048 net.cpp:165] Memory required for data: 1029337800
I0408 21:12:00.269224  9048 layer_factory.hpp:77] Creating layer pool1_0
I0408 21:12:00.269233  9048 net.cpp:100] Creating Layer pool1_0
I0408 21:12:00.269237  9048 net.cpp:434] pool1_0 <- conv1_0
I0408 21:12:00.269244  9048 net.cpp:408] pool1_0 -> pool1_0
I0408 21:12:00.269295  9048 net.cpp:150] Setting up pool1_0
I0408 21:12:00.269304  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.269309  9048 net.cpp:165] Memory required for data: 1055797800
I0408 21:12:00.269312  9048 layer_factory.hpp:77] Creating layer conv1_1
I0408 21:12:00.269321  9048 net.cpp:100] Creating Layer conv1_1
I0408 21:12:00.269326  9048 net.cpp:434] conv1_1 <- pool1_0
I0408 21:12:00.269332  9048 net.cpp:408] conv1_1 -> conv1_1
I0408 21:12:00.274307  9048 net.cpp:150] Setting up conv1_1
I0408 21:12:00.274336  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.274343  9048 net.cpp:165] Memory required for data: 1084957800
I0408 21:12:00.274353  9048 layer_factory.hpp:77] Creating layer conv1_1_prescale
I0408 21:12:00.274368  9048 net.cpp:100] Creating Layer conv1_1_prescale
I0408 21:12:00.274376  9048 net.cpp:434] conv1_1_prescale <- conv1_1
I0408 21:12:00.274384  9048 net.cpp:395] conv1_1_prescale -> conv1_1 (in-place)
I0408 21:12:00.274549  9048 net.cpp:150] Setting up conv1_1_prescale
I0408 21:12:00.274561  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.274565  9048 net.cpp:165] Memory required for data: 1114117800
I0408 21:12:00.274570  9048 layer_factory.hpp:77] Creating layer conv1_1_sTanH
I0408 21:12:00.274590  9048 net.cpp:100] Creating Layer conv1_1_sTanH
I0408 21:12:00.274595  9048 net.cpp:434] conv1_1_sTanH <- conv1_1
I0408 21:12:00.274600  9048 net.cpp:395] conv1_1_sTanH -> conv1_1 (in-place)
I0408 21:12:00.274844  9048 net.cpp:150] Setting up conv1_1_sTanH
I0408 21:12:00.274862  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.274868  9048 net.cpp:165] Memory required for data: 1143277800
I0408 21:12:00.274870  9048 layer_factory.hpp:77] Creating layer conv1_1_postscale
I0408 21:12:00.274878  9048 net.cpp:100] Creating Layer conv1_1_postscale
I0408 21:12:00.274890  9048 net.cpp:434] conv1_1_postscale <- conv1_1
I0408 21:12:00.274899  9048 net.cpp:395] conv1_1_postscale -> conv1_1 (in-place)
I0408 21:12:00.275061  9048 net.cpp:150] Setting up conv1_1_postscale
I0408 21:12:00.275071  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.275074  9048 net.cpp:165] Memory required for data: 1172437800
I0408 21:12:00.275082  9048 layer_factory.hpp:77] Creating layer pool1_1
I0408 21:12:00.275092  9048 net.cpp:100] Creating Layer pool1_1
I0408 21:12:00.275097  9048 net.cpp:434] pool1_1 <- conv1_1
I0408 21:12:00.275104  9048 net.cpp:408] pool1_1 -> pool1_1
I0408 21:12:00.275172  9048 net.cpp:150] Setting up pool1_1
I0408 21:12:00.275184  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.275189  9048 net.cpp:165] Memory required for data: 1179727800
I0408 21:12:00.275192  9048 layer_factory.hpp:77] Creating layer conv1_2
I0408 21:12:00.275204  9048 net.cpp:100] Creating Layer conv1_2
I0408 21:12:00.275213  9048 net.cpp:434] conv1_2 <- pool1_1
I0408 21:12:00.275220  9048 net.cpp:408] conv1_2 -> conv1_2
I0408 21:12:00.283664  9048 net.cpp:150] Setting up conv1_2
I0408 21:12:00.283680  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.283685  9048 net.cpp:165] Memory required for data: 1185127800
I0408 21:12:00.283692  9048 layer_factory.hpp:77] Creating layer conv1_2_prescale
I0408 21:12:00.283701  9048 net.cpp:100] Creating Layer conv1_2_prescale
I0408 21:12:00.283707  9048 net.cpp:434] conv1_2_prescale <- conv1_2
I0408 21:12:00.283717  9048 net.cpp:395] conv1_2_prescale -> conv1_2 (in-place)
I0408 21:12:00.284164  9048 net.cpp:150] Setting up conv1_2_prescale
I0408 21:12:00.284180  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.284186  9048 net.cpp:165] Memory required for data: 1190527800
I0408 21:12:00.284193  9048 layer_factory.hpp:77] Creating layer conv1_2_sTanH
I0408 21:12:00.284199  9048 net.cpp:100] Creating Layer conv1_2_sTanH
I0408 21:12:00.284209  9048 net.cpp:434] conv1_2_sTanH <- conv1_2
I0408 21:12:00.284220  9048 net.cpp:395] conv1_2_sTanH -> conv1_2 (in-place)
I0408 21:12:00.284467  9048 net.cpp:150] Setting up conv1_2_sTanH
I0408 21:12:00.284482  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.284489  9048 net.cpp:165] Memory required for data: 1195927800
I0408 21:12:00.284497  9048 layer_factory.hpp:77] Creating layer conv1_2_postscale
I0408 21:12:00.284509  9048 net.cpp:100] Creating Layer conv1_2_postscale
I0408 21:12:00.284518  9048 net.cpp:434] conv1_2_postscale <- conv1_2
I0408 21:12:00.284528  9048 net.cpp:395] conv1_2_postscale -> conv1_2 (in-place)
I0408 21:12:00.284692  9048 net.cpp:150] Setting up conv1_2_postscale
I0408 21:12:00.284708  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.284711  9048 net.cpp:165] Memory required for data: 1201327800
I0408 21:12:00.284718  9048 layer_factory.hpp:77] Creating layer pool1_2
I0408 21:12:00.284726  9048 net.cpp:100] Creating Layer pool1_2
I0408 21:12:00.284734  9048 net.cpp:434] pool1_2 <- conv1_2
I0408 21:12:00.284746  9048 net.cpp:408] pool1_2 -> pool1_2
I0408 21:12:00.284812  9048 net.cpp:150] Setting up pool1_2
I0408 21:12:00.284822  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.284827  9048 net.cpp:165] Memory required for data: 1202677800
I0408 21:12:00.284832  9048 layer_factory.hpp:77] Creating layer fc1_4_300
I0408 21:12:00.284845  9048 net.cpp:100] Creating Layer fc1_4_300
I0408 21:12:00.284853  9048 net.cpp:434] fc1_4_300 <- pool1_2
I0408 21:12:00.284859  9048 net.cpp:408] fc1_4_300 -> fc1_4
I0408 21:12:00.296629  9048 net.cpp:150] Setting up fc1_4_300
I0408 21:12:00.296643  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.296659  9048 net.cpp:165] Memory required for data: 1202857800
I0408 21:12:00.296666  9048 layer_factory.hpp:77] Creating layer fc1_4_prescale
I0408 21:12:00.296675  9048 net.cpp:100] Creating Layer fc1_4_prescale
I0408 21:12:00.296679  9048 net.cpp:434] fc1_4_prescale <- fc1_4
I0408 21:12:00.296684  9048 net.cpp:395] fc1_4_prescale -> fc1_4 (in-place)
I0408 21:12:00.296802  9048 net.cpp:150] Setting up fc1_4_prescale
I0408 21:12:00.296810  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.296813  9048 net.cpp:165] Memory required for data: 1203037800
I0408 21:12:00.296823  9048 layer_factory.hpp:77] Creating layer fc1_4_sTanH
I0408 21:12:00.296838  9048 net.cpp:100] Creating Layer fc1_4_sTanH
I0408 21:12:00.296840  9048 net.cpp:434] fc1_4_sTanH <- fc1_4
I0408 21:12:00.296845  9048 net.cpp:395] fc1_4_sTanH -> fc1_4 (in-place)
I0408 21:12:00.297052  9048 net.cpp:150] Setting up fc1_4_sTanH
I0408 21:12:00.297063  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.297066  9048 net.cpp:165] Memory required for data: 1203217800
I0408 21:12:00.297070  9048 layer_factory.hpp:77] Creating layer fc1_4_postscale
I0408 21:12:00.297080  9048 net.cpp:100] Creating Layer fc1_4_postscale
I0408 21:12:00.297086  9048 net.cpp:434] fc1_4_postscale <- fc1_4
I0408 21:12:00.297093  9048 net.cpp:395] fc1_4_postscale -> fc1_4 (in-place)
I0408 21:12:00.297219  9048 net.cpp:150] Setting up fc1_4_postscale
I0408 21:12:00.297226  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.297230  9048 net.cpp:165] Memory required for data: 1203397800
I0408 21:12:00.297235  9048 layer_factory.hpp:77] Creating layer drop1_4
I0408 21:12:00.297240  9048 net.cpp:100] Creating Layer drop1_4
I0408 21:12:00.297245  9048 net.cpp:434] drop1_4 <- fc1_4
I0408 21:12:00.297250  9048 net.cpp:395] drop1_4 -> fc1_4 (in-place)
I0408 21:12:00.297279  9048 net.cpp:150] Setting up drop1_4
I0408 21:12:00.297287  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.297302  9048 net.cpp:165] Memory required for data: 1203577800
I0408 21:12:00.297305  9048 layer_factory.hpp:77] Creating layer fc1_5_67
I0408 21:12:00.297313  9048 net.cpp:100] Creating Layer fc1_5_67
I0408 21:12:00.297317  9048 net.cpp:434] fc1_5_67 <- fc1_4
I0408 21:12:00.297322  9048 net.cpp:408] fc1_5_67 -> fc1_5
I0408 21:12:00.297600  9048 net.cpp:150] Setting up fc1_5_67
I0408 21:12:00.297608  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.297611  9048 net.cpp:165] Memory required for data: 1203618000
I0408 21:12:00.297617  9048 layer_factory.hpp:77] Creating layer softmax_1
I0408 21:12:00.297622  9048 net.cpp:100] Creating Layer softmax_1
I0408 21:12:00.297626  9048 net.cpp:434] softmax_1 <- fc1_5
I0408 21:12:00.297631  9048 net.cpp:408] softmax_1 -> softmax_1
I0408 21:12:00.300233  9048 net.cpp:150] Setting up softmax_1
I0408 21:12:00.300249  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.300252  9048 net.cpp:165] Memory required for data: 1203658200
I0408 21:12:00.300256  9048 layer_factory.hpp:77] Creating layer data_2
I0408 21:12:00.300611  9048 net.cpp:100] Creating Layer data_2
I0408 21:12:00.300643  9048 net.cpp:408] data_2 -> data_2
I0408 21:12:00.300655  9048 net.cpp:408] data_2 -> label_2
I0408 21:12:00.302498  9158 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/AHE/test/lmdb
I0408 21:12:00.302649  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.311627  9048 net.cpp:150] Setting up data_2
I0408 21:12:00.311657  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.311662  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.311666  9048 net.cpp:165] Memory required for data: 1207806000
I0408 21:12:00.311668  9048 layer_factory.hpp:77] Creating layer conv2_0
I0408 21:12:00.311679  9048 net.cpp:100] Creating Layer conv2_0
I0408 21:12:00.311683  9048 net.cpp:434] conv2_0 <- data_2
I0408 21:12:00.311692  9048 net.cpp:408] conv2_0 -> conv2_0
I0408 21:12:00.314617  9048 net.cpp:150] Setting up conv2_0
I0408 21:12:00.314633  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.314637  9048 net.cpp:165] Memory required for data: 1313646000
I0408 21:12:00.314644  9048 layer_factory.hpp:77] Creating layer conv2_0_prescale
I0408 21:12:00.314653  9048 net.cpp:100] Creating Layer conv2_0_prescale
I0408 21:12:00.314657  9048 net.cpp:434] conv2_0_prescale <- conv2_0
I0408 21:12:00.314662  9048 net.cpp:395] conv2_0_prescale -> conv2_0 (in-place)
I0408 21:12:00.314820  9048 net.cpp:150] Setting up conv2_0_prescale
I0408 21:12:00.314831  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.314836  9048 net.cpp:165] Memory required for data: 1419486000
I0408 21:12:00.314841  9048 layer_factory.hpp:77] Creating layer conv2_0_sTanH
I0408 21:12:00.314848  9048 net.cpp:100] Creating Layer conv2_0_sTanH
I0408 21:12:00.314852  9048 net.cpp:434] conv2_0_sTanH <- conv2_0
I0408 21:12:00.314857  9048 net.cpp:395] conv2_0_sTanH -> conv2_0 (in-place)
I0408 21:12:00.315088  9048 net.cpp:150] Setting up conv2_0_sTanH
I0408 21:12:00.315099  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.315104  9048 net.cpp:165] Memory required for data: 1525326000
I0408 21:12:00.315107  9048 layer_factory.hpp:77] Creating layer conv2_0_postscale
I0408 21:12:00.315115  9048 net.cpp:100] Creating Layer conv2_0_postscale
I0408 21:12:00.315124  9048 net.cpp:434] conv2_0_postscale <- conv2_0
I0408 21:12:00.315131  9048 net.cpp:395] conv2_0_postscale -> conv2_0 (in-place)
I0408 21:12:00.315268  9048 net.cpp:150] Setting up conv2_0_postscale
I0408 21:12:00.315277  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.315282  9048 net.cpp:165] Memory required for data: 1631166000
I0408 21:12:00.315287  9048 layer_factory.hpp:77] Creating layer pool2_0
I0408 21:12:00.315295  9048 net.cpp:100] Creating Layer pool2_0
I0408 21:12:00.315300  9048 net.cpp:434] pool2_0 <- conv2_0
I0408 21:12:00.315306  9048 net.cpp:408] pool2_0 -> pool2_0
I0408 21:12:00.315359  9048 net.cpp:150] Setting up pool2_0
I0408 21:12:00.315381  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.315385  9048 net.cpp:165] Memory required for data: 1657626000
I0408 21:12:00.315389  9048 layer_factory.hpp:77] Creating layer conv2_1
I0408 21:12:00.315403  9048 net.cpp:100] Creating Layer conv2_1
I0408 21:12:00.315409  9048 net.cpp:434] conv2_1 <- pool2_0
I0408 21:12:00.315415  9048 net.cpp:408] conv2_1 -> conv2_1
I0408 21:12:00.318562  9048 net.cpp:150] Setting up conv2_1
I0408 21:12:00.318579  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.318584  9048 net.cpp:165] Memory required for data: 1686786000
I0408 21:12:00.318593  9048 layer_factory.hpp:77] Creating layer conv2_1_prescale
I0408 21:12:00.318603  9048 net.cpp:100] Creating Layer conv2_1_prescale
I0408 21:12:00.318608  9048 net.cpp:434] conv2_1_prescale <- conv2_1
I0408 21:12:00.318614  9048 net.cpp:395] conv2_1_prescale -> conv2_1 (in-place)
I0408 21:12:00.318744  9048 net.cpp:150] Setting up conv2_1_prescale
I0408 21:12:00.318753  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.318758  9048 net.cpp:165] Memory required for data: 1715946000
I0408 21:12:00.318763  9048 layer_factory.hpp:77] Creating layer conv2_1_sTanH
I0408 21:12:00.318768  9048 net.cpp:100] Creating Layer conv2_1_sTanH
I0408 21:12:00.318773  9048 net.cpp:434] conv2_1_sTanH <- conv2_1
I0408 21:12:00.318778  9048 net.cpp:395] conv2_1_sTanH -> conv2_1 (in-place)
I0408 21:12:00.318979  9048 net.cpp:150] Setting up conv2_1_sTanH
I0408 21:12:00.318990  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.318994  9048 net.cpp:165] Memory required for data: 1745106000
I0408 21:12:00.318998  9048 layer_factory.hpp:77] Creating layer conv2_1_postscale
I0408 21:12:00.319005  9048 net.cpp:100] Creating Layer conv2_1_postscale
I0408 21:12:00.319010  9048 net.cpp:434] conv2_1_postscale <- conv2_1
I0408 21:12:00.319017  9048 net.cpp:395] conv2_1_postscale -> conv2_1 (in-place)
I0408 21:12:00.319145  9048 net.cpp:150] Setting up conv2_1_postscale
I0408 21:12:00.319154  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.319156  9048 net.cpp:165] Memory required for data: 1774266000
I0408 21:12:00.319161  9048 layer_factory.hpp:77] Creating layer pool2_1
I0408 21:12:00.319170  9048 net.cpp:100] Creating Layer pool2_1
I0408 21:12:00.319175  9048 net.cpp:434] pool2_1 <- conv2_1
I0408 21:12:00.319182  9048 net.cpp:408] pool2_1 -> pool2_1
I0408 21:12:00.319233  9048 net.cpp:150] Setting up pool2_1
I0408 21:12:00.319241  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.319243  9048 net.cpp:165] Memory required for data: 1781556000
I0408 21:12:00.319252  9048 layer_factory.hpp:77] Creating layer conv2_2
I0408 21:12:00.319274  9048 net.cpp:100] Creating Layer conv2_2
I0408 21:12:00.319279  9048 net.cpp:434] conv2_2 <- pool2_1
I0408 21:12:00.319286  9048 net.cpp:408] conv2_2 -> conv2_2
I0408 21:12:00.325740  9048 net.cpp:150] Setting up conv2_2
I0408 21:12:00.325757  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.325762  9048 net.cpp:165] Memory required for data: 1786956000
I0408 21:12:00.325783  9048 layer_factory.hpp:77] Creating layer conv2_2_prescale
I0408 21:12:00.325794  9048 net.cpp:100] Creating Layer conv2_2_prescale
I0408 21:12:00.325799  9048 net.cpp:434] conv2_2_prescale <- conv2_2
I0408 21:12:00.325805  9048 net.cpp:395] conv2_2_prescale -> conv2_2 (in-place)
I0408 21:12:00.325934  9048 net.cpp:150] Setting up conv2_2_prescale
I0408 21:12:00.325943  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.325947  9048 net.cpp:165] Memory required for data: 1792356000
I0408 21:12:00.325950  9048 layer_factory.hpp:77] Creating layer conv2_2_sTanH
I0408 21:12:00.325958  9048 net.cpp:100] Creating Layer conv2_2_sTanH
I0408 21:12:00.325963  9048 net.cpp:434] conv2_2_sTanH <- conv2_2
I0408 21:12:00.325969  9048 net.cpp:395] conv2_2_sTanH -> conv2_2 (in-place)
I0408 21:12:00.326174  9048 net.cpp:150] Setting up conv2_2_sTanH
I0408 21:12:00.326184  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.326200  9048 net.cpp:165] Memory required for data: 1797756000
I0408 21:12:00.326210  9048 layer_factory.hpp:77] Creating layer conv2_2_postscale
I0408 21:12:00.326218  9048 net.cpp:100] Creating Layer conv2_2_postscale
I0408 21:12:00.326223  9048 net.cpp:434] conv2_2_postscale <- conv2_2
I0408 21:12:00.326228  9048 net.cpp:395] conv2_2_postscale -> conv2_2 (in-place)
I0408 21:12:00.326359  9048 net.cpp:150] Setting up conv2_2_postscale
I0408 21:12:00.326369  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.326372  9048 net.cpp:165] Memory required for data: 1803156000
I0408 21:12:00.326377  9048 layer_factory.hpp:77] Creating layer pool2_2
I0408 21:12:00.326385  9048 net.cpp:100] Creating Layer pool2_2
I0408 21:12:00.326390  9048 net.cpp:434] pool2_2 <- conv2_2
I0408 21:12:00.326395  9048 net.cpp:408] pool2_2 -> pool2_2
I0408 21:12:00.326452  9048 net.cpp:150] Setting up pool2_2
I0408 21:12:00.326464  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.326467  9048 net.cpp:165] Memory required for data: 1804506000
I0408 21:12:00.326472  9048 layer_factory.hpp:77] Creating layer fc2_4_300
I0408 21:12:00.326478  9048 net.cpp:100] Creating Layer fc2_4_300
I0408 21:12:00.326481  9048 net.cpp:434] fc2_4_300 <- pool2_2
I0408 21:12:00.326488  9048 net.cpp:408] fc2_4_300 -> fc2_4
I0408 21:12:00.331933  9048 net.cpp:150] Setting up fc2_4_300
I0408 21:12:00.331948  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.331953  9048 net.cpp:165] Memory required for data: 1804686000
I0408 21:12:00.331959  9048 layer_factory.hpp:77] Creating layer fc2_4_prescale
I0408 21:12:00.331979  9048 net.cpp:100] Creating Layer fc2_4_prescale
I0408 21:12:00.331985  9048 net.cpp:434] fc2_4_prescale <- fc2_4
I0408 21:12:00.331991  9048 net.cpp:395] fc2_4_prescale -> fc2_4 (in-place)
I0408 21:12:00.332123  9048 net.cpp:150] Setting up fc2_4_prescale
I0408 21:12:00.332131  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.332134  9048 net.cpp:165] Memory required for data: 1804866000
I0408 21:12:00.332140  9048 layer_factory.hpp:77] Creating layer fc2_4_sTanH
I0408 21:12:00.332149  9048 net.cpp:100] Creating Layer fc2_4_sTanH
I0408 21:12:00.332154  9048 net.cpp:434] fc2_4_sTanH <- fc2_4
I0408 21:12:00.332157  9048 net.cpp:395] fc2_4_sTanH -> fc2_4 (in-place)
I0408 21:12:00.332365  9048 net.cpp:150] Setting up fc2_4_sTanH
I0408 21:12:00.332376  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.332379  9048 net.cpp:165] Memory required for data: 1805046000
I0408 21:12:00.332382  9048 layer_factory.hpp:77] Creating layer fc2_4_postscale
I0408 21:12:00.332391  9048 net.cpp:100] Creating Layer fc2_4_postscale
I0408 21:12:00.332396  9048 net.cpp:434] fc2_4_postscale <- fc2_4
I0408 21:12:00.332403  9048 net.cpp:395] fc2_4_postscale -> fc2_4 (in-place)
I0408 21:12:00.332535  9048 net.cpp:150] Setting up fc2_4_postscale
I0408 21:12:00.332545  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.332547  9048 net.cpp:165] Memory required for data: 1805226000
I0408 21:12:00.332551  9048 layer_factory.hpp:77] Creating layer drop2_4
I0408 21:12:00.332561  9048 net.cpp:100] Creating Layer drop2_4
I0408 21:12:00.332566  9048 net.cpp:434] drop2_4 <- fc2_4
I0408 21:12:00.332571  9048 net.cpp:395] drop2_4 -> fc2_4 (in-place)
I0408 21:12:00.332602  9048 net.cpp:150] Setting up drop2_4
I0408 21:12:00.332609  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.332612  9048 net.cpp:165] Memory required for data: 1805406000
I0408 21:12:00.332615  9048 layer_factory.hpp:77] Creating layer fc2_5_67
I0408 21:12:00.332623  9048 net.cpp:100] Creating Layer fc2_5_67
I0408 21:12:00.332628  9048 net.cpp:434] fc2_5_67 <- fc2_4
I0408 21:12:00.332633  9048 net.cpp:408] fc2_5_67 -> fc2_5
I0408 21:12:00.332908  9048 net.cpp:150] Setting up fc2_5_67
I0408 21:12:00.332917  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.332919  9048 net.cpp:165] Memory required for data: 1805446200
I0408 21:12:00.332926  9048 layer_factory.hpp:77] Creating layer softmax_2
I0408 21:12:00.332933  9048 net.cpp:100] Creating Layer softmax_2
I0408 21:12:00.332949  9048 net.cpp:434] softmax_2 <- fc2_5
I0408 21:12:00.332955  9048 net.cpp:408] softmax_2 -> softmax_2
I0408 21:12:00.333958  9048 net.cpp:150] Setting up softmax_2
I0408 21:12:00.333972  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.333976  9048 net.cpp:165] Memory required for data: 1805486400
I0408 21:12:00.333981  9048 layer_factory.hpp:77] Creating layer data_3
I0408 21:12:00.334125  9048 net.cpp:100] Creating Layer data_3
I0408 21:12:00.334136  9048 net.cpp:408] data_3 -> data_3
I0408 21:12:00.334147  9048 net.cpp:408] data_3 -> label_3
I0408 21:12:00.335336  9160 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/imajust/test/lmdb
I0408 21:12:00.335487  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.344395  9048 net.cpp:150] Setting up data_3
I0408 21:12:00.344425  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.344430  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.344434  9048 net.cpp:165] Memory required for data: 1809634200
I0408 21:12:00.344439  9048 layer_factory.hpp:77] Creating layer conv3_0
I0408 21:12:00.344449  9048 net.cpp:100] Creating Layer conv3_0
I0408 21:12:00.344455  9048 net.cpp:434] conv3_0 <- data_3
I0408 21:12:00.344465  9048 net.cpp:408] conv3_0 -> conv3_0
I0408 21:12:00.346763  9048 net.cpp:150] Setting up conv3_0
I0408 21:12:00.346792  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.346796  9048 net.cpp:165] Memory required for data: 1915474200
I0408 21:12:00.346803  9048 layer_factory.hpp:77] Creating layer conv3_0_prescale
I0408 21:12:00.346812  9048 net.cpp:100] Creating Layer conv3_0_prescale
I0408 21:12:00.346815  9048 net.cpp:434] conv3_0_prescale <- conv3_0
I0408 21:12:00.346825  9048 net.cpp:395] conv3_0_prescale -> conv3_0 (in-place)
I0408 21:12:00.346963  9048 net.cpp:150] Setting up conv3_0_prescale
I0408 21:12:00.346972  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.346976  9048 net.cpp:165] Memory required for data: 2021314200
I0408 21:12:00.346982  9048 layer_factory.hpp:77] Creating layer conv3_0_sTanH
I0408 21:12:00.346989  9048 net.cpp:100] Creating Layer conv3_0_sTanH
I0408 21:12:00.346994  9048 net.cpp:434] conv3_0_sTanH <- conv3_0
I0408 21:12:00.346999  9048 net.cpp:395] conv3_0_sTanH -> conv3_0 (in-place)
I0408 21:12:00.347213  9048 net.cpp:150] Setting up conv3_0_sTanH
I0408 21:12:00.347223  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.347228  9048 net.cpp:165] Memory required for data: 2127154200
I0408 21:12:00.347231  9048 layer_factory.hpp:77] Creating layer conv3_0_postscale
I0408 21:12:00.347239  9048 net.cpp:100] Creating Layer conv3_0_postscale
I0408 21:12:00.347244  9048 net.cpp:434] conv3_0_postscale <- conv3_0
I0408 21:12:00.347249  9048 net.cpp:395] conv3_0_postscale -> conv3_0 (in-place)
I0408 21:12:00.347388  9048 net.cpp:150] Setting up conv3_0_postscale
I0408 21:12:00.347396  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.347399  9048 net.cpp:165] Memory required for data: 2232994200
I0408 21:12:00.347404  9048 layer_factory.hpp:77] Creating layer pool3_0
I0408 21:12:00.347411  9048 net.cpp:100] Creating Layer pool3_0
I0408 21:12:00.347416  9048 net.cpp:434] pool3_0 <- conv3_0
I0408 21:12:00.347421  9048 net.cpp:408] pool3_0 -> pool3_0
I0408 21:12:00.347476  9048 net.cpp:150] Setting up pool3_0
I0408 21:12:00.347483  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.347486  9048 net.cpp:165] Memory required for data: 2259454200
I0408 21:12:00.347489  9048 layer_factory.hpp:77] Creating layer conv3_1
I0408 21:12:00.347499  9048 net.cpp:100] Creating Layer conv3_1
I0408 21:12:00.347506  9048 net.cpp:434] conv3_1 <- pool3_0
I0408 21:12:00.347510  9048 net.cpp:408] conv3_1 -> conv3_1
I0408 21:12:00.351755  9048 net.cpp:150] Setting up conv3_1
I0408 21:12:00.351773  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.351778  9048 net.cpp:165] Memory required for data: 2288614200
I0408 21:12:00.351784  9048 layer_factory.hpp:77] Creating layer conv3_1_prescale
I0408 21:12:00.351809  9048 net.cpp:100] Creating Layer conv3_1_prescale
I0408 21:12:00.351814  9048 net.cpp:434] conv3_1_prescale <- conv3_1
I0408 21:12:00.351820  9048 net.cpp:395] conv3_1_prescale -> conv3_1 (in-place)
I0408 21:12:00.352000  9048 net.cpp:150] Setting up conv3_1_prescale
I0408 21:12:00.352011  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.352015  9048 net.cpp:165] Memory required for data: 2317774200
I0408 21:12:00.352020  9048 layer_factory.hpp:77] Creating layer conv3_1_sTanH
I0408 21:12:00.352027  9048 net.cpp:100] Creating Layer conv3_1_sTanH
I0408 21:12:00.352032  9048 net.cpp:434] conv3_1_sTanH <- conv3_1
I0408 21:12:00.352037  9048 net.cpp:395] conv3_1_sTanH -> conv3_1 (in-place)
I0408 21:12:00.352557  9048 net.cpp:150] Setting up conv3_1_sTanH
I0408 21:12:00.352569  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.352574  9048 net.cpp:165] Memory required for data: 2346934200
I0408 21:12:00.352578  9048 layer_factory.hpp:77] Creating layer conv3_1_postscale
I0408 21:12:00.352587  9048 net.cpp:100] Creating Layer conv3_1_postscale
I0408 21:12:00.352593  9048 net.cpp:434] conv3_1_postscale <- conv3_1
I0408 21:12:00.352599  9048 net.cpp:395] conv3_1_postscale -> conv3_1 (in-place)
I0408 21:12:00.352738  9048 net.cpp:150] Setting up conv3_1_postscale
I0408 21:12:00.352747  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.352751  9048 net.cpp:165] Memory required for data: 2376094200
I0408 21:12:00.352756  9048 layer_factory.hpp:77] Creating layer pool3_1
I0408 21:12:00.352762  9048 net.cpp:100] Creating Layer pool3_1
I0408 21:12:00.352767  9048 net.cpp:434] pool3_1 <- conv3_1
I0408 21:12:00.352774  9048 net.cpp:408] pool3_1 -> pool3_1
I0408 21:12:00.352829  9048 net.cpp:150] Setting up pool3_1
I0408 21:12:00.352838  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.352840  9048 net.cpp:165] Memory required for data: 2383384200
I0408 21:12:00.352843  9048 layer_factory.hpp:77] Creating layer conv3_2
I0408 21:12:00.352852  9048 net.cpp:100] Creating Layer conv3_2
I0408 21:12:00.352864  9048 net.cpp:434] conv3_2 <- pool3_1
I0408 21:12:00.352871  9048 net.cpp:408] conv3_2 -> conv3_2
I0408 21:12:00.359355  9048 net.cpp:150] Setting up conv3_2
I0408 21:12:00.359372  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.359377  9048 net.cpp:165] Memory required for data: 2388784200
I0408 21:12:00.359385  9048 layer_factory.hpp:77] Creating layer conv3_2_prescale
I0408 21:12:00.359396  9048 net.cpp:100] Creating Layer conv3_2_prescale
I0408 21:12:00.359410  9048 net.cpp:434] conv3_2_prescale <- conv3_2
I0408 21:12:00.359416  9048 net.cpp:395] conv3_2_prescale -> conv3_2 (in-place)
I0408 21:12:00.359547  9048 net.cpp:150] Setting up conv3_2_prescale
I0408 21:12:00.359556  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.359560  9048 net.cpp:165] Memory required for data: 2394184200
I0408 21:12:00.359575  9048 layer_factory.hpp:77] Creating layer conv3_2_sTanH
I0408 21:12:00.359582  9048 net.cpp:100] Creating Layer conv3_2_sTanH
I0408 21:12:00.359591  9048 net.cpp:434] conv3_2_sTanH <- conv3_2
I0408 21:12:00.359598  9048 net.cpp:395] conv3_2_sTanH -> conv3_2 (in-place)
I0408 21:12:00.359800  9048 net.cpp:150] Setting up conv3_2_sTanH
I0408 21:12:00.359812  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.359815  9048 net.cpp:165] Memory required for data: 2399584200
I0408 21:12:00.359820  9048 layer_factory.hpp:77] Creating layer conv3_2_postscale
I0408 21:12:00.359834  9048 net.cpp:100] Creating Layer conv3_2_postscale
I0408 21:12:00.359839  9048 net.cpp:434] conv3_2_postscale <- conv3_2
I0408 21:12:00.359848  9048 net.cpp:395] conv3_2_postscale -> conv3_2 (in-place)
I0408 21:12:00.359997  9048 net.cpp:150] Setting up conv3_2_postscale
I0408 21:12:00.360008  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.360010  9048 net.cpp:165] Memory required for data: 2404984200
I0408 21:12:00.360015  9048 layer_factory.hpp:77] Creating layer pool3_2
I0408 21:12:00.360035  9048 net.cpp:100] Creating Layer pool3_2
I0408 21:12:00.360041  9048 net.cpp:434] pool3_2 <- conv3_2
I0408 21:12:00.360049  9048 net.cpp:408] pool3_2 -> pool3_2
I0408 21:12:00.360105  9048 net.cpp:150] Setting up pool3_2
I0408 21:12:00.360113  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.360116  9048 net.cpp:165] Memory required for data: 2406334200
I0408 21:12:00.360119  9048 layer_factory.hpp:77] Creating layer fc3_4_300
I0408 21:12:00.360127  9048 net.cpp:100] Creating Layer fc3_4_300
I0408 21:12:00.360132  9048 net.cpp:434] fc3_4_300 <- pool3_2
I0408 21:12:00.360138  9048 net.cpp:408] fc3_4_300 -> fc3_4
I0408 21:12:00.365666  9048 net.cpp:150] Setting up fc3_4_300
I0408 21:12:00.365681  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.365685  9048 net.cpp:165] Memory required for data: 2406514200
I0408 21:12:00.365692  9048 layer_factory.hpp:77] Creating layer fc3_4_prescale
I0408 21:12:00.365702  9048 net.cpp:100] Creating Layer fc3_4_prescale
I0408 21:12:00.365708  9048 net.cpp:434] fc3_4_prescale <- fc3_4
I0408 21:12:00.365715  9048 net.cpp:395] fc3_4_prescale -> fc3_4 (in-place)
I0408 21:12:00.365844  9048 net.cpp:150] Setting up fc3_4_prescale
I0408 21:12:00.365852  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.365855  9048 net.cpp:165] Memory required for data: 2406694200
I0408 21:12:00.365860  9048 layer_factory.hpp:77] Creating layer fc3_4_sTanH
I0408 21:12:00.365865  9048 net.cpp:100] Creating Layer fc3_4_sTanH
I0408 21:12:00.365870  9048 net.cpp:434] fc3_4_sTanH <- fc3_4
I0408 21:12:00.365875  9048 net.cpp:395] fc3_4_sTanH -> fc3_4 (in-place)
I0408 21:12:00.366082  9048 net.cpp:150] Setting up fc3_4_sTanH
I0408 21:12:00.366093  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.366096  9048 net.cpp:165] Memory required for data: 2406874200
I0408 21:12:00.366101  9048 layer_factory.hpp:77] Creating layer fc3_4_postscale
I0408 21:12:00.366109  9048 net.cpp:100] Creating Layer fc3_4_postscale
I0408 21:12:00.366114  9048 net.cpp:434] fc3_4_postscale <- fc3_4
I0408 21:12:00.366119  9048 net.cpp:395] fc3_4_postscale -> fc3_4 (in-place)
I0408 21:12:00.366252  9048 net.cpp:150] Setting up fc3_4_postscale
I0408 21:12:00.366261  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.366263  9048 net.cpp:165] Memory required for data: 2407054200
I0408 21:12:00.366267  9048 layer_factory.hpp:77] Creating layer drop3_4
I0408 21:12:00.366276  9048 net.cpp:100] Creating Layer drop3_4
I0408 21:12:00.366281  9048 net.cpp:434] drop3_4 <- fc3_4
I0408 21:12:00.366284  9048 net.cpp:395] drop3_4 -> fc3_4 (in-place)
I0408 21:12:00.366317  9048 net.cpp:150] Setting up drop3_4
I0408 21:12:00.366323  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.366327  9048 net.cpp:165] Memory required for data: 2407234200
I0408 21:12:00.366329  9048 layer_factory.hpp:77] Creating layer fc3_5_67
I0408 21:12:00.366335  9048 net.cpp:100] Creating Layer fc3_5_67
I0408 21:12:00.366338  9048 net.cpp:434] fc3_5_67 <- fc3_4
I0408 21:12:00.366344  9048 net.cpp:408] fc3_5_67 -> fc3_5
I0408 21:12:00.366623  9048 net.cpp:150] Setting up fc3_5_67
I0408 21:12:00.366632  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.366634  9048 net.cpp:165] Memory required for data: 2407274400
I0408 21:12:00.366641  9048 layer_factory.hpp:77] Creating layer softmax_3
I0408 21:12:00.366648  9048 net.cpp:100] Creating Layer softmax_3
I0408 21:12:00.366652  9048 net.cpp:434] softmax_3 <- fc3_5
I0408 21:12:00.366657  9048 net.cpp:408] softmax_3 -> softmax_3
I0408 21:12:00.367782  9048 net.cpp:150] Setting up softmax_3
I0408 21:12:00.367797  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.367800  9048 net.cpp:165] Memory required for data: 2407314600
I0408 21:12:00.367805  9048 layer_factory.hpp:77] Creating layer data_4
I0408 21:12:00.367959  9048 net.cpp:100] Creating Layer data_4
I0408 21:12:00.367969  9048 net.cpp:408] data_4 -> data_4
I0408 21:12:00.367980  9048 net.cpp:408] data_4 -> label_4
I0408 21:12:00.371492  9165 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0408 21:12:00.371655  9048 data_layer.cpp:41] output data size: 150,3,48,48
I0408 21:12:00.390272  9048 net.cpp:150] Setting up data_4
I0408 21:12:00.390290  9048 net.cpp:157] Top shape: 150 3 48 48 (1036800)
I0408 21:12:00.390306  9048 net.cpp:157] Top shape: 150 (150)
I0408 21:12:00.390310  9048 net.cpp:165] Memory required for data: 2411462400
I0408 21:12:00.390313  9048 layer_factory.hpp:77] Creating layer conv4_0
I0408 21:12:00.390326  9048 net.cpp:100] Creating Layer conv4_0
I0408 21:12:00.390336  9048 net.cpp:434] conv4_0 <- data_4
I0408 21:12:00.390343  9048 net.cpp:408] conv4_0 -> conv4_0
I0408 21:12:00.397742  9048 net.cpp:150] Setting up conv4_0
I0408 21:12:00.397758  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.397761  9048 net.cpp:165] Memory required for data: 2517302400
I0408 21:12:00.397769  9048 layer_factory.hpp:77] Creating layer conv4_0_prescale
I0408 21:12:00.397776  9048 net.cpp:100] Creating Layer conv4_0_prescale
I0408 21:12:00.397780  9048 net.cpp:434] conv4_0_prescale <- conv4_0
I0408 21:12:00.397789  9048 net.cpp:395] conv4_0_prescale -> conv4_0 (in-place)
I0408 21:12:00.397927  9048 net.cpp:150] Setting up conv4_0_prescale
I0408 21:12:00.397936  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.397939  9048 net.cpp:165] Memory required for data: 2623142400
I0408 21:12:00.397944  9048 layer_factory.hpp:77] Creating layer conv4_0_sTanH
I0408 21:12:00.397950  9048 net.cpp:100] Creating Layer conv4_0_sTanH
I0408 21:12:00.397954  9048 net.cpp:434] conv4_0_sTanH <- conv4_0
I0408 21:12:00.397960  9048 net.cpp:395] conv4_0_sTanH -> conv4_0 (in-place)
I0408 21:12:00.398175  9048 net.cpp:150] Setting up conv4_0_sTanH
I0408 21:12:00.398186  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.398191  9048 net.cpp:165] Memory required for data: 2728982400
I0408 21:12:00.398195  9048 layer_factory.hpp:77] Creating layer conv4_0_postscale
I0408 21:12:00.398203  9048 net.cpp:100] Creating Layer conv4_0_postscale
I0408 21:12:00.398208  9048 net.cpp:434] conv4_0_postscale <- conv4_0
I0408 21:12:00.398214  9048 net.cpp:395] conv4_0_postscale -> conv4_0 (in-place)
I0408 21:12:00.398353  9048 net.cpp:150] Setting up conv4_0_postscale
I0408 21:12:00.398362  9048 net.cpp:157] Top shape: 150 100 42 42 (26460000)
I0408 21:12:00.398365  9048 net.cpp:165] Memory required for data: 2834822400
I0408 21:12:00.398370  9048 layer_factory.hpp:77] Creating layer pool4_0
I0408 21:12:00.398381  9048 net.cpp:100] Creating Layer pool4_0
I0408 21:12:00.398386  9048 net.cpp:434] pool4_0 <- conv4_0
I0408 21:12:00.398392  9048 net.cpp:408] pool4_0 -> pool4_0
I0408 21:12:00.398449  9048 net.cpp:150] Setting up pool4_0
I0408 21:12:00.398458  9048 net.cpp:157] Top shape: 150 100 21 21 (6615000)
I0408 21:12:00.398460  9048 net.cpp:165] Memory required for data: 2861282400
I0408 21:12:00.398463  9048 layer_factory.hpp:77] Creating layer conv4_1
I0408 21:12:00.398473  9048 net.cpp:100] Creating Layer conv4_1
I0408 21:12:00.398478  9048 net.cpp:434] conv4_1 <- pool4_0
I0408 21:12:00.398484  9048 net.cpp:408] conv4_1 -> conv4_1
I0408 21:12:00.401664  9048 net.cpp:150] Setting up conv4_1
I0408 21:12:00.401684  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.401690  9048 net.cpp:165] Memory required for data: 2890442400
I0408 21:12:00.401696  9048 layer_factory.hpp:77] Creating layer conv4_1_prescale
I0408 21:12:00.401707  9048 net.cpp:100] Creating Layer conv4_1_prescale
I0408 21:12:00.401715  9048 net.cpp:434] conv4_1_prescale <- conv4_1
I0408 21:12:00.401721  9048 net.cpp:395] conv4_1_prescale -> conv4_1 (in-place)
I0408 21:12:00.401862  9048 net.cpp:150] Setting up conv4_1_prescale
I0408 21:12:00.401872  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.401875  9048 net.cpp:165] Memory required for data: 2919602400
I0408 21:12:00.401880  9048 layer_factory.hpp:77] Creating layer conv4_1_sTanH
I0408 21:12:00.401887  9048 net.cpp:100] Creating Layer conv4_1_sTanH
I0408 21:12:00.401892  9048 net.cpp:434] conv4_1_sTanH <- conv4_1
I0408 21:12:00.401911  9048 net.cpp:395] conv4_1_sTanH -> conv4_1 (in-place)
I0408 21:12:00.402124  9048 net.cpp:150] Setting up conv4_1_sTanH
I0408 21:12:00.402137  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.402142  9048 net.cpp:165] Memory required for data: 2948762400
I0408 21:12:00.402145  9048 layer_factory.hpp:77] Creating layer conv4_1_postscale
I0408 21:12:00.402153  9048 net.cpp:100] Creating Layer conv4_1_postscale
I0408 21:12:00.402155  9048 net.cpp:434] conv4_1_postscale <- conv4_1
I0408 21:12:00.402163  9048 net.cpp:395] conv4_1_postscale -> conv4_1 (in-place)
I0408 21:12:00.402302  9048 net.cpp:150] Setting up conv4_1_postscale
I0408 21:12:00.402310  9048 net.cpp:157] Top shape: 150 150 18 18 (7290000)
I0408 21:12:00.402313  9048 net.cpp:165] Memory required for data: 2977922400
I0408 21:12:00.402318  9048 layer_factory.hpp:77] Creating layer pool4_1
I0408 21:12:00.402328  9048 net.cpp:100] Creating Layer pool4_1
I0408 21:12:00.402335  9048 net.cpp:434] pool4_1 <- conv4_1
I0408 21:12:00.402343  9048 net.cpp:408] pool4_1 -> pool4_1
I0408 21:12:00.402398  9048 net.cpp:150] Setting up pool4_1
I0408 21:12:00.402406  9048 net.cpp:157] Top shape: 150 150 9 9 (1822500)
I0408 21:12:00.402410  9048 net.cpp:165] Memory required for data: 2985212400
I0408 21:12:00.402412  9048 layer_factory.hpp:77] Creating layer conv4_2
I0408 21:12:00.402421  9048 net.cpp:100] Creating Layer conv4_2
I0408 21:12:00.402426  9048 net.cpp:434] conv4_2 <- pool4_1
I0408 21:12:00.402433  9048 net.cpp:408] conv4_2 -> conv4_2
I0408 21:12:00.409080  9048 net.cpp:150] Setting up conv4_2
I0408 21:12:00.409098  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.409102  9048 net.cpp:165] Memory required for data: 2990612400
I0408 21:12:00.409109  9048 layer_factory.hpp:77] Creating layer conv4_2_prescale
I0408 21:12:00.409118  9048 net.cpp:100] Creating Layer conv4_2_prescale
I0408 21:12:00.409124  9048 net.cpp:434] conv4_2_prescale <- conv4_2
I0408 21:12:00.409132  9048 net.cpp:395] conv4_2_prescale -> conv4_2 (in-place)
I0408 21:12:00.409273  9048 net.cpp:150] Setting up conv4_2_prescale
I0408 21:12:00.409282  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.409286  9048 net.cpp:165] Memory required for data: 2996012400
I0408 21:12:00.409291  9048 layer_factory.hpp:77] Creating layer conv4_2_sTanH
I0408 21:12:00.409297  9048 net.cpp:100] Creating Layer conv4_2_sTanH
I0408 21:12:00.409302  9048 net.cpp:434] conv4_2_sTanH <- conv4_2
I0408 21:12:00.409308  9048 net.cpp:395] conv4_2_sTanH -> conv4_2 (in-place)
I0408 21:12:00.409879  9048 net.cpp:150] Setting up conv4_2_sTanH
I0408 21:12:00.409891  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.409896  9048 net.cpp:165] Memory required for data: 3001412400
I0408 21:12:00.409899  9048 layer_factory.hpp:77] Creating layer conv4_2_postscale
I0408 21:12:00.409909  9048 net.cpp:100] Creating Layer conv4_2_postscale
I0408 21:12:00.409914  9048 net.cpp:434] conv4_2_postscale <- conv4_2
I0408 21:12:00.409919  9048 net.cpp:395] conv4_2_postscale -> conv4_2 (in-place)
I0408 21:12:00.410058  9048 net.cpp:150] Setting up conv4_2_postscale
I0408 21:12:00.410066  9048 net.cpp:157] Top shape: 150 250 6 6 (1350000)
I0408 21:12:00.410069  9048 net.cpp:165] Memory required for data: 3006812400
I0408 21:12:00.410074  9048 layer_factory.hpp:77] Creating layer pool4_2
I0408 21:12:00.410082  9048 net.cpp:100] Creating Layer pool4_2
I0408 21:12:00.410089  9048 net.cpp:434] pool4_2 <- conv4_2
I0408 21:12:00.410094  9048 net.cpp:408] pool4_2 -> pool4_2
I0408 21:12:00.410150  9048 net.cpp:150] Setting up pool4_2
I0408 21:12:00.410156  9048 net.cpp:157] Top shape: 150 250 3 3 (337500)
I0408 21:12:00.410159  9048 net.cpp:165] Memory required for data: 3008162400
I0408 21:12:00.410163  9048 layer_factory.hpp:77] Creating layer fc4_4_300
I0408 21:12:00.410169  9048 net.cpp:100] Creating Layer fc4_4_300
I0408 21:12:00.410174  9048 net.cpp:434] fc4_4_300 <- pool4_2
I0408 21:12:00.410181  9048 net.cpp:408] fc4_4_300 -> fc4_4
I0408 21:12:00.416978  9048 net.cpp:150] Setting up fc4_4_300
I0408 21:12:00.416993  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.416998  9048 net.cpp:165] Memory required for data: 3008342400
I0408 21:12:00.417006  9048 layer_factory.hpp:77] Creating layer fc4_4_prescale
I0408 21:12:00.417013  9048 net.cpp:100] Creating Layer fc4_4_prescale
I0408 21:12:00.417018  9048 net.cpp:434] fc4_4_prescale <- fc4_4
I0408 21:12:00.417026  9048 net.cpp:395] fc4_4_prescale -> fc4_4 (in-place)
I0408 21:12:00.417156  9048 net.cpp:150] Setting up fc4_4_prescale
I0408 21:12:00.417165  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.417167  9048 net.cpp:165] Memory required for data: 3008522400
I0408 21:12:00.417172  9048 layer_factory.hpp:77] Creating layer fc4_4_sTanH
I0408 21:12:00.417177  9048 net.cpp:100] Creating Layer fc4_4_sTanH
I0408 21:12:00.417181  9048 net.cpp:434] fc4_4_sTanH <- fc4_4
I0408 21:12:00.417186  9048 net.cpp:395] fc4_4_sTanH -> fc4_4 (in-place)
I0408 21:12:00.418614  9048 net.cpp:150] Setting up fc4_4_sTanH
I0408 21:12:00.418629  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.418633  9048 net.cpp:165] Memory required for data: 3008702400
I0408 21:12:00.418637  9048 layer_factory.hpp:77] Creating layer fc4_4_postscale
I0408 21:12:00.418648  9048 net.cpp:100] Creating Layer fc4_4_postscale
I0408 21:12:00.418653  9048 net.cpp:434] fc4_4_postscale <- fc4_4
I0408 21:12:00.418658  9048 net.cpp:395] fc4_4_postscale -> fc4_4 (in-place)
I0408 21:12:00.418807  9048 net.cpp:150] Setting up fc4_4_postscale
I0408 21:12:00.418817  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.418819  9048 net.cpp:165] Memory required for data: 3008882400
I0408 21:12:00.418826  9048 layer_factory.hpp:77] Creating layer drop4_4
I0408 21:12:00.418834  9048 net.cpp:100] Creating Layer drop4_4
I0408 21:12:00.418839  9048 net.cpp:434] drop4_4 <- fc4_4
I0408 21:12:00.418843  9048 net.cpp:395] drop4_4 -> fc4_4 (in-place)
I0408 21:12:00.418879  9048 net.cpp:150] Setting up drop4_4
I0408 21:12:00.418885  9048 net.cpp:157] Top shape: 150 300 (45000)
I0408 21:12:00.418889  9048 net.cpp:165] Memory required for data: 3009062400
I0408 21:12:00.418891  9048 layer_factory.hpp:77] Creating layer fc4_5_67
I0408 21:12:00.418897  9048 net.cpp:100] Creating Layer fc4_5_67
I0408 21:12:00.418902  9048 net.cpp:434] fc4_5_67 <- fc4_4
I0408 21:12:00.418908  9048 net.cpp:408] fc4_5_67 -> fc4_5
I0408 21:12:00.419198  9048 net.cpp:150] Setting up fc4_5_67
I0408 21:12:00.419206  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.419209  9048 net.cpp:165] Memory required for data: 3009102600
I0408 21:12:00.419215  9048 layer_factory.hpp:77] Creating layer softmax_4
I0408 21:12:00.419222  9048 net.cpp:100] Creating Layer softmax_4
I0408 21:12:00.419227  9048 net.cpp:434] softmax_4 <- fc4_5
I0408 21:12:00.419231  9048 net.cpp:408] softmax_4 -> softmax_4
I0408 21:12:00.419523  9048 net.cpp:150] Setting up softmax_4
I0408 21:12:00.419534  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.419538  9048 net.cpp:165] Memory required for data: 3009142800
I0408 21:12:00.419543  9048 layer_factory.hpp:77] Creating layer averaging
I0408 21:12:00.419551  9048 net.cpp:100] Creating Layer averaging
I0408 21:12:00.419556  9048 net.cpp:434] averaging <- softmax_0
I0408 21:12:00.419561  9048 net.cpp:434] averaging <- softmax_1
I0408 21:12:00.419564  9048 net.cpp:434] averaging <- softmax_2
I0408 21:12:00.419569  9048 net.cpp:434] averaging <- softmax_3
I0408 21:12:00.419574  9048 net.cpp:434] averaging <- softmax_4
I0408 21:12:00.419580  9048 net.cpp:408] averaging -> eltwize
I0408 21:12:00.419617  9048 net.cpp:150] Setting up averaging
I0408 21:12:00.419625  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.419627  9048 net.cpp:165] Memory required for data: 3009183000
I0408 21:12:00.419631  9048 layer_factory.hpp:77] Creating layer eltwize_averaging_0_split
I0408 21:12:00.419639  9048 net.cpp:100] Creating Layer eltwize_averaging_0_split
I0408 21:12:00.419643  9048 net.cpp:434] eltwize_averaging_0_split <- eltwize
I0408 21:12:00.419663  9048 net.cpp:408] eltwize_averaging_0_split -> eltwize_averaging_0_split_0
I0408 21:12:00.419672  9048 net.cpp:408] eltwize_averaging_0_split -> eltwize_averaging_0_split_1
I0408 21:12:00.419680  9048 net.cpp:408] eltwize_averaging_0_split -> eltwize_averaging_0_split_2
I0408 21:12:00.419751  9048 net.cpp:150] Setting up eltwize_averaging_0_split
I0408 21:12:00.419759  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.419762  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.419765  9048 net.cpp:157] Top shape: 150 67 (10050)
I0408 21:12:00.419769  9048 net.cpp:165] Memory required for data: 3009303600
I0408 21:12:00.419771  9048 layer_factory.hpp:77] Creating layer loss
I0408 21:12:00.419780  9048 net.cpp:100] Creating Layer loss
I0408 21:12:00.419785  9048 net.cpp:434] loss <- eltwize_averaging_0_split_0
I0408 21:12:00.419788  9048 net.cpp:434] loss <- label_0_data_0_1_split_0
I0408 21:12:00.419795  9048 net.cpp:408] loss -> loss
I0408 21:12:00.419829  9048 net.cpp:150] Setting up loss
I0408 21:12:00.419836  9048 net.cpp:157] Top shape: (1)
I0408 21:12:00.419838  9048 net.cpp:160]     with loss weight 1
I0408 21:12:00.419849  9048 net.cpp:165] Memory required for data: 3009303604
I0408 21:12:00.419852  9048 layer_factory.hpp:77] Creating layer accuracy_1
I0408 21:12:00.419862  9048 net.cpp:100] Creating Layer accuracy_1
I0408 21:12:00.419867  9048 net.cpp:434] accuracy_1 <- eltwize_averaging_0_split_1
I0408 21:12:00.419872  9048 net.cpp:434] accuracy_1 <- label_0_data_0_1_split_1
I0408 21:12:00.419876  9048 net.cpp:408] accuracy_1 -> accuracy_1
I0408 21:12:00.419896  9048 net.cpp:150] Setting up accuracy_1
I0408 21:12:00.419904  9048 net.cpp:157] Top shape: (1)
I0408 21:12:00.419909  9048 net.cpp:165] Memory required for data: 3009303608
I0408 21:12:00.419912  9048 layer_factory.hpp:77] Creating layer accuracy_5
I0408 21:12:00.419917  9048 net.cpp:100] Creating Layer accuracy_5
I0408 21:12:00.419921  9048 net.cpp:434] accuracy_5 <- eltwize_averaging_0_split_2
I0408 21:12:00.419925  9048 net.cpp:434] accuracy_5 <- label_0_data_0_1_split_2
I0408 21:12:00.419930  9048 net.cpp:408] accuracy_5 -> accuracy_5
I0408 21:12:00.419951  9048 net.cpp:150] Setting up accuracy_5
I0408 21:12:00.419957  9048 net.cpp:157] Top shape: (1)
I0408 21:12:00.419960  9048 net.cpp:165] Memory required for data: 3009303612
I0408 21:12:00.419963  9048 layer_factory.hpp:77] Creating layer silence
I0408 21:12:00.419968  9048 net.cpp:100] Creating Layer silence
I0408 21:12:00.419973  9048 net.cpp:434] silence <- label_1
I0408 21:12:00.419977  9048 net.cpp:434] silence <- label_2
I0408 21:12:00.419982  9048 net.cpp:434] silence <- label_3
I0408 21:12:00.419986  9048 net.cpp:434] silence <- label_4
I0408 21:12:00.419991  9048 net.cpp:150] Setting up silence
I0408 21:12:00.419992  9048 net.cpp:165] Memory required for data: 3009303612
I0408 21:12:00.419996  9048 net.cpp:228] silence does not need backward computation.
I0408 21:12:00.420001  9048 net.cpp:228] accuracy_5 does not need backward computation.
I0408 21:12:00.420003  9048 net.cpp:228] accuracy_1 does not need backward computation.
I0408 21:12:00.420007  9048 net.cpp:226] loss needs backward computation.
I0408 21:12:00.420011  9048 net.cpp:226] eltwize_averaging_0_split needs backward computation.
I0408 21:12:00.420014  9048 net.cpp:226] averaging needs backward computation.
I0408 21:12:00.420019  9048 net.cpp:226] softmax_4 needs backward computation.
I0408 21:12:00.420022  9048 net.cpp:226] fc4_5_67 needs backward computation.
I0408 21:12:00.420025  9048 net.cpp:226] drop4_4 needs backward computation.
I0408 21:12:00.420028  9048 net.cpp:226] fc4_4_postscale needs backward computation.
I0408 21:12:00.420032  9048 net.cpp:226] fc4_4_sTanH needs backward computation.
I0408 21:12:00.420034  9048 net.cpp:226] fc4_4_prescale needs backward computation.
I0408 21:12:00.420037  9048 net.cpp:226] fc4_4_300 needs backward computation.
I0408 21:12:00.420040  9048 net.cpp:226] pool4_2 needs backward computation.
I0408 21:12:00.420044  9048 net.cpp:226] conv4_2_postscale needs backward computation.
I0408 21:12:00.420058  9048 net.cpp:226] conv4_2_sTanH needs backward computation.
I0408 21:12:00.420061  9048 net.cpp:226] conv4_2_prescale needs backward computation.
I0408 21:12:00.420064  9048 net.cpp:226] conv4_2 needs backward computation.
I0408 21:12:00.420068  9048 net.cpp:226] pool4_1 needs backward computation.
I0408 21:12:00.420071  9048 net.cpp:226] conv4_1_postscale needs backward computation.
I0408 21:12:00.420074  9048 net.cpp:226] conv4_1_sTanH needs backward computation.
I0408 21:12:00.420078  9048 net.cpp:226] conv4_1_prescale needs backward computation.
I0408 21:12:00.420079  9048 net.cpp:226] conv4_1 needs backward computation.
I0408 21:12:00.420083  9048 net.cpp:226] pool4_0 needs backward computation.
I0408 21:12:00.420086  9048 net.cpp:226] conv4_0_postscale needs backward computation.
I0408 21:12:00.420089  9048 net.cpp:226] conv4_0_sTanH needs backward computation.
I0408 21:12:00.420092  9048 net.cpp:226] conv4_0_prescale needs backward computation.
I0408 21:12:00.420095  9048 net.cpp:226] conv4_0 needs backward computation.
I0408 21:12:00.420099  9048 net.cpp:228] data_4 does not need backward computation.
I0408 21:12:00.420102  9048 net.cpp:226] softmax_3 needs backward computation.
I0408 21:12:00.420105  9048 net.cpp:226] fc3_5_67 needs backward computation.
I0408 21:12:00.420109  9048 net.cpp:226] drop3_4 needs backward computation.
I0408 21:12:00.420112  9048 net.cpp:226] fc3_4_postscale needs backward computation.
I0408 21:12:00.420115  9048 net.cpp:226] fc3_4_sTanH needs backward computation.
I0408 21:12:00.420119  9048 net.cpp:226] fc3_4_prescale needs backward computation.
I0408 21:12:00.420121  9048 net.cpp:226] fc3_4_300 needs backward computation.
I0408 21:12:00.420125  9048 net.cpp:226] pool3_2 needs backward computation.
I0408 21:12:00.420128  9048 net.cpp:226] conv3_2_postscale needs backward computation.
I0408 21:12:00.420131  9048 net.cpp:226] conv3_2_sTanH needs backward computation.
I0408 21:12:00.420135  9048 net.cpp:226] conv3_2_prescale needs backward computation.
I0408 21:12:00.420137  9048 net.cpp:226] conv3_2 needs backward computation.
I0408 21:12:00.420141  9048 net.cpp:226] pool3_1 needs backward computation.
I0408 21:12:00.420145  9048 net.cpp:226] conv3_1_postscale needs backward computation.
I0408 21:12:00.420148  9048 net.cpp:226] conv3_1_sTanH needs backward computation.
I0408 21:12:00.420151  9048 net.cpp:226] conv3_1_prescale needs backward computation.
I0408 21:12:00.420155  9048 net.cpp:226] conv3_1 needs backward computation.
I0408 21:12:00.420157  9048 net.cpp:226] pool3_0 needs backward computation.
I0408 21:12:00.420161  9048 net.cpp:226] conv3_0_postscale needs backward computation.
I0408 21:12:00.420164  9048 net.cpp:226] conv3_0_sTanH needs backward computation.
I0408 21:12:00.420167  9048 net.cpp:226] conv3_0_prescale needs backward computation.
I0408 21:12:00.420171  9048 net.cpp:226] conv3_0 needs backward computation.
I0408 21:12:00.420174  9048 net.cpp:228] data_3 does not need backward computation.
I0408 21:12:00.420177  9048 net.cpp:226] softmax_2 needs backward computation.
I0408 21:12:00.420181  9048 net.cpp:226] fc2_5_67 needs backward computation.
I0408 21:12:00.420184  9048 net.cpp:226] drop2_4 needs backward computation.
I0408 21:12:00.420187  9048 net.cpp:226] fc2_4_postscale needs backward computation.
I0408 21:12:00.420192  9048 net.cpp:226] fc2_4_sTanH needs backward computation.
I0408 21:12:00.420194  9048 net.cpp:226] fc2_4_prescale needs backward computation.
I0408 21:12:00.420197  9048 net.cpp:226] fc2_4_300 needs backward computation.
I0408 21:12:00.420200  9048 net.cpp:226] pool2_2 needs backward computation.
I0408 21:12:00.420203  9048 net.cpp:226] conv2_2_postscale needs backward computation.
I0408 21:12:00.420207  9048 net.cpp:226] conv2_2_sTanH needs backward computation.
I0408 21:12:00.420210  9048 net.cpp:226] conv2_2_prescale needs backward computation.
I0408 21:12:00.420213  9048 net.cpp:226] conv2_2 needs backward computation.
I0408 21:12:00.420217  9048 net.cpp:226] pool2_1 needs backward computation.
I0408 21:12:00.420227  9048 net.cpp:226] conv2_1_postscale needs backward computation.
I0408 21:12:00.420229  9048 net.cpp:226] conv2_1_sTanH needs backward computation.
I0408 21:12:00.420233  9048 net.cpp:226] conv2_1_prescale needs backward computation.
I0408 21:12:00.420235  9048 net.cpp:226] conv2_1 needs backward computation.
I0408 21:12:00.420239  9048 net.cpp:226] pool2_0 needs backward computation.
I0408 21:12:00.420243  9048 net.cpp:226] conv2_0_postscale needs backward computation.
I0408 21:12:00.420245  9048 net.cpp:226] conv2_0_sTanH needs backward computation.
I0408 21:12:00.420249  9048 net.cpp:226] conv2_0_prescale needs backward computation.
I0408 21:12:00.420253  9048 net.cpp:226] conv2_0 needs backward computation.
I0408 21:12:00.420256  9048 net.cpp:228] data_2 does not need backward computation.
I0408 21:12:00.420259  9048 net.cpp:226] softmax_1 needs backward computation.
I0408 21:12:00.420262  9048 net.cpp:226] fc1_5_67 needs backward computation.
I0408 21:12:00.420265  9048 net.cpp:226] drop1_4 needs backward computation.
I0408 21:12:00.420269  9048 net.cpp:226] fc1_4_postscale needs backward computation.
I0408 21:12:00.420272  9048 net.cpp:226] fc1_4_sTanH needs backward computation.
I0408 21:12:00.420275  9048 net.cpp:226] fc1_4_prescale needs backward computation.
I0408 21:12:00.420279  9048 net.cpp:226] fc1_4_300 needs backward computation.
I0408 21:12:00.420281  9048 net.cpp:226] pool1_2 needs backward computation.
I0408 21:12:00.420284  9048 net.cpp:226] conv1_2_postscale needs backward computation.
I0408 21:12:00.420287  9048 net.cpp:226] conv1_2_sTanH needs backward computation.
I0408 21:12:00.420290  9048 net.cpp:226] conv1_2_prescale needs backward computation.
I0408 21:12:00.420294  9048 net.cpp:226] conv1_2 needs backward computation.
I0408 21:12:00.420297  9048 net.cpp:226] pool1_1 needs backward computation.
I0408 21:12:00.420300  9048 net.cpp:226] conv1_1_postscale needs backward computation.
I0408 21:12:00.420303  9048 net.cpp:226] conv1_1_sTanH needs backward computation.
I0408 21:12:00.420306  9048 net.cpp:226] conv1_1_prescale needs backward computation.
I0408 21:12:00.420310  9048 net.cpp:226] conv1_1 needs backward computation.
I0408 21:12:00.420312  9048 net.cpp:226] pool1_0 needs backward computation.
I0408 21:12:00.420316  9048 net.cpp:226] conv1_0_postscale needs backward computation.
I0408 21:12:00.420320  9048 net.cpp:226] conv1_0_sTanH needs backward computation.
I0408 21:12:00.420322  9048 net.cpp:226] conv1_0_prescale needs backward computation.
I0408 21:12:00.420325  9048 net.cpp:226] conv1_0 needs backward computation.
I0408 21:12:00.420330  9048 net.cpp:228] data_1 does not need backward computation.
I0408 21:12:00.420332  9048 net.cpp:226] softmax_0 needs backward computation.
I0408 21:12:00.420336  9048 net.cpp:226] fc0_5_67 needs backward computation.
I0408 21:12:00.420339  9048 net.cpp:226] drop0_4 needs backward computation.
I0408 21:12:00.420342  9048 net.cpp:226] fc0_4_postscale needs backward computation.
I0408 21:12:00.420346  9048 net.cpp:226] fc0_4_sTanH needs backward computation.
I0408 21:12:00.420348  9048 net.cpp:226] fc0_4_prescale needs backward computation.
I0408 21:12:00.420351  9048 net.cpp:226] fc0_4_300 needs backward computation.
I0408 21:12:00.420356  9048 net.cpp:226] pool0_2 needs backward computation.
I0408 21:12:00.420361  9048 net.cpp:226] conv0_2_postscale needs backward computation.
I0408 21:12:00.420363  9048 net.cpp:226] conv0_2_sTanH needs backward computation.
I0408 21:12:00.420367  9048 net.cpp:226] conv0_2_prescale needs backward computation.
I0408 21:12:00.420369  9048 net.cpp:226] conv0_2 needs backward computation.
I0408 21:12:00.420373  9048 net.cpp:226] pool0_1 needs backward computation.
I0408 21:12:00.420377  9048 net.cpp:226] conv0_1_postscale needs backward computation.
I0408 21:12:00.420379  9048 net.cpp:226] conv0_1_sTanH needs backward computation.
I0408 21:12:00.420382  9048 net.cpp:226] conv0_1_prescale needs backward computation.
I0408 21:12:00.420387  9048 net.cpp:226] conv0_1 needs backward computation.
I0408 21:12:00.420395  9048 net.cpp:226] pool0_0 needs backward computation.
I0408 21:12:00.420399  9048 net.cpp:226] conv0_0_postscale needs backward computation.
I0408 21:12:00.420403  9048 net.cpp:226] conv0_0_sTanH needs backward computation.
I0408 21:12:00.420405  9048 net.cpp:226] conv0_0_prescale needs backward computation.
I0408 21:12:00.420408  9048 net.cpp:226] conv0_0 needs backward computation.
I0408 21:12:00.420413  9048 net.cpp:228] label_0_data_0_1_split does not need backward computation.
I0408 21:12:00.420418  9048 net.cpp:228] data_0 does not need backward computation.
I0408 21:12:00.420420  9048 net.cpp:270] This network produces output accuracy_1
I0408 21:12:00.420424  9048 net.cpp:270] This network produces output accuracy_5
I0408 21:12:00.420428  9048 net.cpp:270] This network produces output loss
I0408 21:12:00.420487  9048 net.cpp:283] Network initialization done.
I0408 21:12:00.420750  9048 solver.cpp:72] Solver scaffolding done.
I0408 21:12:00.426537  9048 caffe.cpp:251] Starting Optimization
I0408 21:12:00.426548  9048 solver.cpp:291] Solving 
I0408 21:12:00.426550  9048 solver.cpp:292] Learning Rate Policy: step
I0408 21:12:00.453291  9048 solver.cpp:349] Iteration 0, Testing net (#0)
I0408 21:12:48.537693  9048 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0116005
I0408 21:12:48.537781  9048 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0646826
I0408 21:12:48.537793  9048 solver.cpp:416]     Test net output #2: loss = 4.33912 (* 1 = 4.33912 loss)
I0408 21:12:48.730597  9048 solver.cpp:240] Iteration 0, loss = 4.51563
I0408 21:12:48.730633  9048 solver.cpp:256]     Train net output #0: loss = 4.51563 (* 1 = 4.51563 loss)
I0408 21:12:48.730649  9048 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0408 21:12:48.966967  9048 solver.cpp:240] Iteration 1, loss = 4.79197
I0408 21:12:48.967000  9048 solver.cpp:256]     Train net output #0: loss = 4.79197 (* 1 = 4.79197 loss)
I0408 21:12:48.967008  9048 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I0408 21:12:49.244217  9048 solver.cpp:240] Iteration 2, loss = 5.69113
I0408 21:12:49.244256  9048 solver.cpp:256]     Train net output #0: loss = 5.69113 (* 1 = 5.69113 loss)
I0408 21:12:49.244266  9048 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I0408 21:12:49.520699  9048 solver.cpp:240] Iteration 3, loss = 7.3677
I0408 21:12:49.520741  9048 solver.cpp:256]     Train net output #0: loss = 7.3677 (* 1 = 7.3677 loss)
I0408 21:12:49.520750  9048 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I0408 21:12:49.796983  9048 solver.cpp:240] Iteration 4, loss = 5.42653
I0408 21:12:49.797019  9048 solver.cpp:256]     Train net output #0: loss = 5.42653 (* 1 = 5.42653 loss)
I0408 21:12:49.797027  9048 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I0408 21:12:50.073369  9048 solver.cpp:240] Iteration 5, loss = 5.11935
I0408 21:12:50.073401  9048 solver.cpp:256]     Train net output #0: loss = 5.11935 (* 1 = 5.11935 loss)
I0408 21:12:50.073408  9048 sgd_solver.cpp:106] Iteration 5, lr = 0.01
I0408 21:12:50.350039  9048 solver.cpp:240] Iteration 6, loss = 3.97502
I0408 21:12:50.350072  9048 solver.cpp:256]     Train net output #0: loss = 3.97502 (* 1 = 3.97502 loss)
I0408 21:12:50.350080  9048 sgd_solver.cpp:106] Iteration 6, lr = 0.01
I0408 21:12:50.627025  9048 solver.cpp:240] Iteration 7, loss = 5.79124
I0408 21:12:50.627060  9048 solver.cpp:256]     Train net output #0: loss = 5.79124 (* 1 = 5.79124 loss)
I0408 21:12:50.627068  9048 sgd_solver.cpp:106] Iteration 7, lr = 0.01
I0408 21:12:50.903259  9048 solver.cpp:240] Iteration 8, loss = 9.28106
I0408 21:12:50.903292  9048 solver.cpp:256]     Train net output #0: loss = 9.28106 (* 1 = 9.28106 loss)
I0408 21:12:50.903301  9048 sgd_solver.cpp:106] Iteration 8, lr = 0.01
I0408 21:12:51.180624  9048 solver.cpp:240] Iteration 9, loss = 5.63728
I0408 21:12:51.180661  9048 solver.cpp:256]     Train net output #0: loss = 5.63728 (* 1 = 5.63728 loss)
I0408 21:12:51.180670  9048 sgd_solver.cpp:106] Iteration 9, lr = 0.01
I0408 21:12:51.457123  9048 solver.cpp:240] Iteration 10, loss = 5.68356
I0408 21:12:51.457166  9048 solver.cpp:256]     Train net output #0: loss = 5.68356 (* 1 = 5.68356 loss)
I0408 21:12:51.457175  9048 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I0408 21:12:51.733237  9048 solver.cpp:240] Iteration 11, loss = 5.20852
I0408 21:12:51.733283  9048 solver.cpp:256]     Train net output #0: loss = 5.20852 (* 1 = 5.20852 loss)
I0408 21:12:51.733290  9048 sgd_solver.cpp:106] Iteration 11, lr = 0.01
I0408 21:12:52.010027  9048 solver.cpp:240] Iteration 12, loss = 4.55006
I0408 21:12:52.010059  9048 solver.cpp:256]     Train net output #0: loss = 4.55006 (* 1 = 4.55006 loss)
I0408 21:12:52.010067  9048 sgd_solver.cpp:106] Iteration 12, lr = 0.01
I0408 21:12:52.286386  9048 solver.cpp:240] Iteration 13, loss = 5.72441
I0408 21:12:52.286415  9048 solver.cpp:256]     Train net output #0: loss = 5.72441 (* 1 = 5.72441 loss)
I0408 21:12:52.286423  9048 sgd_solver.cpp:106] Iteration 13, lr = 0.01
I0408 21:12:52.563379  9048 solver.cpp:240] Iteration 14, loss = 4.14754
I0408 21:12:52.563411  9048 solver.cpp:256]     Train net output #0: loss = 4.14754 (* 1 = 4.14754 loss)
I0408 21:12:52.563419  9048 sgd_solver.cpp:106] Iteration 14, lr = 0.01
I0408 21:12:52.839931  9048 solver.cpp:240] Iteration 15, loss = 4.96266
I0408 21:12:52.839962  9048 solver.cpp:256]     Train net output #0: loss = 4.96266 (* 1 = 4.96266 loss)
I0408 21:12:52.839994  9048 sgd_solver.cpp:106] Iteration 15, lr = 0.01
I0408 21:12:53.116261  9048 solver.cpp:240] Iteration 16, loss = 4.58292
I0408 21:12:53.116297  9048 solver.cpp:256]     Train net output #0: loss = 4.58292 (* 1 = 4.58292 loss)
I0408 21:12:53.116304  9048 sgd_solver.cpp:106] Iteration 16, lr = 0.01
I0408 21:12:53.393529  9048 solver.cpp:240] Iteration 17, loss = 4.58193
I0408 21:12:53.393561  9048 solver.cpp:256]     Train net output #0: loss = 4.58193 (* 1 = 4.58193 loss)
I0408 21:12:53.393569  9048 sgd_solver.cpp:106] Iteration 17, lr = 0.01
I0408 21:12:53.670198  9048 solver.cpp:240] Iteration 18, loss = 6.85576
I0408 21:12:53.670233  9048 solver.cpp:256]     Train net output #0: loss = 6.85576 (* 1 = 6.85576 loss)
I0408 21:12:53.670241  9048 sgd_solver.cpp:106] Iteration 18, lr = 0.01
I0408 21:12:53.946221  9048 solver.cpp:240] Iteration 19, loss = 4.76719
I0408 21:12:53.946264  9048 solver.cpp:256]     Train net output #0: loss = 4.76719 (* 1 = 4.76719 loss)
I0408 21:12:53.946271  9048 sgd_solver.cpp:106] Iteration 19, lr = 0.01
I0408 21:12:54.222285  9048 solver.cpp:240] Iteration 20, loss = 2.90905
I0408 21:12:54.222316  9048 solver.cpp:256]     Train net output #0: loss = 2.90905 (* 1 = 2.90905 loss)
I0408 21:12:54.222323  9048 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0408 21:12:54.499358  9048 solver.cpp:240] Iteration 21, loss = 2.68462
I0408 21:12:54.499389  9048 solver.cpp:256]     Train net output #0: loss = 2.68462 (* 1 = 2.68462 loss)
I0408 21:12:54.499397  9048 sgd_solver.cpp:106] Iteration 21, lr = 0.01
I0408 21:12:54.775349  9048 solver.cpp:240] Iteration 22, loss = 5.26845
I0408 21:12:54.775380  9048 solver.cpp:256]     Train net output #0: loss = 5.26845 (* 1 = 5.26845 loss)
I0408 21:12:54.775388  9048 sgd_solver.cpp:106] Iteration 22, lr = 0.01
I0408 21:12:55.052278  9048 solver.cpp:240] Iteration 23, loss = 7.34288
I0408 21:12:55.052309  9048 solver.cpp:256]     Train net output #0: loss = 7.34288 (* 1 = 7.34288 loss)
I0408 21:12:55.052316  9048 sgd_solver.cpp:106] Iteration 23, lr = 0.01
I0408 21:12:55.329238  9048 solver.cpp:240] Iteration 24, loss = 4.45401
I0408 21:12:55.329268  9048 solver.cpp:256]     Train net output #0: loss = 4.45401 (* 1 = 4.45401 loss)
I0408 21:12:55.329277  9048 sgd_solver.cpp:106] Iteration 24, lr = 0.01
I0408 21:12:55.605553  9048 solver.cpp:240] Iteration 25, loss = 6.76978
I0408 21:12:55.605599  9048 solver.cpp:256]     Train net output #0: loss = 6.76978 (* 1 = 6.76978 loss)
I0408 21:12:55.605607  9048 sgd_solver.cpp:106] Iteration 25, lr = 0.01
I0408 21:12:55.882292  9048 solver.cpp:240] Iteration 26, loss = 4.71454
I0408 21:12:55.882323  9048 solver.cpp:256]     Train net output #0: loss = 4.71454 (* 1 = 4.71454 loss)
I0408 21:12:55.882331  9048 sgd_solver.cpp:106] Iteration 26, lr = 0.01
I0408 21:12:56.158319  9048 solver.cpp:240] Iteration 27, loss = 5.61984
I0408 21:12:56.158350  9048 solver.cpp:256]     Train net output #0: loss = 5.61984 (* 1 = 5.61984 loss)
I0408 21:12:56.158359  9048 sgd_solver.cpp:106] Iteration 27, lr = 0.01
I0408 21:12:56.434522  9048 solver.cpp:240] Iteration 28, loss = 3.46155
I0408 21:12:56.434554  9048 solver.cpp:256]     Train net output #0: loss = 3.46155 (* 1 = 3.46155 loss)
I0408 21:12:56.434562  9048 sgd_solver.cpp:106] Iteration 28, lr = 0.01
I0408 21:12:56.711354  9048 solver.cpp:240] Iteration 29, loss = 7.07469
I0408 21:12:56.711385  9048 solver.cpp:256]     Train net output #0: loss = 7.07469 (* 1 = 7.07469 loss)
I0408 21:12:56.711392  9048 sgd_solver.cpp:106] Iteration 29, lr = 0.01
I0408 21:12:56.988454  9048 solver.cpp:240] Iteration 30, loss = 6.17636
I0408 21:12:56.988486  9048 solver.cpp:256]     Train net output #0: loss = 6.17636 (* 1 = 6.17636 loss)
I0408 21:12:56.988492  9048 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I0408 21:12:57.265897  9048 solver.cpp:240] Iteration 31, loss = 7.02412
I0408 21:12:57.265933  9048 solver.cpp:256]     Train net output #0: loss = 7.02412 (* 1 = 7.02412 loss)
I0408 21:12:57.265941  9048 sgd_solver.cpp:106] Iteration 31, lr = 0.01
I0408 21:12:57.542083  9048 solver.cpp:240] Iteration 32, loss = 9.27415
I0408 21:12:57.542147  9048 solver.cpp:256]     Train net output #0: loss = 9.27415 (* 1 = 9.27415 loss)
I0408 21:12:57.542157  9048 sgd_solver.cpp:106] Iteration 32, lr = 0.01
I0408 21:12:57.818222  9048 solver.cpp:240] Iteration 33, loss = 5.93826
I0408 21:12:57.818265  9048 solver.cpp:256]     Train net output #0: loss = 5.93826 (* 1 = 5.93826 loss)
I0408 21:12:57.818272  9048 sgd_solver.cpp:106] Iteration 33, lr = 0.01
I0408 21:12:58.094347  9048 solver.cpp:240] Iteration 34, loss = 4.22956
I0408 21:12:58.094383  9048 solver.cpp:256]     Train net output #0: loss = 4.22956 (* 1 = 4.22956 loss)
I0408 21:12:58.094391  9048 sgd_solver.cpp:106] Iteration 34, lr = 0.01
I0408 21:12:58.371125  9048 solver.cpp:240] Iteration 35, loss = 7.268
I0408 21:12:58.371155  9048 solver.cpp:256]     Train net output #0: loss = 7.268 (* 1 = 7.268 loss)
I0408 21:12:58.371165  9048 sgd_solver.cpp:106] Iteration 35, lr = 0.01
I0408 21:12:58.648017  9048 solver.cpp:240] Iteration 36, loss = 4.82242
I0408 21:12:58.648049  9048 solver.cpp:256]     Train net output #0: loss = 4.82242 (* 1 = 4.82242 loss)
I0408 21:12:58.648057  9048 sgd_solver.cpp:106] Iteration 36, lr = 0.01
I0408 21:12:58.924743  9048 solver.cpp:240] Iteration 37, loss = 4.96788
I0408 21:12:58.924774  9048 solver.cpp:256]     Train net output #0: loss = 4.96788 (* 1 = 4.96788 loss)
I0408 21:12:58.924782  9048 sgd_solver.cpp:106] Iteration 37, lr = 0.01
I0408 21:12:59.201337  9048 solver.cpp:240] Iteration 38, loss = 6.80062
I0408 21:12:59.201367  9048 solver.cpp:256]     Train net output #0: loss = 6.80062 (* 1 = 6.80062 loss)
I0408 21:12:59.201375  9048 sgd_solver.cpp:106] Iteration 38, lr = 0.01
I0408 21:12:59.478884  9048 solver.cpp:240] Iteration 39, loss = 6.35784
I0408 21:12:59.478915  9048 solver.cpp:256]     Train net output #0: loss = 6.35784 (* 1 = 6.35784 loss)
I0408 21:12:59.478922  9048 sgd_solver.cpp:106] Iteration 39, lr = 0.01
I0408 21:12:59.755635  9048 solver.cpp:240] Iteration 40, loss = 8.18979
I0408 21:12:59.755666  9048 solver.cpp:256]     Train net output #0: loss = 8.18979 (* 1 = 8.18979 loss)
I0408 21:12:59.755674  9048 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0408 21:13:00.032497  9048 solver.cpp:240] Iteration 41, loss = 5.52057
I0408 21:13:00.032527  9048 solver.cpp:256]     Train net output #0: loss = 5.52057 (* 1 = 5.52057 loss)
I0408 21:13:00.032536  9048 sgd_solver.cpp:106] Iteration 41, lr = 0.01
I0408 21:13:00.309270  9048 solver.cpp:240] Iteration 42, loss = 6.39806
I0408 21:13:00.309303  9048 solver.cpp:256]     Train net output #0: loss = 6.39806 (* 1 = 6.39806 loss)
I0408 21:13:00.309309  9048 sgd_solver.cpp:106] Iteration 42, lr = 0.01
I0408 21:13:00.585984  9048 solver.cpp:240] Iteration 43, loss = 7.47166
I0408 21:13:00.586016  9048 solver.cpp:256]     Train net output #0: loss = 7.47166 (* 1 = 7.47166 loss)
I0408 21:13:00.586024  9048 sgd_solver.cpp:106] Iteration 43, lr = 0.01
I0408 21:13:00.863214  9048 solver.cpp:240] Iteration 44, loss = 11.1304
I0408 21:13:00.863247  9048 solver.cpp:256]     Train net output #0: loss = 11.1304 (* 1 = 11.1304 loss)
I0408 21:13:00.863255  9048 sgd_solver.cpp:106] Iteration 44, lr = 0.01
I0408 21:13:01.140985  9048 solver.cpp:240] Iteration 45, loss = 9.50937
I0408 21:13:01.141029  9048 solver.cpp:256]     Train net output #0: loss = 9.50937 (* 1 = 9.50937 loss)
I0408 21:13:01.141037  9048 sgd_solver.cpp:106] Iteration 45, lr = 0.01
I0408 21:13:01.417639  9048 solver.cpp:240] Iteration 46, loss = 12.5679
I0408 21:13:01.417680  9048 solver.cpp:256]     Train net output #0: loss = 12.5679 (* 1 = 12.5679 loss)
I0408 21:13:01.417690  9048 sgd_solver.cpp:106] Iteration 46, lr = 0.01
I0408 21:13:01.694032  9048 solver.cpp:240] Iteration 47, loss = 6.32636
I0408 21:13:01.694075  9048 solver.cpp:256]     Train net output #0: loss = 6.32636 (* 1 = 6.32636 loss)
I0408 21:13:01.694083  9048 sgd_solver.cpp:106] Iteration 47, lr = 0.01
I0408 21:13:01.970903  9048 solver.cpp:240] Iteration 48, loss = 8.38966
I0408 21:13:01.970948  9048 solver.cpp:256]     Train net output #0: loss = 8.38966 (* 1 = 8.38966 loss)
I0408 21:13:01.970980  9048 sgd_solver.cpp:106] Iteration 48, lr = 0.01
I0408 21:13:02.247648  9048 solver.cpp:240] Iteration 49, loss = 8.8891
I0408 21:13:02.247702  9048 solver.cpp:256]     Train net output #0: loss = 8.8891 (* 1 = 8.8891 loss)
I0408 21:13:02.247710  9048 sgd_solver.cpp:106] Iteration 49, lr = 0.01
I0408 21:13:02.525101  9048 solver.cpp:240] Iteration 50, loss = 7.91937
I0408 21:13:02.525132  9048 solver.cpp:256]     Train net output #0: loss = 7.91937 (* 1 = 7.91937 loss)
I0408 21:13:02.525141  9048 sgd_solver.cpp:106] Iteration 50, lr = 0.01
I0408 21:13:02.801954  9048 solver.cpp:240] Iteration 51, loss = 9.45398
I0408 21:13:02.801986  9048 solver.cpp:256]     Train net output #0: loss = 9.45398 (* 1 = 9.45398 loss)
I0408 21:13:02.801995  9048 sgd_solver.cpp:106] Iteration 51, lr = 0.01
I0408 21:13:03.079227  9048 solver.cpp:240] Iteration 52, loss = 5.25461
I0408 21:13:03.079258  9048 solver.cpp:256]     Train net output #0: loss = 5.25461 (* 1 = 5.25461 loss)
I0408 21:13:03.079267  9048 sgd_solver.cpp:106] Iteration 52, lr = 0.01
I0408 21:13:03.358162  9048 solver.cpp:240] Iteration 53, loss = 5.5864
I0408 21:13:03.358192  9048 solver.cpp:256]     Train net output #0: loss = 5.5864 (* 1 = 5.5864 loss)
I0408 21:13:03.358201  9048 sgd_solver.cpp:106] Iteration 53, lr = 0.01
I0408 21:13:03.634701  9048 solver.cpp:240] Iteration 54, loss = 11.0443
I0408 21:13:03.634733  9048 solver.cpp:256]     Train net output #0: loss = 11.0443 (* 1 = 11.0443 loss)
I0408 21:13:03.634742  9048 sgd_solver.cpp:106] Iteration 54, lr = 0.01
I0408 21:13:03.911239  9048 solver.cpp:240] Iteration 55, loss = 11.5042
I0408 21:13:03.911285  9048 solver.cpp:256]     Train net output #0: loss = 11.5042 (* 1 = 11.5042 loss)
I0408 21:13:03.911293  9048 sgd_solver.cpp:106] Iteration 55, lr = 0.01
I0408 21:13:04.188261  9048 solver.cpp:240] Iteration 56, loss = 12.3408
I0408 21:13:04.188292  9048 solver.cpp:256]     Train net output #0: loss = 12.3408 (* 1 = 12.3408 loss)
I0408 21:13:04.188300  9048 sgd_solver.cpp:106] Iteration 56, lr = 0.01
I0408 21:13:04.464725  9048 solver.cpp:240] Iteration 57, loss = 8.32504
I0408 21:13:04.464756  9048 solver.cpp:256]     Train net output #0: loss = 8.32504 (* 1 = 8.32504 loss)
I0408 21:13:04.464763  9048 sgd_solver.cpp:106] Iteration 57, lr = 0.01
I0408 21:13:04.741276  9048 solver.cpp:240] Iteration 58, loss = 4.77111
I0408 21:13:04.741312  9048 solver.cpp:256]     Train net output #0: loss = 4.77111 (* 1 = 4.77111 loss)
I0408 21:13:04.741322  9048 sgd_solver.cpp:106] Iteration 58, lr = 0.01
I0408 21:13:05.017833  9048 solver.cpp:240] Iteration 59, loss = 7.52573
I0408 21:13:05.017865  9048 solver.cpp:256]     Train net output #0: loss = 7.52573 (* 1 = 7.52573 loss)
I0408 21:13:05.017874  9048 sgd_solver.cpp:106] Iteration 59, lr = 0.01
I0408 21:13:05.292953  9048 solver.cpp:240] Iteration 60, loss = 5.16577
I0408 21:13:05.292991  9048 solver.cpp:256]     Train net output #0: loss = 5.16577 (* 1 = 5.16577 loss)
I0408 21:13:05.293004  9048 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0408 21:13:05.569602  9048 solver.cpp:240] Iteration 61, loss = 7.71883
I0408 21:13:05.569645  9048 solver.cpp:256]     Train net output #0: loss = 7.71883 (* 1 = 7.71883 loss)
I0408 21:13:05.569658  9048 sgd_solver.cpp:106] Iteration 61, lr = 0.01
I0408 21:13:05.846345  9048 solver.cpp:240] Iteration 62, loss = 7.95308
I0408 21:13:05.846384  9048 solver.cpp:256]     Train net output #0: loss = 7.95308 (* 1 = 7.95308 loss)
I0408 21:13:05.846395  9048 sgd_solver.cpp:106] Iteration 62, lr = 0.01
I0408 21:13:06.123157  9048 solver.cpp:240] Iteration 63, loss = 6.77769
I0408 21:13:06.123191  9048 solver.cpp:256]     Train net output #0: loss = 6.77769 (* 1 = 6.77769 loss)
I0408 21:13:06.123203  9048 sgd_solver.cpp:106] Iteration 63, lr = 0.01
I0408 21:13:06.400004  9048 solver.cpp:240] Iteration 64, loss = 10.486
I0408 21:13:06.400040  9048 solver.cpp:256]     Train net output #0: loss = 10.486 (* 1 = 10.486 loss)
I0408 21:13:06.400053  9048 sgd_solver.cpp:106] Iteration 64, lr = 0.01
I0408 21:13:06.676720  9048 solver.cpp:240] Iteration 65, loss = 10.0768
I0408 21:13:06.676755  9048 solver.cpp:256]     Train net output #0: loss = 10.0768 (* 1 = 10.0768 loss)
I0408 21:13:06.676767  9048 sgd_solver.cpp:106] Iteration 65, lr = 0.01
I0408 21:13:06.953192  9048 solver.cpp:240] Iteration 66, loss = 9.09171
I0408 21:13:06.953228  9048 solver.cpp:256]     Train net output #0: loss = 9.09171 (* 1 = 9.09171 loss)
I0408 21:13:06.953239  9048 sgd_solver.cpp:106] Iteration 66, lr = 0.01
I0408 21:13:07.229537  9048 solver.cpp:240] Iteration 67, loss = 5.66799
I0408 21:13:07.229575  9048 solver.cpp:256]     Train net output #0: loss = 5.66799 (* 1 = 5.66799 loss)
I0408 21:13:07.229588  9048 sgd_solver.cpp:106] Iteration 67, lr = 0.01
I0408 21:13:07.506285  9048 solver.cpp:240] Iteration 68, loss = 5.73421
I0408 21:13:07.506317  9048 solver.cpp:256]     Train net output #0: loss = 5.73421 (* 1 = 5.73421 loss)
I0408 21:13:07.506327  9048 sgd_solver.cpp:106] Iteration 68, lr = 0.01
I0408 21:13:07.782956  9048 solver.cpp:240] Iteration 69, loss = 5.45179
I0408 21:13:07.782990  9048 solver.cpp:256]     Train net output #0: loss = 5.45179 (* 1 = 5.45179 loss)
I0408 21:13:07.783015  9048 sgd_solver.cpp:106] Iteration 69, lr = 0.01
I0408 21:13:08.059908  9048 solver.cpp:240] Iteration 70, loss = 3.02705
I0408 21:13:08.059942  9048 solver.cpp:256]     Train net output #0: loss = 3.02705 (* 1 = 3.02705 loss)
I0408 21:13:08.059952  9048 sgd_solver.cpp:106] Iteration 70, lr = 0.01
I0408 21:13:08.336491  9048 solver.cpp:240] Iteration 71, loss = 4.10436
I0408 21:13:08.336524  9048 solver.cpp:256]     Train net output #0: loss = 4.10436 (* 1 = 4.10436 loss)
I0408 21:13:08.336546  9048 sgd_solver.cpp:106] Iteration 71, lr = 0.01
I0408 21:13:08.612241  9048 solver.cpp:240] Iteration 72, loss = 2.97234
I0408 21:13:08.612275  9048 solver.cpp:256]     Train net output #0: loss = 2.97234 (* 1 = 2.97234 loss)
I0408 21:13:08.612287  9048 sgd_solver.cpp:106] Iteration 72, lr = 0.01
I0408 21:13:08.888368  9048 solver.cpp:240] Iteration 73, loss = 1.53692
I0408 21:13:08.888404  9048 solver.cpp:256]     Train net output #0: loss = 1.53692 (* 1 = 1.53692 loss)
I0408 21:13:08.888415  9048 sgd_solver.cpp:106] Iteration 73, lr = 0.01
I0408 21:13:09.165174  9048 solver.cpp:240] Iteration 74, loss = 6.23075
I0408 21:13:09.165210  9048 solver.cpp:256]     Train net output #0: loss = 6.23076 (* 1 = 6.23076 loss)
I0408 21:13:09.165231  9048 sgd_solver.cpp:106] Iteration 74, lr = 0.01
I0408 21:13:09.441862  9048 solver.cpp:240] Iteration 75, loss = 5.429
I0408 21:13:09.441897  9048 solver.cpp:256]     Train net output #0: loss = 5.429 (* 1 = 5.429 loss)
I0408 21:13:09.441908  9048 sgd_solver.cpp:106] Iteration 75, lr = 0.01
I0408 21:13:09.717828  9048 solver.cpp:240] Iteration 76, loss = 10.3907
I0408 21:13:09.717864  9048 solver.cpp:256]     Train net output #0: loss = 10.3907 (* 1 = 10.3907 loss)
I0408 21:13:09.717877  9048 sgd_solver.cpp:106] Iteration 76, lr = 0.01
I0408 21:13:09.994094  9048 solver.cpp:240] Iteration 77, loss = 12.0162
I0408 21:13:09.994130  9048 solver.cpp:256]     Train net output #0: loss = 12.0162 (* 1 = 12.0162 loss)
I0408 21:13:09.994143  9048 sgd_solver.cpp:106] Iteration 77, lr = 0.01
I0408 21:13:10.270674  9048 solver.cpp:240] Iteration 78, loss = 8.47215
I0408 21:13:10.270710  9048 solver.cpp:256]     Train net output #0: loss = 8.47215 (* 1 = 8.47215 loss)
I0408 21:13:10.270721  9048 sgd_solver.cpp:106] Iteration 78, lr = 0.01
I0408 21:13:10.547140  9048 solver.cpp:240] Iteration 79, loss = 7.60071
I0408 21:13:10.547181  9048 solver.cpp:256]     Train net output #0: loss = 7.60071 (* 1 = 7.60071 loss)
I0408 21:13:10.547194  9048 sgd_solver.cpp:106] Iteration 79, lr = 0.01
I0408 21:13:10.823745  9048 solver.cpp:240] Iteration 80, loss = 5.57907
I0408 21:13:10.823781  9048 solver.cpp:256]     Train net output #0: loss = 5.57907 (* 1 = 5.57907 loss)
I0408 21:13:10.823793  9048 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0408 21:13:11.100412  9048 solver.cpp:240] Iteration 81, loss = 6.71477
I0408 21:13:11.100450  9048 solver.cpp:256]     Train net output #0: loss = 6.71477 (* 1 = 6.71477 loss)
I0408 21:13:11.100493  9048 sgd_solver.cpp:106] Iteration 81, lr = 0.01
I0408 21:13:11.376982  9048 solver.cpp:240] Iteration 82, loss = 14.4138
I0408 21:13:11.377018  9048 solver.cpp:256]     Train net output #0: loss = 14.4138 (* 1 = 14.4138 loss)
I0408 21:13:11.377043  9048 sgd_solver.cpp:106] Iteration 82, lr = 0.01
I0408 21:13:11.654661  9048 solver.cpp:240] Iteration 83, loss = 10.4446
I0408 21:13:11.654700  9048 solver.cpp:256]     Train net output #0: loss = 10.4446 (* 1 = 10.4446 loss)
I0408 21:13:11.654711  9048 sgd_solver.cpp:106] Iteration 83, lr = 0.01
I0408 21:13:11.931354  9048 solver.cpp:240] Iteration 84, loss = 11.7901
I0408 21:13:11.931394  9048 solver.cpp:256]     Train net output #0: loss = 11.7901 (* 1 = 11.7901 loss)
I0408 21:13:11.931418  9048 sgd_solver.cpp:106] Iteration 84, lr = 0.01
I0408 21:13:12.208026  9048 solver.cpp:240] Iteration 85, loss = 15.3635
I0408 21:13:12.208065  9048 solver.cpp:256]     Train net output #0: loss = 15.3635 (* 1 = 15.3635 loss)
I0408 21:13:12.208077  9048 sgd_solver.cpp:106] Iteration 85, lr = 0.01
I0408 21:13:12.484189  9048 solver.cpp:240] Iteration 86, loss = 7.9048
I0408 21:13:12.484235  9048 solver.cpp:256]     Train net output #0: loss = 7.9048 (* 1 = 7.9048 loss)
I0408 21:13:12.484258  9048 sgd_solver.cpp:106] Iteration 86, lr = 0.01
I0408 21:13:12.761008  9048 solver.cpp:240] Iteration 87, loss = 10.3589
I0408 21:13:12.761041  9048 solver.cpp:256]     Train net output #0: loss = 10.3589 (* 1 = 10.3589 loss)
I0408 21:13:12.761065  9048 sgd_solver.cpp:106] Iteration 87, lr = 0.01
I0408 21:13:13.037940  9048 solver.cpp:240] Iteration 88, loss = 8.84093
I0408 21:13:13.037976  9048 solver.cpp:256]     Train net output #0: loss = 8.84093 (* 1 = 8.84093 loss)
I0408 21:13:13.037986  9048 sgd_solver.cpp:106] Iteration 88, lr = 0.01
I0408 21:13:13.314642  9048 solver.cpp:240] Iteration 89, loss = 7.60743
I0408 21:13:13.314680  9048 solver.cpp:256]     Train net output #0: loss = 7.60743 (* 1 = 7.60743 loss)
I0408 21:13:13.314692  9048 sgd_solver.cpp:106] Iteration 89, lr = 0.01
I0408 21:13:13.591429  9048 solver.cpp:240] Iteration 90, loss = 7.56548
I0408 21:13:13.591464  9048 solver.cpp:256]     Train net output #0: loss = 7.56548 (* 1 = 7.56548 loss)
I0408 21:13:13.591476  9048 sgd_solver.cpp:106] Iteration 90, lr = 0.01
I0408 21:13:13.867911  9048 solver.cpp:240] Iteration 91, loss = 4.86582
I0408 21:13:13.867944  9048 solver.cpp:256]     Train net output #0: loss = 4.86582 (* 1 = 4.86582 loss)
I0408 21:13:13.867955  9048 sgd_solver.cpp:106] Iteration 91, lr = 0.01
I0408 21:13:14.144747  9048 solver.cpp:240] Iteration 92, loss = 4.04789
I0408 21:13:14.144780  9048 solver.cpp:256]     Train net output #0: loss = 4.04789 (* 1 = 4.04789 loss)
I0408 21:13:14.144790  9048 sgd_solver.cpp:106] Iteration 92, lr = 0.01
I0408 21:13:14.420852  9048 solver.cpp:240] Iteration 93, loss = 4.1634
I0408 21:13:14.420887  9048 solver.cpp:256]     Train net output #0: loss = 4.1634 (* 1 = 4.1634 loss)
I0408 21:13:14.420898  9048 sgd_solver.cpp:106] Iteration 93, lr = 0.01
I0408 21:13:14.696938  9048 solver.cpp:240] Iteration 94, loss = 2.52405
I0408 21:13:14.696971  9048 solver.cpp:256]     Train net output #0: loss = 2.52405 (* 1 = 2.52405 loss)
I0408 21:13:14.696982  9048 sgd_solver.cpp:106] Iteration 94, lr = 0.01
I0408 21:13:14.973150  9048 solver.cpp:240] Iteration 95, loss = 5.89261
I0408 21:13:14.973181  9048 solver.cpp:256]     Train net output #0: loss = 5.89261 (* 1 = 5.89261 loss)
I0408 21:13:14.973192  9048 sgd_solver.cpp:106] Iteration 95, lr = 0.01
I0408 21:13:15.249306  9048 solver.cpp:240] Iteration 96, loss = 4.59592
I0408 21:13:15.249341  9048 solver.cpp:256]     Train net output #0: loss = 4.59592 (* 1 = 4.59592 loss)
I0408 21:13:15.249353  9048 sgd_solver.cpp:106] Iteration 96, lr = 0.01
I0408 21:13:15.525545  9048 solver.cpp:240] Iteration 97, loss = 6.47449
I0408 21:13:15.525579  9048 solver.cpp:256]     Train net output #0: loss = 6.47449 (* 1 = 6.47449 loss)
I0408 21:13:15.525590  9048 sgd_solver.cpp:106] Iteration 97, lr = 0.01
I0408 21:13:15.801398  9048 solver.cpp:240] Iteration 98, loss = 15.4385
I0408 21:13:15.801434  9048 solver.cpp:256]     Train net output #0: loss = 15.4385 (* 1 = 15.4385 loss)
I0408 21:13:15.801445  9048 sgd_solver.cpp:106] Iteration 98, lr = 0.01
I0408 21:13:16.077443  9048 solver.cpp:240] Iteration 99, loss = 9.93287
I0408 21:13:16.077478  9048 solver.cpp:256]     Train net output #0: loss = 9.93287 (* 1 = 9.93287 loss)
I0408 21:13:16.077489  9048 sgd_solver.cpp:106] Iteration 99, lr = 0.01
I0408 21:13:16.353886  9048 solver.cpp:240] Iteration 100, loss = 10.0671
I0408 21:13:16.353922  9048 solver.cpp:256]     Train net output #0: loss = 10.0671 (* 1 = 10.0671 loss)
I0408 21:13:16.353935  9048 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0408 21:13:16.630704  9048 solver.cpp:240] Iteration 101, loss = 5.86225
I0408 21:13:16.630741  9048 solver.cpp:256]     Train net output #0: loss = 5.86225 (* 1 = 5.86225 loss)
I0408 21:13:16.630753  9048 sgd_solver.cpp:106] Iteration 101, lr = 0.01
I0408 21:13:16.907968  9048 solver.cpp:240] Iteration 102, loss = 1.65968
I0408 21:13:16.908004  9048 solver.cpp:256]     Train net output #0: loss = 1.65968 (* 1 = 1.65968 loss)
I0408 21:13:16.908015  9048 sgd_solver.cpp:106] Iteration 102, lr = 0.01
I0408 21:13:17.184244  9048 solver.cpp:240] Iteration 103, loss = 13.059
I0408 21:13:17.184278  9048 solver.cpp:256]     Train net output #0: loss = 13.059 (* 1 = 13.059 loss)
I0408 21:13:17.184301  9048 sgd_solver.cpp:106] Iteration 103, lr = 0.01
I0408 21:13:17.460971  9048 solver.cpp:240] Iteration 104, loss = 12.596
I0408 21:13:17.461006  9048 solver.cpp:256]     Train net output #0: loss = 12.596 (* 1 = 12.596 loss)
I0408 21:13:17.461019  9048 sgd_solver.cpp:106] Iteration 104, lr = 0.01
I0408 21:13:17.737033  9048 solver.cpp:240] Iteration 105, loss = 2.3503
I0408 21:13:17.737069  9048 solver.cpp:256]     Train net output #0: loss = 2.3503 (* 1 = 2.3503 loss)
I0408 21:13:17.737082  9048 sgd_solver.cpp:106] Iteration 105, lr = 0.01
I0408 21:13:18.013726  9048 solver.cpp:240] Iteration 106, loss = 13.3926
I0408 21:13:18.013772  9048 solver.cpp:256]     Train net output #0: loss = 13.3926 (* 1 = 13.3926 loss)
I0408 21:13:18.013797  9048 sgd_solver.cpp:106] Iteration 106, lr = 0.01
I0408 21:13:18.290910  9048 solver.cpp:240] Iteration 107, loss = 16.41
I0408 21:13:18.290947  9048 solver.cpp:256]     Train net output #0: loss = 16.41 (* 1 = 16.41 loss)
I0408 21:13:18.290959  9048 sgd_solver.cpp:106] Iteration 107, lr = 0.01
I0408 21:13:18.567312  9048 solver.cpp:240] Iteration 108, loss = 11.4542
I0408 21:13:18.567623  9048 solver.cpp:256]     Train net output #0: loss = 11.4542 (* 1 = 11.4542 loss)
I0408 21:13:18.567651  9048 sgd_solver.cpp:106] Iteration 108, lr = 0.01
I0408 21:13:18.843940  9048 solver.cpp:240] Iteration 109, loss = 10.1789
I0408 21:13:18.843976  9048 solver.cpp:256]     Train net output #0: loss = 10.1789 (* 1 = 10.1789 loss)
I0408 21:13:18.843987  9048 sgd_solver.cpp:106] Iteration 109, lr = 0.01
I0408 21:13:19.120304  9048 solver.cpp:240] Iteration 110, loss = 11.2965
I0408 21:13:19.120340  9048 solver.cpp:256]     Train net output #0: loss = 11.2965 (* 1 = 11.2965 loss)
I0408 21:13:19.120352  9048 sgd_solver.cpp:106] Iteration 110, lr = 0.01
I0408 21:13:19.395311  9048 solver.cpp:240] Iteration 111, loss = 13.4265
I0408 21:13:19.395352  9048 solver.cpp:256]     Train net output #0: loss = 13.4265 (* 1 = 13.4265 loss)
I0408 21:13:19.395364  9048 sgd_solver.cpp:106] Iteration 111, lr = 0.01
I0408 21:13:19.670958  9048 solver.cpp:240] Iteration 112, loss = 3.68793
I0408 21:13:19.670995  9048 solver.cpp:256]     Train net output #0: loss = 3.68793 (* 1 = 3.68793 loss)
I0408 21:13:19.671007  9048 sgd_solver.cpp:106] Iteration 112, lr = 0.01
I0408 21:13:19.947494  9048 solver.cpp:240] Iteration 113, loss = 13.2047
I0408 21:13:19.947535  9048 solver.cpp:256]     Train net output #0: loss = 13.2047 (* 1 = 13.2047 loss)
I0408 21:13:19.947548  9048 sgd_solver.cpp:106] Iteration 113, lr = 0.01
I0408 21:13:20.224187  9048 solver.cpp:240] Iteration 114, loss = 8.28065
I0408 21:13:20.224233  9048 solver.cpp:256]     Train net output #0: loss = 8.28064 (* 1 = 8.28064 loss)
I0408 21:13:20.224244  9048 sgd_solver.cpp:106] Iteration 114, lr = 0.01
I0408 21:13:20.501701  9048 solver.cpp:240] Iteration 115, loss = 5.69781
I0408 21:13:20.501739  9048 solver.cpp:256]     Train net output #0: loss = 5.69781 (* 1 = 5.69781 loss)
I0408 21:13:20.501749  9048 sgd_solver.cpp:106] Iteration 115, lr = 0.01
I0408 21:13:20.778132  9048 solver.cpp:240] Iteration 116, loss = 3.15607
I0408 21:13:20.778168  9048 solver.cpp:256]     Train net output #0: loss = 3.15607 (* 1 = 3.15607 loss)
I0408 21:13:20.778178  9048 sgd_solver.cpp:106] Iteration 116, lr = 0.01
I0408 21:13:21.055130  9048 solver.cpp:240] Iteration 117, loss = 5.73106
I0408 21:13:21.055166  9048 solver.cpp:256]     Train net output #0: loss = 5.73106 (* 1 = 5.73106 loss)
I0408 21:13:21.055178  9048 sgd_solver.cpp:106] Iteration 117, lr = 0.01
I0408 21:13:21.330268  9048 solver.cpp:240] Iteration 118, loss = 23.8857
I0408 21:13:21.330309  9048 solver.cpp:256]     Train net output #0: loss = 23.8857 (* 1 = 23.8857 loss)
I0408 21:13:21.330322  9048 sgd_solver.cpp:106] Iteration 118, lr = 0.01
I0408 21:13:21.606499  9048 solver.cpp:240] Iteration 119, loss = 11.1633
I0408 21:13:21.606537  9048 solver.cpp:256]     Train net output #0: loss = 11.1633 (* 1 = 11.1633 loss)
I0408 21:13:21.606550  9048 sgd_solver.cpp:106] Iteration 119, lr = 0.01
I0408 21:13:21.883160  9048 solver.cpp:240] Iteration 120, loss = 7.20963
I0408 21:13:21.883196  9048 solver.cpp:256]     Train net output #0: loss = 7.20963 (* 1 = 7.20963 loss)
I0408 21:13:21.883208  9048 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0408 21:13:22.159083  9048 solver.cpp:240] Iteration 121, loss = 5.06122
I0408 21:13:22.159129  9048 solver.cpp:256]     Train net output #0: loss = 5.06122 (* 1 = 5.06122 loss)
I0408 21:13:22.159140  9048 sgd_solver.cpp:106] Iteration 121, lr = 0.01
I0408 21:13:22.435151  9048 solver.cpp:240] Iteration 122, loss = 10.0435
I0408 21:13:22.435185  9048 solver.cpp:256]     Train net output #0: loss = 10.0435 (* 1 = 10.0435 loss)
I0408 21:13:22.435197  9048 sgd_solver.cpp:106] Iteration 122, lr = 0.01
I0408 21:13:22.711561  9048 solver.cpp:240] Iteration 123, loss = 10.3572
I0408 21:13:22.711603  9048 solver.cpp:256]     Train net output #0: loss = 10.3572 (* 1 = 10.3572 loss)
I0408 21:13:22.711616  9048 sgd_solver.cpp:106] Iteration 123, lr = 0.01
I0408 21:13:22.988806  9048 solver.cpp:240] Iteration 124, loss = 9.47589
I0408 21:13:22.988840  9048 solver.cpp:256]     Train net output #0: loss = 9.47589 (* 1 = 9.47589 loss)
I0408 21:13:22.988891  9048 sgd_solver.cpp:106] Iteration 124, lr = 0.01
I0408 21:13:23.266140  9048 solver.cpp:240] Iteration 125, loss = 20.6833
I0408 21:13:23.266176  9048 solver.cpp:256]     Train net output #0: loss = 20.6833 (* 1 = 20.6833 loss)
I0408 21:13:23.266201  9048 sgd_solver.cpp:106] Iteration 125, lr = 0.01
I0408 21:13:23.542953  9048 solver.cpp:240] Iteration 126, loss = 12.7515
I0408 21:13:23.542991  9048 solver.cpp:256]     Train net output #0: loss = 12.7515 (* 1 = 12.7515 loss)
I0408 21:13:23.543004  9048 sgd_solver.cpp:106] Iteration 126, lr = 0.01
I0408 21:13:23.819914  9048 solver.cpp:240] Iteration 127, loss = 12.2132
I0408 21:13:23.819952  9048 solver.cpp:256]     Train net output #0: loss = 12.2132 (* 1 = 12.2132 loss)
I0408 21:13:23.819962  9048 sgd_solver.cpp:106] Iteration 127, lr = 0.01
I0408 21:13:24.096771  9048 solver.cpp:240] Iteration 128, loss = 13.0133
I0408 21:13:24.096807  9048 solver.cpp:256]     Train net output #0: loss = 13.0133 (* 1 = 13.0133 loss)
I0408 21:13:24.096832  9048 sgd_solver.cpp:106] Iteration 128, lr = 0.01
I0408 21:13:24.373421  9048 solver.cpp:240] Iteration 129, loss = 12.1672
I0408 21:13:24.373458  9048 solver.cpp:256]     Train net output #0: loss = 12.1672 (* 1 = 12.1672 loss)
I0408 21:13:24.373471  9048 sgd_solver.cpp:106] Iteration 129, lr = 0.01
I0408 21:13:24.649077  9048 solver.cpp:240] Iteration 130, loss = 1.59916
I0408 21:13:24.649116  9048 solver.cpp:256]     Train net output #0: loss = 1.59916 (* 1 = 1.59916 loss)
I0408 21:13:24.649132  9048 sgd_solver.cpp:106] Iteration 130, lr = 0.01
I0408 21:13:24.925902  9048 solver.cpp:240] Iteration 131, loss = 2.60788
I0408 21:13:24.925936  9048 solver.cpp:256]     Train net output #0: loss = 2.60788 (* 1 = 2.60788 loss)
I0408 21:13:24.925959  9048 sgd_solver.cpp:106] Iteration 131, lr = 0.01
I0408 21:13:25.202055  9048 solver.cpp:240] Iteration 132, loss = 8.20869
I0408 21:13:25.202090  9048 solver.cpp:256]     Train net output #0: loss = 8.20868 (* 1 = 8.20868 loss)
I0408 21:13:25.202112  9048 sgd_solver.cpp:106] Iteration 132, lr = 0.01
I0408 21:13:25.478247  9048 solver.cpp:240] Iteration 133, loss = 6.96181
I0408 21:13:25.478287  9048 solver.cpp:256]     Train net output #0: loss = 6.96181 (* 1 = 6.96181 loss)
I0408 21:13:25.478299  9048 sgd_solver.cpp:106] Iteration 133, lr = 0.01
I0408 21:13:25.754602  9048 solver.cpp:240] Iteration 134, loss = 17.5512
I0408 21:13:25.754639  9048 solver.cpp:256]     Train net output #0: loss = 17.5512 (* 1 = 17.5512 loss)
I0408 21:13:25.754652  9048 sgd_solver.cpp:106] Iteration 134, lr = 0.01
I0408 21:13:26.031837  9048 solver.cpp:240] Iteration 135, loss = 12.9615
I0408 21:13:26.031874  9048 solver.cpp:256]     Train net output #0: loss = 12.9615 (* 1 = 12.9615 loss)
I0408 21:13:26.031898  9048 sgd_solver.cpp:106] Iteration 135, lr = 0.01
I0408 21:13:26.308310  9048 solver.cpp:240] Iteration 136, loss = 19.0124
I0408 21:13:26.308346  9048 solver.cpp:256]     Train net output #0: loss = 19.0124 (* 1 = 19.0124 loss)
I0408 21:13:26.308358  9048 sgd_solver.cpp:106] Iteration 136, lr = 0.01
I0408 21:13:26.585161  9048 solver.cpp:240] Iteration 137, loss = 8.97178
I0408 21:13:26.585196  9048 solver.cpp:256]     Train net output #0: loss = 8.97178 (* 1 = 8.97178 loss)
I0408 21:13:26.585207  9048 sgd_solver.cpp:106] Iteration 137, lr = 0.01
I0408 21:13:26.861985  9048 solver.cpp:240] Iteration 138, loss = 14.0327
I0408 21:13:26.862021  9048 solver.cpp:256]     Train net output #0: loss = 14.0327 (* 1 = 14.0327 loss)
I0408 21:13:26.862033  9048 sgd_solver.cpp:106] Iteration 138, lr = 0.01
I0408 21:13:27.138413  9048 solver.cpp:240] Iteration 139, loss = 7.99854
I0408 21:13:27.138451  9048 solver.cpp:256]     Train net output #0: loss = 7.99854 (* 1 = 7.99854 loss)
I0408 21:13:27.138463  9048 sgd_solver.cpp:106] Iteration 139, lr = 0.01
I0408 21:13:27.416801  9048 solver.cpp:240] Iteration 140, loss = 2.03955
I0408 21:13:27.416841  9048 solver.cpp:256]     Train net output #0: loss = 2.03955 (* 1 = 2.03955 loss)
I0408 21:13:27.416863  9048 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0408 21:13:27.692543  9048 solver.cpp:240] Iteration 141, loss = 1.93947
I0408 21:13:27.692575  9048 solver.cpp:256]     Train net output #0: loss = 1.93947 (* 1 = 1.93947 loss)
I0408 21:13:27.692587  9048 sgd_solver.cpp:106] Iteration 141, lr = 0.01
I0408 21:13:27.968628  9048 solver.cpp:240] Iteration 142, loss = 3.1191
I0408 21:13:27.968663  9048 solver.cpp:256]     Train net output #0: loss = 3.11909 (* 1 = 3.11909 loss)
I0408 21:13:27.968675  9048 sgd_solver.cpp:106] Iteration 142, lr = 0.01
I0408 21:13:28.245425  9048 solver.cpp:240] Iteration 143, loss = 9.23602
I0408 21:13:28.245465  9048 solver.cpp:256]     Train net output #0: loss = 9.23602 (* 1 = 9.23602 loss)
I0408 21:13:28.245476  9048 sgd_solver.cpp:106] Iteration 143, lr = 0.01
I0408 21:13:28.522181  9048 solver.cpp:240] Iteration 144, loss = 8.78567
I0408 21:13:28.522217  9048 solver.cpp:256]     Train net output #0: loss = 8.78566 (* 1 = 8.78566 loss)
I0408 21:13:28.522229  9048 sgd_solver.cpp:106] Iteration 144, lr = 0.01
I0408 21:13:28.798866  9048 solver.cpp:240] Iteration 145, loss = 11.4751
I0408 21:13:28.798902  9048 solver.cpp:256]     Train net output #0: loss = 11.4751 (* 1 = 11.4751 loss)
I0408 21:13:28.798914  9048 sgd_solver.cpp:106] Iteration 145, lr = 0.01
I0408 21:13:29.075026  9048 solver.cpp:240] Iteration 146, loss = 9.78722
I0408 21:13:29.075059  9048 solver.cpp:256]     Train net output #0: loss = 9.78722 (* 1 = 9.78722 loss)
I0408 21:13:29.075070  9048 sgd_solver.cpp:106] Iteration 146, lr = 0.01
I0408 21:13:29.351594  9048 solver.cpp:240] Iteration 147, loss = 5.39782
I0408 21:13:29.351631  9048 solver.cpp:256]     Train net output #0: loss = 5.39782 (* 1 = 5.39782 loss)
I0408 21:13:29.351644  9048 sgd_solver.cpp:106] Iteration 147, lr = 0.01
I0408 21:13:29.628175  9048 solver.cpp:240] Iteration 148, loss = 5.26303
I0408 21:13:29.628216  9048 solver.cpp:256]     Train net output #0: loss = 5.26303 (* 1 = 5.26303 loss)
I0408 21:13:29.628227  9048 sgd_solver.cpp:106] Iteration 148, lr = 0.01
I0408 21:13:29.904865  9048 solver.cpp:240] Iteration 149, loss = 4.96809
I0408 21:13:29.904899  9048 solver.cpp:256]     Train net output #0: loss = 4.96808 (* 1 = 4.96808 loss)
I0408 21:13:29.904909  9048 sgd_solver.cpp:106] Iteration 149, lr = 0.01
I0408 21:13:30.181380  9048 solver.cpp:240] Iteration 150, loss = 5.34749
I0408 21:13:30.181416  9048 solver.cpp:256]     Train net output #0: loss = 5.34749 (* 1 = 5.34749 loss)
I0408 21:13:30.181427  9048 sgd_solver.cpp:106] Iteration 150, lr = 0.01
I0408 21:13:30.457955  9048 solver.cpp:240] Iteration 151, loss = 6.56807
I0408 21:13:30.457988  9048 solver.cpp:256]     Train net output #0: loss = 6.56807 (* 1 = 6.56807 loss)
I0408 21:13:30.457999  9048 sgd_solver.cpp:106] Iteration 151, lr = 0.01
I0408 21:13:30.734235  9048 solver.cpp:240] Iteration 152, loss = 3.48438
I0408 21:13:30.734267  9048 solver.cpp:256]     Train net output #0: loss = 3.48438 (* 1 = 3.48438 loss)
I0408 21:13:30.734279  9048 sgd_solver.cpp:106] Iteration 152, lr = 0.01
I0408 21:13:31.010845  9048 solver.cpp:240] Iteration 153, loss = 9.29454
I0408 21:13:31.010885  9048 solver.cpp:256]     Train net output #0: loss = 9.29454 (* 1 = 9.29454 loss)
I0408 21:13:31.010907  9048 sgd_solver.cpp:106] Iteration 153, lr = 0.01
I0408 21:13:31.286768  9048 solver.cpp:240] Iteration 154, loss = 9.34913
I0408 21:13:31.286803  9048 solver.cpp:256]     Train net output #0: loss = 9.34913 (* 1 = 9.34913 loss)
I0408 21:13:31.286815  9048 sgd_solver.cpp:106] Iteration 154, lr = 0.01
I0408 21:13:31.563143  9048 solver.cpp:240] Iteration 155, loss = 14.8171
I0408 21:13:31.563179  9048 solver.cpp:256]     Train net output #0: loss = 14.8171 (* 1 = 14.8171 loss)
I0408 21:13:31.563191  9048 sgd_solver.cpp:106] Iteration 155, lr = 0.01
I0408 21:13:31.839859  9048 solver.cpp:240] Iteration 156, loss = 8.24443
I0408 21:13:31.839906  9048 solver.cpp:256]     Train net output #0: loss = 8.24443 (* 1 = 8.24443 loss)
I0408 21:13:31.839918  9048 sgd_solver.cpp:106] Iteration 156, lr = 0.01
I0408 21:13:32.116971  9048 solver.cpp:240] Iteration 157, loss = 7.91997
I0408 21:13:32.117032  9048 solver.cpp:256]     Train net output #0: loss = 7.91997 (* 1 = 7.91997 loss)
I0408 21:13:32.117055  9048 sgd_solver.cpp:106] Iteration 157, lr = 0.01
I0408 21:13:32.393836  9048 solver.cpp:240] Iteration 158, loss = 8.47958
I0408 21:13:32.393872  9048 solver.cpp:256]     Train net output #0: loss = 8.47958 (* 1 = 8.47958 loss)
I0408 21:13:32.393883  9048 sgd_solver.cpp:106] Iteration 158, lr = 0.01
I0408 21:13:32.670266  9048 solver.cpp:240] Iteration 159, loss = 6.73847
I0408 21:13:32.670300  9048 solver.cpp:256]     Train net output #0: loss = 6.73847 (* 1 = 6.73847 loss)
I0408 21:13:32.670311  9048 sgd_solver.cpp:106] Iteration 159, lr = 0.01
I0408 21:13:32.946324  9048 solver.cpp:240] Iteration 160, loss = 6.22423
I0408 21:13:32.946367  9048 solver.cpp:256]     Train net output #0: loss = 6.22423 (* 1 = 6.22423 loss)
I0408 21:13:32.946380  9048 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0408 21:13:33.222335  9048 solver.cpp:240] Iteration 161, loss = 7.58295
I0408 21:13:33.222370  9048 solver.cpp:256]     Train net output #0: loss = 7.58295 (* 1 = 7.58295 loss)
I0408 21:13:33.222393  9048 sgd_solver.cpp:106] Iteration 161, lr = 0.01
I0408 21:13:33.498286  9048 solver.cpp:240] Iteration 162, loss = 10.2854
I0408 21:13:33.498322  9048 solver.cpp:256]     Train net output #0: loss = 10.2854 (* 1 = 10.2854 loss)
I0408 21:13:33.498333  9048 sgd_solver.cpp:106] Iteration 162, lr = 0.01
I0408 21:13:33.774644  9048 solver.cpp:240] Iteration 163, loss = 4.93835
I0408 21:13:33.774679  9048 solver.cpp:256]     Train net output #0: loss = 4.93835 (* 1 = 4.93835 loss)
I0408 21:13:33.774690  9048 sgd_solver.cpp:106] Iteration 163, lr = 0.01
I0408 21:13:34.051378  9048 solver.cpp:240] Iteration 164, loss = 16.9946
I0408 21:13:34.051414  9048 solver.cpp:256]     Train net output #0: loss = 16.9946 (* 1 = 16.9946 loss)
I0408 21:13:34.051427  9048 sgd_solver.cpp:106] Iteration 164, lr = 0.01
I0408 21:13:34.328372  9048 solver.cpp:240] Iteration 165, loss = 11.5764
I0408 21:13:34.328409  9048 solver.cpp:256]     Train net output #0: loss = 11.5764 (* 1 = 11.5764 loss)
I0408 21:13:34.328420  9048 sgd_solver.cpp:106] Iteration 165, lr = 0.01
I0408 21:13:34.604313  9048 solver.cpp:240] Iteration 166, loss = 11.7858
I0408 21:13:34.604352  9048 solver.cpp:256]     Train net output #0: loss = 11.7858 (* 1 = 11.7858 loss)
I0408 21:13:34.604364  9048 sgd_solver.cpp:106] Iteration 166, lr = 0.01
I0408 21:13:34.880380  9048 solver.cpp:240] Iteration 167, loss = 3.59828
I0408 21:13:34.880414  9048 solver.cpp:256]     Train net output #0: loss = 3.59828 (* 1 = 3.59828 loss)
I0408 21:13:34.880425  9048 sgd_solver.cpp:106] Iteration 167, lr = 0.01
I0408 21:13:35.156687  9048 solver.cpp:240] Iteration 168, loss = 9.49687
I0408 21:13:35.156723  9048 solver.cpp:256]     Train net output #0: loss = 9.49686 (* 1 = 9.49686 loss)
I0408 21:13:35.156735  9048 sgd_solver.cpp:106] Iteration 168, lr = 0.01
I0408 21:13:35.433562  9048 solver.cpp:240] Iteration 169, loss = 2.75684
I0408 21:13:35.433598  9048 solver.cpp:256]     Train net output #0: loss = 2.75684 (* 1 = 2.75684 loss)
I0408 21:13:35.433609  9048 sgd_solver.cpp:106] Iteration 169, lr = 0.01
I0408 21:13:35.709841  9048 solver.cpp:240] Iteration 170, loss = 9.15757
I0408 21:13:35.709879  9048 solver.cpp:256]     Train net output #0: loss = 9.15756 (* 1 = 9.15756 loss)
I0408 21:13:35.709892  9048 sgd_solver.cpp:106] Iteration 170, lr = 0.01
I0408 21:13:35.986760  9048 solver.cpp:240] Iteration 171, loss = 6.9176
I0408 21:13:35.986795  9048 solver.cpp:256]     Train net output #0: loss = 6.9176 (* 1 = 6.9176 loss)
I0408 21:13:35.986806  9048 sgd_solver.cpp:106] Iteration 171, lr = 0.01
I0408 21:13:36.262552  9048 solver.cpp:240] Iteration 172, loss = 2.63546
I0408 21:13:36.262588  9048 solver.cpp:256]     Train net output #0: loss = 2.63546 (* 1 = 2.63546 loss)
I0408 21:13:36.262599  9048 sgd_solver.cpp:106] Iteration 172, lr = 0.01
I0408 21:13:36.540809  9048 solver.cpp:240] Iteration 173, loss = 6.86662
I0408 21:13:36.540848  9048 solver.cpp:256]     Train net output #0: loss = 6.86661 (* 1 = 6.86661 loss)
I0408 21:13:36.540885  9048 sgd_solver.cpp:106] Iteration 173, lr = 0.01
I0408 21:13:36.816882  9048 solver.cpp:240] Iteration 174, loss = 5.54799
I0408 21:13:36.816915  9048 solver.cpp:256]     Train net output #0: loss = 5.54799 (* 1 = 5.54799 loss)
I0408 21:13:36.816925  9048 sgd_solver.cpp:106] Iteration 174, lr = 0.01
I0408 21:13:37.093036  9048 solver.cpp:240] Iteration 175, loss = 7.66492
I0408 21:13:37.093075  9048 solver.cpp:256]     Train net output #0: loss = 7.66491 (* 1 = 7.66491 loss)
I0408 21:13:37.093098  9048 sgd_solver.cpp:106] Iteration 175, lr = 0.01
I0408 21:13:37.368940  9048 solver.cpp:240] Iteration 176, loss = 6.06635
I0408 21:13:37.368974  9048 solver.cpp:256]     Train net output #0: loss = 6.06634 (* 1 = 6.06634 loss)
I0408 21:13:37.368996  9048 sgd_solver.cpp:106] Iteration 176, lr = 0.01
I0408 21:13:37.645015  9048 solver.cpp:240] Iteration 177, loss = 11.3966
I0408 21:13:37.645052  9048 solver.cpp:256]     Train net output #0: loss = 11.3966 (* 1 = 11.3966 loss)
I0408 21:13:37.645064  9048 sgd_solver.cpp:106] Iteration 177, lr = 0.01
I0408 21:13:37.921048  9048 solver.cpp:240] Iteration 178, loss = 9.44708
I0408 21:13:37.921087  9048 solver.cpp:256]     Train net output #0: loss = 9.44707 (* 1 = 9.44707 loss)
I0408 21:13:37.921108  9048 sgd_solver.cpp:106] Iteration 178, lr = 0.01
I0408 21:13:38.196844  9048 solver.cpp:240] Iteration 179, loss = 10.9729
I0408 21:13:38.196878  9048 solver.cpp:256]     Train net output #0: loss = 10.9729 (* 1 = 10.9729 loss)
I0408 21:13:38.196890  9048 sgd_solver.cpp:106] Iteration 179, lr = 0.01
I0408 21:13:38.473919  9048 solver.cpp:240] Iteration 180, loss = 12.7035
I0408 21:13:38.473954  9048 solver.cpp:256]     Train net output #0: loss = 12.7035 (* 1 = 12.7035 loss)
I0408 21:13:38.473965  9048 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0408 21:13:38.750309  9048 solver.cpp:240] Iteration 181, loss = 14.0097
I0408 21:13:38.750345  9048 solver.cpp:256]     Train net output #0: loss = 14.0097 (* 1 = 14.0097 loss)
I0408 21:13:38.750368  9048 sgd_solver.cpp:106] Iteration 181, lr = 0.01
I0408 21:13:39.026738  9048 solver.cpp:240] Iteration 182, loss = 8.45715
I0408 21:13:39.026772  9048 solver.cpp:256]     Train net output #0: loss = 8.45715 (* 1 = 8.45715 loss)
I0408 21:13:39.026784  9048 sgd_solver.cpp:106] Iteration 182, lr = 0.01
I0408 21:13:39.303627  9048 solver.cpp:240] Iteration 183, loss = 4.87142
I0408 21:13:39.303665  9048 solver.cpp:256]     Train net output #0: loss = 4.87141 (* 1 = 4.87141 loss)
I0408 21:13:39.303676  9048 sgd_solver.cpp:106] Iteration 183, lr = 0.01
I0408 21:13:39.579825  9048 solver.cpp:240] Iteration 184, loss = 10.7192
I0408 21:13:39.579862  9048 solver.cpp:256]     Train net output #0: loss = 10.7192 (* 1 = 10.7192 loss)
I0408 21:13:39.579874  9048 sgd_solver.cpp:106] Iteration 184, lr = 0.01
I0408 21:13:39.856757  9048 solver.cpp:240] Iteration 185, loss = 8.5941
I0408 21:13:39.856794  9048 solver.cpp:256]     Train net output #0: loss = 8.5941 (* 1 = 8.5941 loss)
I0408 21:13:39.856806  9048 sgd_solver.cpp:106] Iteration 185, lr = 0.01
I0408 21:13:40.133139  9048 solver.cpp:240] Iteration 186, loss = 2.31773
I0408 21:13:40.133172  9048 solver.cpp:256]     Train net output #0: loss = 2.31773 (* 1 = 2.31773 loss)
I0408 21:13:40.133194  9048 sgd_solver.cpp:106] Iteration 186, lr = 0.01
I0408 21:13:40.409250  9048 solver.cpp:240] Iteration 187, loss = 20.7752
I0408 21:13:40.409287  9048 solver.cpp:256]     Train net output #0: loss = 20.7752 (* 1 = 20.7752 loss)
I0408 21:13:40.409299  9048 sgd_solver.cpp:106] Iteration 187, lr = 0.01
I0408 21:13:40.686156  9048 solver.cpp:240] Iteration 188, loss = 18.4317
I0408 21:13:40.686192  9048 solver.cpp:256]     Train net output #0: loss = 18.4317 (* 1 = 18.4317 loss)
I0408 21:13:40.686203  9048 sgd_solver.cpp:106] Iteration 188, lr = 0.01
I0408 21:13:40.962126  9048 solver.cpp:240] Iteration 189, loss = 1.99222
I0408 21:13:40.962160  9048 solver.cpp:256]     Train net output #0: loss = 1.99221 (* 1 = 1.99221 loss)
I0408 21:13:40.962196  9048 sgd_solver.cpp:106] Iteration 189, lr = 0.01
I0408 21:13:41.238039  9048 solver.cpp:240] Iteration 190, loss = 5.9359
I0408 21:13:41.238075  9048 solver.cpp:256]     Train net output #0: loss = 5.9359 (* 1 = 5.9359 loss)
I0408 21:13:41.238086  9048 sgd_solver.cpp:106] Iteration 190, lr = 0.01
I0408 21:13:41.514353  9048 solver.cpp:240] Iteration 191, loss = 13.3997
I0408 21:13:41.514392  9048 solver.cpp:256]     Train net output #0: loss = 13.3997 (* 1 = 13.3997 loss)
I0408 21:13:41.514405  9048 sgd_solver.cpp:106] Iteration 191, lr = 0.01
I0408 21:13:41.791182  9048 solver.cpp:240] Iteration 192, loss = 17.8019
I0408 21:13:41.791219  9048 solver.cpp:256]     Train net output #0: loss = 17.8019 (* 1 = 17.8019 loss)
I0408 21:13:41.791231  9048 sgd_solver.cpp:106] Iteration 192, lr = 0.01
I0408 21:13:42.068100  9048 solver.cpp:240] Iteration 193, loss = 9.94107
I0408 21:13:42.068137  9048 solver.cpp:256]     Train net output #0: loss = 9.94106 (* 1 = 9.94106 loss)
I0408 21:13:42.068148  9048 sgd_solver.cpp:106] Iteration 193, lr = 0.01
I0408 21:13:42.344825  9048 solver.cpp:240] Iteration 194, loss = 11.2051
I0408 21:13:42.344861  9048 solver.cpp:256]     Train net output #0: loss = 11.2051 (* 1 = 11.2051 loss)
I0408 21:13:42.344873  9048 sgd_solver.cpp:106] Iteration 194, lr = 0.01
I0408 21:13:42.621768  9048 solver.cpp:240] Iteration 195, loss = 22.5942
I0408 21:13:42.621803  9048 solver.cpp:256]     Train net output #0: loss = 22.5942 (* 1 = 22.5942 loss)
I0408 21:13:42.621816  9048 sgd_solver.cpp:106] Iteration 195, lr = 0.01
I0408 21:13:42.899114  9048 solver.cpp:240] Iteration 196, loss = 15.0027
I0408 21:13:42.899158  9048 solver.cpp:256]     Train net output #0: loss = 15.0027 (* 1 = 15.0027 loss)
I0408 21:13:42.899166  9048 sgd_solver.cpp:106] Iteration 196, lr = 0.01
I0408 21:13:43.175988  9048 solver.cpp:240] Iteration 197, loss = 16.3604
I0408 21:13:43.176025  9048 solver.cpp:256]     Train net output #0: loss = 16.3604 (* 1 = 16.3604 loss)
I0408 21:13:43.176033  9048 sgd_solver.cpp:106] Iteration 197, lr = 0.01
I0408 21:13:43.452808  9048 solver.cpp:240] Iteration 198, loss = 14.5135
I0408 21:13:43.452844  9048 solver.cpp:256]     Train net output #0: loss = 14.5135 (* 1 = 14.5135 loss)
I0408 21:13:43.452852  9048 sgd_solver.cpp:106] Iteration 198, lr = 0.01
I0408 21:13:43.729302  9048 solver.cpp:240] Iteration 199, loss = 10.0505
I0408 21:13:43.729337  9048 solver.cpp:256]     Train net output #0: loss = 10.0505 (* 1 = 10.0505 loss)
I0408 21:13:43.729346  9048 sgd_solver.cpp:106] Iteration 199, lr = 0.01
I0408 21:13:44.006158  9048 solver.cpp:240] Iteration 200, loss = 10.1723
I0408 21:13:44.006193  9048 solver.cpp:256]     Train net output #0: loss = 10.1723 (* 1 = 10.1723 loss)
I0408 21:13:44.006202  9048 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0408 21:13:44.282953  9048 solver.cpp:240] Iteration 201, loss = 3.44144
I0408 21:13:44.282986  9048 solver.cpp:256]     Train net output #0: loss = 3.44143 (* 1 = 3.44143 loss)
I0408 21:13:44.282994  9048 sgd_solver.cpp:106] Iteration 201, lr = 0.01
I0408 21:13:44.559775  9048 solver.cpp:240] Iteration 202, loss = 14.1035
I0408 21:13:44.559813  9048 solver.cpp:256]     Train net output #0: loss = 14.1035 (* 1 = 14.1035 loss)
I0408 21:13:44.559823  9048 sgd_solver.cpp:106] Iteration 202, lr = 0.01
I0408 21:13:44.836550  9048 solver.cpp:240] Iteration 203, loss = 8.72177
I0408 21:13:44.836583  9048 solver.cpp:256]     Train net output #0: loss = 8.72176 (* 1 = 8.72176 loss)
I0408 21:13:44.836591  9048 sgd_solver.cpp:106] Iteration 203, lr = 0.01
I0408 21:13:45.112885  9048 solver.cpp:240] Iteration 204, loss = 4.51082
I0408 21:13:45.112917  9048 solver.cpp:256]     Train net output #0: loss = 4.51082 (* 1 = 4.51082 loss)
I0408 21:13:45.112926  9048 sgd_solver.cpp:106] Iteration 204, lr = 0.01
I0408 21:13:45.389016  9048 solver.cpp:240] Iteration 205, loss = 4.94162
I0408 21:13:45.389048  9048 solver.cpp:256]     Train net output #0: loss = 4.94162 (* 1 = 4.94162 loss)
I0408 21:13:45.389056  9048 sgd_solver.cpp:106] Iteration 205, lr = 0.01
I0408 21:13:45.665479  9048 solver.cpp:240] Iteration 206, loss = 14.101
I0408 21:13:45.665513  9048 solver.cpp:256]     Train net output #0: loss = 14.101 (* 1 = 14.101 loss)
I0408 21:13:45.665520  9048 sgd_solver.cpp:106] Iteration 206, lr = 0.01
I0408 21:13:45.941929  9048 solver.cpp:240] Iteration 207, loss = 8.45228
I0408 21:13:45.941970  9048 solver.cpp:256]     Train net output #0: loss = 8.45228 (* 1 = 8.45228 loss)
I0408 21:13:45.941979  9048 sgd_solver.cpp:106] Iteration 207, lr = 0.01
I0408 21:13:46.218034  9048 solver.cpp:240] Iteration 208, loss = 2.70054
I0408 21:13:46.218066  9048 solver.cpp:256]     Train net output #0: loss = 2.70054 (* 1 = 2.70054 loss)
I0408 21:13:46.218075  9048 sgd_solver.cpp:106] Iteration 208, lr = 0.01
I0408 21:13:46.493995  9048 solver.cpp:240] Iteration 209, loss = 13.677
I0408 21:13:46.494029  9048 solver.cpp:256]     Train net output #0: loss = 13.677 (* 1 = 13.677 loss)
I0408 21:13:46.494037  9048 sgd_solver.cpp:106] Iteration 209, lr = 0.01
I0408 21:13:46.769480  9048 solver.cpp:240] Iteration 210, loss = 1.9478
I0408 21:13:46.769513  9048 solver.cpp:256]     Train net output #0: loss = 1.9478 (* 1 = 1.9478 loss)
I0408 21:13:46.769521  9048 sgd_solver.cpp:106] Iteration 210, lr = 0.01
I0408 21:13:47.045473  9048 solver.cpp:240] Iteration 211, loss = 7.71462
I0408 21:13:47.045505  9048 solver.cpp:256]     Train net output #0: loss = 7.71462 (* 1 = 7.71462 loss)
I0408 21:13:47.045512  9048 sgd_solver.cpp:106] Iteration 211, lr = 0.01
I0408 21:13:47.321749  9048 solver.cpp:240] Iteration 212, loss = 21.0199
I0408 21:13:47.321784  9048 solver.cpp:256]     Train net output #0: loss = 21.0199 (* 1 = 21.0199 loss)
I0408 21:13:47.321791  9048 sgd_solver.cpp:106] Iteration 212, lr = 0.01
I0408 21:13:47.597797  9048 solver.cpp:240] Iteration 213, loss = 10.8383
I0408 21:13:47.597841  9048 solver.cpp:256]     Train net output #0: loss = 10.8383 (* 1 = 10.8383 loss)
I0408 21:13:47.597851  9048 sgd_solver.cpp:106] Iteration 213, lr = 0.01
I0408 21:13:47.874665  9048 solver.cpp:240] Iteration 214, loss = 16.5078
I0408 21:13:47.874701  9048 solver.cpp:256]     Train net output #0: loss = 16.5078 (* 1 = 16.5078 loss)
I0408 21:13:47.874709  9048 sgd_solver.cpp:106] Iteration 214, lr = 0.01
I0408 21:13:48.151437  9048 solver.cpp:240] Iteration 215, loss = 9.88407
I0408 21:13:48.151469  9048 solver.cpp:256]     Train net output #0: loss = 9.88407 (* 1 = 9.88407 loss)
I0408 21:13:48.151479  9048 sgd_solver.cpp:106] Iteration 215, lr = 0.01
I0408 21:13:48.427294  9048 solver.cpp:240] Iteration 216, loss = 4.84471
I0408 21:13:48.427325  9048 solver.cpp:256]     Train net output #0: loss = 4.84471 (* 1 = 4.84471 loss)
I0408 21:13:48.427332  9048 sgd_solver.cpp:106] Iteration 216, lr = 0.01
I0408 21:13:48.703284  9048 solver.cpp:240] Iteration 217, loss = 14.494
I0408 21:13:48.704494  9048 solver.cpp:256]     Train net output #0: loss = 14.494 (* 1 = 14.494 loss)
I0408 21:13:48.704505  9048 sgd_solver.cpp:106] Iteration 217, lr = 0.01
I0408 21:13:48.978807  9048 solver.cpp:240] Iteration 218, loss = 12.7128
I0408 21:13:48.978852  9048 solver.cpp:256]     Train net output #0: loss = 12.7128 (* 1 = 12.7128 loss)
I0408 21:13:48.978860  9048 sgd_solver.cpp:106] Iteration 218, lr = 0.01
I0408 21:13:49.254964  9048 solver.cpp:240] Iteration 219, loss = 8.35911
I0408 21:13:49.254997  9048 solver.cpp:256]     Train net output #0: loss = 8.35911 (* 1 = 8.35911 loss)
I0408 21:13:49.255004  9048 sgd_solver.cpp:106] Iteration 219, lr = 0.01
I0408 21:13:49.530457  9048 solver.cpp:240] Iteration 220, loss = 5.40673
I0408 21:13:49.530488  9048 solver.cpp:256]     Train net output #0: loss = 5.40673 (* 1 = 5.40673 loss)
I0408 21:13:49.530495  9048 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0408 21:13:49.807044  9048 solver.cpp:240] Iteration 221, loss = 10.3905
I0408 21:13:49.807076  9048 solver.cpp:256]     Train net output #0: loss = 10.3905 (* 1 = 10.3905 loss)
I0408 21:13:49.807085  9048 sgd_solver.cpp:106] Iteration 221, lr = 0.01
I0408 21:13:50.083451  9048 solver.cpp:240] Iteration 222, loss = 17.9627
I0408 21:13:50.083495  9048 solver.cpp:256]     Train net output #0: loss = 17.9627 (* 1 = 17.9627 loss)
I0408 21:13:50.083504  9048 sgd_solver.cpp:106] Iteration 222, lr = 0.01
I0408 21:13:50.360442  9048 solver.cpp:240] Iteration 223, loss = 6.10378
I0408 21:13:50.360474  9048 solver.cpp:256]     Train net output #0: loss = 6.10378 (* 1 = 6.10378 loss)
I0408 21:13:50.360483  9048 sgd_solver.cpp:106] Iteration 223, lr = 0.01
I0408 21:13:50.636605  9048 solver.cpp:240] Iteration 224, loss = 21.4828
I0408 21:13:50.636638  9048 solver.cpp:256]     Train net output #0: loss = 21.4828 (* 1 = 21.4828 loss)
I0408 21:13:50.636647  9048 sgd_solver.cpp:106] Iteration 224, lr = 0.01
I0408 21:13:50.913816  9048 solver.cpp:240] Iteration 225, loss = 21.7449
I0408 21:13:50.913851  9048 solver.cpp:256]     Train net output #0: loss = 21.7449 (* 1 = 21.7449 loss)
I0408 21:13:50.913859  9048 sgd_solver.cpp:106] Iteration 225, lr = 0.01
I0408 21:13:51.190423  9048 solver.cpp:240] Iteration 226, loss = 21.5886
I0408 21:13:51.190457  9048 solver.cpp:256]     Train net output #0: loss = 21.5886 (* 1 = 21.5886 loss)
I0408 21:13:51.190466  9048 sgd_solver.cpp:106] Iteration 226, lr = 0.01
I0408 21:13:51.467356  9048 solver.cpp:240] Iteration 227, loss = 18.2502
I0408 21:13:51.467391  9048 solver.cpp:256]     Train net output #0: loss = 18.2502 (* 1 = 18.2502 loss)
I0408 21:13:51.467399  9048 sgd_solver.cpp:106] Iteration 227, lr = 0.01
I0408 21:13:51.744168  9048 solver.cpp:240] Iteration 228, loss = 5.93647
I0408 21:13:51.744199  9048 solver.cpp:256]     Train net output #0: loss = 5.93647 (* 1 = 5.93647 loss)
I0408 21:13:51.744205  9048 sgd_solver.cpp:106] Iteration 228, lr = 0.01
I0408 21:13:52.022182  9048 solver.cpp:240] Iteration 229, loss = 18.4142
I0408 21:13:52.022217  9048 solver.cpp:256]     Train net output #0: loss = 18.4142 (* 1 = 18.4142 loss)
I0408 21:13:52.022224  9048 sgd_solver.cpp:106] Iteration 229, lr = 0.01
I0408 21:13:52.298554  9048 solver.cpp:240] Iteration 230, loss = 13.8063
I0408 21:13:52.298586  9048 solver.cpp:256]     Train net output #0: loss = 13.8063 (* 1 = 13.8063 loss)
I0408 21:13:52.298594  9048 sgd_solver.cpp:106] Iteration 230, lr = 0.01
I0408 21:13:52.575012  9048 solver.cpp:240] Iteration 231, loss = 6.27645
I0408 21:13:52.575060  9048 solver.cpp:256]     Train net output #0: loss = 6.27645 (* 1 = 6.27645 loss)
I0408 21:13:52.575069  9048 sgd_solver.cpp:106] Iteration 231, lr = 0.01
I0408 21:13:52.850680  9048 solver.cpp:240] Iteration 232, loss = 4.69341
I0408 21:13:52.850713  9048 solver.cpp:256]     Train net output #0: loss = 4.69341 (* 1 = 4.69341 loss)
I0408 21:13:52.850720  9048 sgd_solver.cpp:106] Iteration 232, lr = 0.01
I0408 21:13:53.127019  9048 solver.cpp:240] Iteration 233, loss = 10.333
I0408 21:13:53.127053  9048 solver.cpp:256]     Train net output #0: loss = 10.333 (* 1 = 10.333 loss)
I0408 21:13:53.127084  9048 sgd_solver.cpp:106] Iteration 233, lr = 0.01
I0408 21:13:53.403316  9048 solver.cpp:240] Iteration 234, loss = 2.67835
I0408 21:13:53.403350  9048 solver.cpp:256]     Train net output #0: loss = 2.67835 (* 1 = 2.67835 loss)
I0408 21:13:53.403358  9048 sgd_solver.cpp:106] Iteration 234, lr = 0.01
I0408 21:13:53.680059  9048 solver.cpp:240] Iteration 235, loss = 3.85806
I0408 21:13:53.680091  9048 solver.cpp:256]     Train net output #0: loss = 3.85806 (* 1 = 3.85806 loss)
I0408 21:13:53.680099  9048 sgd_solver.cpp:106] Iteration 235, lr = 0.01
I0408 21:13:53.956821  9048 solver.cpp:240] Iteration 236, loss = 11.1478
I0408 21:13:53.956858  9048 solver.cpp:256]     Train net output #0: loss = 11.1478 (* 1 = 11.1478 loss)
I0408 21:13:53.956867  9048 sgd_solver.cpp:106] Iteration 236, lr = 0.01
I0408 21:13:54.233091  9048 solver.cpp:240] Iteration 237, loss = 7.45811
I0408 21:13:54.233124  9048 solver.cpp:256]     Train net output #0: loss = 7.45811 (* 1 = 7.45811 loss)
I0408 21:13:54.233131  9048 sgd_solver.cpp:106] Iteration 237, lr = 0.01
I0408 21:13:54.509977  9048 solver.cpp:240] Iteration 238, loss = 11.5992
I0408 21:13:54.510009  9048 solver.cpp:256]     Train net output #0: loss = 11.5992 (* 1 = 11.5992 loss)
I0408 21:13:54.510016  9048 sgd_solver.cpp:106] Iteration 238, lr = 0.01
I0408 21:13:54.786136  9048 solver.cpp:240] Iteration 239, loss = 2.95939
I0408 21:13:54.786180  9048 solver.cpp:256]     Train net output #0: loss = 2.95939 (* 1 = 2.95939 loss)
I0408 21:13:54.786190  9048 sgd_solver.cpp:106] Iteration 239, lr = 0.01
I0408 21:13:55.062079  9048 solver.cpp:240] Iteration 240, loss = 11.2384
I0408 21:13:55.062111  9048 solver.cpp:256]     Train net output #0: loss = 11.2384 (* 1 = 11.2384 loss)
I0408 21:13:55.062120  9048 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0408 21:13:55.338729  9048 solver.cpp:240] Iteration 241, loss = 14.2361
I0408 21:13:55.338762  9048 solver.cpp:256]     Train net output #0: loss = 14.2361 (* 1 = 14.2361 loss)
I0408 21:13:55.338770  9048 sgd_solver.cpp:106] Iteration 241, lr = 0.01
I0408 21:13:55.615255  9048 solver.cpp:240] Iteration 242, loss = 15.9062
I0408 21:13:55.615289  9048 solver.cpp:256]     Train net output #0: loss = 15.9062 (* 1 = 15.9062 loss)
I0408 21:13:55.615298  9048 sgd_solver.cpp:106] Iteration 242, lr = 0.01
I0408 21:13:55.892747  9048 solver.cpp:240] Iteration 243, loss = 8.7041
I0408 21:13:55.892786  9048 solver.cpp:256]     Train net output #0: loss = 8.70409 (* 1 = 8.70409 loss)
I0408 21:13:55.892796  9048 sgd_solver.cpp:106] Iteration 243, lr = 0.01
I0408 21:13:56.168514  9048 solver.cpp:240] Iteration 244, loss = 15.139
I0408 21:13:56.168546  9048 solver.cpp:256]     Train net output #0: loss = 15.139 (* 1 = 15.139 loss)
I0408 21:13:56.168555  9048 sgd_solver.cpp:106] Iteration 244, lr = 0.01
I0408 21:13:56.445590  9048 solver.cpp:240] Iteration 245, loss = 24.8247
I0408 21:13:56.445622  9048 solver.cpp:256]     Train net output #0: loss = 24.8247 (* 1 = 24.8247 loss)
I0408 21:13:56.445631  9048 sgd_solver.cpp:106] Iteration 245, lr = 0.01
I0408 21:13:56.721812  9048 solver.cpp:240] Iteration 246, loss = 9.83381
I0408 21:13:56.721843  9048 solver.cpp:256]     Train net output #0: loss = 9.83381 (* 1 = 9.83381 loss)
I0408 21:13:56.721851  9048 sgd_solver.cpp:106] Iteration 246, lr = 0.01
I0408 21:13:56.998358  9048 solver.cpp:240] Iteration 247, loss = 11.58
I0408 21:13:56.998390  9048 solver.cpp:256]     Train net output #0: loss = 11.58 (* 1 = 11.58 loss)
I0408 21:13:56.998399  9048 sgd_solver.cpp:106] Iteration 247, lr = 0.01
I0408 21:13:57.274596  9048 solver.cpp:240] Iteration 248, loss = 7.03232
I0408 21:13:57.274628  9048 solver.cpp:256]     Train net output #0: loss = 7.03231 (* 1 = 7.03231 loss)
I0408 21:13:57.274637  9048 sgd_solver.cpp:106] Iteration 248, lr = 0.01
I0408 21:13:57.550765  9048 solver.cpp:240] Iteration 249, loss = 9.62388
I0408 21:13:57.550797  9048 solver.cpp:256]     Train net output #0: loss = 9.62388 (* 1 = 9.62388 loss)
I0408 21:13:57.550806  9048 sgd_solver.cpp:106] Iteration 249, lr = 0.01
I0408 21:13:57.827415  9048 solver.cpp:240] Iteration 250, loss = 9.26962
I0408 21:13:57.827447  9048 solver.cpp:256]     Train net output #0: loss = 9.26961 (* 1 = 9.26961 loss)
I0408 21:13:57.827455  9048 sgd_solver.cpp:106] Iteration 250, lr = 0.01
I0408 21:13:58.103715  9048 solver.cpp:240] Iteration 251, loss = 8.90239
I0408 21:13:58.103745  9048 solver.cpp:256]     Train net output #0: loss = 8.90238 (* 1 = 8.90238 loss)
I0408 21:13:58.103754  9048 sgd_solver.cpp:106] Iteration 251, lr = 0.01
I0408 21:13:58.380103  9048 solver.cpp:240] Iteration 252, loss = 6.28657
I0408 21:13:58.380134  9048 solver.cpp:256]     Train net output #0: loss = 6.28656 (* 1 = 6.28656 loss)
I0408 21:13:58.380143  9048 sgd_solver.cpp:106] Iteration 252, lr = 0.01
I0408 21:13:58.656702  9048 solver.cpp:240] Iteration 253, loss = 6.99715
I0408 21:13:58.656745  9048 solver.cpp:256]     Train net output #0: loss = 6.99715 (* 1 = 6.99715 loss)
I0408 21:13:58.656754  9048 sgd_solver.cpp:106] Iteration 253, lr = 0.01
I0408 21:13:58.932868  9048 solver.cpp:240] Iteration 254, loss = 13.8922
I0408 21:13:58.932904  9048 solver.cpp:256]     Train net output #0: loss = 13.8922 (* 1 = 13.8922 loss)
I0408 21:13:58.932912  9048 sgd_solver.cpp:106] Iteration 254, lr = 0.01
I0408 21:13:59.208607  9048 solver.cpp:240] Iteration 255, loss = 11.2006
I0408 21:13:59.208640  9048 solver.cpp:256]     Train net output #0: loss = 11.2006 (* 1 = 11.2006 loss)
I0408 21:13:59.208648  9048 sgd_solver.cpp:106] Iteration 255, lr = 0.01
I0408 21:13:59.485213  9048 solver.cpp:240] Iteration 256, loss = 9.28433
I0408 21:13:59.485244  9048 solver.cpp:256]     Train net output #0: loss = 9.28433 (* 1 = 9.28433 loss)
I0408 21:13:59.485254  9048 sgd_solver.cpp:106] Iteration 256, lr = 0.01
I0408 21:13:59.762094  9048 solver.cpp:240] Iteration 257, loss = 3.83131
I0408 21:13:59.762136  9048 solver.cpp:256]     Train net output #0: loss = 3.83131 (* 1 = 3.83131 loss)
I0408 21:13:59.762145  9048 sgd_solver.cpp:106] Iteration 257, lr = 0.01
I0408 21:14:00.038475  9048 solver.cpp:240] Iteration 258, loss = 12.1377
I0408 21:14:00.038508  9048 solver.cpp:256]     Train net output #0: loss = 12.1377 (* 1 = 12.1377 loss)
I0408 21:14:00.038516  9048 sgd_solver.cpp:106] Iteration 258, lr = 0.01
I0408 21:14:00.314838  9048 solver.cpp:240] Iteration 259, loss = 6.92362
I0408 21:14:00.314874  9048 solver.cpp:256]     Train net output #0: loss = 6.92362 (* 1 = 6.92362 loss)
I0408 21:14:00.314882  9048 sgd_solver.cpp:106] Iteration 259, lr = 0.01
I0408 21:14:00.590898  9048 solver.cpp:240] Iteration 260, loss = 7.84542
I0408 21:14:00.590930  9048 solver.cpp:256]     Train net output #0: loss = 7.84541 (* 1 = 7.84541 loss)
I0408 21:14:00.590937  9048 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0408 21:14:00.868094  9048 solver.cpp:240] Iteration 261, loss = 9.70501
I0408 21:14:00.868134  9048 solver.cpp:256]     Train net output #0: loss = 9.705 (* 1 = 9.705 loss)
I0408 21:14:00.868144  9048 sgd_solver.cpp:106] Iteration 261, lr = 0.01
I0408 21:14:01.143350  9048 solver.cpp:240] Iteration 262, loss = 10.9883
I0408 21:14:01.143381  9048 solver.cpp:256]     Train net output #0: loss = 10.9883 (* 1 = 10.9883 loss)
I0408 21:14:01.143389  9048 sgd_solver.cpp:106] Iteration 262, lr = 0.01
I0408 21:14:01.419751  9048 solver.cpp:240] Iteration 263, loss = 6.53266
I0408 21:14:01.419781  9048 solver.cpp:256]     Train net output #0: loss = 6.53266 (* 1 = 6.53266 loss)
I0408 21:14:01.419790  9048 sgd_solver.cpp:106] Iteration 263, lr = 0.01
I0408 21:14:01.697093  9048 solver.cpp:240] Iteration 264, loss = 10.7214
I0408 21:14:01.697131  9048 solver.cpp:256]     Train net output #0: loss = 10.7214 (* 1 = 10.7214 loss)
I0408 21:14:01.697140  9048 sgd_solver.cpp:106] Iteration 264, lr = 0.01
I0408 21:14:01.974002  9048 solver.cpp:240] Iteration 265, loss = 10.8765
I0408 21:14:01.974036  9048 solver.cpp:256]     Train net output #0: loss = 10.8765 (* 1 = 10.8765 loss)
I0408 21:14:01.974045  9048 sgd_solver.cpp:106] Iteration 265, lr = 0.01
I0408 21:14:02.250870  9048 solver.cpp:240] Iteration 266, loss = 2.40512
I0408 21:14:02.250926  9048 solver.cpp:256]     Train net output #0: loss = 2.40512 (* 1 = 2.40512 loss)
I0408 21:14:02.250936  9048 sgd_solver.cpp:106] Iteration 266, lr = 0.01
I0408 21:14:02.527122  9048 solver.cpp:240] Iteration 267, loss = 6.13471
I0408 21:14:02.527164  9048 solver.cpp:256]     Train net output #0: loss = 6.13471 (* 1 = 6.13471 loss)
I0408 21:14:02.527171  9048 sgd_solver.cpp:106] Iteration 267, lr = 0.01
I0408 21:14:02.803181  9048 solver.cpp:240] Iteration 268, loss = 11.8662
I0408 21:14:02.803227  9048 solver.cpp:256]     Train net output #0: loss = 11.8662 (* 1 = 11.8662 loss)
I0408 21:14:02.803236  9048 sgd_solver.cpp:106] Iteration 268, lr = 0.01
I0408 21:14:03.078876  9048 solver.cpp:240] Iteration 269, loss = 5.48586
I0408 21:14:03.078922  9048 solver.cpp:256]     Train net output #0: loss = 5.48585 (* 1 = 5.48585 loss)
I0408 21:14:03.078930  9048 sgd_solver.cpp:106] Iteration 269, lr = 0.01
I0408 21:14:03.355526  9048 solver.cpp:240] Iteration 270, loss = 5.36107
I0408 21:14:03.355564  9048 solver.cpp:256]     Train net output #0: loss = 5.36107 (* 1 = 5.36107 loss)
I0408 21:14:03.355574  9048 sgd_solver.cpp:106] Iteration 270, lr = 0.01
I0408 21:14:03.632421  9048 solver.cpp:240] Iteration 271, loss = 1.95246
I0408 21:14:03.632458  9048 solver.cpp:256]     Train net output #0: loss = 1.95246 (* 1 = 1.95246 loss)
I0408 21:14:03.632468  9048 sgd_solver.cpp:106] Iteration 271, lr = 0.01
I0408 21:14:03.908027  9048 solver.cpp:240] Iteration 272, loss = 15.8592
I0408 21:14:03.908062  9048 solver.cpp:256]     Train net output #0: loss = 15.8592 (* 1 = 15.8592 loss)
I0408 21:14:03.908071  9048 sgd_solver.cpp:106] Iteration 272, lr = 0.01
I0408 21:14:04.184267  9048 solver.cpp:240] Iteration 273, loss = 6.89279
I0408 21:14:04.184298  9048 solver.cpp:256]     Train net output #0: loss = 6.89278 (* 1 = 6.89278 loss)
I0408 21:14:04.184304  9048 sgd_solver.cpp:106] Iteration 273, lr = 0.01
I0408 21:14:04.460603  9048 solver.cpp:240] Iteration 274, loss = 4.92895
I0408 21:14:04.460649  9048 solver.cpp:256]     Train net output #0: loss = 4.92894 (* 1 = 4.92894 loss)
I0408 21:14:04.460657  9048 sgd_solver.cpp:106] Iteration 274, lr = 0.01
I0408 21:14:04.737102  9048 solver.cpp:240] Iteration 275, loss = 4.24469
I0408 21:14:04.737145  9048 solver.cpp:256]     Train net output #0: loss = 4.24469 (* 1 = 4.24469 loss)
I0408 21:14:04.737154  9048 sgd_solver.cpp:106] Iteration 275, lr = 0.01
I0408 21:14:05.013738  9048 solver.cpp:240] Iteration 276, loss = 7.36785
I0408 21:14:05.013782  9048 solver.cpp:256]     Train net output #0: loss = 7.36785 (* 1 = 7.36785 loss)
I0408 21:14:05.013792  9048 sgd_solver.cpp:106] Iteration 276, lr = 0.01
I0408 21:14:05.290622  9048 solver.cpp:240] Iteration 277, loss = 5.08959
I0408 21:14:05.290657  9048 solver.cpp:256]     Train net output #0: loss = 5.08959 (* 1 = 5.08959 loss)
I0408 21:14:05.290664  9048 sgd_solver.cpp:106] Iteration 277, lr = 0.01
I0408 21:14:05.567489  9048 solver.cpp:240] Iteration 278, loss = 16.8334
I0408 21:14:05.567525  9048 solver.cpp:256]     Train net output #0: loss = 16.8334 (* 1 = 16.8334 loss)
I0408 21:14:05.567534  9048 sgd_solver.cpp:106] Iteration 278, lr = 0.01
I0408 21:14:05.843566  9048 solver.cpp:240] Iteration 279, loss = 13.4243
I0408 21:14:05.843605  9048 solver.cpp:256]     Train net output #0: loss = 13.4243 (* 1 = 13.4243 loss)
I0408 21:14:05.843614  9048 sgd_solver.cpp:106] Iteration 279, lr = 0.01
I0408 21:14:06.120031  9048 solver.cpp:240] Iteration 280, loss = 12.4995
I0408 21:14:06.120065  9048 solver.cpp:256]     Train net output #0: loss = 12.4995 (* 1 = 12.4995 loss)
I0408 21:14:06.120074  9048 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0408 21:14:06.396729  9048 solver.cpp:240] Iteration 281, loss = 22.254
I0408 21:14:06.396764  9048 solver.cpp:256]     Train net output #0: loss = 22.254 (* 1 = 22.254 loss)
I0408 21:14:06.396771  9048 sgd_solver.cpp:106] Iteration 281, lr = 0.01
I0408 21:14:06.673213  9048 solver.cpp:240] Iteration 282, loss = 22.4421
I0408 21:14:06.673245  9048 solver.cpp:256]     Train net output #0: loss = 22.4421 (* 1 = 22.4421 loss)
I0408 21:14:06.673286  9048 sgd_solver.cpp:106] Iteration 282, lr = 0.01
I0408 21:14:06.949162  9048 solver.cpp:240] Iteration 283, loss = 13.2397
I0408 21:14:06.949193  9048 solver.cpp:256]     Train net output #0: loss = 13.2397 (* 1 = 13.2397 loss)
I0408 21:14:06.949201  9048 sgd_solver.cpp:106] Iteration 283, lr = 0.01
I0408 21:14:07.224897  9048 solver.cpp:240] Iteration 284, loss = 20.1354
I0408 21:14:07.224931  9048 solver.cpp:256]     Train net output #0: loss = 20.1354 (* 1 = 20.1354 loss)
I0408 21:14:07.224938  9048 sgd_solver.cpp:106] Iteration 284, lr = 0.01
I0408 21:14:07.500957  9048 solver.cpp:240] Iteration 285, loss = 13.1313
I0408 21:14:07.500988  9048 solver.cpp:256]     Train net output #0: loss = 13.1313 (* 1 = 13.1313 loss)
I0408 21:14:07.500998  9048 sgd_solver.cpp:106] Iteration 285, lr = 0.01
I0408 21:14:07.776782  9048 solver.cpp:240] Iteration 286, loss = 3.84557
I0408 21:14:07.776815  9048 solver.cpp:256]     Train net output #0: loss = 3.84556 (* 1 = 3.84556 loss)
I0408 21:14:07.776823  9048 sgd_solver.cpp:106] Iteration 286, lr = 0.01
I0408 21:14:08.053140  9048 solver.cpp:240] Iteration 287, loss = 15.2388
I0408 21:14:08.053170  9048 solver.cpp:256]     Train net output #0: loss = 15.2388 (* 1 = 15.2388 loss)
I0408 21:14:08.053179  9048 sgd_solver.cpp:106] Iteration 287, lr = 0.01
I0408 21:14:08.329648  9048 solver.cpp:240] Iteration 288, loss = 13.44
I0408 21:14:08.329681  9048 solver.cpp:256]     Train net output #0: loss = 13.44 (* 1 = 13.44 loss)
I0408 21:14:08.329689  9048 sgd_solver.cpp:106] Iteration 288, lr = 0.01
I0408 21:14:08.606284  9048 solver.cpp:240] Iteration 289, loss = 11.7818
I0408 21:14:08.606333  9048 solver.cpp:256]     Train net output #0: loss = 11.7818 (* 1 = 11.7818 loss)
I0408 21:14:08.606340  9048 sgd_solver.cpp:106] Iteration 289, lr = 0.01
I0408 21:14:08.882995  9048 solver.cpp:240] Iteration 290, loss = 10.5917
I0408 21:14:08.883036  9048 solver.cpp:256]     Train net output #0: loss = 10.5917 (* 1 = 10.5917 loss)
I0408 21:14:08.883047  9048 sgd_solver.cpp:106] Iteration 290, lr = 0.01
I0408 21:14:09.158787  9048 solver.cpp:240] Iteration 291, loss = 17.1183
I0408 21:14:09.158824  9048 solver.cpp:256]     Train net output #0: loss = 17.1183 (* 1 = 17.1183 loss)
I0408 21:14:09.158833  9048 sgd_solver.cpp:106] Iteration 291, lr = 0.01
I0408 21:14:09.435850  9048 solver.cpp:240] Iteration 292, loss = 5.5654
I0408 21:14:09.435899  9048 solver.cpp:256]     Train net output #0: loss = 5.5654 (* 1 = 5.5654 loss)
I0408 21:14:09.435909  9048 sgd_solver.cpp:106] Iteration 292, lr = 0.01
I0408 21:14:09.712414  9048 solver.cpp:240] Iteration 293, loss = 3.74874
I0408 21:14:09.712450  9048 solver.cpp:256]     Train net output #0: loss = 3.74874 (* 1 = 3.74874 loss)
I0408 21:14:09.712460  9048 sgd_solver.cpp:106] Iteration 293, lr = 0.01
I0408 21:14:09.988091  9048 solver.cpp:240] Iteration 294, loss = 3.48694
I0408 21:14:09.988122  9048 solver.cpp:256]     Train net output #0: loss = 3.48693 (* 1 = 3.48693 loss)
I0408 21:14:09.988131  9048 sgd_solver.cpp:106] Iteration 294, lr = 0.01
I0408 21:14:10.263948  9048 solver.cpp:240] Iteration 295, loss = 3.35041
I0408 21:14:10.263979  9048 solver.cpp:256]     Train net output #0: loss = 3.35041 (* 1 = 3.35041 loss)
I0408 21:14:10.263988  9048 sgd_solver.cpp:106] Iteration 295, lr = 0.01
I0408 21:14:10.540130  9048 solver.cpp:240] Iteration 296, loss = 1.54926
I0408 21:14:10.540169  9048 solver.cpp:256]     Train net output #0: loss = 1.54926 (* 1 = 1.54926 loss)
I0408 21:14:10.540177  9048 sgd_solver.cpp:106] Iteration 296, lr = 0.01
I0408 21:14:10.816615  9048 solver.cpp:240] Iteration 297, loss = 5.60983
I0408 21:14:10.816648  9048 solver.cpp:256]     Train net output #0: loss = 5.60982 (* 1 = 5.60982 loss)
I0408 21:14:10.816656  9048 sgd_solver.cpp:106] Iteration 297, lr = 0.01
I0408 21:14:11.093015  9048 solver.cpp:240] Iteration 298, loss = 5.88941
I0408 21:14:11.093045  9048 solver.cpp:256]     Train net output #0: loss = 5.88941 (* 1 = 5.88941 loss)
I0408 21:14:11.093072  9048 sgd_solver.cpp:106] Iteration 298, lr = 0.01
I0408 21:14:11.369426  9048 solver.cpp:240] Iteration 299, loss = 18.6652
I0408 21:14:11.369459  9048 solver.cpp:256]     Train net output #0: loss = 18.6652 (* 1 = 18.6652 loss)
I0408 21:14:11.369467  9048 sgd_solver.cpp:106] Iteration 299, lr = 0.01
I0408 21:14:11.645143  9048 solver.cpp:240] Iteration 300, loss = 21.0664
I0408 21:14:11.645175  9048 solver.cpp:256]     Train net output #0: loss = 21.0664 (* 1 = 21.0664 loss)
I0408 21:14:11.645184  9048 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0408 21:14:11.921808  9048 solver.cpp:240] Iteration 301, loss = 21.8449
I0408 21:14:11.921847  9048 solver.cpp:256]     Train net output #0: loss = 21.8449 (* 1 = 21.8449 loss)
I0408 21:14:11.921856  9048 sgd_solver.cpp:106] Iteration 301, lr = 0.01
I0408 21:14:12.198071  9048 solver.cpp:240] Iteration 302, loss = 23.8529
I0408 21:14:12.198104  9048 solver.cpp:256]     Train net output #0: loss = 23.8529 (* 1 = 23.8529 loss)
I0408 21:14:12.198113  9048 sgd_solver.cpp:106] Iteration 302, lr = 0.01
I0408 21:14:12.474903  9048 solver.cpp:240] Iteration 303, loss = 19.7675
I0408 21:14:12.474937  9048 solver.cpp:256]     Train net output #0: loss = 19.7675 (* 1 = 19.7675 loss)
I0408 21:14:12.474946  9048 sgd_solver.cpp:106] Iteration 303, lr = 0.01
I0408 21:14:12.751312  9048 solver.cpp:240] Iteration 304, loss = 18.7658
I0408 21:14:12.751346  9048 solver.cpp:256]     Train net output #0: loss = 18.7658 (* 1 = 18.7658 loss)
I0408 21:14:12.751354  9048 sgd_solver.cpp:106] Iteration 304, lr = 0.01
I0408 21:14:13.028025  9048 solver.cpp:240] Iteration 305, loss = 20.4391
I0408 21:14:13.028059  9048 solver.cpp:256]     Train net output #0: loss = 20.4391 (* 1 = 20.4391 loss)
I0408 21:14:13.028067  9048 sgd_solver.cpp:106] Iteration 305, lr = 0.01
I0408 21:14:13.303414  9048 solver.cpp:240] Iteration 306, loss = 22.2629
I0408 21:14:13.303452  9048 solver.cpp:256]     Train net output #0: loss = 22.2629 (* 1 = 22.2629 loss)
I0408 21:14:13.303462  9048 sgd_solver.cpp:106] Iteration 306, lr = 0.01
I0408 21:14:13.580394  9048 solver.cpp:240] Iteration 307, loss = 25.3519
I0408 21:14:13.580427  9048 solver.cpp:256]     Train net output #0: loss = 25.3519 (* 1 = 25.3519 loss)
I0408 21:14:13.580435  9048 sgd_solver.cpp:106] Iteration 307, lr = 0.01
I0408 21:14:13.857038  9048 solver.cpp:240] Iteration 308, loss = 22.452
I0408 21:14:13.857072  9048 solver.cpp:256]     Train net output #0: loss = 22.452 (* 1 = 22.452 loss)
I0408 21:14:13.857080  9048 sgd_solver.cpp:106] Iteration 308, lr = 0.01
I0408 21:14:14.132772  9048 solver.cpp:240] Iteration 309, loss = 20.8057
I0408 21:14:14.132805  9048 solver.cpp:256]     Train net output #0: loss = 20.8057 (* 1 = 20.8057 loss)
I0408 21:14:14.132813  9048 sgd_solver.cpp:106] Iteration 309, lr = 0.01
I0408 21:14:14.408390  9048 solver.cpp:240] Iteration 310, loss = 15.2735
I0408 21:14:14.408421  9048 solver.cpp:256]     Train net output #0: loss = 15.2735 (* 1 = 15.2735 loss)
I0408 21:14:14.408429  9048 sgd_solver.cpp:106] Iteration 310, lr = 0.01
I0408 21:14:14.684764  9048 solver.cpp:240] Iteration 311, loss = 13.3404
I0408 21:14:14.684798  9048 solver.cpp:256]     Train net output #0: loss = 13.3404 (* 1 = 13.3404 loss)
I0408 21:14:14.684806  9048 sgd_solver.cpp:106] Iteration 311, lr = 0.01
I0408 21:14:14.961206  9048 solver.cpp:240] Iteration 312, loss = 6.6698
I0408 21:14:14.961236  9048 solver.cpp:256]     Train net output #0: loss = 6.6698 (* 1 = 6.6698 loss)
I0408 21:14:14.961244  9048 sgd_solver.cpp:106] Iteration 312, lr = 0.01
I0408 21:14:15.238060  9048 solver.cpp:240] Iteration 313, loss = 3.12251
I0408 21:14:15.238093  9048 solver.cpp:256]     Train net output #0: loss = 3.1225 (* 1 = 3.1225 loss)
I0408 21:14:15.238101  9048 sgd_solver.cpp:106] Iteration 313, lr = 0.01
I0408 21:14:15.514974  9048 solver.cpp:240] Iteration 314, loss = 13.6642
I0408 21:14:15.515012  9048 solver.cpp:256]     Train net output #0: loss = 13.6642 (* 1 = 13.6642 loss)
I0408 21:14:15.515022  9048 sgd_solver.cpp:106] Iteration 314, lr = 0.01
I0408 21:14:15.791771  9048 solver.cpp:240] Iteration 315, loss = 20.7576
I0408 21:14:15.791805  9048 solver.cpp:256]     Train net output #0: loss = 20.7576 (* 1 = 20.7576 loss)
I0408 21:14:15.791812  9048 sgd_solver.cpp:106] Iteration 315, lr = 0.01
I0408 21:14:16.068538  9048 solver.cpp:240] Iteration 316, loss = 15.6588
I0408 21:14:16.068572  9048 solver.cpp:256]     Train net output #0: loss = 15.6588 (* 1 = 15.6588 loss)
I0408 21:14:16.068580  9048 sgd_solver.cpp:106] Iteration 316, lr = 0.01
I0408 21:14:16.345644  9048 solver.cpp:240] Iteration 317, loss = 10.5798
I0408 21:14:16.345677  9048 solver.cpp:256]     Train net output #0: loss = 10.5798 (* 1 = 10.5798 loss)
I0408 21:14:16.345685  9048 sgd_solver.cpp:106] Iteration 317, lr = 0.01
I0408 21:14:16.622076  9048 solver.cpp:240] Iteration 318, loss = 23.5466
I0408 21:14:16.622110  9048 solver.cpp:256]     Train net output #0: loss = 23.5465 (* 1 = 23.5465 loss)
I0408 21:14:16.622118  9048 sgd_solver.cpp:106] Iteration 318, lr = 0.01
I0408 21:14:16.898128  9048 solver.cpp:240] Iteration 319, loss = 17.0468
I0408 21:14:16.898160  9048 solver.cpp:256]     Train net output #0: loss = 17.0468 (* 1 = 17.0468 loss)
I0408 21:14:16.898169  9048 sgd_solver.cpp:106] Iteration 319, lr = 0.01
I0408 21:14:17.174360  9048 solver.cpp:240] Iteration 320, loss = 23.8581
I0408 21:14:17.174392  9048 solver.cpp:256]     Train net output #0: loss = 23.8581 (* 1 = 23.8581 loss)
I0408 21:14:17.174401  9048 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0408 21:14:17.450860  9048 solver.cpp:240] Iteration 321, loss = 10.3953
I0408 21:14:17.450893  9048 solver.cpp:256]     Train net output #0: loss = 10.3953 (* 1 = 10.3953 loss)
I0408 21:14:17.450901  9048 sgd_solver.cpp:106] Iteration 321, lr = 0.01
I0408 21:14:17.726670  9048 solver.cpp:240] Iteration 322, loss = 11.0701
I0408 21:14:17.726701  9048 solver.cpp:256]     Train net output #0: loss = 11.0701 (* 1 = 11.0701 loss)
I0408 21:14:17.726708  9048 sgd_solver.cpp:106] Iteration 322, lr = 0.01
I0408 21:14:18.002979  9048 solver.cpp:240] Iteration 323, loss = 23.1252
I0408 21:14:18.003024  9048 solver.cpp:256]     Train net output #0: loss = 23.1252 (* 1 = 23.1252 loss)
I0408 21:14:18.003032  9048 sgd_solver.cpp:106] Iteration 323, lr = 0.01
I0408 21:14:18.279772  9048 solver.cpp:240] Iteration 324, loss = 18.9512
I0408 21:14:18.279805  9048 solver.cpp:256]     Train net output #0: loss = 18.9512 (* 1 = 18.9512 loss)
I0408 21:14:18.279814  9048 sgd_solver.cpp:106] Iteration 324, lr = 0.01
I0408 21:14:18.555591  9048 solver.cpp:240] Iteration 325, loss = 15.0532
I0408 21:14:18.555634  9048 solver.cpp:256]     Train net output #0: loss = 15.0532 (* 1 = 15.0532 loss)
I0408 21:14:18.555641  9048 sgd_solver.cpp:106] Iteration 325, lr = 0.01
I0408 21:14:18.831981  9048 solver.cpp:240] Iteration 326, loss = 9.48721
I0408 21:14:18.832192  9048 solver.cpp:256]     Train net output #0: loss = 9.4872 (* 1 = 9.4872 loss)
I0408 21:14:18.832202  9048 sgd_solver.cpp:106] Iteration 326, lr = 0.01
I0408 21:14:19.108260  9048 solver.cpp:240] Iteration 327, loss = 9.30352
I0408 21:14:19.108294  9048 solver.cpp:256]     Train net output #0: loss = 9.30352 (* 1 = 9.30352 loss)
I0408 21:14:19.108301  9048 sgd_solver.cpp:106] Iteration 327, lr = 0.01
I0408 21:14:19.384826  9048 solver.cpp:240] Iteration 328, loss = 16.7231
I0408 21:14:19.384860  9048 solver.cpp:256]     Train net output #0: loss = 16.7231 (* 1 = 16.7231 loss)
I0408 21:14:19.384868  9048 sgd_solver.cpp:106] Iteration 328, lr = 0.01
I0408 21:14:19.661000  9048 solver.cpp:240] Iteration 329, loss = 21.6307
I0408 21:14:19.661033  9048 solver.cpp:256]     Train net output #0: loss = 21.6307 (* 1 = 21.6307 loss)
I0408 21:14:19.661041  9048 sgd_solver.cpp:106] Iteration 329, lr = 0.01
I0408 21:14:19.937433  9048 solver.cpp:240] Iteration 330, loss = 22.6142
I0408 21:14:19.937465  9048 solver.cpp:256]     Train net output #0: loss = 22.6142 (* 1 = 22.6142 loss)
I0408 21:14:19.937474  9048 sgd_solver.cpp:106] Iteration 330, lr = 0.01
I0408 21:14:20.214517  9048 solver.cpp:240] Iteration 331, loss = 20.5369
I0408 21:14:20.214550  9048 solver.cpp:256]     Train net output #0: loss = 20.5369 (* 1 = 20.5369 loss)
I0408 21:14:20.214560  9048 sgd_solver.cpp:106] Iteration 331, lr = 0.01
I0408 21:14:20.489965  9048 solver.cpp:240] Iteration 332, loss = 14.6045
I0408 21:14:20.490012  9048 solver.cpp:256]     Train net output #0: loss = 14.6045 (* 1 = 14.6045 loss)
I0408 21:14:20.490022  9048 sgd_solver.cpp:106] Iteration 332, lr = 0.01
I0408 21:14:20.766090  9048 solver.cpp:240] Iteration 333, loss = 8.84099
I0408 21:14:20.766149  9048 solver.cpp:256]     Train net output #0: loss = 8.84098 (* 1 = 8.84098 loss)
I0408 21:14:20.766156  9048 sgd_solver.cpp:106] Iteration 333, lr = 0.01
I0408 21:14:21.041959  9048 solver.cpp:240] Iteration 334, loss = 6.41384
I0408 21:14:21.041995  9048 solver.cpp:256]     Train net output #0: loss = 6.41383 (* 1 = 6.41383 loss)
I0408 21:14:21.042003  9048 sgd_solver.cpp:106] Iteration 334, lr = 0.01
I0408 21:14:21.317939  9048 solver.cpp:240] Iteration 335, loss = 4.6985
I0408 21:14:21.317972  9048 solver.cpp:256]     Train net output #0: loss = 4.69849 (* 1 = 4.69849 loss)
I0408 21:14:21.317981  9048 sgd_solver.cpp:106] Iteration 335, lr = 0.01
I0408 21:14:21.593374  9048 solver.cpp:240] Iteration 336, loss = 4.05557
I0408 21:14:21.593422  9048 solver.cpp:256]     Train net output #0: loss = 4.05556 (* 1 = 4.05556 loss)
I0408 21:14:21.593442  9048 sgd_solver.cpp:106] Iteration 336, lr = 0.01
I0408 21:14:21.869297  9048 solver.cpp:240] Iteration 337, loss = 7.36748
I0408 21:14:21.869328  9048 solver.cpp:256]     Train net output #0: loss = 7.36747 (* 1 = 7.36747 loss)
I0408 21:14:21.869336  9048 sgd_solver.cpp:106] Iteration 337, lr = 0.01
I0408 21:14:22.145958  9048 solver.cpp:240] Iteration 338, loss = 16.4989
I0408 21:14:22.145992  9048 solver.cpp:256]     Train net output #0: loss = 16.4989 (* 1 = 16.4989 loss)
I0408 21:14:22.146001  9048 sgd_solver.cpp:106] Iteration 338, lr = 0.01
I0408 21:14:22.423537  9048 solver.cpp:240] Iteration 339, loss = 22.6067
I0408 21:14:22.423579  9048 solver.cpp:256]     Train net output #0: loss = 22.6067 (* 1 = 22.6067 loss)
I0408 21:14:22.423588  9048 sgd_solver.cpp:106] Iteration 339, lr = 0.01
I0408 21:14:22.701174  9048 solver.cpp:240] Iteration 340, loss = 9.62683
I0408 21:14:22.701220  9048 solver.cpp:256]     Train net output #0: loss = 9.62682 (* 1 = 9.62682 loss)
I0408 21:14:22.701228  9048 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0408 21:14:22.977206  9048 solver.cpp:240] Iteration 341, loss = 9.70633
I0408 21:14:22.977242  9048 solver.cpp:256]     Train net output #0: loss = 9.70632 (* 1 = 9.70632 loss)
I0408 21:14:22.977250  9048 sgd_solver.cpp:106] Iteration 341, lr = 0.01
I0408 21:14:23.253506  9048 solver.cpp:240] Iteration 342, loss = 8.5563
I0408 21:14:23.253540  9048 solver.cpp:256]     Train net output #0: loss = 8.5563 (* 1 = 8.5563 loss)
I0408 21:14:23.253571  9048 sgd_solver.cpp:106] Iteration 342, lr = 0.01
I0408 21:14:23.530467  9048 solver.cpp:240] Iteration 343, loss = 4.69633
I0408 21:14:23.530499  9048 solver.cpp:256]     Train net output #0: loss = 4.69632 (* 1 = 4.69632 loss)
I0408 21:14:23.530508  9048 sgd_solver.cpp:106] Iteration 343, lr = 0.01
I0408 21:14:23.807389  9048 solver.cpp:240] Iteration 344, loss = 20.1822
I0408 21:14:23.807423  9048 solver.cpp:256]     Train net output #0: loss = 20.1822 (* 1 = 20.1822 loss)
I0408 21:14:23.807431  9048 sgd_solver.cpp:106] Iteration 344, lr = 0.01
I0408 21:14:24.083441  9048 solver.cpp:240] Iteration 345, loss = 24.7799
I0408 21:14:24.083475  9048 solver.cpp:256]     Train net output #0: loss = 24.7799 (* 1 = 24.7799 loss)
I0408 21:14:24.083484  9048 sgd_solver.cpp:106] Iteration 345, lr = 0.01
I0408 21:14:24.359333  9048 solver.cpp:240] Iteration 346, loss = 13.7562
I0408 21:14:24.359367  9048 solver.cpp:256]     Train net output #0: loss = 13.7562 (* 1 = 13.7562 loss)
I0408 21:14:24.359375  9048 sgd_solver.cpp:106] Iteration 346, lr = 0.01
I0408 21:14:24.635159  9048 solver.cpp:240] Iteration 347, loss = 13.7835
I0408 21:14:24.635195  9048 solver.cpp:256]     Train net output #0: loss = 13.7835 (* 1 = 13.7835 loss)
I0408 21:14:24.635202  9048 sgd_solver.cpp:106] Iteration 347, lr = 0.01
I0408 21:14:24.912376  9048 solver.cpp:240] Iteration 348, loss = 16.3417
I0408 21:14:24.912412  9048 solver.cpp:256]     Train net output #0: loss = 16.3417 (* 1 = 16.3417 loss)
I0408 21:14:24.912420  9048 sgd_solver.cpp:106] Iteration 348, lr = 0.01
I0408 21:14:25.188788  9048 solver.cpp:240] Iteration 349, loss = 3.48411
I0408 21:14:25.188819  9048 solver.cpp:256]     Train net output #0: loss = 3.4841 (* 1 = 3.4841 loss)
I0408 21:14:25.188827  9048 sgd_solver.cpp:106] Iteration 349, lr = 0.01
I0408 21:14:25.465152  9048 solver.cpp:240] Iteration 350, loss = 14.1189
I0408 21:14:25.465184  9048 solver.cpp:256]     Train net output #0: loss = 14.1189 (* 1 = 14.1189 loss)
I0408 21:14:25.465193  9048 sgd_solver.cpp:106] Iteration 350, lr = 0.01
I0408 21:14:25.741562  9048 solver.cpp:240] Iteration 351, loss = 13.3201
I0408 21:14:25.741600  9048 solver.cpp:256]     Train net output #0: loss = 13.3201 (* 1 = 13.3201 loss)
I0408 21:14:25.741610  9048 sgd_solver.cpp:106] Iteration 351, lr = 0.01
I0408 21:14:26.016818  9048 solver.cpp:240] Iteration 352, loss = 14.4987
I0408 21:14:26.016852  9048 solver.cpp:256]     Train net output #0: loss = 14.4987 (* 1 = 14.4987 loss)
I0408 21:14:26.016860  9048 sgd_solver.cpp:106] Iteration 352, lr = 0.01
I0408 21:14:26.294626  9048 solver.cpp:240] Iteration 353, loss = 14.9248
I0408 21:14:26.294662  9048 solver.cpp:256]     Train net output #0: loss = 14.9248 (* 1 = 14.9248 loss)
I0408 21:14:26.294670  9048 sgd_solver.cpp:106] Iteration 353, lr = 0.01
I0408 21:14:26.571831  9048 solver.cpp:240] Iteration 354, loss = 45.0683
I0408 21:14:26.571864  9048 solver.cpp:256]     Train net output #0: loss = 45.0683 (* 1 = 45.0683 loss)
I0408 21:14:26.571872  9048 sgd_solver.cpp:106] Iteration 354, lr = 0.01
I0408 21:14:26.847439  9048 solver.cpp:240] Iteration 355, loss = 29.0315
I0408 21:14:26.847481  9048 solver.cpp:256]     Train net output #0: loss = 29.0315 (* 1 = 29.0315 loss)
I0408 21:14:26.847491  9048 sgd_solver.cpp:106] Iteration 355, lr = 0.01
I0408 21:14:27.124367  9048 solver.cpp:240] Iteration 356, loss = 29.4909
I0408 21:14:27.124408  9048 solver.cpp:256]     Train net output #0: loss = 29.4909 (* 1 = 29.4909 loss)
I0408 21:14:27.124418  9048 sgd_solver.cpp:106] Iteration 356, lr = 0.01
I0408 21:14:27.401379  9048 solver.cpp:240] Iteration 357, loss = 33.5412
I0408 21:14:27.401418  9048 solver.cpp:256]     Train net output #0: loss = 33.5412 (* 1 = 33.5412 loss)
I0408 21:14:27.401429  9048 sgd_solver.cpp:106] Iteration 357, lr = 0.01
I0408 21:14:27.677268  9048 solver.cpp:240] Iteration 358, loss = 7.62417
I0408 21:14:27.677305  9048 solver.cpp:256]     Train net output #0: loss = 7.62417 (* 1 = 7.62417 loss)
I0408 21:14:27.677315  9048 sgd_solver.cpp:106] Iteration 358, lr = 0.01
I0408 21:14:27.954028  9048 solver.cpp:240] Iteration 359, loss = 9.82215
I0408 21:14:27.954061  9048 solver.cpp:256]     Train net output #0: loss = 9.82215 (* 1 = 9.82215 loss)
I0408 21:14:27.954068  9048 sgd_solver.cpp:106] Iteration 359, lr = 0.01
I0408 21:14:28.230675  9048 solver.cpp:240] Iteration 360, loss = 11.9237
I0408 21:14:28.230710  9048 solver.cpp:256]     Train net output #0: loss = 11.9237 (* 1 = 11.9237 loss)
I0408 21:14:28.230720  9048 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0408 21:14:28.506481  9048 solver.cpp:240] Iteration 361, loss = 12.3813
I0408 21:14:28.506515  9048 solver.cpp:256]     Train net output #0: loss = 12.3813 (* 1 = 12.3813 loss)
I0408 21:14:28.506522  9048 sgd_solver.cpp:106] Iteration 361, lr = 0.01
I0408 21:14:28.781334  9048 solver.cpp:240] Iteration 362, loss = 22.9485
I0408 21:14:28.781378  9048 solver.cpp:256]     Train net output #0: loss = 22.9485 (* 1 = 22.9485 loss)
I0408 21:14:28.781385  9048 sgd_solver.cpp:106] Iteration 362, lr = 0.01
I0408 21:14:29.057255  9048 solver.cpp:240] Iteration 363, loss = 17.7832
I0408 21:14:29.057297  9048 solver.cpp:256]     Train net output #0: loss = 17.7831 (* 1 = 17.7831 loss)
I0408 21:14:29.057307  9048 sgd_solver.cpp:106] Iteration 363, lr = 0.01
I0408 21:14:29.332917  9048 solver.cpp:240] Iteration 364, loss = 21.5626
I0408 21:14:29.332952  9048 solver.cpp:256]     Train net output #0: loss = 21.5626 (* 1 = 21.5626 loss)
I0408 21:14:29.332959  9048 sgd_solver.cpp:106] Iteration 364, lr = 0.01
I0408 21:14:29.608822  9048 solver.cpp:240] Iteration 365, loss = 33.1208
I0408 21:14:29.608856  9048 solver.cpp:256]     Train net output #0: loss = 33.1208 (* 1 = 33.1208 loss)
I0408 21:14:29.608865  9048 sgd_solver.cpp:106] Iteration 365, lr = 0.01
I0408 21:14:29.885606  9048 solver.cpp:240] Iteration 366, loss = 31.2413
I0408 21:14:29.885637  9048 solver.cpp:256]     Train net output #0: loss = 31.2413 (* 1 = 31.2413 loss)
I0408 21:14:29.885646  9048 sgd_solver.cpp:106] Iteration 366, lr = 0.01
I0408 21:14:30.161741  9048 solver.cpp:240] Iteration 367, loss = 16.9033
I0408 21:14:30.161773  9048 solver.cpp:256]     Train net output #0: loss = 16.9033 (* 1 = 16.9033 loss)
I0408 21:14:30.161782  9048 sgd_solver.cpp:106] Iteration 367, lr = 0.01
I0408 21:14:30.436786  9048 solver.cpp:240] Iteration 368, loss = 8.13995
I0408 21:14:30.436821  9048 solver.cpp:256]     Train net output #0: loss = 8.13995 (* 1 = 8.13995 loss)
I0408 21:14:30.436830  9048 sgd_solver.cpp:106] Iteration 368, lr = 0.01
I0408 21:14:30.711498  9048 solver.cpp:240] Iteration 369, loss = 18.6212
I0408 21:14:30.711530  9048 solver.cpp:256]     Train net output #0: loss = 18.6212 (* 1 = 18.6212 loss)
I0408 21:14:30.711539  9048 sgd_solver.cpp:106] Iteration 369, lr = 0.01
I0408 21:14:30.987531  9048 solver.cpp:240] Iteration 370, loss = 10.4055
I0408 21:14:30.987565  9048 solver.cpp:256]     Train net output #0: loss = 10.4055 (* 1 = 10.4055 loss)
I0408 21:14:30.987573  9048 sgd_solver.cpp:106] Iteration 370, lr = 0.01
I0408 21:14:31.263528  9048 solver.cpp:240] Iteration 371, loss = 18.9042
I0408 21:14:31.263561  9048 solver.cpp:256]     Train net output #0: loss = 18.9042 (* 1 = 18.9042 loss)
I0408 21:14:31.263568  9048 sgd_solver.cpp:106] Iteration 371, lr = 0.01
I0408 21:14:31.538789  9048 solver.cpp:240] Iteration 372, loss = 18.9406
I0408 21:14:31.538833  9048 solver.cpp:256]     Train net output #0: loss = 18.9406 (* 1 = 18.9406 loss)
I0408 21:14:31.538841  9048 sgd_solver.cpp:106] Iteration 372, lr = 0.01
I0408 21:14:31.814491  9048 solver.cpp:240] Iteration 373, loss = 19.0553
I0408 21:14:31.814528  9048 solver.cpp:256]     Train net output #0: loss = 19.0553 (* 1 = 19.0553 loss)
I0408 21:14:31.814549  9048 sgd_solver.cpp:106] Iteration 373, lr = 0.01
I0408 21:14:32.091837  9048 solver.cpp:240] Iteration 374, loss = 11.3529
I0408 21:14:32.091871  9048 solver.cpp:256]     Train net output #0: loss = 11.3529 (* 1 = 11.3529 loss)
I0408 21:14:32.091889  9048 sgd_solver.cpp:106] Iteration 374, lr = 0.01
I0408 21:14:32.367322  9048 solver.cpp:240] Iteration 375, loss = 25.7139
I0408 21:14:32.367379  9048 solver.cpp:256]     Train net output #0: loss = 25.7139 (* 1 = 25.7139 loss)
I0408 21:14:32.367388  9048 sgd_solver.cpp:106] Iteration 375, lr = 0.01
I0408 21:14:32.643610  9048 solver.cpp:240] Iteration 376, loss = 25.1965
I0408 21:14:32.643643  9048 solver.cpp:256]     Train net output #0: loss = 25.1965 (* 1 = 25.1965 loss)
I0408 21:14:32.643651  9048 sgd_solver.cpp:106] Iteration 376, lr = 0.01
I0408 21:14:32.920330  9048 solver.cpp:240] Iteration 377, loss = 15.6053
I0408 21:14:32.920362  9048 solver.cpp:256]     Train net output #0: loss = 15.6053 (* 1 = 15.6053 loss)
I0408 21:14:32.920372  9048 sgd_solver.cpp:106] Iteration 377, lr = 0.01
I0408 21:14:33.196086  9048 solver.cpp:240] Iteration 378, loss = 29.4441
I0408 21:14:33.196120  9048 solver.cpp:256]     Train net output #0: loss = 29.4441 (* 1 = 29.4441 loss)
I0408 21:14:33.196127  9048 sgd_solver.cpp:106] Iteration 378, lr = 0.01
I0408 21:14:33.473364  9048 solver.cpp:240] Iteration 379, loss = 8.28961
I0408 21:14:33.473395  9048 solver.cpp:256]     Train net output #0: loss = 8.28961 (* 1 = 8.28961 loss)
I0408 21:14:33.473402  9048 sgd_solver.cpp:106] Iteration 379, lr = 0.01
I0408 21:14:33.750406  9048 solver.cpp:240] Iteration 380, loss = 7.16495
I0408 21:14:33.750437  9048 solver.cpp:256]     Train net output #0: loss = 7.16494 (* 1 = 7.16494 loss)
I0408 21:14:33.750444  9048 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0408 21:14:34.026553  9048 solver.cpp:240] Iteration 381, loss = 10.0232
I0408 21:14:34.026598  9048 solver.cpp:256]     Train net output #0: loss = 10.0232 (* 1 = 10.0232 loss)
I0408 21:14:34.026607  9048 sgd_solver.cpp:106] Iteration 381, lr = 0.01
I0408 21:14:34.302996  9048 solver.cpp:240] Iteration 382, loss = 22.5806
I0408 21:14:34.303030  9048 solver.cpp:256]     Train net output #0: loss = 22.5806 (* 1 = 22.5806 loss)
I0408 21:14:34.303037  9048 sgd_solver.cpp:106] Iteration 382, lr = 0.01
I0408 21:14:34.579337  9048 solver.cpp:240] Iteration 383, loss = 14.8314
I0408 21:14:34.579372  9048 solver.cpp:256]     Train net output #0: loss = 14.8314 (* 1 = 14.8314 loss)
I0408 21:14:34.579381  9048 sgd_solver.cpp:106] Iteration 383, lr = 0.01
I0408 21:14:34.856350  9048 solver.cpp:240] Iteration 384, loss = 13.0081
I0408 21:14:34.856395  9048 solver.cpp:256]     Train net output #0: loss = 13.0081 (* 1 = 13.0081 loss)
I0408 21:14:34.856403  9048 sgd_solver.cpp:106] Iteration 384, lr = 0.01
I0408 21:14:35.132258  9048 solver.cpp:240] Iteration 385, loss = 26.0966
I0408 21:14:35.132294  9048 solver.cpp:256]     Train net output #0: loss = 26.0966 (* 1 = 26.0966 loss)
I0408 21:14:35.132303  9048 sgd_solver.cpp:106] Iteration 385, lr = 0.01
I0408 21:14:35.409116  9048 solver.cpp:240] Iteration 386, loss = 28.5345
I0408 21:14:35.409152  9048 solver.cpp:256]     Train net output #0: loss = 28.5345 (* 1 = 28.5345 loss)
I0408 21:14:35.409160  9048 sgd_solver.cpp:106] Iteration 386, lr = 0.01
I0408 21:14:35.685770  9048 solver.cpp:240] Iteration 387, loss = 13.6115
I0408 21:14:35.685806  9048 solver.cpp:256]     Train net output #0: loss = 13.6115 (* 1 = 13.6115 loss)
I0408 21:14:35.685814  9048 sgd_solver.cpp:106] Iteration 387, lr = 0.01
I0408 21:14:35.962788  9048 solver.cpp:240] Iteration 388, loss = 4.77791
I0408 21:14:35.962822  9048 solver.cpp:256]     Train net output #0: loss = 4.7779 (* 1 = 4.7779 loss)
I0408 21:14:35.962831  9048 sgd_solver.cpp:106] Iteration 388, lr = 0.01
I0408 21:14:36.240003  9048 solver.cpp:240] Iteration 389, loss = 1.83225
I0408 21:14:36.240036  9048 solver.cpp:256]     Train net output #0: loss = 1.83224 (* 1 = 1.83224 loss)
I0408 21:14:36.240042  9048 sgd_solver.cpp:106] Iteration 389, lr = 0.01
I0408 21:14:36.516108  9048 solver.cpp:240] Iteration 390, loss = 39.9241
I0408 21:14:36.516141  9048 solver.cpp:256]     Train net output #0: loss = 39.9241 (* 1 = 39.9241 loss)
I0408 21:14:36.516150  9048 sgd_solver.cpp:106] Iteration 390, lr = 0.01
I0408 21:14:36.793059  9048 solver.cpp:240] Iteration 391, loss = 26.0871
I0408 21:14:36.793090  9048 solver.cpp:256]     Train net output #0: loss = 26.087 (* 1 = 26.087 loss)
I0408 21:14:36.793121  9048 sgd_solver.cpp:106] Iteration 391, lr = 0.01
I0408 21:14:37.068250  9048 solver.cpp:240] Iteration 392, loss = 18.7715
I0408 21:14:37.068285  9048 solver.cpp:256]     Train net output #0: loss = 18.7715 (* 1 = 18.7715 loss)
I0408 21:14:37.068295  9048 sgd_solver.cpp:106] Iteration 392, lr = 0.01
I0408 21:14:37.345665  9048 solver.cpp:240] Iteration 393, loss = 38.4064
I0408 21:14:37.345715  9048 solver.cpp:256]     Train net output #0: loss = 38.4064 (* 1 = 38.4064 loss)
I0408 21:14:37.345724  9048 sgd_solver.cpp:106] Iteration 393, lr = 0.01
I0408 21:14:37.622476  9048 solver.cpp:240] Iteration 394, loss = 27.6462
I0408 21:14:37.622509  9048 solver.cpp:256]     Train net output #0: loss = 27.6462 (* 1 = 27.6462 loss)
I0408 21:14:37.622517  9048 sgd_solver.cpp:106] Iteration 394, lr = 0.01
I0408 21:14:37.897987  9048 solver.cpp:240] Iteration 395, loss = 33.9251
I0408 21:14:37.898020  9048 solver.cpp:256]     Train net output #0: loss = 33.9251 (* 1 = 33.9251 loss)
I0408 21:14:37.898028  9048 sgd_solver.cpp:106] Iteration 395, lr = 0.01
I0408 21:14:38.173547  9048 solver.cpp:240] Iteration 396, loss = 24.3436
I0408 21:14:38.173585  9048 solver.cpp:256]     Train net output #0: loss = 24.3436 (* 1 = 24.3436 loss)
I0408 21:14:38.173595  9048 sgd_solver.cpp:106] Iteration 396, lr = 0.01
I0408 21:14:38.450371  9048 solver.cpp:240] Iteration 397, loss = 26.0496
I0408 21:14:38.450402  9048 solver.cpp:256]     Train net output #0: loss = 26.0496 (* 1 = 26.0496 loss)
I0408 21:14:38.450412  9048 sgd_solver.cpp:106] Iteration 397, lr = 0.01
I0408 21:14:38.726737  9048 solver.cpp:240] Iteration 398, loss = 17.9531
I0408 21:14:38.726769  9048 solver.cpp:256]     Train net output #0: loss = 17.9531 (* 1 = 17.9531 loss)
I0408 21:14:38.726778  9048 sgd_solver.cpp:106] Iteration 398, lr = 0.01
I0408 21:14:39.003099  9048 solver.cpp:240] Iteration 399, loss = 27.7364
I0408 21:14:39.003146  9048 solver.cpp:256]     Train net output #0: loss = 27.7364 (* 1 = 27.7364 loss)
I0408 21:14:39.003155  9048 sgd_solver.cpp:106] Iteration 399, lr = 0.01
I0408 21:14:39.279501  9048 solver.cpp:240] Iteration 400, loss = 13.5871
I0408 21:14:39.279537  9048 solver.cpp:256]     Train net output #0: loss = 13.5871 (* 1 = 13.5871 loss)
I0408 21:14:39.279546  9048 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0408 21:14:39.555949  9048 solver.cpp:240] Iteration 401, loss = 8.0858
I0408 21:14:39.555982  9048 solver.cpp:256]     Train net output #0: loss = 8.08579 (* 1 = 8.08579 loss)
I0408 21:14:39.555990  9048 sgd_solver.cpp:106] Iteration 401, lr = 0.01
I0408 21:14:39.833750  9048 solver.cpp:240] Iteration 402, loss = 27.9855
I0408 21:14:39.833797  9048 solver.cpp:256]     Train net output #0: loss = 27.9855 (* 1 = 27.9855 loss)
I0408 21:14:39.833806  9048 sgd_solver.cpp:106] Iteration 402, lr = 0.01
I0408 21:14:40.110802  9048 solver.cpp:240] Iteration 403, loss = 35.1272
I0408 21:14:40.110836  9048 solver.cpp:256]     Train net output #0: loss = 35.1272 (* 1 = 35.1272 loss)
I0408 21:14:40.110844  9048 sgd_solver.cpp:106] Iteration 403, lr = 0.01
I0408 21:14:40.387199  9048 solver.cpp:240] Iteration 404, loss = 31.5228
I0408 21:14:40.387233  9048 solver.cpp:256]     Train net output #0: loss = 31.5228 (* 1 = 31.5228 loss)
I0408 21:14:40.387240  9048 sgd_solver.cpp:106] Iteration 404, lr = 0.01
I0408 21:14:40.664111  9048 solver.cpp:240] Iteration 405, loss = 37.106
I0408 21:14:40.664146  9048 solver.cpp:256]     Train net output #0: loss = 37.106 (* 1 = 37.106 loss)
I0408 21:14:40.664155  9048 sgd_solver.cpp:106] Iteration 405, lr = 0.01
I0408 21:14:40.941078  9048 solver.cpp:240] Iteration 406, loss = 28.4708
I0408 21:14:40.941114  9048 solver.cpp:256]     Train net output #0: loss = 28.4708 (* 1 = 28.4708 loss)
I0408 21:14:40.941123  9048 sgd_solver.cpp:106] Iteration 406, lr = 0.01
I0408 21:14:41.218051  9048 solver.cpp:240] Iteration 407, loss = 18.2225
I0408 21:14:41.218081  9048 solver.cpp:256]     Train net output #0: loss = 18.2225 (* 1 = 18.2225 loss)
I0408 21:14:41.218112  9048 sgd_solver.cpp:106] Iteration 407, lr = 0.01
I0408 21:14:41.494441  9048 solver.cpp:240] Iteration 408, loss = 19.2715
I0408 21:14:41.494477  9048 solver.cpp:256]     Train net output #0: loss = 19.2715 (* 1 = 19.2715 loss)
I0408 21:14:41.494487  9048 sgd_solver.cpp:106] Iteration 408, lr = 0.01
I0408 21:14:41.769577  9048 solver.cpp:240] Iteration 409, loss = 32.5311
I0408 21:14:41.769623  9048 solver.cpp:256]     Train net output #0: loss = 32.5311 (* 1 = 32.5311 loss)
I0408 21:14:41.769632  9048 sgd_solver.cpp:106] Iteration 409, lr = 0.01
I0408 21:14:42.045517  9048 solver.cpp:240] Iteration 410, loss = 22.1283
I0408 21:14:42.045563  9048 solver.cpp:256]     Train net output #0: loss = 22.1282 (* 1 = 22.1282 loss)
I0408 21:14:42.045572  9048 sgd_solver.cpp:106] Iteration 410, lr = 0.01
I0408 21:14:42.322199  9048 solver.cpp:240] Iteration 411, loss = 17.2622
I0408 21:14:42.322238  9048 solver.cpp:256]     Train net output #0: loss = 17.2622 (* 1 = 17.2622 loss)
I0408 21:14:42.322247  9048 sgd_solver.cpp:106] Iteration 411, lr = 0.01
I0408 21:14:42.598829  9048 solver.cpp:240] Iteration 412, loss = 4.94199
I0408 21:14:42.598860  9048 solver.cpp:256]     Train net output #0: loss = 4.94199 (* 1 = 4.94199 loss)
I0408 21:14:42.598868  9048 sgd_solver.cpp:106] Iteration 412, lr = 0.01
I0408 21:14:42.876020  9048 solver.cpp:240] Iteration 413, loss = 4.16635
I0408 21:14:42.876058  9048 solver.cpp:256]     Train net output #0: loss = 4.16634 (* 1 = 4.16634 loss)
I0408 21:14:42.876068  9048 sgd_solver.cpp:106] Iteration 413, lr = 0.01
I0408 21:14:43.151947  9048 solver.cpp:240] Iteration 414, loss = 9.38587
I0408 21:14:43.151979  9048 solver.cpp:256]     Train net output #0: loss = 9.38586 (* 1 = 9.38586 loss)
I0408 21:14:43.151988  9048 sgd_solver.cpp:106] Iteration 414, lr = 0.01
I0408 21:14:43.428263  9048 solver.cpp:240] Iteration 415, loss = 11.392
I0408 21:14:43.428297  9048 solver.cpp:256]     Train net output #0: loss = 11.392 (* 1 = 11.392 loss)
I0408 21:14:43.428305  9048 sgd_solver.cpp:106] Iteration 415, lr = 0.01
I0408 21:14:43.704362  9048 solver.cpp:240] Iteration 416, loss = 31.0271
I0408 21:14:43.704397  9048 solver.cpp:256]     Train net output #0: loss = 31.0271 (* 1 = 31.0271 loss)
I0408 21:14:43.704411  9048 sgd_solver.cpp:106] Iteration 416, lr = 0.01
I0408 21:14:43.980880  9048 solver.cpp:240] Iteration 417, loss = 23.2404
I0408 21:14:43.980914  9048 solver.cpp:256]     Train net output #0: loss = 23.2404 (* 1 = 23.2404 loss)
I0408 21:14:43.980922  9048 sgd_solver.cpp:106] Iteration 417, lr = 0.01
I0408 21:14:44.256767  9048 solver.cpp:240] Iteration 418, loss = 34.6691
I0408 21:14:44.256799  9048 solver.cpp:256]     Train net output #0: loss = 34.6691 (* 1 = 34.6691 loss)
I0408 21:14:44.256808  9048 sgd_solver.cpp:106] Iteration 418, lr = 0.01
I0408 21:14:44.533192  9048 solver.cpp:240] Iteration 419, loss = 15.1474
I0408 21:14:44.533226  9048 solver.cpp:256]     Train net output #0: loss = 15.1474 (* 1 = 15.1474 loss)
I0408 21:14:44.533234  9048 sgd_solver.cpp:106] Iteration 419, lr = 0.01
I0408 21:14:44.809927  9048 solver.cpp:240] Iteration 420, loss = 11.063
I0408 21:14:44.809962  9048 solver.cpp:256]     Train net output #0: loss = 11.063 (* 1 = 11.063 loss)
I0408 21:14:44.809970  9048 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0408 21:14:45.087931  9048 solver.cpp:240] Iteration 421, loss = 25.2345
I0408 21:14:45.087968  9048 solver.cpp:256]     Train net output #0: loss = 25.2345 (* 1 = 25.2345 loss)
I0408 21:14:45.087977  9048 sgd_solver.cpp:106] Iteration 421, lr = 0.01
I0408 21:14:45.364369  9048 solver.cpp:240] Iteration 422, loss = 20.5154
I0408 21:14:45.364401  9048 solver.cpp:256]     Train net output #0: loss = 20.5154 (* 1 = 20.5154 loss)
I0408 21:14:45.364410  9048 sgd_solver.cpp:106] Iteration 422, lr = 0.01
I0408 21:14:45.640519  9048 solver.cpp:240] Iteration 423, loss = 25.0972
I0408 21:14:45.640558  9048 solver.cpp:256]     Train net output #0: loss = 25.0972 (* 1 = 25.0972 loss)
I0408 21:14:45.640566  9048 sgd_solver.cpp:106] Iteration 423, lr = 0.01
I0408 21:14:45.916074  9048 solver.cpp:240] Iteration 424, loss = 22.6876
I0408 21:14:45.916107  9048 solver.cpp:256]     Train net output #0: loss = 22.6876 (* 1 = 22.6876 loss)
I0408 21:14:45.916115  9048 sgd_solver.cpp:106] Iteration 424, lr = 0.01
I0408 21:14:46.192044  9048 solver.cpp:240] Iteration 425, loss = 15.691
I0408 21:14:46.192076  9048 solver.cpp:256]     Train net output #0: loss = 15.691 (* 1 = 15.691 loss)
I0408 21:14:46.192085  9048 sgd_solver.cpp:106] Iteration 425, lr = 0.01
I0408 21:14:46.468127  9048 solver.cpp:240] Iteration 426, loss = 8.75704
I0408 21:14:46.468159  9048 solver.cpp:256]     Train net output #0: loss = 8.75704 (* 1 = 8.75704 loss)
I0408 21:14:46.468168  9048 sgd_solver.cpp:106] Iteration 426, lr = 0.01
I0408 21:14:46.744063  9048 solver.cpp:240] Iteration 427, loss = 10.5873
I0408 21:14:46.744097  9048 solver.cpp:256]     Train net output #0: loss = 10.5873 (* 1 = 10.5873 loss)
I0408 21:14:46.744105  9048 sgd_solver.cpp:106] Iteration 427, lr = 0.01
I0408 21:14:47.021028  9048 solver.cpp:240] Iteration 428, loss = 9.39744
I0408 21:14:47.021065  9048 solver.cpp:256]     Train net output #0: loss = 9.39744 (* 1 = 9.39744 loss)
I0408 21:14:47.021075  9048 sgd_solver.cpp:106] Iteration 428, lr = 0.01
I0408 21:14:47.297814  9048 solver.cpp:240] Iteration 429, loss = 8.86695
I0408 21:14:47.297847  9048 solver.cpp:256]     Train net output #0: loss = 8.86695 (* 1 = 8.86695 loss)
I0408 21:14:47.297854  9048 sgd_solver.cpp:106] Iteration 429, lr = 0.01
I0408 21:14:47.573962  9048 solver.cpp:240] Iteration 430, loss = 23.5291
I0408 21:14:47.573995  9048 solver.cpp:256]     Train net output #0: loss = 23.5291 (* 1 = 23.5291 loss)
I0408 21:14:47.574004  9048 sgd_solver.cpp:106] Iteration 430, lr = 0.01
I0408 21:14:47.850343  9048 solver.cpp:240] Iteration 431, loss = 14.7242
I0408 21:14:47.850376  9048 solver.cpp:256]     Train net output #0: loss = 14.7242 (* 1 = 14.7242 loss)
I0408 21:14:47.850384  9048 sgd_solver.cpp:106] Iteration 431, lr = 0.01
I0408 21:14:48.126777  9048 solver.cpp:240] Iteration 432, loss = 3.34282
I0408 21:14:48.126811  9048 solver.cpp:256]     Train net output #0: loss = 3.34282 (* 1 = 3.34282 loss)
I0408 21:14:48.126818  9048 sgd_solver.cpp:106] Iteration 432, lr = 0.01
I0408 21:14:48.402943  9048 solver.cpp:240] Iteration 433, loss = 9.98488
I0408 21:14:48.402978  9048 solver.cpp:256]     Train net output #0: loss = 9.98488 (* 1 = 9.98488 loss)
I0408 21:14:48.402987  9048 sgd_solver.cpp:106] Iteration 433, lr = 0.01
I0408 21:14:48.679133  9048 solver.cpp:240] Iteration 434, loss = 10.7296
I0408 21:14:48.679168  9048 solver.cpp:256]     Train net output #0: loss = 10.7296 (* 1 = 10.7296 loss)
I0408 21:14:48.679177  9048 sgd_solver.cpp:106] Iteration 434, lr = 0.01
I0408 21:14:48.953451  9048 solver.cpp:240] Iteration 435, loss = 20.3895
I0408 21:14:48.953644  9048 solver.cpp:256]     Train net output #0: loss = 20.3895 (* 1 = 20.3895 loss)
I0408 21:14:48.953654  9048 sgd_solver.cpp:106] Iteration 435, lr = 0.01
I0408 21:14:49.228972  9048 solver.cpp:240] Iteration 436, loss = 14.5051
I0408 21:14:49.229003  9048 solver.cpp:256]     Train net output #0: loss = 14.5051 (* 1 = 14.5051 loss)
I0408 21:14:49.229012  9048 sgd_solver.cpp:106] Iteration 436, lr = 0.01
I0408 21:14:49.505043  9048 solver.cpp:240] Iteration 437, loss = 25.4006
I0408 21:14:49.505075  9048 solver.cpp:256]     Train net output #0: loss = 25.4006 (* 1 = 25.4006 loss)
I0408 21:14:49.505084  9048 sgd_solver.cpp:106] Iteration 437, lr = 0.01
I0408 21:14:49.781100  9048 solver.cpp:240] Iteration 438, loss = 32.1939
I0408 21:14:49.781136  9048 solver.cpp:256]     Train net output #0: loss = 32.1939 (* 1 = 32.1939 loss)
I0408 21:14:49.781144  9048 sgd_solver.cpp:106] Iteration 438, lr = 0.01
I0408 21:14:50.057166  9048 solver.cpp:240] Iteration 439, loss = 10.5922
I0408 21:14:50.057199  9048 solver.cpp:256]     Train net output #0: loss = 10.5922 (* 1 = 10.5922 loss)
I0408 21:14:50.057209  9048 sgd_solver.cpp:106] Iteration 439, lr = 0.01
I0408 21:14:50.333940  9048 solver.cpp:240] Iteration 440, loss = 12.0272
I0408 21:14:50.333979  9048 solver.cpp:256]     Train net output #0: loss = 12.0272 (* 1 = 12.0272 loss)
I0408 21:14:50.333988  9048 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0408 21:14:50.610412  9048 solver.cpp:240] Iteration 441, loss = 17.0823
I0408 21:14:50.610450  9048 solver.cpp:256]     Train net output #0: loss = 17.0823 (* 1 = 17.0823 loss)
I0408 21:14:50.610458  9048 sgd_solver.cpp:106] Iteration 441, lr = 0.01
I0408 21:14:50.887970  9048 solver.cpp:240] Iteration 442, loss = 27.4411
I0408 21:14:50.888005  9048 solver.cpp:256]     Train net output #0: loss = 27.441 (* 1 = 27.441 loss)
I0408 21:14:50.888012  9048 sgd_solver.cpp:106] Iteration 442, lr = 0.01
I0408 21:14:51.165230  9048 solver.cpp:240] Iteration 443, loss = 33.7761
I0408 21:14:51.165264  9048 solver.cpp:256]     Train net output #0: loss = 33.7761 (* 1 = 33.7761 loss)
I0408 21:14:51.165272  9048 sgd_solver.cpp:106] Iteration 443, lr = 0.01
I0408 21:14:51.442066  9048 solver.cpp:240] Iteration 444, loss = 19.1885
I0408 21:14:51.442101  9048 solver.cpp:256]     Train net output #0: loss = 19.1885 (* 1 = 19.1885 loss)
I0408 21:14:51.442109  9048 sgd_solver.cpp:106] Iteration 444, lr = 0.01
I0408 21:14:51.718055  9048 solver.cpp:240] Iteration 445, loss = 27.9889
I0408 21:14:51.718088  9048 solver.cpp:256]     Train net output #0: loss = 27.9889 (* 1 = 27.9889 loss)
I0408 21:14:51.718096  9048 sgd_solver.cpp:106] Iteration 445, lr = 0.01
I0408 21:14:51.995404  9048 solver.cpp:240] Iteration 446, loss = 14.1605
I0408 21:14:51.995437  9048 solver.cpp:256]     Train net output #0: loss = 14.1605 (* 1 = 14.1605 loss)
I0408 21:14:51.995446  9048 sgd_solver.cpp:106] Iteration 446, lr = 0.01
I0408 21:14:52.270818  9048 solver.cpp:240] Iteration 447, loss = 11.7427
I0408 21:14:52.270849  9048 solver.cpp:256]     Train net output #0: loss = 11.7427 (* 1 = 11.7427 loss)
I0408 21:14:52.270859  9048 sgd_solver.cpp:106] Iteration 447, lr = 0.01
I0408 21:14:52.547788  9048 solver.cpp:240] Iteration 448, loss = 18.6727
I0408 21:14:52.547821  9048 solver.cpp:256]     Train net output #0: loss = 18.6727 (* 1 = 18.6727 loss)
I0408 21:14:52.547829  9048 sgd_solver.cpp:106] Iteration 448, lr = 0.01
I0408 21:14:52.823745  9048 solver.cpp:240] Iteration 449, loss = 24.4712
I0408 21:14:52.823779  9048 solver.cpp:256]     Train net output #0: loss = 24.4712 (* 1 = 24.4712 loss)
I0408 21:14:52.823788  9048 sgd_solver.cpp:106] Iteration 449, lr = 0.01
I0408 21:14:53.099678  9048 solver.cpp:240] Iteration 450, loss = 21.4423
I0408 21:14:53.099722  9048 solver.cpp:256]     Train net output #0: loss = 21.4423 (* 1 = 21.4423 loss)
I0408 21:14:53.099731  9048 sgd_solver.cpp:106] Iteration 450, lr = 0.01
I0408 21:14:53.375924  9048 solver.cpp:240] Iteration 451, loss = 29.7145
I0408 21:14:53.375958  9048 solver.cpp:256]     Train net output #0: loss = 29.7145 (* 1 = 29.7145 loss)
I0408 21:14:53.375988  9048 sgd_solver.cpp:106] Iteration 451, lr = 0.01
I0408 21:14:53.652009  9048 solver.cpp:240] Iteration 452, loss = 14.1728
I0408 21:14:53.652041  9048 solver.cpp:256]     Train net output #0: loss = 14.1728 (* 1 = 14.1728 loss)
I0408 21:14:53.652048  9048 sgd_solver.cpp:106] Iteration 452, lr = 0.01
I0408 21:14:53.928051  9048 solver.cpp:240] Iteration 453, loss = 2.82454
I0408 21:14:53.928083  9048 solver.cpp:256]     Train net output #0: loss = 2.82453 (* 1 = 2.82453 loss)
I0408 21:14:53.928091  9048 sgd_solver.cpp:106] Iteration 453, lr = 0.01
I0408 21:14:54.203943  9048 solver.cpp:240] Iteration 454, loss = 1.61368
I0408 21:14:54.203974  9048 solver.cpp:256]     Train net output #0: loss = 1.61368 (* 1 = 1.61368 loss)
I0408 21:14:54.203981  9048 sgd_solver.cpp:106] Iteration 454, lr = 0.01
I0408 21:14:54.479187  9048 solver.cpp:240] Iteration 455, loss = 1.83899
I0408 21:14:54.479234  9048 solver.cpp:256]     Train net output #0: loss = 1.83899 (* 1 = 1.83899 loss)
I0408 21:14:54.479243  9048 sgd_solver.cpp:106] Iteration 455, lr = 0.01
I0408 21:14:54.755347  9048 solver.cpp:240] Iteration 456, loss = 19.2911
I0408 21:14:54.755380  9048 solver.cpp:256]     Train net output #0: loss = 19.2911 (* 1 = 19.2911 loss)
I0408 21:14:54.755388  9048 sgd_solver.cpp:106] Iteration 456, lr = 0.01
I0408 21:14:55.031711  9048 solver.cpp:240] Iteration 457, loss = 18.9044
I0408 21:14:55.031755  9048 solver.cpp:256]     Train net output #0: loss = 18.9044 (* 1 = 18.9044 loss)
I0408 21:14:55.031764  9048 sgd_solver.cpp:106] Iteration 457, lr = 0.01
I0408 21:14:55.307765  9048 solver.cpp:240] Iteration 458, loss = 14.0776
I0408 21:14:55.307797  9048 solver.cpp:256]     Train net output #0: loss = 14.0776 (* 1 = 14.0776 loss)
I0408 21:14:55.307806  9048 sgd_solver.cpp:106] Iteration 458, lr = 0.01
I0408 21:14:55.583398  9048 solver.cpp:240] Iteration 459, loss = 31.3022
I0408 21:14:55.583442  9048 solver.cpp:256]     Train net output #0: loss = 31.3022 (* 1 = 31.3022 loss)
I0408 21:14:55.583451  9048 sgd_solver.cpp:106] Iteration 459, lr = 0.01
I0408 21:14:55.860992  9048 solver.cpp:240] Iteration 460, loss = 42.7416
I0408 21:14:55.861027  9048 solver.cpp:256]     Train net output #0: loss = 42.7416 (* 1 = 42.7416 loss)
I0408 21:14:55.861034  9048 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0408 21:14:56.137392  9048 solver.cpp:240] Iteration 461, loss = 34.5501
I0408 21:14:56.137423  9048 solver.cpp:256]     Train net output #0: loss = 34.5501 (* 1 = 34.5501 loss)
I0408 21:14:56.137431  9048 sgd_solver.cpp:106] Iteration 461, lr = 0.01
I0408 21:14:56.413646  9048 solver.cpp:240] Iteration 462, loss = 4.22497
I0408 21:14:56.413681  9048 solver.cpp:256]     Train net output #0: loss = 4.22497 (* 1 = 4.22497 loss)
I0408 21:14:56.413688  9048 sgd_solver.cpp:106] Iteration 462, lr = 0.01
I0408 21:14:56.689991  9048 solver.cpp:240] Iteration 463, loss = 3.77379
I0408 21:14:56.690023  9048 solver.cpp:256]     Train net output #0: loss = 3.77379 (* 1 = 3.77379 loss)
I0408 21:14:56.690031  9048 sgd_solver.cpp:106] Iteration 463, lr = 0.01
I0408 21:14:56.966183  9048 solver.cpp:240] Iteration 464, loss = 22.1912
I0408 21:14:56.966215  9048 solver.cpp:256]     Train net output #0: loss = 22.1912 (* 1 = 22.1912 loss)
I0408 21:14:56.966228  9048 sgd_solver.cpp:106] Iteration 464, lr = 0.01
I0408 21:14:57.243319  9048 solver.cpp:240] Iteration 465, loss = 14.2872
I0408 21:14:57.243352  9048 solver.cpp:256]     Train net output #0: loss = 14.2872 (* 1 = 14.2872 loss)
I0408 21:14:57.243361  9048 sgd_solver.cpp:106] Iteration 465, lr = 0.01
I0408 21:14:57.520390  9048 solver.cpp:240] Iteration 466, loss = 5.41853
I0408 21:14:57.520421  9048 solver.cpp:256]     Train net output #0: loss = 5.41853 (* 1 = 5.41853 loss)
I0408 21:14:57.520427  9048 sgd_solver.cpp:106] Iteration 466, lr = 0.01
I0408 21:14:57.796653  9048 solver.cpp:240] Iteration 467, loss = 12.2303
I0408 21:14:57.796692  9048 solver.cpp:256]     Train net output #0: loss = 12.2303 (* 1 = 12.2303 loss)
I0408 21:14:57.796700  9048 sgd_solver.cpp:106] Iteration 467, lr = 0.01
I0408 21:14:58.073153  9048 solver.cpp:240] Iteration 468, loss = 17.8258
I0408 21:14:58.073204  9048 solver.cpp:256]     Train net output #0: loss = 17.8258 (* 1 = 17.8258 loss)
I0408 21:14:58.073212  9048 sgd_solver.cpp:106] Iteration 468, lr = 0.01
I0408 21:14:58.349390  9048 solver.cpp:240] Iteration 469, loss = 23.2917
I0408 21:14:58.349422  9048 solver.cpp:256]     Train net output #0: loss = 23.2917 (* 1 = 23.2917 loss)
I0408 21:14:58.349431  9048 sgd_solver.cpp:106] Iteration 469, lr = 0.01
I0408 21:14:58.625550  9048 solver.cpp:240] Iteration 470, loss = 14.0212
I0408 21:14:58.625596  9048 solver.cpp:256]     Train net output #0: loss = 14.0212 (* 1 = 14.0212 loss)
I0408 21:14:58.625603  9048 sgd_solver.cpp:106] Iteration 470, lr = 0.01
I0408 21:14:58.901520  9048 solver.cpp:240] Iteration 471, loss = 6.90472
I0408 21:14:58.901552  9048 solver.cpp:256]     Train net output #0: loss = 6.90471 (* 1 = 6.90471 loss)
I0408 21:14:58.901561  9048 sgd_solver.cpp:106] Iteration 471, lr = 0.01
I0408 21:14:59.177247  9048 solver.cpp:240] Iteration 472, loss = 21.2785
I0408 21:14:59.177290  9048 solver.cpp:256]     Train net output #0: loss = 21.2785 (* 1 = 21.2785 loss)
I0408 21:14:59.177299  9048 sgd_solver.cpp:106] Iteration 472, lr = 0.01
I0408 21:14:59.453027  9048 solver.cpp:240] Iteration 473, loss = 12.0305
I0408 21:14:59.453066  9048 solver.cpp:256]     Train net output #0: loss = 12.0305 (* 1 = 12.0305 loss)
I0408 21:14:59.453075  9048 sgd_solver.cpp:106] Iteration 473, lr = 0.01
I0408 21:14:59.728917  9048 solver.cpp:240] Iteration 474, loss = 3.54217
I0408 21:14:59.728947  9048 solver.cpp:256]     Train net output #0: loss = 3.54216 (* 1 = 3.54216 loss)
I0408 21:14:59.728955  9048 sgd_solver.cpp:106] Iteration 474, lr = 0.01
I0408 21:15:00.003533  9048 solver.cpp:240] Iteration 475, loss = 16.7008
I0408 21:15:00.003566  9048 solver.cpp:256]     Train net output #0: loss = 16.7008 (* 1 = 16.7008 loss)
I0408 21:15:00.003576  9048 sgd_solver.cpp:106] Iteration 475, lr = 0.01
I0408 21:15:00.279832  9048 solver.cpp:240] Iteration 476, loss = 11.5184
I0408 21:15:00.279867  9048 solver.cpp:256]     Train net output #0: loss = 11.5184 (* 1 = 11.5184 loss)
I0408 21:15:00.279875  9048 sgd_solver.cpp:106] Iteration 476, lr = 0.01
I0408 21:15:00.555187  9048 solver.cpp:240] Iteration 477, loss = 20.2892
I0408 21:15:00.555220  9048 solver.cpp:256]     Train net output #0: loss = 20.2892 (* 1 = 20.2892 loss)
I0408 21:15:00.555228  9048 sgd_solver.cpp:106] Iteration 477, lr = 0.01
I0408 21:15:00.831256  9048 solver.cpp:240] Iteration 478, loss = 12.8043
I0408 21:15:00.831307  9048 solver.cpp:256]     Train net output #0: loss = 12.8042 (* 1 = 12.8042 loss)
I0408 21:15:00.831316  9048 sgd_solver.cpp:106] Iteration 478, lr = 0.01
I0408 21:15:01.108124  9048 solver.cpp:240] Iteration 479, loss = 10.458
I0408 21:15:01.108156  9048 solver.cpp:256]     Train net output #0: loss = 10.458 (* 1 = 10.458 loss)
I0408 21:15:01.108165  9048 sgd_solver.cpp:106] Iteration 479, lr = 0.01
I0408 21:15:01.383949  9048 solver.cpp:240] Iteration 480, loss = 24.3586
I0408 21:15:01.383982  9048 solver.cpp:256]     Train net output #0: loss = 24.3586 (* 1 = 24.3586 loss)
I0408 21:15:01.383991  9048 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0408 21:15:01.659332  9048 solver.cpp:240] Iteration 481, loss = 3.24346
I0408 21:15:01.659363  9048 solver.cpp:256]     Train net output #0: loss = 3.24345 (* 1 = 3.24345 loss)
I0408 21:15:01.659370  9048 sgd_solver.cpp:106] Iteration 481, lr = 0.01
I0408 21:15:01.933440  9048 solver.cpp:240] Iteration 482, loss = 19.593
I0408 21:15:01.933476  9048 solver.cpp:256]     Train net output #0: loss = 19.593 (* 1 = 19.593 loss)
I0408 21:15:01.933485  9048 sgd_solver.cpp:106] Iteration 482, lr = 0.01
I0408 21:15:02.209502  9048 solver.cpp:240] Iteration 483, loss = 18.7386
I0408 21:15:02.209535  9048 solver.cpp:256]     Train net output #0: loss = 18.7386 (* 1 = 18.7386 loss)
I0408 21:15:02.209543  9048 sgd_solver.cpp:106] Iteration 483, lr = 0.01
I0408 21:15:02.484027  9048 solver.cpp:240] Iteration 484, loss = 13.2057
I0408 21:15:02.484086  9048 solver.cpp:256]     Train net output #0: loss = 13.2057 (* 1 = 13.2057 loss)
I0408 21:15:02.484096  9048 sgd_solver.cpp:106] Iteration 484, lr = 0.01
I0408 21:15:02.760179  9048 solver.cpp:240] Iteration 485, loss = 12.0916
I0408 21:15:02.760226  9048 solver.cpp:256]     Train net output #0: loss = 12.0916 (* 1 = 12.0916 loss)
I0408 21:15:02.760233  9048 sgd_solver.cpp:106] Iteration 485, lr = 0.01
I0408 21:15:03.035392  9048 solver.cpp:240] Iteration 486, loss = 6.04586
I0408 21:15:03.035423  9048 solver.cpp:256]     Train net output #0: loss = 6.04586 (* 1 = 6.04586 loss)
I0408 21:15:03.035430  9048 sgd_solver.cpp:106] Iteration 486, lr = 0.01
I0408 21:15:03.311686  9048 solver.cpp:240] Iteration 487, loss = 20.334
I0408 21:15:03.311720  9048 solver.cpp:256]     Train net output #0: loss = 20.334 (* 1 = 20.334 loss)
I0408 21:15:03.311729  9048 sgd_solver.cpp:106] Iteration 487, lr = 0.01
I0408 21:15:03.587966  9048 solver.cpp:240] Iteration 488, loss = 12.0769
I0408 21:15:03.587999  9048 solver.cpp:256]     Train net output #0: loss = 12.0769 (* 1 = 12.0769 loss)
I0408 21:15:03.588007  9048 sgd_solver.cpp:106] Iteration 488, lr = 0.01
I0408 21:15:03.864399  9048 solver.cpp:240] Iteration 489, loss = 16.0457
I0408 21:15:03.864442  9048 solver.cpp:256]     Train net output #0: loss = 16.0457 (* 1 = 16.0457 loss)
I0408 21:15:03.864451  9048 sgd_solver.cpp:106] Iteration 489, lr = 0.01
I0408 21:15:04.141458  9048 solver.cpp:240] Iteration 490, loss = 12.3778
I0408 21:15:04.141491  9048 solver.cpp:256]     Train net output #0: loss = 12.3778 (* 1 = 12.3778 loss)
I0408 21:15:04.141499  9048 sgd_solver.cpp:106] Iteration 490, lr = 0.01
I0408 21:15:04.418611  9048 solver.cpp:240] Iteration 491, loss = 21.7907
I0408 21:15:04.418648  9048 solver.cpp:256]     Train net output #0: loss = 21.7907 (* 1 = 21.7907 loss)
I0408 21:15:04.418658  9048 sgd_solver.cpp:106] Iteration 491, lr = 0.01
I0408 21:15:04.695037  9048 solver.cpp:240] Iteration 492, loss = 16.2643
I0408 21:15:04.695071  9048 solver.cpp:256]     Train net output #0: loss = 16.2643 (* 1 = 16.2643 loss)
I0408 21:15:04.695080  9048 sgd_solver.cpp:106] Iteration 492, lr = 0.01
I0408 21:15:04.971556  9048 solver.cpp:240] Iteration 493, loss = 17.2543
I0408 21:15:04.971590  9048 solver.cpp:256]     Train net output #0: loss = 17.2542 (* 1 = 17.2542 loss)
I0408 21:15:04.971598  9048 sgd_solver.cpp:106] Iteration 493, lr = 0.01
I0408 21:15:05.247989  9048 solver.cpp:240] Iteration 494, loss = 4.19338
I0408 21:15:05.248020  9048 solver.cpp:256]     Train net output #0: loss = 4.19337 (* 1 = 4.19337 loss)
I0408 21:15:05.248028  9048 sgd_solver.cpp:106] Iteration 494, lr = 0.01
I0408 21:15:05.523823  9048 solver.cpp:240] Iteration 495, loss = 8.93836
I0408 21:15:05.523859  9048 solver.cpp:256]     Train net output #0: loss = 8.93835 (* 1 = 8.93835 loss)
I0408 21:15:05.523867  9048 sgd_solver.cpp:106] Iteration 495, lr = 0.01
I0408 21:15:05.800212  9048 solver.cpp:240] Iteration 496, loss = 4.75338
I0408 21:15:05.800247  9048 solver.cpp:256]     Train net output #0: loss = 4.75338 (* 1 = 4.75338 loss)
I0408 21:15:05.800256  9048 sgd_solver.cpp:106] Iteration 496, lr = 0.01
I0408 21:15:06.076625  9048 solver.cpp:240] Iteration 497, loss = 28.3818
I0408 21:15:06.076658  9048 solver.cpp:256]     Train net output #0: loss = 28.3818 (* 1 = 28.3818 loss)
I0408 21:15:06.076668  9048 sgd_solver.cpp:106] Iteration 497, lr = 0.01
I0408 21:15:06.352646  9048 solver.cpp:240] Iteration 498, loss = 24.8171
I0408 21:15:06.352677  9048 solver.cpp:256]     Train net output #0: loss = 24.8171 (* 1 = 24.8171 loss)
I0408 21:15:06.352690  9048 sgd_solver.cpp:106] Iteration 498, lr = 0.01
I0408 21:15:06.628463  9048 solver.cpp:240] Iteration 499, loss = 16.4964
I0408 21:15:06.628509  9048 solver.cpp:256]     Train net output #0: loss = 16.4964 (* 1 = 16.4964 loss)
I0408 21:15:06.628516  9048 sgd_solver.cpp:106] Iteration 499, lr = 0.01
I0408 21:15:06.904994  9048 solver.cpp:240] Iteration 500, loss = 17.0281
I0408 21:15:06.905030  9048 solver.cpp:256]     Train net output #0: loss = 17.0281 (* 1 = 17.0281 loss)
I0408 21:15:06.905059  9048 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0408 21:15:07.179970  9048 solver.cpp:240] Iteration 501, loss = 20.0074
I0408 21:15:07.180006  9048 solver.cpp:256]     Train net output #0: loss = 20.0074 (* 1 = 20.0074 loss)
I0408 21:15:07.180016  9048 sgd_solver.cpp:106] Iteration 501, lr = 0.01
I0408 21:15:07.455842  9048 solver.cpp:240] Iteration 502, loss = 22.6529
I0408 21:15:07.455896  9048 solver.cpp:256]     Train net output #0: loss = 22.6529 (* 1 = 22.6529 loss)
I0408 21:15:07.455905  9048 sgd_solver.cpp:106] Iteration 502, lr = 0.01
I0408 21:15:07.732273  9048 solver.cpp:240] Iteration 503, loss = 13.1044
I0408 21:15:07.732307  9048 solver.cpp:256]     Train net output #0: loss = 13.1044 (* 1 = 13.1044 loss)
I0408 21:15:07.732316  9048 sgd_solver.cpp:106] Iteration 503, lr = 0.01
I0408 21:15:08.008188  9048 solver.cpp:240] Iteration 504, loss = 12.8182
I0408 21:15:08.008242  9048 solver.cpp:256]     Train net output #0: loss = 12.8182 (* 1 = 12.8182 loss)
I0408 21:15:08.008251  9048 sgd_solver.cpp:106] Iteration 504, lr = 0.01
I0408 21:15:08.284027  9048 solver.cpp:240] Iteration 505, loss = 7.02014
I0408 21:15:08.284059  9048 solver.cpp:256]     Train net output #0: loss = 7.02014 (* 1 = 7.02014 loss)
I0408 21:15:08.284066  9048 sgd_solver.cpp:106] Iteration 505, lr = 0.01
I0408 21:15:08.560616  9048 solver.cpp:240] Iteration 506, loss = 7.83954
I0408 21:15:08.560659  9048 solver.cpp:256]     Train net output #0: loss = 7.83954 (* 1 = 7.83954 loss)
I0408 21:15:08.560667  9048 sgd_solver.cpp:106] Iteration 506, lr = 0.01
I0408 21:15:08.836416  9048 solver.cpp:240] Iteration 507, loss = 4.17228
I0408 21:15:08.836457  9048 solver.cpp:256]     Train net output #0: loss = 4.17227 (* 1 = 4.17227 loss)
I0408 21:15:08.836465  9048 sgd_solver.cpp:106] Iteration 507, lr = 0.01
I0408 21:15:09.112431  9048 solver.cpp:240] Iteration 508, loss = 22.8999
I0408 21:15:09.112476  9048 solver.cpp:256]     Train net output #0: loss = 22.8999 (* 1 = 22.8999 loss)
I0408 21:15:09.112484  9048 sgd_solver.cpp:106] Iteration 508, lr = 0.01
I0408 21:15:09.388536  9048 solver.cpp:240] Iteration 509, loss = 13.3639
I0408 21:15:09.388571  9048 solver.cpp:256]     Train net output #0: loss = 13.3639 (* 1 = 13.3639 loss)
I0408 21:15:09.388579  9048 sgd_solver.cpp:106] Iteration 509, lr = 0.01
I0408 21:15:09.664362  9048 solver.cpp:240] Iteration 510, loss = 17.6588
I0408 21:15:09.664394  9048 solver.cpp:256]     Train net output #0: loss = 17.6588 (* 1 = 17.6588 loss)
I0408 21:15:09.664402  9048 sgd_solver.cpp:106] Iteration 510, lr = 0.01
I0408 21:15:09.940666  9048 solver.cpp:240] Iteration 511, loss = 15.4202
I0408 21:15:09.940703  9048 solver.cpp:256]     Train net output #0: loss = 15.4202 (* 1 = 15.4202 loss)
I0408 21:15:09.940712  9048 sgd_solver.cpp:106] Iteration 511, lr = 0.01
I0408 21:15:10.216526  9048 solver.cpp:240] Iteration 512, loss = 12.7743
I0408 21:15:10.216567  9048 solver.cpp:256]     Train net output #0: loss = 12.7743 (* 1 = 12.7743 loss)
I0408 21:15:10.216575  9048 sgd_solver.cpp:106] Iteration 512, lr = 0.01
I0408 21:15:10.492574  9048 solver.cpp:240] Iteration 513, loss = 12.9868
I0408 21:15:10.492619  9048 solver.cpp:256]     Train net output #0: loss = 12.9868 (* 1 = 12.9868 loss)
I0408 21:15:10.492629  9048 sgd_solver.cpp:106] Iteration 513, lr = 0.01
I0408 21:15:10.768203  9048 solver.cpp:240] Iteration 514, loss = 16.9449
I0408 21:15:10.768237  9048 solver.cpp:256]     Train net output #0: loss = 16.9449 (* 1 = 16.9449 loss)
I0408 21:15:10.768245  9048 sgd_solver.cpp:106] Iteration 514, lr = 0.01
I0408 21:15:11.043591  9048 solver.cpp:240] Iteration 515, loss = 33.5227
I0408 21:15:11.043625  9048 solver.cpp:256]     Train net output #0: loss = 33.5227 (* 1 = 33.5227 loss)
I0408 21:15:11.043634  9048 sgd_solver.cpp:106] Iteration 515, lr = 0.01
I0408 21:15:11.319301  9048 solver.cpp:240] Iteration 516, loss = 8.47856
I0408 21:15:11.319355  9048 solver.cpp:256]     Train net output #0: loss = 8.47856 (* 1 = 8.47856 loss)
I0408 21:15:11.319388  9048 sgd_solver.cpp:106] Iteration 516, lr = 0.01
I0408 21:15:11.595603  9048 solver.cpp:240] Iteration 517, loss = 30.6859
I0408 21:15:11.595638  9048 solver.cpp:256]     Train net output #0: loss = 30.6859 (* 1 = 30.6859 loss)
I0408 21:15:11.595646  9048 sgd_solver.cpp:106] Iteration 517, lr = 0.01
I0408 21:15:11.871455  9048 solver.cpp:240] Iteration 518, loss = 15.2188
I0408 21:15:11.871490  9048 solver.cpp:256]     Train net output #0: loss = 15.2188 (* 1 = 15.2188 loss)
I0408 21:15:11.871497  9048 sgd_solver.cpp:106] Iteration 518, lr = 0.01
I0408 21:15:12.147022  9048 solver.cpp:240] Iteration 519, loss = 17.3178
I0408 21:15:12.147073  9048 solver.cpp:256]     Train net output #0: loss = 17.3178 (* 1 = 17.3178 loss)
I0408 21:15:12.147083  9048 sgd_solver.cpp:106] Iteration 519, lr = 0.01
I0408 21:15:12.423637  9048 solver.cpp:240] Iteration 520, loss = 25.658
I0408 21:15:12.423672  9048 solver.cpp:256]     Train net output #0: loss = 25.658 (* 1 = 25.658 loss)
I0408 21:15:12.423681  9048 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0408 21:15:12.700248  9048 solver.cpp:240] Iteration 521, loss = 30.3727
I0408 21:15:12.700280  9048 solver.cpp:256]     Train net output #0: loss = 30.3727 (* 1 = 30.3727 loss)
I0408 21:15:12.700289  9048 sgd_solver.cpp:106] Iteration 521, lr = 0.01
I0408 21:15:12.976282  9048 solver.cpp:240] Iteration 522, loss = 32.6936
I0408 21:15:12.976316  9048 solver.cpp:256]     Train net output #0: loss = 32.6936 (* 1 = 32.6936 loss)
I0408 21:15:12.976325  9048 sgd_solver.cpp:106] Iteration 522, lr = 0.01
I0408 21:15:13.253280  9048 solver.cpp:240] Iteration 523, loss = 9.15288
I0408 21:15:13.253310  9048 solver.cpp:256]     Train net output #0: loss = 9.15287 (* 1 = 9.15287 loss)
I0408 21:15:13.253319  9048 sgd_solver.cpp:106] Iteration 523, lr = 0.01
I0408 21:15:13.528446  9048 solver.cpp:240] Iteration 524, loss = 5.83825
I0408 21:15:13.528482  9048 solver.cpp:256]     Train net output #0: loss = 5.83825 (* 1 = 5.83825 loss)
I0408 21:15:13.528491  9048 sgd_solver.cpp:106] Iteration 524, lr = 0.01
I0408 21:15:13.804096  9048 solver.cpp:240] Iteration 525, loss = 19.1049
I0408 21:15:13.804131  9048 solver.cpp:256]     Train net output #0: loss = 19.1049 (* 1 = 19.1049 loss)
I0408 21:15:13.804138  9048 sgd_solver.cpp:106] Iteration 525, lr = 0.01
I0408 21:15:14.078697  9048 solver.cpp:240] Iteration 526, loss = 13.9051
I0408 21:15:14.078745  9048 solver.cpp:256]     Train net output #0: loss = 13.9051 (* 1 = 13.9051 loss)
I0408 21:15:14.078754  9048 sgd_solver.cpp:106] Iteration 526, lr = 0.01
I0408 21:15:14.354341  9048 solver.cpp:240] Iteration 527, loss = 19.0361
I0408 21:15:14.354377  9048 solver.cpp:256]     Train net output #0: loss = 19.0361 (* 1 = 19.0361 loss)
I0408 21:15:14.354384  9048 sgd_solver.cpp:106] Iteration 527, lr = 0.01
I0408 21:15:14.631275  9048 solver.cpp:240] Iteration 528, loss = 20.9884
I0408 21:15:14.631309  9048 solver.cpp:256]     Train net output #0: loss = 20.9884 (* 1 = 20.9884 loss)
I0408 21:15:14.631316  9048 sgd_solver.cpp:106] Iteration 528, lr = 0.01
I0408 21:15:14.906853  9048 solver.cpp:240] Iteration 529, loss = 18.9844
I0408 21:15:14.906885  9048 solver.cpp:256]     Train net output #0: loss = 18.9844 (* 1 = 18.9844 loss)
I0408 21:15:14.906893  9048 sgd_solver.cpp:106] Iteration 529, lr = 0.01
I0408 21:15:15.182916  9048 solver.cpp:240] Iteration 530, loss = 18.414
I0408 21:15:15.182961  9048 solver.cpp:256]     Train net output #0: loss = 18.414 (* 1 = 18.414 loss)
I0408 21:15:15.182970  9048 sgd_solver.cpp:106] Iteration 530, lr = 0.01
I0408 21:15:15.460086  9048 solver.cpp:240] Iteration 531, loss = 14.2826
I0408 21:15:15.460126  9048 solver.cpp:256]     Train net output #0: loss = 14.2826 (* 1 = 14.2826 loss)
I0408 21:15:15.460135  9048 sgd_solver.cpp:106] Iteration 531, lr = 0.01
I0408 21:15:15.735163  9048 solver.cpp:240] Iteration 532, loss = 30.3788
I0408 21:15:15.735195  9048 solver.cpp:256]     Train net output #0: loss = 30.3788 (* 1 = 30.3788 loss)
I0408 21:15:15.735204  9048 sgd_solver.cpp:106] Iteration 532, lr = 0.01
I0408 21:15:16.010567  9048 solver.cpp:240] Iteration 533, loss = 7.80345
I0408 21:15:16.010598  9048 solver.cpp:256]     Train net output #0: loss = 7.80344 (* 1 = 7.80344 loss)
I0408 21:15:16.010607  9048 sgd_solver.cpp:106] Iteration 533, lr = 0.01
I0408 21:15:16.287029  9048 solver.cpp:240] Iteration 534, loss = 12.4537
I0408 21:15:16.287061  9048 solver.cpp:256]     Train net output #0: loss = 12.4537 (* 1 = 12.4537 loss)
I0408 21:15:16.287070  9048 sgd_solver.cpp:106] Iteration 534, lr = 0.01
I0408 21:15:16.562701  9048 solver.cpp:240] Iteration 535, loss = 20.8163
I0408 21:15:16.562747  9048 solver.cpp:256]     Train net output #0: loss = 20.8163 (* 1 = 20.8163 loss)
I0408 21:15:16.562754  9048 sgd_solver.cpp:106] Iteration 535, lr = 0.01
I0408 21:15:16.838337  9048 solver.cpp:240] Iteration 536, loss = 17.7075
I0408 21:15:16.838376  9048 solver.cpp:256]     Train net output #0: loss = 17.7075 (* 1 = 17.7075 loss)
I0408 21:15:16.838384  9048 sgd_solver.cpp:106] Iteration 536, lr = 0.01
I0408 21:15:17.114523  9048 solver.cpp:240] Iteration 537, loss = 24.5974
I0408 21:15:17.114570  9048 solver.cpp:256]     Train net output #0: loss = 24.5974 (* 1 = 24.5974 loss)
I0408 21:15:17.114579  9048 sgd_solver.cpp:106] Iteration 537, lr = 0.01
I0408 21:15:17.389616  9048 solver.cpp:240] Iteration 538, loss = 22.543
I0408 21:15:17.389649  9048 solver.cpp:256]     Train net output #0: loss = 22.543 (* 1 = 22.543 loss)
I0408 21:15:17.389657  9048 sgd_solver.cpp:106] Iteration 538, lr = 0.01
I0408 21:15:17.666121  9048 solver.cpp:240] Iteration 539, loss = 9.15725
I0408 21:15:17.666155  9048 solver.cpp:256]     Train net output #0: loss = 9.15724 (* 1 = 9.15724 loss)
I0408 21:15:17.666162  9048 sgd_solver.cpp:106] Iteration 539, lr = 0.01
I0408 21:15:17.942484  9048 solver.cpp:240] Iteration 540, loss = 11.7782
I0408 21:15:17.942517  9048 solver.cpp:256]     Train net output #0: loss = 11.7781 (* 1 = 11.7781 loss)
I0408 21:15:17.942525  9048 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0408 21:15:18.219440  9048 solver.cpp:240] Iteration 541, loss = 15.4104
I0408 21:15:18.219480  9048 solver.cpp:256]     Train net output #0: loss = 15.4104 (* 1 = 15.4104 loss)
I0408 21:15:18.219488  9048 sgd_solver.cpp:106] Iteration 541, lr = 0.01
I0408 21:15:18.494946  9048 solver.cpp:240] Iteration 542, loss = 24.0657
I0408 21:15:18.494978  9048 solver.cpp:256]     Train net output #0: loss = 24.0657 (* 1 = 24.0657 loss)
I0408 21:15:18.494987  9048 sgd_solver.cpp:106] Iteration 542, lr = 0.01
I0408 21:15:18.771647  9048 solver.cpp:240] Iteration 543, loss = 16.655
I0408 21:15:18.771680  9048 solver.cpp:256]     Train net output #0: loss = 16.655 (* 1 = 16.655 loss)
I0408 21:15:18.771688  9048 sgd_solver.cpp:106] Iteration 543, lr = 0.01
I0408 21:15:19.047193  9048 solver.cpp:240] Iteration 544, loss = 13.0164
I0408 21:15:19.047492  9048 solver.cpp:256]     Train net output #0: loss = 13.0164 (* 1 = 13.0164 loss)
I0408 21:15:19.047502  9048 sgd_solver.cpp:106] Iteration 544, lr = 0.01
I0408 21:15:19.323212  9048 solver.cpp:240] Iteration 545, loss = 14.3298
I0408 21:15:19.323246  9048 solver.cpp:256]     Train net output #0: loss = 14.3298 (* 1 = 14.3298 loss)
I0408 21:15:19.323253  9048 sgd_solver.cpp:106] Iteration 545, lr = 0.01
I0408 21:15:19.599643  9048 solver.cpp:240] Iteration 546, loss = 18.4116
I0408 21:15:19.599678  9048 solver.cpp:256]     Train net output #0: loss = 18.4116 (* 1 = 18.4116 loss)
I0408 21:15:19.599686  9048 sgd_solver.cpp:106] Iteration 546, lr = 0.01
I0408 21:15:19.875627  9048 solver.cpp:240] Iteration 547, loss = 16.2394
I0408 21:15:19.875661  9048 solver.cpp:256]     Train net output #0: loss = 16.2394 (* 1 = 16.2394 loss)
I0408 21:15:19.875669  9048 sgd_solver.cpp:106] Iteration 547, lr = 0.01
I0408 21:15:20.152120  9048 solver.cpp:240] Iteration 548, loss = 15.1521
I0408 21:15:20.152156  9048 solver.cpp:256]     Train net output #0: loss = 15.1521 (* 1 = 15.1521 loss)
I0408 21:15:20.152165  9048 sgd_solver.cpp:106] Iteration 548, lr = 0.01
I0408 21:15:20.428437  9048 solver.cpp:240] Iteration 549, loss = 18.2738
I0408 21:15:20.428474  9048 solver.cpp:256]     Train net output #0: loss = 18.2738 (* 1 = 18.2738 loss)
I0408 21:15:20.428483  9048 sgd_solver.cpp:106] Iteration 549, lr = 0.01
I0408 21:15:20.704354  9048 solver.cpp:240] Iteration 550, loss = 16.243
I0408 21:15:20.704390  9048 solver.cpp:256]     Train net output #0: loss = 16.243 (* 1 = 16.243 loss)
I0408 21:15:20.704397  9048 sgd_solver.cpp:106] Iteration 550, lr = 0.01
I0408 21:15:20.980424  9048 solver.cpp:240] Iteration 551, loss = 19.5919
I0408 21:15:20.980458  9048 solver.cpp:256]     Train net output #0: loss = 19.5918 (* 1 = 19.5918 loss)
I0408 21:15:20.980466  9048 sgd_solver.cpp:106] Iteration 551, lr = 0.01
I0408 21:15:21.256069  9048 solver.cpp:240] Iteration 552, loss = 24.0814
I0408 21:15:21.256103  9048 solver.cpp:256]     Train net output #0: loss = 24.0814 (* 1 = 24.0814 loss)
I0408 21:15:21.256111  9048 sgd_solver.cpp:106] Iteration 552, lr = 0.01
I0408 21:15:21.531941  9048 solver.cpp:240] Iteration 553, loss = 25.8144
I0408 21:15:21.531981  9048 solver.cpp:256]     Train net output #0: loss = 25.8144 (* 1 = 25.8144 loss)
I0408 21:15:21.531991  9048 sgd_solver.cpp:106] Iteration 553, lr = 0.01
I0408 21:15:21.808228  9048 solver.cpp:240] Iteration 554, loss = 5.84591
I0408 21:15:21.808260  9048 solver.cpp:256]     Train net output #0: loss = 5.84591 (* 1 = 5.84591 loss)
I0408 21:15:21.808269  9048 sgd_solver.cpp:106] Iteration 554, lr = 0.01
I0408 21:15:22.083843  9048 solver.cpp:240] Iteration 555, loss = 22.4498
I0408 21:15:22.083889  9048 solver.cpp:256]     Train net output #0: loss = 22.4498 (* 1 = 22.4498 loss)
I0408 21:15:22.083899  9048 sgd_solver.cpp:106] Iteration 555, lr = 0.01
I0408 21:15:22.359040  9048 solver.cpp:240] Iteration 556, loss = 1.71965
I0408 21:15:22.359082  9048 solver.cpp:256]     Train net output #0: loss = 1.71964 (* 1 = 1.71964 loss)
I0408 21:15:22.359091  9048 sgd_solver.cpp:106] Iteration 556, lr = 0.01
I0408 21:15:22.635630  9048 solver.cpp:240] Iteration 557, loss = 8.99603
I0408 21:15:22.635673  9048 solver.cpp:256]     Train net output #0: loss = 8.99603 (* 1 = 8.99603 loss)
I0408 21:15:22.635680  9048 sgd_solver.cpp:106] Iteration 557, lr = 0.01
I0408 21:15:22.911296  9048 solver.cpp:240] Iteration 558, loss = 13.5307
I0408 21:15:22.911331  9048 solver.cpp:256]     Train net output #0: loss = 13.5307 (* 1 = 13.5307 loss)
I0408 21:15:22.911339  9048 sgd_solver.cpp:106] Iteration 558, lr = 0.01
I0408 21:15:23.187773  9048 solver.cpp:240] Iteration 559, loss = 12.6084
I0408 21:15:23.187808  9048 solver.cpp:256]     Train net output #0: loss = 12.6084 (* 1 = 12.6084 loss)
I0408 21:15:23.187816  9048 sgd_solver.cpp:106] Iteration 559, lr = 0.01
I0408 21:15:23.464093  9048 solver.cpp:240] Iteration 560, loss = 11.3597
I0408 21:15:23.464128  9048 solver.cpp:256]     Train net output #0: loss = 11.3597 (* 1 = 11.3597 loss)
I0408 21:15:23.464160  9048 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0408 21:15:23.739908  9048 solver.cpp:240] Iteration 561, loss = 10.1954
I0408 21:15:23.739943  9048 solver.cpp:256]     Train net output #0: loss = 10.1954 (* 1 = 10.1954 loss)
I0408 21:15:23.739951  9048 sgd_solver.cpp:106] Iteration 561, lr = 0.01
I0408 21:15:24.015352  9048 solver.cpp:240] Iteration 562, loss = 4.94082
I0408 21:15:24.015383  9048 solver.cpp:256]     Train net output #0: loss = 4.94081 (* 1 = 4.94081 loss)
I0408 21:15:24.015391  9048 sgd_solver.cpp:106] Iteration 562, lr = 0.01
I0408 21:15:24.290756  9048 solver.cpp:240] Iteration 563, loss = 19.3992
I0408 21:15:24.290804  9048 solver.cpp:256]     Train net output #0: loss = 19.3992 (* 1 = 19.3992 loss)
I0408 21:15:24.290813  9048 sgd_solver.cpp:106] Iteration 563, lr = 0.01
I0408 21:15:24.565858  9048 solver.cpp:240] Iteration 564, loss = 28.9637
I0408 21:15:24.565891  9048 solver.cpp:256]     Train net output #0: loss = 28.9637 (* 1 = 28.9637 loss)
I0408 21:15:24.565899  9048 sgd_solver.cpp:106] Iteration 564, lr = 0.01
I0408 21:15:24.841353  9048 solver.cpp:240] Iteration 565, loss = 20.8126
I0408 21:15:24.841385  9048 solver.cpp:256]     Train net output #0: loss = 20.8126 (* 1 = 20.8126 loss)
I0408 21:15:24.841393  9048 sgd_solver.cpp:106] Iteration 565, lr = 0.01
I0408 21:15:25.116266  9048 solver.cpp:240] Iteration 566, loss = 7.31135
I0408 21:15:25.116297  9048 solver.cpp:256]     Train net output #0: loss = 7.31135 (* 1 = 7.31135 loss)
I0408 21:15:25.116305  9048 sgd_solver.cpp:106] Iteration 566, lr = 0.01
I0408 21:15:25.390946  9048 solver.cpp:240] Iteration 567, loss = 7.65054
I0408 21:15:25.390977  9048 solver.cpp:256]     Train net output #0: loss = 7.65053 (* 1 = 7.65053 loss)
I0408 21:15:25.390985  9048 sgd_solver.cpp:106] Iteration 567, lr = 0.01
I0408 21:15:25.667248  9048 solver.cpp:240] Iteration 568, loss = 20.3141
I0408 21:15:25.667281  9048 solver.cpp:256]     Train net output #0: loss = 20.3141 (* 1 = 20.3141 loss)
I0408 21:15:25.667289  9048 sgd_solver.cpp:106] Iteration 568, lr = 0.01
I0408 21:15:25.943796  9048 solver.cpp:240] Iteration 569, loss = 13.6951
I0408 21:15:25.943830  9048 solver.cpp:256]     Train net output #0: loss = 13.6951 (* 1 = 13.6951 loss)
I0408 21:15:25.943837  9048 sgd_solver.cpp:106] Iteration 569, lr = 0.01
I0408 21:15:26.220161  9048 solver.cpp:240] Iteration 570, loss = 30.6833
I0408 21:15:26.220194  9048 solver.cpp:256]     Train net output #0: loss = 30.6833 (* 1 = 30.6833 loss)
I0408 21:15:26.220203  9048 sgd_solver.cpp:106] Iteration 570, lr = 0.01
I0408 21:15:26.496695  9048 solver.cpp:240] Iteration 571, loss = 31.2722
I0408 21:15:26.496740  9048 solver.cpp:256]     Train net output #0: loss = 31.2722 (* 1 = 31.2722 loss)
I0408 21:15:26.496749  9048 sgd_solver.cpp:106] Iteration 571, lr = 0.01
I0408 21:15:26.773073  9048 solver.cpp:240] Iteration 572, loss = 23.4111
I0408 21:15:26.773105  9048 solver.cpp:256]     Train net output #0: loss = 23.4111 (* 1 = 23.4111 loss)
I0408 21:15:26.773114  9048 sgd_solver.cpp:106] Iteration 572, lr = 0.01
I0408 21:15:27.049316  9048 solver.cpp:240] Iteration 573, loss = 14.1053
I0408 21:15:27.049355  9048 solver.cpp:256]     Train net output #0: loss = 14.1053 (* 1 = 14.1053 loss)
I0408 21:15:27.049363  9048 sgd_solver.cpp:106] Iteration 573, lr = 0.01
I0408 21:15:27.324846  9048 solver.cpp:240] Iteration 574, loss = 2.54289
I0408 21:15:27.324878  9048 solver.cpp:256]     Train net output #0: loss = 2.54288 (* 1 = 2.54288 loss)
I0408 21:15:27.324887  9048 sgd_solver.cpp:106] Iteration 574, lr = 0.01
I0408 21:15:27.600656  9048 solver.cpp:240] Iteration 575, loss = 13.3061
I0408 21:15:27.600699  9048 solver.cpp:256]     Train net output #0: loss = 13.3061 (* 1 = 13.3061 loss)
I0408 21:15:27.600708  9048 sgd_solver.cpp:106] Iteration 575, lr = 0.01
I0408 21:15:27.876624  9048 solver.cpp:240] Iteration 576, loss = 5.72418
I0408 21:15:27.876669  9048 solver.cpp:256]     Train net output #0: loss = 5.72417 (* 1 = 5.72417 loss)
I0408 21:15:27.876682  9048 sgd_solver.cpp:106] Iteration 576, lr = 0.01
I0408 21:15:28.152776  9048 solver.cpp:240] Iteration 577, loss = 1.95376
I0408 21:15:28.152807  9048 solver.cpp:256]     Train net output #0: loss = 1.95375 (* 1 = 1.95375 loss)
I0408 21:15:28.152815  9048 sgd_solver.cpp:106] Iteration 577, lr = 0.01
I0408 21:15:28.428930  9048 solver.cpp:240] Iteration 578, loss = 5.9511
I0408 21:15:28.428964  9048 solver.cpp:256]     Train net output #0: loss = 5.9511 (* 1 = 5.9511 loss)
I0408 21:15:28.428972  9048 sgd_solver.cpp:106] Iteration 578, lr = 0.01
I0408 21:15:28.704062  9048 solver.cpp:240] Iteration 579, loss = 16.3562
I0408 21:15:28.704097  9048 solver.cpp:256]     Train net output #0: loss = 16.3562 (* 1 = 16.3562 loss)
I0408 21:15:28.704105  9048 sgd_solver.cpp:106] Iteration 579, lr = 0.01
I0408 21:15:28.979495  9048 solver.cpp:240] Iteration 580, loss = 17.2123
I0408 21:15:28.979540  9048 solver.cpp:256]     Train net output #0: loss = 17.2123 (* 1 = 17.2123 loss)
I0408 21:15:28.979548  9048 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0408 21:15:29.255359  9048 solver.cpp:240] Iteration 581, loss = 2.88312
I0408 21:15:29.255389  9048 solver.cpp:256]     Train net output #0: loss = 2.88311 (* 1 = 2.88311 loss)
I0408 21:15:29.255396  9048 sgd_solver.cpp:106] Iteration 581, lr = 0.01
I0408 21:15:29.531049  9048 solver.cpp:240] Iteration 582, loss = 8.05261
I0408 21:15:29.531082  9048 solver.cpp:256]     Train net output #0: loss = 8.05261 (* 1 = 8.05261 loss)
I0408 21:15:29.531090  9048 sgd_solver.cpp:106] Iteration 582, lr = 0.01
I0408 21:15:29.807104  9048 solver.cpp:240] Iteration 583, loss = 6.56171
I0408 21:15:29.807139  9048 solver.cpp:256]     Train net output #0: loss = 6.5617 (* 1 = 6.5617 loss)
I0408 21:15:29.807148  9048 sgd_solver.cpp:106] Iteration 583, lr = 0.01
I0408 21:15:30.082806  9048 solver.cpp:240] Iteration 584, loss = 14.6678
I0408 21:15:30.082839  9048 solver.cpp:256]     Train net output #0: loss = 14.6678 (* 1 = 14.6678 loss)
I0408 21:15:30.082847  9048 sgd_solver.cpp:106] Iteration 584, lr = 0.01
I0408 21:15:30.359200  9048 solver.cpp:240] Iteration 585, loss = 16.628
I0408 21:15:30.359235  9048 solver.cpp:256]     Train net output #0: loss = 16.628 (* 1 = 16.628 loss)
I0408 21:15:30.359242  9048 sgd_solver.cpp:106] Iteration 585, lr = 0.01
I0408 21:15:30.634727  9048 solver.cpp:240] Iteration 586, loss = 21.6377
I0408 21:15:30.634770  9048 solver.cpp:256]     Train net output #0: loss = 21.6377 (* 1 = 21.6377 loss)
I0408 21:15:30.634779  9048 sgd_solver.cpp:106] Iteration 586, lr = 0.01
I0408 21:15:30.911238  9048 solver.cpp:240] Iteration 587, loss = 16.101
I0408 21:15:30.911280  9048 solver.cpp:256]     Train net output #0: loss = 16.101 (* 1 = 16.101 loss)
I0408 21:15:30.911288  9048 sgd_solver.cpp:106] Iteration 587, lr = 0.01
I0408 21:15:31.186789  9048 solver.cpp:240] Iteration 588, loss = 29.6951
I0408 21:15:31.186832  9048 solver.cpp:256]     Train net output #0: loss = 29.6951 (* 1 = 29.6951 loss)
I0408 21:15:31.186841  9048 sgd_solver.cpp:106] Iteration 588, lr = 0.01
I0408 21:15:31.463060  9048 solver.cpp:240] Iteration 589, loss = 37.0821
I0408 21:15:31.463093  9048 solver.cpp:256]     Train net output #0: loss = 37.0821 (* 1 = 37.0821 loss)
I0408 21:15:31.463100  9048 sgd_solver.cpp:106] Iteration 589, lr = 0.01
I0408 21:15:31.739586  9048 solver.cpp:240] Iteration 590, loss = 28.5232
I0408 21:15:31.739621  9048 solver.cpp:256]     Train net output #0: loss = 28.5232 (* 1 = 28.5232 loss)
I0408 21:15:31.739629  9048 sgd_solver.cpp:106] Iteration 590, lr = 0.01
I0408 21:15:32.016067  9048 solver.cpp:240] Iteration 591, loss = 25.1827
I0408 21:15:32.016100  9048 solver.cpp:256]     Train net output #0: loss = 25.1827 (* 1 = 25.1827 loss)
I0408 21:15:32.016109  9048 sgd_solver.cpp:106] Iteration 591, lr = 0.01
I0408 21:15:32.292265  9048 solver.cpp:240] Iteration 592, loss = 17.8009
I0408 21:15:32.292299  9048 solver.cpp:256]     Train net output #0: loss = 17.8009 (* 1 = 17.8009 loss)
I0408 21:15:32.292307  9048 sgd_solver.cpp:106] Iteration 592, lr = 0.01
I0408 21:15:32.568500  9048 solver.cpp:240] Iteration 593, loss = 13.9273
I0408 21:15:32.568555  9048 solver.cpp:256]     Train net output #0: loss = 13.9273 (* 1 = 13.9273 loss)
I0408 21:15:32.568564  9048 sgd_solver.cpp:106] Iteration 593, lr = 0.01
I0408 21:15:32.845448  9048 solver.cpp:240] Iteration 594, loss = 12.6315
I0408 21:15:32.845481  9048 solver.cpp:256]     Train net output #0: loss = 12.6315 (* 1 = 12.6315 loss)
I0408 21:15:32.845489  9048 sgd_solver.cpp:106] Iteration 594, lr = 0.01
I0408 21:15:33.121549  9048 solver.cpp:240] Iteration 595, loss = 16.5028
I0408 21:15:33.121597  9048 solver.cpp:256]     Train net output #0: loss = 16.5028 (* 1 = 16.5028 loss)
I0408 21:15:33.121606  9048 sgd_solver.cpp:106] Iteration 595, lr = 0.01
I0408 21:15:33.398216  9048 solver.cpp:240] Iteration 596, loss = 16.3017
I0408 21:15:33.398248  9048 solver.cpp:256]     Train net output #0: loss = 16.3017 (* 1 = 16.3017 loss)
I0408 21:15:33.398257  9048 sgd_solver.cpp:106] Iteration 596, lr = 0.01
I0408 21:15:33.674643  9048 solver.cpp:240] Iteration 597, loss = 13.8576
I0408 21:15:33.674687  9048 solver.cpp:256]     Train net output #0: loss = 13.8576 (* 1 = 13.8576 loss)
I0408 21:15:33.674696  9048 sgd_solver.cpp:106] Iteration 597, lr = 0.01
I0408 21:15:33.950225  9048 solver.cpp:240] Iteration 598, loss = 8.79135
I0408 21:15:33.950268  9048 solver.cpp:256]     Train net output #0: loss = 8.79135 (* 1 = 8.79135 loss)
I0408 21:15:33.950276  9048 sgd_solver.cpp:106] Iteration 598, lr = 0.01
I0408 21:15:34.227267  9048 solver.cpp:240] Iteration 599, loss = 9.4781
I0408 21:15:34.227298  9048 solver.cpp:256]     Train net output #0: loss = 9.4781 (* 1 = 9.4781 loss)
I0408 21:15:34.227308  9048 sgd_solver.cpp:106] Iteration 599, lr = 0.01
I0408 21:15:34.503121  9048 solver.cpp:240] Iteration 600, loss = 7.61544
I0408 21:15:34.503157  9048 solver.cpp:256]     Train net output #0: loss = 7.61544 (* 1 = 7.61544 loss)
I0408 21:15:34.503165  9048 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0408 21:15:34.779508  9048 solver.cpp:240] Iteration 601, loss = 5.22675
I0408 21:15:34.779552  9048 solver.cpp:256]     Train net output #0: loss = 5.22674 (* 1 = 5.22674 loss)
I0408 21:15:34.779561  9048 sgd_solver.cpp:106] Iteration 601, lr = 0.01
I0408 21:15:35.056182  9048 solver.cpp:240] Iteration 602, loss = 3.6995
I0408 21:15:35.056215  9048 solver.cpp:256]     Train net output #0: loss = 3.69949 (* 1 = 3.69949 loss)
I0408 21:15:35.056222  9048 sgd_solver.cpp:106] Iteration 602, lr = 0.01
I0408 21:15:35.332018  9048 solver.cpp:240] Iteration 603, loss = 3.896
I0408 21:15:35.332053  9048 solver.cpp:256]     Train net output #0: loss = 3.896 (* 1 = 3.896 loss)
I0408 21:15:35.332062  9048 sgd_solver.cpp:106] Iteration 603, lr = 0.01
I0408 21:15:35.607707  9048 solver.cpp:240] Iteration 604, loss = 8.63406
I0408 21:15:35.607753  9048 solver.cpp:256]     Train net output #0: loss = 8.63405 (* 1 = 8.63405 loss)
I0408 21:15:35.607759  9048 sgd_solver.cpp:106] Iteration 604, lr = 0.01
I0408 21:15:35.883780  9048 solver.cpp:240] Iteration 605, loss = 6.7658
I0408 21:15:35.883812  9048 solver.cpp:256]     Train net output #0: loss = 6.7658 (* 1 = 6.7658 loss)
I0408 21:15:35.883821  9048 sgd_solver.cpp:106] Iteration 605, lr = 0.01
I0408 21:15:36.158377  9048 solver.cpp:240] Iteration 606, loss = 8.4715
I0408 21:15:36.158421  9048 solver.cpp:256]     Train net output #0: loss = 8.47149 (* 1 = 8.47149 loss)
I0408 21:15:36.158428  9048 sgd_solver.cpp:106] Iteration 606, lr = 0.01
I0408 21:15:36.434157  9048 solver.cpp:240] Iteration 607, loss = 9.72867
I0408 21:15:36.434201  9048 solver.cpp:256]     Train net output #0: loss = 9.72867 (* 1 = 9.72867 loss)
I0408 21:15:36.434211  9048 sgd_solver.cpp:106] Iteration 607, lr = 0.01
I0408 21:15:36.709280  9048 solver.cpp:240] Iteration 608, loss = 7.51792
I0408 21:15:36.709316  9048 solver.cpp:256]     Train net output #0: loss = 7.51791 (* 1 = 7.51791 loss)
I0408 21:15:36.709324  9048 sgd_solver.cpp:106] Iteration 608, lr = 0.01
I0408 21:15:36.983994  9048 solver.cpp:240] Iteration 609, loss = 4.4422
I0408 21:15:36.984027  9048 solver.cpp:256]     Train net output #0: loss = 4.44219 (* 1 = 4.44219 loss)
I0408 21:15:36.984066  9048 sgd_solver.cpp:106] Iteration 609, lr = 0.01
I0408 21:15:37.260129  9048 solver.cpp:240] Iteration 610, loss = 6.50092
I0408 21:15:37.260161  9048 solver.cpp:256]     Train net output #0: loss = 6.50092 (* 1 = 6.50092 loss)
I0408 21:15:37.260169  9048 sgd_solver.cpp:106] Iteration 610, lr = 0.01
I0408 21:15:37.536715  9048 solver.cpp:240] Iteration 611, loss = 17.0186
I0408 21:15:37.536747  9048 solver.cpp:256]     Train net output #0: loss = 17.0186 (* 1 = 17.0186 loss)
I0408 21:15:37.536756  9048 sgd_solver.cpp:106] Iteration 611, lr = 0.01
I0408 21:15:37.811697  9048 solver.cpp:240] Iteration 612, loss = 5.06545
I0408 21:15:37.811730  9048 solver.cpp:256]     Train net output #0: loss = 5.06544 (* 1 = 5.06544 loss)
I0408 21:15:37.811739  9048 sgd_solver.cpp:106] Iteration 612, lr = 0.01
I0408 21:15:38.086045  9048 solver.cpp:240] Iteration 613, loss = 8.75731
I0408 21:15:38.086077  9048 solver.cpp:256]     Train net output #0: loss = 8.75731 (* 1 = 8.75731 loss)
I0408 21:15:38.086086  9048 sgd_solver.cpp:106] Iteration 613, lr = 0.01
I0408 21:15:38.363191  9048 solver.cpp:240] Iteration 614, loss = 30.533
I0408 21:15:38.363237  9048 solver.cpp:256]     Train net output #0: loss = 30.533 (* 1 = 30.533 loss)
I0408 21:15:38.363245  9048 sgd_solver.cpp:106] Iteration 614, lr = 0.01
I0408 21:15:38.640198  9048 solver.cpp:240] Iteration 615, loss = 24.9841
I0408 21:15:38.640231  9048 solver.cpp:256]     Train net output #0: loss = 24.9841 (* 1 = 24.9841 loss)
I0408 21:15:38.640239  9048 sgd_solver.cpp:106] Iteration 615, lr = 0.01
I0408 21:15:38.916098  9048 solver.cpp:240] Iteration 616, loss = 29.7067
I0408 21:15:38.916131  9048 solver.cpp:256]     Train net output #0: loss = 29.7067 (* 1 = 29.7067 loss)
I0408 21:15:38.916139  9048 sgd_solver.cpp:106] Iteration 616, lr = 0.01
I0408 21:15:39.191646  9048 solver.cpp:240] Iteration 617, loss = 23.9335
I0408 21:15:39.191692  9048 solver.cpp:256]     Train net output #0: loss = 23.9335 (* 1 = 23.9335 loss)
I0408 21:15:39.191700  9048 sgd_solver.cpp:106] Iteration 617, lr = 0.01
I0408 21:15:39.467612  9048 solver.cpp:240] Iteration 618, loss = 38.1032
I0408 21:15:39.467659  9048 solver.cpp:256]     Train net output #0: loss = 38.1032 (* 1 = 38.1032 loss)
I0408 21:15:39.467669  9048 sgd_solver.cpp:106] Iteration 618, lr = 0.01
I0408 21:15:39.743710  9048 solver.cpp:240] Iteration 619, loss = 26.9479
I0408 21:15:39.743746  9048 solver.cpp:256]     Train net output #0: loss = 26.9479 (* 1 = 26.9479 loss)
I0408 21:15:39.743753  9048 sgd_solver.cpp:106] Iteration 619, lr = 0.01
I0408 21:15:40.019814  9048 solver.cpp:240] Iteration 620, loss = 18.35
I0408 21:15:40.019850  9048 solver.cpp:256]     Train net output #0: loss = 18.35 (* 1 = 18.35 loss)
I0408 21:15:40.019858  9048 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0408 21:15:40.296212  9048 solver.cpp:240] Iteration 621, loss = 34.4342
I0408 21:15:40.296257  9048 solver.cpp:256]     Train net output #0: loss = 34.4342 (* 1 = 34.4342 loss)
I0408 21:15:40.296264  9048 sgd_solver.cpp:106] Iteration 621, lr = 0.01
I0408 21:15:40.570726  9048 solver.cpp:240] Iteration 622, loss = 16.7307
I0408 21:15:40.570760  9048 solver.cpp:256]     Train net output #0: loss = 16.7307 (* 1 = 16.7307 loss)
I0408 21:15:40.570768  9048 sgd_solver.cpp:106] Iteration 622, lr = 0.01
I0408 21:15:40.845479  9048 solver.cpp:240] Iteration 623, loss = 33.5537
I0408 21:15:40.845513  9048 solver.cpp:256]     Train net output #0: loss = 33.5537 (* 1 = 33.5537 loss)
I0408 21:15:40.845521  9048 sgd_solver.cpp:106] Iteration 623, lr = 0.01
I0408 21:15:41.120455  9048 solver.cpp:240] Iteration 624, loss = 24.8942
I0408 21:15:41.120489  9048 solver.cpp:256]     Train net output #0: loss = 24.8942 (* 1 = 24.8942 loss)
I0408 21:15:41.120498  9048 sgd_solver.cpp:106] Iteration 624, lr = 0.01
I0408 21:15:41.396883  9048 solver.cpp:240] Iteration 625, loss = 18.1899
I0408 21:15:41.396917  9048 solver.cpp:256]     Train net output #0: loss = 18.1899 (* 1 = 18.1899 loss)
I0408 21:15:41.396925  9048 sgd_solver.cpp:106] Iteration 625, lr = 0.01
I0408 21:15:41.672278  9048 solver.cpp:240] Iteration 626, loss = 18.6523
I0408 21:15:41.672312  9048 solver.cpp:256]     Train net output #0: loss = 18.6522 (* 1 = 18.6522 loss)
I0408 21:15:41.672320  9048 sgd_solver.cpp:106] Iteration 626, lr = 0.01
I0408 21:15:41.948240  9048 solver.cpp:240] Iteration 627, loss = 9.38874
I0408 21:15:41.948271  9048 solver.cpp:256]     Train net output #0: loss = 9.38874 (* 1 = 9.38874 loss)
I0408 21:15:41.948278  9048 sgd_solver.cpp:106] Iteration 627, lr = 0.01
I0408 21:15:42.224025  9048 solver.cpp:240] Iteration 628, loss = 11.7075
I0408 21:15:42.224058  9048 solver.cpp:256]     Train net output #0: loss = 11.7075 (* 1 = 11.7075 loss)
I0408 21:15:42.224067  9048 sgd_solver.cpp:106] Iteration 628, lr = 0.01
I0408 21:15:42.498932  9048 solver.cpp:240] Iteration 629, loss = 12.7201
I0408 21:15:42.498965  9048 solver.cpp:256]     Train net output #0: loss = 12.7201 (* 1 = 12.7201 loss)
I0408 21:15:42.498972  9048 sgd_solver.cpp:106] Iteration 629, lr = 0.01
I0408 21:15:42.774199  9048 solver.cpp:240] Iteration 630, loss = 5.10767
I0408 21:15:42.774246  9048 solver.cpp:256]     Train net output #0: loss = 5.10767 (* 1 = 5.10767 loss)
I0408 21:15:42.774255  9048 sgd_solver.cpp:106] Iteration 630, lr = 0.01
I0408 21:15:43.050900  9048 solver.cpp:240] Iteration 631, loss = 11.6342
I0408 21:15:43.050933  9048 solver.cpp:256]     Train net output #0: loss = 11.6342 (* 1 = 11.6342 loss)
I0408 21:15:43.050941  9048 sgd_solver.cpp:106] Iteration 631, lr = 0.01
I0408 21:15:43.326601  9048 solver.cpp:240] Iteration 632, loss = 8.72208
I0408 21:15:43.326645  9048 solver.cpp:256]     Train net output #0: loss = 8.72207 (* 1 = 8.72207 loss)
I0408 21:15:43.326653  9048 sgd_solver.cpp:106] Iteration 632, lr = 0.01
I0408 21:15:43.601604  9048 solver.cpp:240] Iteration 633, loss = 29.087
I0408 21:15:43.601655  9048 solver.cpp:256]     Train net output #0: loss = 29.087 (* 1 = 29.087 loss)
I0408 21:15:43.601665  9048 sgd_solver.cpp:106] Iteration 633, lr = 0.01
I0408 21:15:43.877259  9048 solver.cpp:240] Iteration 634, loss = 28.331
I0408 21:15:43.877292  9048 solver.cpp:256]     Train net output #0: loss = 28.331 (* 1 = 28.331 loss)
I0408 21:15:43.877300  9048 sgd_solver.cpp:106] Iteration 634, lr = 0.01
I0408 21:15:44.153998  9048 solver.cpp:240] Iteration 635, loss = 32.4296
I0408 21:15:44.154034  9048 solver.cpp:256]     Train net output #0: loss = 32.4296 (* 1 = 32.4296 loss)
I0408 21:15:44.154042  9048 sgd_solver.cpp:106] Iteration 635, lr = 0.01
I0408 21:15:44.429852  9048 solver.cpp:240] Iteration 636, loss = 26.1364
I0408 21:15:44.429886  9048 solver.cpp:256]     Train net output #0: loss = 26.1364 (* 1 = 26.1364 loss)
I0408 21:15:44.429895  9048 sgd_solver.cpp:106] Iteration 636, lr = 0.01
I0408 21:15:44.705672  9048 solver.cpp:240] Iteration 637, loss = 11.8597
I0408 21:15:44.705703  9048 solver.cpp:256]     Train net output #0: loss = 11.8597 (* 1 = 11.8597 loss)
I0408 21:15:44.705711  9048 sgd_solver.cpp:106] Iteration 637, lr = 0.01
I0408 21:15:44.980818  9048 solver.cpp:240] Iteration 638, loss = 10.1131
I0408 21:15:44.980855  9048 solver.cpp:256]     Train net output #0: loss = 10.1131 (* 1 = 10.1131 loss)
I0408 21:15:44.980865  9048 sgd_solver.cpp:106] Iteration 638, lr = 0.01
I0408 21:15:45.256471  9048 solver.cpp:240] Iteration 639, loss = 5.33941
I0408 21:15:45.256505  9048 solver.cpp:256]     Train net output #0: loss = 5.3394 (* 1 = 5.3394 loss)
I0408 21:15:45.256512  9048 sgd_solver.cpp:106] Iteration 639, lr = 0.01
I0408 21:15:45.531790  9048 solver.cpp:240] Iteration 640, loss = 19.2766
I0408 21:15:45.531828  9048 solver.cpp:256]     Train net output #0: loss = 19.2766 (* 1 = 19.2766 loss)
I0408 21:15:45.531837  9048 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0408 21:15:45.807821  9048 solver.cpp:240] Iteration 641, loss = 19.0559
I0408 21:15:45.807854  9048 solver.cpp:256]     Train net output #0: loss = 19.0559 (* 1 = 19.0559 loss)
I0408 21:15:45.807863  9048 sgd_solver.cpp:106] Iteration 641, lr = 0.01
I0408 21:15:46.084715  9048 solver.cpp:240] Iteration 642, loss = 20.4262
I0408 21:15:46.084774  9048 solver.cpp:256]     Train net output #0: loss = 20.4262 (* 1 = 20.4262 loss)
I0408 21:15:46.084784  9048 sgd_solver.cpp:106] Iteration 642, lr = 0.01
I0408 21:15:46.360617  9048 solver.cpp:240] Iteration 643, loss = 13.94
I0408 21:15:46.360662  9048 solver.cpp:256]     Train net output #0: loss = 13.94 (* 1 = 13.94 loss)
I0408 21:15:46.360671  9048 sgd_solver.cpp:106] Iteration 643, lr = 0.01
I0408 21:15:46.636379  9048 solver.cpp:240] Iteration 644, loss = 12.5872
I0408 21:15:46.636414  9048 solver.cpp:256]     Train net output #0: loss = 12.5872 (* 1 = 12.5872 loss)
I0408 21:15:46.636422  9048 sgd_solver.cpp:106] Iteration 644, lr = 0.01
I0408 21:15:46.911792  9048 solver.cpp:240] Iteration 645, loss = 8.78069
I0408 21:15:46.911828  9048 solver.cpp:256]     Train net output #0: loss = 8.78069 (* 1 = 8.78069 loss)
I0408 21:15:46.911836  9048 sgd_solver.cpp:106] Iteration 645, lr = 0.01
I0408 21:15:47.186832  9048 solver.cpp:240] Iteration 646, loss = 13.6304
I0408 21:15:47.186866  9048 solver.cpp:256]     Train net output #0: loss = 13.6304 (* 1 = 13.6304 loss)
I0408 21:15:47.186875  9048 sgd_solver.cpp:106] Iteration 646, lr = 0.01
I0408 21:15:47.462309  9048 solver.cpp:240] Iteration 647, loss = 8.07574
I0408 21:15:47.462355  9048 solver.cpp:256]     Train net output #0: loss = 8.07574 (* 1 = 8.07574 loss)
I0408 21:15:47.462363  9048 sgd_solver.cpp:106] Iteration 647, lr = 0.01
I0408 21:15:47.737545  9048 solver.cpp:240] Iteration 648, loss = 23.6891
I0408 21:15:47.737577  9048 solver.cpp:256]     Train net output #0: loss = 23.6891 (* 1 = 23.6891 loss)
I0408 21:15:47.737586  9048 sgd_solver.cpp:106] Iteration 648, lr = 0.01
I0408 21:15:48.013265  9048 solver.cpp:240] Iteration 649, loss = 10.8755
I0408 21:15:48.013296  9048 solver.cpp:256]     Train net output #0: loss = 10.8755 (* 1 = 10.8755 loss)
I0408 21:15:48.013305  9048 sgd_solver.cpp:106] Iteration 649, lr = 0.01
I0408 21:15:48.290122  9048 solver.cpp:240] Iteration 650, loss = 5.8838
I0408 21:15:48.290153  9048 solver.cpp:256]     Train net output #0: loss = 5.88379 (* 1 = 5.88379 loss)
I0408 21:15:48.290161  9048 sgd_solver.cpp:106] Iteration 650, lr = 0.01
I0408 21:15:48.567358  9048 solver.cpp:240] Iteration 651, loss = 28.9612
I0408 21:15:48.567395  9048 solver.cpp:256]     Train net output #0: loss = 28.9612 (* 1 = 28.9612 loss)
I0408 21:15:48.567405  9048 sgd_solver.cpp:106] Iteration 651, lr = 0.01
I0408 21:15:48.842149  9048 solver.cpp:240] Iteration 652, loss = 28.0507
I0408 21:15:48.842182  9048 solver.cpp:256]     Train net output #0: loss = 28.0507 (* 1 = 28.0507 loss)
I0408 21:15:48.842190  9048 sgd_solver.cpp:106] Iteration 652, lr = 0.01
I0408 21:15:49.118485  9048 solver.cpp:240] Iteration 653, loss = 4.05606
I0408 21:15:49.118644  9048 solver.cpp:256]     Train net output #0: loss = 4.05606 (* 1 = 4.05606 loss)
I0408 21:15:49.118654  9048 sgd_solver.cpp:106] Iteration 653, lr = 0.01
I0408 21:15:49.393187  9048 solver.cpp:240] Iteration 654, loss = 8.60315
I0408 21:15:49.393218  9048 solver.cpp:256]     Train net output #0: loss = 8.60314 (* 1 = 8.60314 loss)
I0408 21:15:49.393227  9048 sgd_solver.cpp:106] Iteration 654, lr = 0.01
I0408 21:15:49.668993  9048 solver.cpp:240] Iteration 655, loss = 23.9082
I0408 21:15:49.669028  9048 solver.cpp:256]     Train net output #0: loss = 23.9082 (* 1 = 23.9082 loss)
I0408 21:15:49.669036  9048 sgd_solver.cpp:106] Iteration 655, lr = 0.01
I0408 21:15:49.944789  9048 solver.cpp:240] Iteration 656, loss = 9.7118
I0408 21:15:49.944821  9048 solver.cpp:256]     Train net output #0: loss = 9.7118 (* 1 = 9.7118 loss)
I0408 21:15:49.944830  9048 sgd_solver.cpp:106] Iteration 656, lr = 0.01
I0408 21:15:50.219996  9048 solver.cpp:240] Iteration 657, loss = 20.2742
I0408 21:15:50.220032  9048 solver.cpp:256]     Train net output #0: loss = 20.2742 (* 1 = 20.2742 loss)
I0408 21:15:50.220041  9048 sgd_solver.cpp:106] Iteration 657, lr = 0.01
I0408 21:15:50.495585  9048 solver.cpp:240] Iteration 658, loss = 9.24756
I0408 21:15:50.495632  9048 solver.cpp:256]     Train net output #0: loss = 9.24756 (* 1 = 9.24756 loss)
I0408 21:15:50.495640  9048 sgd_solver.cpp:106] Iteration 658, lr = 0.01
I0408 21:15:50.772135  9048 solver.cpp:240] Iteration 659, loss = 24.1863
I0408 21:15:50.772171  9048 solver.cpp:256]     Train net output #0: loss = 24.1863 (* 1 = 24.1863 loss)
I0408 21:15:50.772178  9048 sgd_solver.cpp:106] Iteration 659, lr = 0.01
I0408 21:15:51.048209  9048 solver.cpp:240] Iteration 660, loss = 22.9087
I0408 21:15:51.048243  9048 solver.cpp:256]     Train net output #0: loss = 22.9087 (* 1 = 22.9087 loss)
I0408 21:15:51.048251  9048 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0408 21:15:51.325306  9048 solver.cpp:240] Iteration 661, loss = 14.1643
I0408 21:15:51.325350  9048 solver.cpp:256]     Train net output #0: loss = 14.1643 (* 1 = 14.1643 loss)
I0408 21:15:51.325359  9048 sgd_solver.cpp:106] Iteration 661, lr = 0.01
I0408 21:15:51.599722  9048 solver.cpp:240] Iteration 662, loss = 20.9532
I0408 21:15:51.599756  9048 solver.cpp:256]     Train net output #0: loss = 20.9532 (* 1 = 20.9532 loss)
I0408 21:15:51.599764  9048 sgd_solver.cpp:106] Iteration 662, lr = 0.01
I0408 21:15:51.875486  9048 solver.cpp:240] Iteration 663, loss = 20.8734
I0408 21:15:51.875519  9048 solver.cpp:256]     Train net output #0: loss = 20.8734 (* 1 = 20.8734 loss)
I0408 21:15:51.875529  9048 sgd_solver.cpp:106] Iteration 663, lr = 0.01
I0408 21:15:52.151401  9048 solver.cpp:240] Iteration 664, loss = 15.839
I0408 21:15:52.151434  9048 solver.cpp:256]     Train net output #0: loss = 15.839 (* 1 = 15.839 loss)
I0408 21:15:52.151443  9048 sgd_solver.cpp:106] Iteration 664, lr = 0.01
I0408 21:15:52.426798  9048 solver.cpp:240] Iteration 665, loss = 7.16875
I0408 21:15:52.426829  9048 solver.cpp:256]     Train net output #0: loss = 7.16874 (* 1 = 7.16874 loss)
I0408 21:15:52.426837  9048 sgd_solver.cpp:106] Iteration 665, lr = 0.01
I0408 21:15:52.702216  9048 solver.cpp:240] Iteration 666, loss = 13.8471
I0408 21:15:52.702252  9048 solver.cpp:256]     Train net output #0: loss = 13.8471 (* 1 = 13.8471 loss)
I0408 21:15:52.702261  9048 sgd_solver.cpp:106] Iteration 666, lr = 0.01
I0408 21:15:52.978054  9048 solver.cpp:240] Iteration 667, loss = 14.97
I0408 21:15:52.978096  9048 solver.cpp:256]     Train net output #0: loss = 14.97 (* 1 = 14.97 loss)
I0408 21:15:52.978104  9048 sgd_solver.cpp:106] Iteration 667, lr = 0.01
I0408 21:15:53.254396  9048 solver.cpp:240] Iteration 668, loss = 22.6235
I0408 21:15:53.254441  9048 solver.cpp:256]     Train net output #0: loss = 22.6235 (* 1 = 22.6235 loss)
I0408 21:15:53.254448  9048 sgd_solver.cpp:106] Iteration 668, lr = 0.01
I0408 21:15:53.530586  9048 solver.cpp:240] Iteration 669, loss = 12.7512
I0408 21:15:53.530623  9048 solver.cpp:256]     Train net output #0: loss = 12.7512 (* 1 = 12.7512 loss)
I0408 21:15:53.530654  9048 sgd_solver.cpp:106] Iteration 669, lr = 0.01
I0408 21:15:53.806295  9048 solver.cpp:240] Iteration 670, loss = 12.5656
I0408 21:15:53.806329  9048 solver.cpp:256]     Train net output #0: loss = 12.5656 (* 1 = 12.5656 loss)
I0408 21:15:53.806337  9048 sgd_solver.cpp:106] Iteration 670, lr = 0.01
I0408 21:15:54.083429  9048 solver.cpp:240] Iteration 671, loss = 8.1603
I0408 21:15:54.083463  9048 solver.cpp:256]     Train net output #0: loss = 8.1603 (* 1 = 8.1603 loss)
I0408 21:15:54.083472  9048 sgd_solver.cpp:106] Iteration 671, lr = 0.01
I0408 21:15:54.359256  9048 solver.cpp:240] Iteration 672, loss = 9.68993
I0408 21:15:54.359298  9048 solver.cpp:256]     Train net output #0: loss = 9.68993 (* 1 = 9.68993 loss)
I0408 21:15:54.359307  9048 sgd_solver.cpp:106] Iteration 672, lr = 0.01
I0408 21:15:54.634595  9048 solver.cpp:240] Iteration 673, loss = 11.8757
I0408 21:15:54.634626  9048 solver.cpp:256]     Train net output #0: loss = 11.8757 (* 1 = 11.8757 loss)
I0408 21:15:54.634634  9048 sgd_solver.cpp:106] Iteration 673, lr = 0.01
I0408 21:15:54.909291  9048 solver.cpp:240] Iteration 674, loss = 13.9091
I0408 21:15:54.909333  9048 solver.cpp:256]     Train net output #0: loss = 13.9091 (* 1 = 13.9091 loss)
I0408 21:15:54.909343  9048 sgd_solver.cpp:106] Iteration 674, lr = 0.01
I0408 21:15:55.184269  9048 solver.cpp:240] Iteration 675, loss = 21.6255
I0408 21:15:55.184309  9048 solver.cpp:256]     Train net output #0: loss = 21.6255 (* 1 = 21.6255 loss)
I0408 21:15:55.184319  9048 sgd_solver.cpp:106] Iteration 675, lr = 0.01
I0408 21:15:55.459786  9048 solver.cpp:240] Iteration 676, loss = 25.3658
I0408 21:15:55.459825  9048 solver.cpp:256]     Train net output #0: loss = 25.3658 (* 1 = 25.3658 loss)
I0408 21:15:55.459836  9048 sgd_solver.cpp:106] Iteration 676, lr = 0.01
I0408 21:15:55.735311  9048 solver.cpp:240] Iteration 677, loss = 14.1401
I0408 21:15:55.735345  9048 solver.cpp:256]     Train net output #0: loss = 14.1401 (* 1 = 14.1401 loss)
I0408 21:15:55.735354  9048 sgd_solver.cpp:106] Iteration 677, lr = 0.01
I0408 21:15:56.010466  9048 solver.cpp:240] Iteration 678, loss = 6.99833
I0408 21:15:56.010500  9048 solver.cpp:256]     Train net output #0: loss = 6.99832 (* 1 = 6.99832 loss)
I0408 21:15:56.010509  9048 sgd_solver.cpp:106] Iteration 678, lr = 0.01
I0408 21:15:56.287622  9048 solver.cpp:240] Iteration 679, loss = 9.77208
I0408 21:15:56.287657  9048 solver.cpp:256]     Train net output #0: loss = 9.77208 (* 1 = 9.77208 loss)
I0408 21:15:56.287667  9048 sgd_solver.cpp:106] Iteration 679, lr = 0.01
I0408 21:15:56.563357  9048 solver.cpp:240] Iteration 680, loss = 5.93655
I0408 21:15:56.563400  9048 solver.cpp:256]     Train net output #0: loss = 5.93655 (* 1 = 5.93655 loss)
I0408 21:15:56.563408  9048 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0408 21:15:56.839061  9048 solver.cpp:240] Iteration 681, loss = 21.8999
I0408 21:15:56.839094  9048 solver.cpp:256]     Train net output #0: loss = 21.8999 (* 1 = 21.8999 loss)
I0408 21:15:56.839102  9048 sgd_solver.cpp:106] Iteration 681, lr = 0.01
I0408 21:15:57.114703  9048 solver.cpp:240] Iteration 682, loss = 16.782
I0408 21:15:57.114737  9048 solver.cpp:256]     Train net output #0: loss = 16.782 (* 1 = 16.782 loss)
I0408 21:15:57.114744  9048 sgd_solver.cpp:106] Iteration 682, lr = 0.01
I0408 21:15:57.391671  9048 solver.cpp:240] Iteration 683, loss = 25.8752
I0408 21:15:57.391706  9048 solver.cpp:256]     Train net output #0: loss = 25.8752 (* 1 = 25.8752 loss)
I0408 21:15:57.391715  9048 sgd_solver.cpp:106] Iteration 683, lr = 0.01
I0408 21:15:57.668027  9048 solver.cpp:240] Iteration 684, loss = 19.7252
I0408 21:15:57.668066  9048 solver.cpp:256]     Train net output #0: loss = 19.7252 (* 1 = 19.7252 loss)
I0408 21:15:57.668074  9048 sgd_solver.cpp:106] Iteration 684, lr = 0.01
I0408 21:15:57.943691  9048 solver.cpp:240] Iteration 685, loss = 18.5569
I0408 21:15:57.943724  9048 solver.cpp:256]     Train net output #0: loss = 18.5569 (* 1 = 18.5569 loss)
I0408 21:15:57.943732  9048 sgd_solver.cpp:106] Iteration 685, lr = 0.01
I0408 21:15:58.219528  9048 solver.cpp:240] Iteration 686, loss = 3.70771
I0408 21:15:58.219558  9048 solver.cpp:256]     Train net output #0: loss = 3.70771 (* 1 = 3.70771 loss)
I0408 21:15:58.219566  9048 sgd_solver.cpp:106] Iteration 686, lr = 0.01
I0408 21:15:58.496223  9048 solver.cpp:240] Iteration 687, loss = 4.15833
I0408 21:15:58.496254  9048 solver.cpp:256]     Train net output #0: loss = 4.15833 (* 1 = 4.15833 loss)
I0408 21:15:58.496261  9048 sgd_solver.cpp:106] Iteration 687, lr = 0.01
I0408 21:15:58.772495  9048 solver.cpp:240] Iteration 688, loss = 7.69155
I0408 21:15:58.772526  9048 solver.cpp:256]     Train net output #0: loss = 7.69155 (* 1 = 7.69155 loss)
I0408 21:15:58.772534  9048 sgd_solver.cpp:106] Iteration 688, lr = 0.01
I0408 21:15:59.048208  9048 solver.cpp:240] Iteration 689, loss = 12.4939
I0408 21:15:59.048245  9048 solver.cpp:256]     Train net output #0: loss = 12.4939 (* 1 = 12.4939 loss)
I0408 21:15:59.048254  9048 sgd_solver.cpp:106] Iteration 689, lr = 0.01
I0408 21:15:59.323849  9048 solver.cpp:240] Iteration 690, loss = 16.9804
I0408 21:15:59.323915  9048 solver.cpp:256]     Train net output #0: loss = 16.9804 (* 1 = 16.9804 loss)
I0408 21:15:59.323925  9048 sgd_solver.cpp:106] Iteration 690, lr = 0.01
I0408 21:15:59.599578  9048 solver.cpp:240] Iteration 691, loss = 7.8281
I0408 21:15:59.599625  9048 solver.cpp:256]     Train net output #0: loss = 7.8281 (* 1 = 7.8281 loss)
I0408 21:15:59.599634  9048 sgd_solver.cpp:106] Iteration 691, lr = 0.01
I0408 21:15:59.875584  9048 solver.cpp:240] Iteration 692, loss = 32.7172
I0408 21:15:59.875617  9048 solver.cpp:256]     Train net output #0: loss = 32.7172 (* 1 = 32.7172 loss)
I0408 21:15:59.875627  9048 sgd_solver.cpp:106] Iteration 692, lr = 0.01
I0408 21:16:00.152952  9048 solver.cpp:240] Iteration 693, loss = 28.296
I0408 21:16:00.152988  9048 solver.cpp:256]     Train net output #0: loss = 28.296 (* 1 = 28.296 loss)
I0408 21:16:00.152997  9048 sgd_solver.cpp:106] Iteration 693, lr = 0.01
I0408 21:16:00.428928  9048 solver.cpp:240] Iteration 694, loss = 24.3991
I0408 21:16:00.428961  9048 solver.cpp:256]     Train net output #0: loss = 24.3991 (* 1 = 24.3991 loss)
I0408 21:16:00.428969  9048 sgd_solver.cpp:106] Iteration 694, lr = 0.01
I0408 21:16:00.705183  9048 solver.cpp:240] Iteration 695, loss = 17.08
I0408 21:16:00.705215  9048 solver.cpp:256]     Train net output #0: loss = 17.08 (* 1 = 17.08 loss)
I0408 21:16:00.705224  9048 sgd_solver.cpp:106] Iteration 695, lr = 0.01
I0408 21:16:00.980881  9048 solver.cpp:240] Iteration 696, loss = 13.0956
I0408 21:16:00.980931  9048 solver.cpp:256]     Train net output #0: loss = 13.0956 (* 1 = 13.0956 loss)
I0408 21:16:00.980939  9048 sgd_solver.cpp:106] Iteration 696, lr = 0.01
I0408 21:16:01.257135  9048 solver.cpp:240] Iteration 697, loss = 10.9917
I0408 21:16:01.257169  9048 solver.cpp:256]     Train net output #0: loss = 10.9917 (* 1 = 10.9917 loss)
I0408 21:16:01.257176  9048 sgd_solver.cpp:106] Iteration 697, lr = 0.01
I0408 21:16:01.532469  9048 solver.cpp:240] Iteration 698, loss = 5.18597
I0408 21:16:01.532500  9048 solver.cpp:256]     Train net output #0: loss = 5.18597 (* 1 = 5.18597 loss)
I0408 21:16:01.532506  9048 sgd_solver.cpp:106] Iteration 698, lr = 0.01
I0408 21:16:01.808710  9048 solver.cpp:240] Iteration 699, loss = 7.58838
I0408 21:16:01.808754  9048 solver.cpp:256]     Train net output #0: loss = 7.58838 (* 1 = 7.58838 loss)
I0408 21:16:01.808763  9048 sgd_solver.cpp:106] Iteration 699, lr = 0.01
I0408 21:16:02.085032  9048 solver.cpp:240] Iteration 700, loss = 10.8267
I0408 21:16:02.085065  9048 solver.cpp:256]     Train net output #0: loss = 10.8267 (* 1 = 10.8267 loss)
I0408 21:16:02.085074  9048 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0408 21:16:02.361464  9048 solver.cpp:240] Iteration 701, loss = 5.77492
I0408 21:16:02.361495  9048 solver.cpp:256]     Train net output #0: loss = 5.77492 (* 1 = 5.77492 loss)
I0408 21:16:02.361503  9048 sgd_solver.cpp:106] Iteration 701, lr = 0.01
I0408 21:16:02.637161  9048 solver.cpp:240] Iteration 702, loss = 6.43395
I0408 21:16:02.637218  9048 solver.cpp:256]     Train net output #0: loss = 6.43395 (* 1 = 6.43395 loss)
I0408 21:16:02.637228  9048 sgd_solver.cpp:106] Iteration 702, lr = 0.01
I0408 21:16:02.911655  9048 solver.cpp:240] Iteration 703, loss = 8.41425
I0408 21:16:02.911702  9048 solver.cpp:256]     Train net output #0: loss = 8.41425 (* 1 = 8.41425 loss)
I0408 21:16:02.911710  9048 sgd_solver.cpp:106] Iteration 703, lr = 0.01
I0408 21:16:03.189265  9048 solver.cpp:240] Iteration 704, loss = 14.9316
I0408 21:16:03.189299  9048 solver.cpp:256]     Train net output #0: loss = 14.9316 (* 1 = 14.9316 loss)
I0408 21:16:03.189307  9048 sgd_solver.cpp:106] Iteration 704, lr = 0.01
I0408 21:16:03.465291  9048 solver.cpp:240] Iteration 705, loss = 27.0862
I0408 21:16:03.465335  9048 solver.cpp:256]     Train net output #0: loss = 27.0862 (* 1 = 27.0862 loss)
I0408 21:16:03.465343  9048 sgd_solver.cpp:106] Iteration 705, lr = 0.01
I0408 21:16:03.740020  9048 solver.cpp:240] Iteration 706, loss = 12.188
I0408 21:16:03.740052  9048 solver.cpp:256]     Train net output #0: loss = 12.188 (* 1 = 12.188 loss)
I0408 21:16:03.740061  9048 sgd_solver.cpp:106] Iteration 706, lr = 0.01
I0408 21:16:04.016453  9048 solver.cpp:240] Iteration 707, loss = 21.111
I0408 21:16:04.016485  9048 solver.cpp:256]     Train net output #0: loss = 21.111 (* 1 = 21.111 loss)
I0408 21:16:04.016494  9048 sgd_solver.cpp:106] Iteration 707, lr = 0.01
I0408 21:16:04.292121  9048 solver.cpp:240] Iteration 708, loss = 11.7327
I0408 21:16:04.292155  9048 solver.cpp:256]     Train net output #0: loss = 11.7327 (* 1 = 11.7327 loss)
I0408 21:16:04.292163  9048 sgd_solver.cpp:106] Iteration 708, lr = 0.01
I0408 21:16:04.568433  9048 solver.cpp:240] Iteration 709, loss = 6.48457
I0408 21:16:04.568478  9048 solver.cpp:256]     Train net output #0: loss = 6.48457 (* 1 = 6.48457 loss)
I0408 21:16:04.568488  9048 sgd_solver.cpp:106] Iteration 709, lr = 0.01
I0408 21:16:04.843540  9048 solver.cpp:240] Iteration 710, loss = 1.50244
I0408 21:16:04.843572  9048 solver.cpp:256]     Train net output #0: loss = 1.50244 (* 1 = 1.50244 loss)
I0408 21:16:04.843580  9048 sgd_solver.cpp:106] Iteration 710, lr = 0.01
I0408 21:16:05.119801  9048 solver.cpp:240] Iteration 711, loss = 1.57046
I0408 21:16:05.119835  9048 solver.cpp:256]     Train net output #0: loss = 1.57046 (* 1 = 1.57046 loss)
I0408 21:16:05.119843  9048 sgd_solver.cpp:106] Iteration 711, lr = 0.01
I0408 21:16:05.396186  9048 solver.cpp:240] Iteration 712, loss = 12.3001
I0408 21:16:05.396220  9048 solver.cpp:256]     Train net output #0: loss = 12.3001 (* 1 = 12.3001 loss)
I0408 21:16:05.396229  9048 sgd_solver.cpp:106] Iteration 712, lr = 0.01
I0408 21:16:05.672648  9048 solver.cpp:240] Iteration 713, loss = 10.3561
I0408 21:16:05.672683  9048 solver.cpp:256]     Train net output #0: loss = 10.3561 (* 1 = 10.3561 loss)
I0408 21:16:05.672693  9048 sgd_solver.cpp:106] Iteration 713, lr = 0.01
I0408 21:16:05.949193  9048 solver.cpp:240] Iteration 714, loss = 13.7625
I0408 21:16:05.949228  9048 solver.cpp:256]     Train net output #0: loss = 13.7625 (* 1 = 13.7625 loss)
I0408 21:16:05.949235  9048 sgd_solver.cpp:106] Iteration 714, lr = 0.01
I0408 21:16:06.225764  9048 solver.cpp:240] Iteration 715, loss = 11.4046
I0408 21:16:06.225798  9048 solver.cpp:256]     Train net output #0: loss = 11.4046 (* 1 = 11.4046 loss)
I0408 21:16:06.225807  9048 sgd_solver.cpp:106] Iteration 715, lr = 0.01
I0408 21:16:06.502037  9048 solver.cpp:240] Iteration 716, loss = 7.35731
I0408 21:16:06.502074  9048 solver.cpp:256]     Train net output #0: loss = 7.35731 (* 1 = 7.35731 loss)
I0408 21:16:06.502082  9048 sgd_solver.cpp:106] Iteration 716, lr = 0.01
I0408 21:16:06.778724  9048 solver.cpp:240] Iteration 717, loss = 20.4085
I0408 21:16:06.778758  9048 solver.cpp:256]     Train net output #0: loss = 20.4085 (* 1 = 20.4085 loss)
I0408 21:16:06.778765  9048 sgd_solver.cpp:106] Iteration 717, lr = 0.01
I0408 21:16:07.054683  9048 solver.cpp:240] Iteration 718, loss = 3.44732
I0408 21:16:07.054716  9048 solver.cpp:256]     Train net output #0: loss = 3.44732 (* 1 = 3.44732 loss)
I0408 21:16:07.054749  9048 sgd_solver.cpp:106] Iteration 718, lr = 0.01
I0408 21:16:07.331233  9048 solver.cpp:240] Iteration 719, loss = 20.2853
I0408 21:16:07.331266  9048 solver.cpp:256]     Train net output #0: loss = 20.2853 (* 1 = 20.2853 loss)
I0408 21:16:07.331274  9048 sgd_solver.cpp:106] Iteration 719, lr = 0.01
I0408 21:16:07.607348  9048 solver.cpp:240] Iteration 720, loss = 24.1318
I0408 21:16:07.607383  9048 solver.cpp:256]     Train net output #0: loss = 24.1318 (* 1 = 24.1318 loss)
I0408 21:16:07.607391  9048 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0408 21:16:07.883389  9048 solver.cpp:240] Iteration 721, loss = 6.94093
I0408 21:16:07.883424  9048 solver.cpp:256]     Train net output #0: loss = 6.94093 (* 1 = 6.94093 loss)
I0408 21:16:07.883433  9048 sgd_solver.cpp:106] Iteration 721, lr = 0.01
I0408 21:16:08.159994  9048 solver.cpp:240] Iteration 722, loss = 22.4595
I0408 21:16:08.160032  9048 solver.cpp:256]     Train net output #0: loss = 22.4595 (* 1 = 22.4595 loss)
I0408 21:16:08.160042  9048 sgd_solver.cpp:106] Iteration 722, lr = 0.01
I0408 21:16:08.436522  9048 solver.cpp:240] Iteration 723, loss = 24.3731
I0408 21:16:08.436556  9048 solver.cpp:256]     Train net output #0: loss = 24.3731 (* 1 = 24.3731 loss)
I0408 21:16:08.436564  9048 sgd_solver.cpp:106] Iteration 723, lr = 0.01
I0408 21:16:08.711570  9048 solver.cpp:240] Iteration 724, loss = 20.0278
I0408 21:16:08.711603  9048 solver.cpp:256]     Train net output #0: loss = 20.0278 (* 1 = 20.0278 loss)
I0408 21:16:08.711611  9048 sgd_solver.cpp:106] Iteration 724, lr = 0.01
I0408 21:16:08.988402  9048 solver.cpp:240] Iteration 725, loss = 22.0443
I0408 21:16:08.988436  9048 solver.cpp:256]     Train net output #0: loss = 22.0443 (* 1 = 22.0443 loss)
I0408 21:16:08.988445  9048 sgd_solver.cpp:106] Iteration 725, lr = 0.01
I0408 21:16:09.264189  9048 solver.cpp:240] Iteration 726, loss = 13.9376
I0408 21:16:09.264221  9048 solver.cpp:256]     Train net output #0: loss = 13.9376 (* 1 = 13.9376 loss)
I0408 21:16:09.264230  9048 sgd_solver.cpp:106] Iteration 726, lr = 0.01
I0408 21:16:09.540931  9048 solver.cpp:240] Iteration 727, loss = 22.5364
I0408 21:16:09.540966  9048 solver.cpp:256]     Train net output #0: loss = 22.5364 (* 1 = 22.5364 loss)
I0408 21:16:09.540973  9048 sgd_solver.cpp:106] Iteration 727, lr = 0.01
I0408 21:16:09.817276  9048 solver.cpp:240] Iteration 728, loss = 19.7353
I0408 21:16:09.817308  9048 solver.cpp:256]     Train net output #0: loss = 19.7353 (* 1 = 19.7353 loss)
I0408 21:16:09.817317  9048 sgd_solver.cpp:106] Iteration 728, lr = 0.01
I0408 21:16:10.093142  9048 solver.cpp:240] Iteration 729, loss = 9.72326
I0408 21:16:10.093189  9048 solver.cpp:256]     Train net output #0: loss = 9.72326 (* 1 = 9.72326 loss)
I0408 21:16:10.093199  9048 sgd_solver.cpp:106] Iteration 729, lr = 0.01
I0408 21:16:10.369644  9048 solver.cpp:240] Iteration 730, loss = 13.0199
I0408 21:16:10.369688  9048 solver.cpp:256]     Train net output #0: loss = 13.0199 (* 1 = 13.0199 loss)
I0408 21:16:10.369696  9048 sgd_solver.cpp:106] Iteration 730, lr = 0.01
I0408 21:16:10.646417  9048 solver.cpp:240] Iteration 731, loss = 8.63443
I0408 21:16:10.646448  9048 solver.cpp:256]     Train net output #0: loss = 8.63443 (* 1 = 8.63443 loss)
I0408 21:16:10.646456  9048 sgd_solver.cpp:106] Iteration 731, lr = 0.01
I0408 21:16:10.922127  9048 solver.cpp:240] Iteration 732, loss = 8.87831
I0408 21:16:10.922158  9048 solver.cpp:256]     Train net output #0: loss = 8.87831 (* 1 = 8.87831 loss)
I0408 21:16:10.922165  9048 sgd_solver.cpp:106] Iteration 732, lr = 0.01
I0408 21:16:11.198168  9048 solver.cpp:240] Iteration 733, loss = 4.95728
I0408 21:16:11.198197  9048 solver.cpp:256]     Train net output #0: loss = 4.95728 (* 1 = 4.95728 loss)
I0408 21:16:11.198205  9048 sgd_solver.cpp:106] Iteration 733, lr = 0.01
I0408 21:16:11.474570  9048 solver.cpp:240] Iteration 734, loss = 28.516
I0408 21:16:11.474608  9048 solver.cpp:256]     Train net output #0: loss = 28.516 (* 1 = 28.516 loss)
I0408 21:16:11.474617  9048 sgd_solver.cpp:106] Iteration 734, lr = 0.01
I0408 21:16:11.751021  9048 solver.cpp:240] Iteration 735, loss = 16.8132
I0408 21:16:11.751055  9048 solver.cpp:256]     Train net output #0: loss = 16.8132 (* 1 = 16.8132 loss)
I0408 21:16:11.751063  9048 sgd_solver.cpp:106] Iteration 735, lr = 0.01
I0408 21:16:12.027490  9048 solver.cpp:240] Iteration 736, loss = 30.0528
I0408 21:16:12.027523  9048 solver.cpp:256]     Train net output #0: loss = 30.0528 (* 1 = 30.0528 loss)
I0408 21:16:12.027530  9048 sgd_solver.cpp:106] Iteration 736, lr = 0.01
I0408 21:16:12.303606  9048 solver.cpp:240] Iteration 737, loss = 25.6575
I0408 21:16:12.303640  9048 solver.cpp:256]     Train net output #0: loss = 25.6575 (* 1 = 25.6575 loss)
I0408 21:16:12.303649  9048 sgd_solver.cpp:106] Iteration 737, lr = 0.01
I0408 21:16:12.580307  9048 solver.cpp:240] Iteration 738, loss = 14.2841
I0408 21:16:12.580340  9048 solver.cpp:256]     Train net output #0: loss = 14.2841 (* 1 = 14.2841 loss)
I0408 21:16:12.580348  9048 sgd_solver.cpp:106] Iteration 738, lr = 0.01
I0408 21:16:12.856704  9048 solver.cpp:240] Iteration 739, loss = 17.2633
I0408 21:16:12.856755  9048 solver.cpp:256]     Train net output #0: loss = 17.2633 (* 1 = 17.2633 loss)
I0408 21:16:12.856763  9048 sgd_solver.cpp:106] Iteration 739, lr = 0.01
I0408 21:16:13.133589  9048 solver.cpp:240] Iteration 740, loss = 21.4428
I0408 21:16:13.133620  9048 solver.cpp:256]     Train net output #0: loss = 21.4428 (* 1 = 21.4428 loss)
I0408 21:16:13.133628  9048 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0408 21:16:13.409793  9048 solver.cpp:240] Iteration 741, loss = 24.4264
I0408 21:16:13.409837  9048 solver.cpp:256]     Train net output #0: loss = 24.4264 (* 1 = 24.4264 loss)
I0408 21:16:13.409845  9048 sgd_solver.cpp:106] Iteration 741, lr = 0.01
I0408 21:16:13.686347  9048 solver.cpp:240] Iteration 742, loss = 8.89501
I0408 21:16:13.686380  9048 solver.cpp:256]     Train net output #0: loss = 8.89501 (* 1 = 8.89501 loss)
I0408 21:16:13.686388  9048 sgd_solver.cpp:106] Iteration 742, lr = 0.01
I0408 21:16:13.962724  9048 solver.cpp:240] Iteration 743, loss = 2.7386
I0408 21:16:13.962757  9048 solver.cpp:256]     Train net output #0: loss = 2.7386 (* 1 = 2.7386 loss)
I0408 21:16:13.962765  9048 sgd_solver.cpp:106] Iteration 743, lr = 0.01
I0408 21:16:14.238878  9048 solver.cpp:240] Iteration 744, loss = 3.52619
I0408 21:16:14.238911  9048 solver.cpp:256]     Train net output #0: loss = 3.52619 (* 1 = 3.52619 loss)
I0408 21:16:14.238919  9048 sgd_solver.cpp:106] Iteration 744, lr = 0.01
I0408 21:16:14.515292  9048 solver.cpp:240] Iteration 745, loss = 26.9627
I0408 21:16:14.515326  9048 solver.cpp:256]     Train net output #0: loss = 26.9627 (* 1 = 26.9627 loss)
I0408 21:16:14.515336  9048 sgd_solver.cpp:106] Iteration 745, lr = 0.01
I0408 21:16:14.790920  9048 solver.cpp:240] Iteration 746, loss = 26.5965
I0408 21:16:14.790952  9048 solver.cpp:256]     Train net output #0: loss = 26.5965 (* 1 = 26.5965 loss)
I0408 21:16:14.790961  9048 sgd_solver.cpp:106] Iteration 746, lr = 0.01
I0408 21:16:15.066567  9048 solver.cpp:240] Iteration 747, loss = 22.3199
I0408 21:16:15.066601  9048 solver.cpp:256]     Train net output #0: loss = 22.3199 (* 1 = 22.3199 loss)
I0408 21:16:15.066608  9048 sgd_solver.cpp:106] Iteration 747, lr = 0.01
I0408 21:16:15.342506  9048 solver.cpp:240] Iteration 748, loss = 12.2494
I0408 21:16:15.342540  9048 solver.cpp:256]     Train net output #0: loss = 12.2494 (* 1 = 12.2494 loss)
I0408 21:16:15.342548  9048 sgd_solver.cpp:106] Iteration 748, lr = 0.01
I0408 21:16:15.618528  9048 solver.cpp:240] Iteration 749, loss = 32.148
I0408 21:16:15.618561  9048 solver.cpp:256]     Train net output #0: loss = 32.148 (* 1 = 32.148 loss)
I0408 21:16:15.618568  9048 sgd_solver.cpp:106] Iteration 749, lr = 0.01
I0408 21:16:15.894379  9048 solver.cpp:240] Iteration 750, loss = 28.0753
I0408 21:16:15.894412  9048 solver.cpp:256]     Train net output #0: loss = 28.0753 (* 1 = 28.0753 loss)
I0408 21:16:15.894420  9048 sgd_solver.cpp:106] Iteration 750, lr = 0.01
I0408 21:16:16.170500  9048 solver.cpp:240] Iteration 751, loss = 7.67809
I0408 21:16:16.170529  9048 solver.cpp:256]     Train net output #0: loss = 7.67809 (* 1 = 7.67809 loss)
I0408 21:16:16.170538  9048 sgd_solver.cpp:106] Iteration 751, lr = 0.01
I0408 21:16:16.445402  9048 solver.cpp:240] Iteration 752, loss = 8.99632
I0408 21:16:16.445448  9048 solver.cpp:256]     Train net output #0: loss = 8.99632 (* 1 = 8.99632 loss)
I0408 21:16:16.445456  9048 sgd_solver.cpp:106] Iteration 752, lr = 0.01
I0408 21:16:16.722299  9048 solver.cpp:240] Iteration 753, loss = 23.5164
I0408 21:16:16.722333  9048 solver.cpp:256]     Train net output #0: loss = 23.5164 (* 1 = 23.5164 loss)
I0408 21:16:16.722342  9048 sgd_solver.cpp:106] Iteration 753, lr = 0.01
I0408 21:16:16.999433  9048 solver.cpp:240] Iteration 754, loss = 21.4445
I0408 21:16:16.999466  9048 solver.cpp:256]     Train net output #0: loss = 21.4445 (* 1 = 21.4445 loss)
I0408 21:16:16.999475  9048 sgd_solver.cpp:106] Iteration 754, lr = 0.01
I0408 21:16:17.276269  9048 solver.cpp:240] Iteration 755, loss = 18.7442
I0408 21:16:17.276312  9048 solver.cpp:256]     Train net output #0: loss = 18.7442 (* 1 = 18.7442 loss)
I0408 21:16:17.276321  9048 sgd_solver.cpp:106] Iteration 755, lr = 0.01
I0408 21:16:17.552285  9048 solver.cpp:240] Iteration 756, loss = 9.34579
I0408 21:16:17.552317  9048 solver.cpp:256]     Train net output #0: loss = 9.34579 (* 1 = 9.34579 loss)
I0408 21:16:17.552325  9048 sgd_solver.cpp:106] Iteration 756, lr = 0.01
I0408 21:16:17.828598  9048 solver.cpp:240] Iteration 757, loss = 1.17001
I0408 21:16:17.828637  9048 solver.cpp:256]     Train net output #0: loss = 1.17001 (* 1 = 1.17001 loss)
I0408 21:16:17.828646  9048 sgd_solver.cpp:106] Iteration 757, lr = 0.01
I0408 21:16:18.103787  9048 solver.cpp:240] Iteration 758, loss = 14.0422
I0408 21:16:18.103832  9048 solver.cpp:256]     Train net output #0: loss = 14.0422 (* 1 = 14.0422 loss)
I0408 21:16:18.103839  9048 sgd_solver.cpp:106] Iteration 758, lr = 0.01
I0408 21:16:18.379761  9048 solver.cpp:240] Iteration 759, loss = 4.75506
I0408 21:16:18.379793  9048 solver.cpp:256]     Train net output #0: loss = 4.75506 (* 1 = 4.75506 loss)
I0408 21:16:18.379801  9048 sgd_solver.cpp:106] Iteration 759, lr = 0.01
I0408 21:16:18.655629  9048 solver.cpp:240] Iteration 760, loss = 20.4928
I0408 21:16:18.655665  9048 solver.cpp:256]     Train net output #0: loss = 20.4928 (* 1 = 20.4928 loss)
I0408 21:16:18.655673  9048 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0408 21:16:18.931380  9048 solver.cpp:240] Iteration 761, loss = 10.9636
I0408 21:16:18.931412  9048 solver.cpp:256]     Train net output #0: loss = 10.9636 (* 1 = 10.9636 loss)
I0408 21:16:18.931421  9048 sgd_solver.cpp:106] Iteration 761, lr = 0.01
I0408 21:16:19.207566  9048 solver.cpp:240] Iteration 762, loss = 26.2073
I0408 21:16:19.207733  9048 solver.cpp:256]     Train net output #0: loss = 26.2073 (* 1 = 26.2073 loss)
I0408 21:16:19.207744  9048 sgd_solver.cpp:106] Iteration 762, lr = 0.01
I0408 21:16:19.483476  9048 solver.cpp:240] Iteration 763, loss = 17.3598
I0408 21:16:19.483518  9048 solver.cpp:256]     Train net output #0: loss = 17.3598 (* 1 = 17.3598 loss)
I0408 21:16:19.483527  9048 sgd_solver.cpp:106] Iteration 763, lr = 0.01
I0408 21:16:19.759379  9048 solver.cpp:240] Iteration 764, loss = 22.7222
I0408 21:16:19.759415  9048 solver.cpp:256]     Train net output #0: loss = 22.7222 (* 1 = 22.7222 loss)
I0408 21:16:19.759423  9048 sgd_solver.cpp:106] Iteration 764, lr = 0.01
I0408 21:16:20.035316  9048 solver.cpp:240] Iteration 765, loss = 22.5184
I0408 21:16:20.035362  9048 solver.cpp:256]     Train net output #0: loss = 22.5184 (* 1 = 22.5184 loss)
I0408 21:16:20.035370  9048 sgd_solver.cpp:106] Iteration 765, lr = 0.01
I0408 21:16:20.311247  9048 solver.cpp:240] Iteration 766, loss = 10.4561
I0408 21:16:20.311281  9048 solver.cpp:256]     Train net output #0: loss = 10.4561 (* 1 = 10.4561 loss)
I0408 21:16:20.311290  9048 sgd_solver.cpp:106] Iteration 766, lr = 0.01
I0408 21:16:20.586480  9048 solver.cpp:240] Iteration 767, loss = 10.4152
I0408 21:16:20.586514  9048 solver.cpp:256]     Train net output #0: loss = 10.4152 (* 1 = 10.4152 loss)
I0408 21:16:20.586522  9048 sgd_solver.cpp:106] Iteration 767, lr = 0.01
I0408 21:16:20.862418  9048 solver.cpp:240] Iteration 768, loss = 8.76956
I0408 21:16:20.862450  9048 solver.cpp:256]     Train net output #0: loss = 8.76956 (* 1 = 8.76956 loss)
I0408 21:16:20.862458  9048 sgd_solver.cpp:106] Iteration 768, lr = 0.01
I0408 21:16:21.138505  9048 solver.cpp:240] Iteration 769, loss = 17.0678
I0408 21:16:21.138540  9048 solver.cpp:256]     Train net output #0: loss = 17.0678 (* 1 = 17.0678 loss)
I0408 21:16:21.138548  9048 sgd_solver.cpp:106] Iteration 769, lr = 0.01
I0408 21:16:21.415098  9048 solver.cpp:240] Iteration 770, loss = 8.89308
I0408 21:16:21.415138  9048 solver.cpp:256]     Train net output #0: loss = 8.89308 (* 1 = 8.89308 loss)
I0408 21:16:21.415146  9048 sgd_solver.cpp:106] Iteration 770, lr = 0.01
I0408 21:16:21.691257  9048 solver.cpp:240] Iteration 771, loss = 6.43034
I0408 21:16:21.691289  9048 solver.cpp:256]     Train net output #0: loss = 6.43034 (* 1 = 6.43034 loss)
I0408 21:16:21.691298  9048 sgd_solver.cpp:106] Iteration 771, lr = 0.01
I0408 21:16:21.968811  9048 solver.cpp:240] Iteration 772, loss = 10.1159
I0408 21:16:21.968863  9048 solver.cpp:256]     Train net output #0: loss = 10.1159 (* 1 = 10.1159 loss)
I0408 21:16:21.968874  9048 sgd_solver.cpp:106] Iteration 772, lr = 0.01
I0408 21:16:22.244935  9048 solver.cpp:240] Iteration 773, loss = 12.5582
I0408 21:16:22.244989  9048 solver.cpp:256]     Train net output #0: loss = 12.5582 (* 1 = 12.5582 loss)
I0408 21:16:22.245000  9048 sgd_solver.cpp:106] Iteration 773, lr = 0.01
I0408 21:16:22.521416  9048 solver.cpp:240] Iteration 774, loss = 17.0485
I0408 21:16:22.521459  9048 solver.cpp:256]     Train net output #0: loss = 17.0485 (* 1 = 17.0485 loss)
I0408 21:16:22.521467  9048 sgd_solver.cpp:106] Iteration 774, lr = 0.01
I0408 21:16:22.797664  9048 solver.cpp:240] Iteration 775, loss = 14.936
I0408 21:16:22.797703  9048 solver.cpp:256]     Train net output #0: loss = 14.936 (* 1 = 14.936 loss)
I0408 21:16:22.797711  9048 sgd_solver.cpp:106] Iteration 775, lr = 0.01
I0408 21:16:23.073987  9048 solver.cpp:240] Iteration 776, loss = 15.4246
I0408 21:16:23.074023  9048 solver.cpp:256]     Train net output #0: loss = 15.4246 (* 1 = 15.4246 loss)
I0408 21:16:23.074031  9048 sgd_solver.cpp:106] Iteration 776, lr = 0.01
I0408 21:16:23.349328  9048 solver.cpp:240] Iteration 777, loss = 2.58618
I0408 21:16:23.349360  9048 solver.cpp:256]     Train net output #0: loss = 2.58618 (* 1 = 2.58618 loss)
I0408 21:16:23.349369  9048 sgd_solver.cpp:106] Iteration 777, lr = 0.01
I0408 21:16:23.625290  9048 solver.cpp:240] Iteration 778, loss = 2.22302
I0408 21:16:23.625331  9048 solver.cpp:256]     Train net output #0: loss = 2.22302 (* 1 = 2.22302 loss)
I0408 21:16:23.625355  9048 sgd_solver.cpp:106] Iteration 778, lr = 0.01
I0408 21:16:23.900398  9048 solver.cpp:240] Iteration 779, loss = 10.112
I0408 21:16:23.900430  9048 solver.cpp:256]     Train net output #0: loss = 10.112 (* 1 = 10.112 loss)
I0408 21:16:23.900439  9048 sgd_solver.cpp:106] Iteration 779, lr = 0.01
I0408 21:16:24.176275  9048 solver.cpp:240] Iteration 780, loss = 9.59805
I0408 21:16:24.176311  9048 solver.cpp:256]     Train net output #0: loss = 9.59805 (* 1 = 9.59805 loss)
I0408 21:16:24.176321  9048 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0408 21:16:24.452481  9048 solver.cpp:240] Iteration 781, loss = 13.2409
I0408 21:16:24.452513  9048 solver.cpp:256]     Train net output #0: loss = 13.2409 (* 1 = 13.2409 loss)
I0408 21:16:24.452522  9048 sgd_solver.cpp:106] Iteration 781, lr = 0.01
I0408 21:16:24.728631  9048 solver.cpp:240] Iteration 782, loss = 8.03806
I0408 21:16:24.728663  9048 solver.cpp:256]     Train net output #0: loss = 8.03806 (* 1 = 8.03806 loss)
I0408 21:16:24.728672  9048 sgd_solver.cpp:106] Iteration 782, lr = 0.01
I0408 21:16:25.004693  9048 solver.cpp:240] Iteration 783, loss = 14.2502
I0408 21:16:25.004726  9048 solver.cpp:256]     Train net output #0: loss = 14.2502 (* 1 = 14.2502 loss)
I0408 21:16:25.004735  9048 sgd_solver.cpp:106] Iteration 783, lr = 0.01
I0408 21:16:25.280511  9048 solver.cpp:240] Iteration 784, loss = 10.5622
I0408 21:16:25.280555  9048 solver.cpp:256]     Train net output #0: loss = 10.5622 (* 1 = 10.5622 loss)
I0408 21:16:25.280563  9048 sgd_solver.cpp:106] Iteration 784, lr = 0.01
I0408 21:16:25.556648  9048 solver.cpp:240] Iteration 785, loss = 7.39428
I0408 21:16:25.556677  9048 solver.cpp:256]     Train net output #0: loss = 7.39428 (* 1 = 7.39428 loss)
I0408 21:16:25.556685  9048 sgd_solver.cpp:106] Iteration 785, lr = 0.01
I0408 21:16:25.833477  9048 solver.cpp:240] Iteration 786, loss = 23.1587
I0408 21:16:25.833513  9048 solver.cpp:256]     Train net output #0: loss = 23.1587 (* 1 = 23.1587 loss)
I0408 21:16:25.833520  9048 sgd_solver.cpp:106] Iteration 786, lr = 0.01
I0408 21:16:26.110416  9048 solver.cpp:240] Iteration 787, loss = 20.2088
I0408 21:16:26.110448  9048 solver.cpp:256]     Train net output #0: loss = 20.2088 (* 1 = 20.2088 loss)
I0408 21:16:26.110456  9048 sgd_solver.cpp:106] Iteration 787, lr = 0.01
I0408 21:16:26.387538  9048 solver.cpp:240] Iteration 788, loss = 15.9415
I0408 21:16:26.387573  9048 solver.cpp:256]     Train net output #0: loss = 15.9415 (* 1 = 15.9415 loss)
I0408 21:16:26.387580  9048 sgd_solver.cpp:106] Iteration 788, lr = 0.01
I0408 21:16:26.663714  9048 solver.cpp:240] Iteration 789, loss = 20.8321
I0408 21:16:26.663758  9048 solver.cpp:256]     Train net output #0: loss = 20.8321 (* 1 = 20.8321 loss)
I0408 21:16:26.663767  9048 sgd_solver.cpp:106] Iteration 789, lr = 0.01
I0408 21:16:26.940196  9048 solver.cpp:240] Iteration 790, loss = 28.7032
I0408 21:16:26.940228  9048 solver.cpp:256]     Train net output #0: loss = 28.7032 (* 1 = 28.7032 loss)
I0408 21:16:26.940237  9048 sgd_solver.cpp:106] Iteration 790, lr = 0.01
I0408 21:16:27.216560  9048 solver.cpp:240] Iteration 791, loss = 15.9329
I0408 21:16:27.216594  9048 solver.cpp:256]     Train net output #0: loss = 15.9329 (* 1 = 15.9329 loss)
I0408 21:16:27.216603  9048 sgd_solver.cpp:106] Iteration 791, lr = 0.01
I0408 21:16:27.493901  9048 solver.cpp:240] Iteration 792, loss = 6.64928
I0408 21:16:27.493930  9048 solver.cpp:256]     Train net output #0: loss = 6.64928 (* 1 = 6.64928 loss)
I0408 21:16:27.493937  9048 sgd_solver.cpp:106] Iteration 792, lr = 0.01
I0408 21:16:27.770618  9048 solver.cpp:240] Iteration 793, loss = 2.73611
I0408 21:16:27.770651  9048 solver.cpp:256]     Train net output #0: loss = 2.73611 (* 1 = 2.73611 loss)
I0408 21:16:27.770659  9048 sgd_solver.cpp:106] Iteration 793, lr = 0.01
I0408 21:16:28.047005  9048 solver.cpp:240] Iteration 794, loss = 15.701
I0408 21:16:28.047039  9048 solver.cpp:256]     Train net output #0: loss = 15.701 (* 1 = 15.701 loss)
I0408 21:16:28.047046  9048 sgd_solver.cpp:106] Iteration 794, lr = 0.01
I0408 21:16:28.323269  9048 solver.cpp:240] Iteration 795, loss = 11.088
I0408 21:16:28.323302  9048 solver.cpp:256]     Train net output #0: loss = 11.088 (* 1 = 11.088 loss)
I0408 21:16:28.323312  9048 sgd_solver.cpp:106] Iteration 795, lr = 0.01
I0408 21:16:28.599733  9048 solver.cpp:240] Iteration 796, loss = 26.9632
I0408 21:16:28.599767  9048 solver.cpp:256]     Train net output #0: loss = 26.9632 (* 1 = 26.9632 loss)
I0408 21:16:28.599776  9048 sgd_solver.cpp:106] Iteration 796, lr = 0.01
I0408 21:16:28.877482  9048 solver.cpp:240] Iteration 797, loss = 20.0691
I0408 21:16:28.877527  9048 solver.cpp:256]     Train net output #0: loss = 20.0691 (* 1 = 20.0691 loss)
I0408 21:16:28.877537  9048 sgd_solver.cpp:106] Iteration 797, lr = 0.01
I0408 21:16:29.153918  9048 solver.cpp:240] Iteration 798, loss = 6.84772
I0408 21:16:29.153954  9048 solver.cpp:256]     Train net output #0: loss = 6.84772 (* 1 = 6.84772 loss)
I0408 21:16:29.153962  9048 sgd_solver.cpp:106] Iteration 798, lr = 0.01
I0408 21:16:29.430222  9048 solver.cpp:240] Iteration 799, loss = 7.41386
I0408 21:16:29.430254  9048 solver.cpp:256]     Train net output #0: loss = 7.41386 (* 1 = 7.41386 loss)
I0408 21:16:29.430263  9048 sgd_solver.cpp:106] Iteration 799, lr = 0.01
I0408 21:16:29.706374  9048 solver.cpp:240] Iteration 800, loss = 14.9012
I0408 21:16:29.706405  9048 solver.cpp:256]     Train net output #0: loss = 14.9012 (* 1 = 14.9012 loss)
I0408 21:16:29.706414  9048 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0408 21:16:29.982606  9048 solver.cpp:240] Iteration 801, loss = 8.07425
I0408 21:16:29.982638  9048 solver.cpp:256]     Train net output #0: loss = 8.07425 (* 1 = 8.07425 loss)
I0408 21:16:29.982646  9048 sgd_solver.cpp:106] Iteration 801, lr = 0.01
I0408 21:16:30.259333  9048 solver.cpp:240] Iteration 802, loss = 11.6039
I0408 21:16:30.259366  9048 solver.cpp:256]     Train net output #0: loss = 11.6039 (* 1 = 11.6039 loss)
I0408 21:16:30.259376  9048 sgd_solver.cpp:106] Iteration 802, lr = 0.01
I0408 21:16:30.535087  9048 solver.cpp:240] Iteration 803, loss = 6.74619
I0408 21:16:30.535123  9048 solver.cpp:256]     Train net output #0: loss = 6.74619 (* 1 = 6.74619 loss)
I0408 21:16:30.535131  9048 sgd_solver.cpp:106] Iteration 803, lr = 0.01
I0408 21:16:30.810309  9048 solver.cpp:240] Iteration 804, loss = 22.4177
I0408 21:16:30.810341  9048 solver.cpp:256]     Train net output #0: loss = 22.4177 (* 1 = 22.4177 loss)
I0408 21:16:30.810349  9048 sgd_solver.cpp:106] Iteration 804, lr = 0.01
I0408 21:16:31.086513  9048 solver.cpp:240] Iteration 805, loss = 3.06738
I0408 21:16:31.086544  9048 solver.cpp:256]     Train net output #0: loss = 3.06738 (* 1 = 3.06738 loss)
I0408 21:16:31.086552  9048 sgd_solver.cpp:106] Iteration 805, lr = 0.01
I0408 21:16:31.362304  9048 solver.cpp:240] Iteration 806, loss = 4.91771
I0408 21:16:31.362334  9048 solver.cpp:256]     Train net output #0: loss = 4.91771 (* 1 = 4.91771 loss)
I0408 21:16:31.362342  9048 sgd_solver.cpp:106] Iteration 806, lr = 0.01
I0408 21:16:31.638599  9048 solver.cpp:240] Iteration 807, loss = 12.7818
I0408 21:16:31.638645  9048 solver.cpp:256]     Train net output #0: loss = 12.7818 (* 1 = 12.7818 loss)
I0408 21:16:31.638654  9048 sgd_solver.cpp:106] Iteration 807, lr = 0.01
I0408 21:16:31.915081  9048 solver.cpp:240] Iteration 808, loss = 7.57643
I0408 21:16:31.915114  9048 solver.cpp:256]     Train net output #0: loss = 7.57643 (* 1 = 7.57643 loss)
I0408 21:16:31.915122  9048 sgd_solver.cpp:106] Iteration 808, lr = 0.01
I0408 21:16:32.191083  9048 solver.cpp:240] Iteration 809, loss = 7.67593
I0408 21:16:32.191115  9048 solver.cpp:256]     Train net output #0: loss = 7.67593 (* 1 = 7.67593 loss)
I0408 21:16:32.191123  9048 sgd_solver.cpp:106] Iteration 809, lr = 0.01
I0408 21:16:32.468575  9048 solver.cpp:240] Iteration 810, loss = 3.35803
I0408 21:16:32.468607  9048 solver.cpp:256]     Train net output #0: loss = 3.35804 (* 1 = 3.35804 loss)
I0408 21:16:32.468616  9048 sgd_solver.cpp:106] Iteration 810, lr = 0.01
I0408 21:16:32.744422  9048 solver.cpp:240] Iteration 811, loss = 6.78283
I0408 21:16:32.744478  9048 solver.cpp:256]     Train net output #0: loss = 6.78283 (* 1 = 6.78283 loss)
I0408 21:16:32.744487  9048 sgd_solver.cpp:106] Iteration 811, lr = 0.01
I0408 21:16:33.019942  9048 solver.cpp:240] Iteration 812, loss = 7.21927
I0408 21:16:33.019971  9048 solver.cpp:256]     Train net output #0: loss = 7.21927 (* 1 = 7.21927 loss)
I0408 21:16:33.019980  9048 sgd_solver.cpp:106] Iteration 812, lr = 0.01
I0408 21:16:33.296471  9048 solver.cpp:240] Iteration 813, loss = 9.33067
I0408 21:16:33.296504  9048 solver.cpp:256]     Train net output #0: loss = 9.33067 (* 1 = 9.33067 loss)
I0408 21:16:33.296514  9048 sgd_solver.cpp:106] Iteration 813, lr = 0.01
I0408 21:16:33.571789  9048 solver.cpp:240] Iteration 814, loss = 17.5978
I0408 21:16:33.571820  9048 solver.cpp:256]     Train net output #0: loss = 17.5978 (* 1 = 17.5978 loss)
I0408 21:16:33.571828  9048 sgd_solver.cpp:106] Iteration 814, lr = 0.01
I0408 21:16:33.848037  9048 solver.cpp:240] Iteration 815, loss = 28.2278
I0408 21:16:33.848071  9048 solver.cpp:256]     Train net output #0: loss = 28.2278 (* 1 = 28.2278 loss)
I0408 21:16:33.848080  9048 sgd_solver.cpp:106] Iteration 815, lr = 0.01
I0408 21:16:34.123819  9048 solver.cpp:240] Iteration 816, loss = 36.4444
I0408 21:16:34.123852  9048 solver.cpp:256]     Train net output #0: loss = 36.4444 (* 1 = 36.4444 loss)
I0408 21:16:34.123862  9048 sgd_solver.cpp:106] Iteration 816, lr = 0.01
I0408 21:16:34.399845  9048 solver.cpp:240] Iteration 817, loss = 27.7843
I0408 21:16:34.399889  9048 solver.cpp:256]     Train net output #0: loss = 27.7843 (* 1 = 27.7843 loss)
I0408 21:16:34.399899  9048 sgd_solver.cpp:106] Iteration 817, lr = 0.01
I0408 21:16:34.676069  9048 solver.cpp:240] Iteration 818, loss = 16.0809
I0408 21:16:34.676103  9048 solver.cpp:256]     Train net output #0: loss = 16.0809 (* 1 = 16.0809 loss)
I0408 21:16:34.676112  9048 sgd_solver.cpp:106] Iteration 818, lr = 0.01
I0408 21:16:34.953176  9048 solver.cpp:240] Iteration 819, loss = 14.1519
I0408 21:16:34.953218  9048 solver.cpp:256]     Train net output #0: loss = 14.1519 (* 1 = 14.1519 loss)
I0408 21:16:34.953227  9048 sgd_solver.cpp:106] Iteration 819, lr = 0.01
I0408 21:16:35.229493  9048 solver.cpp:240] Iteration 820, loss = 30.5937
I0408 21:16:35.229532  9048 solver.cpp:256]     Train net output #0: loss = 30.5937 (* 1 = 30.5937 loss)
I0408 21:16:35.229542  9048 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0408 21:16:35.504952  9048 solver.cpp:240] Iteration 821, loss = 33.0162
I0408 21:16:35.504998  9048 solver.cpp:256]     Train net output #0: loss = 33.0162 (* 1 = 33.0162 loss)
I0408 21:16:35.505007  9048 sgd_solver.cpp:106] Iteration 821, lr = 0.01
I0408 21:16:35.781137  9048 solver.cpp:240] Iteration 822, loss = 11.235
I0408 21:16:35.781173  9048 solver.cpp:256]     Train net output #0: loss = 11.235 (* 1 = 11.235 loss)
I0408 21:16:35.781183  9048 sgd_solver.cpp:106] Iteration 822, lr = 0.01
I0408 21:16:36.056252  9048 solver.cpp:240] Iteration 823, loss = 22.7871
I0408 21:16:36.056298  9048 solver.cpp:256]     Train net output #0: loss = 22.7871 (* 1 = 22.7871 loss)
I0408 21:16:36.056306  9048 sgd_solver.cpp:106] Iteration 823, lr = 0.01
I0408 21:16:36.331254  9048 solver.cpp:240] Iteration 824, loss = 17.5633
I0408 21:16:36.331287  9048 solver.cpp:256]     Train net output #0: loss = 17.5633 (* 1 = 17.5633 loss)
I0408 21:16:36.331296  9048 sgd_solver.cpp:106] Iteration 824, lr = 0.01
I0408 21:16:36.607630  9048 solver.cpp:240] Iteration 825, loss = 23.7684
I0408 21:16:36.607668  9048 solver.cpp:256]     Train net output #0: loss = 23.7684 (* 1 = 23.7684 loss)
I0408 21:16:36.607677  9048 sgd_solver.cpp:106] Iteration 825, lr = 0.01
I0408 21:16:36.883479  9048 solver.cpp:240] Iteration 826, loss = 15.4811
I0408 21:16:36.883523  9048 solver.cpp:256]     Train net output #0: loss = 15.4811 (* 1 = 15.4811 loss)
I0408 21:16:36.883532  9048 sgd_solver.cpp:106] Iteration 826, lr = 0.01
I0408 21:16:37.158587  9048 solver.cpp:240] Iteration 827, loss = 3.84819
I0408 21:16:37.158618  9048 solver.cpp:256]     Train net output #0: loss = 3.8482 (* 1 = 3.8482 loss)
I0408 21:16:37.158650  9048 sgd_solver.cpp:106] Iteration 827, lr = 0.01
I0408 21:16:37.434167  9048 solver.cpp:240] Iteration 828, loss = 24.0686
I0408 21:16:37.434202  9048 solver.cpp:256]     Train net output #0: loss = 24.0686 (* 1 = 24.0686 loss)
I0408 21:16:37.434211  9048 sgd_solver.cpp:106] Iteration 828, lr = 0.01
I0408 21:16:37.709781  9048 solver.cpp:240] Iteration 829, loss = 19.1924
I0408 21:16:37.709828  9048 solver.cpp:256]     Train net output #0: loss = 19.1924 (* 1 = 19.1924 loss)
I0408 21:16:37.709836  9048 sgd_solver.cpp:106] Iteration 829, lr = 0.01
I0408 21:16:37.985517  9048 solver.cpp:240] Iteration 830, loss = 8.87981
I0408 21:16:37.985548  9048 solver.cpp:256]     Train net output #0: loss = 8.87982 (* 1 = 8.87982 loss)
I0408 21:16:37.985555  9048 sgd_solver.cpp:106] Iteration 830, lr = 0.01
I0408 21:16:38.262310  9048 solver.cpp:240] Iteration 831, loss = 3.84957
I0408 21:16:38.262341  9048 solver.cpp:256]     Train net output #0: loss = 3.84957 (* 1 = 3.84957 loss)
I0408 21:16:38.262348  9048 sgd_solver.cpp:106] Iteration 831, lr = 0.01
I0408 21:16:38.538130  9048 solver.cpp:240] Iteration 832, loss = 6.67163
I0408 21:16:38.538163  9048 solver.cpp:256]     Train net output #0: loss = 6.67164 (* 1 = 6.67164 loss)
I0408 21:16:38.538172  9048 sgd_solver.cpp:106] Iteration 832, lr = 0.01
I0408 21:16:38.814576  9048 solver.cpp:240] Iteration 833, loss = 16.3026
I0408 21:16:38.814610  9048 solver.cpp:256]     Train net output #0: loss = 16.3026 (* 1 = 16.3026 loss)
I0408 21:16:38.814618  9048 sgd_solver.cpp:106] Iteration 833, lr = 0.01
I0408 21:16:39.090319  9048 solver.cpp:240] Iteration 834, loss = 17.2928
I0408 21:16:39.090353  9048 solver.cpp:256]     Train net output #0: loss = 17.2928 (* 1 = 17.2928 loss)
I0408 21:16:39.090361  9048 sgd_solver.cpp:106] Iteration 834, lr = 0.01
I0408 21:16:39.366363  9048 solver.cpp:240] Iteration 835, loss = 15.9388
I0408 21:16:39.366395  9048 solver.cpp:256]     Train net output #0: loss = 15.9388 (* 1 = 15.9388 loss)
I0408 21:16:39.366403  9048 sgd_solver.cpp:106] Iteration 835, lr = 0.01
I0408 21:16:39.641572  9048 solver.cpp:240] Iteration 836, loss = 12.4845
I0408 21:16:39.641604  9048 solver.cpp:256]     Train net output #0: loss = 12.4845 (* 1 = 12.4845 loss)
I0408 21:16:39.641613  9048 sgd_solver.cpp:106] Iteration 836, lr = 0.01
I0408 21:16:39.917667  9048 solver.cpp:240] Iteration 837, loss = 9.33954
I0408 21:16:39.917713  9048 solver.cpp:256]     Train net output #0: loss = 9.33955 (* 1 = 9.33955 loss)
I0408 21:16:39.917721  9048 sgd_solver.cpp:106] Iteration 837, lr = 0.01
I0408 21:16:40.193761  9048 solver.cpp:240] Iteration 838, loss = 18.9142
I0408 21:16:40.193794  9048 solver.cpp:256]     Train net output #0: loss = 18.9142 (* 1 = 18.9142 loss)
I0408 21:16:40.193802  9048 sgd_solver.cpp:106] Iteration 838, lr = 0.01
I0408 21:16:40.469645  9048 solver.cpp:240] Iteration 839, loss = 11.5178
I0408 21:16:40.469678  9048 solver.cpp:256]     Train net output #0: loss = 11.5178 (* 1 = 11.5178 loss)
I0408 21:16:40.469686  9048 sgd_solver.cpp:106] Iteration 839, lr = 0.01
I0408 21:16:40.746181  9048 solver.cpp:240] Iteration 840, loss = 2.42446
I0408 21:16:40.746215  9048 solver.cpp:256]     Train net output #0: loss = 2.42446 (* 1 = 2.42446 loss)
I0408 21:16:40.746223  9048 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0408 21:16:41.022446  9048 solver.cpp:240] Iteration 841, loss = 7.21076
I0408 21:16:41.022490  9048 solver.cpp:256]     Train net output #0: loss = 7.21077 (* 1 = 7.21077 loss)
I0408 21:16:41.022497  9048 sgd_solver.cpp:106] Iteration 841, lr = 0.01
I0408 21:16:41.298511  9048 solver.cpp:240] Iteration 842, loss = 4.04382
I0408 21:16:41.298543  9048 solver.cpp:256]     Train net output #0: loss = 4.04382 (* 1 = 4.04382 loss)
I0408 21:16:41.298552  9048 sgd_solver.cpp:106] Iteration 842, lr = 0.01
I0408 21:16:41.574167  9048 solver.cpp:240] Iteration 843, loss = 7.95252
I0408 21:16:41.574213  9048 solver.cpp:256]     Train net output #0: loss = 7.95252 (* 1 = 7.95252 loss)
I0408 21:16:41.574246  9048 sgd_solver.cpp:106] Iteration 843, lr = 0.01
I0408 21:16:41.850543  9048 solver.cpp:240] Iteration 844, loss = 6.01479
I0408 21:16:41.850577  9048 solver.cpp:256]     Train net output #0: loss = 6.01479 (* 1 = 6.01479 loss)
I0408 21:16:41.850585  9048 sgd_solver.cpp:106] Iteration 844, lr = 0.01
I0408 21:16:42.127013  9048 solver.cpp:240] Iteration 845, loss = 3.53307
I0408 21:16:42.127045  9048 solver.cpp:256]     Train net output #0: loss = 3.53307 (* 1 = 3.53307 loss)
I0408 21:16:42.127053  9048 sgd_solver.cpp:106] Iteration 845, lr = 0.01
I0408 21:16:42.402227  9048 solver.cpp:240] Iteration 846, loss = 7.55546
I0408 21:16:42.402257  9048 solver.cpp:256]     Train net output #0: loss = 7.55547 (* 1 = 7.55547 loss)
I0408 21:16:42.402266  9048 sgd_solver.cpp:106] Iteration 846, lr = 0.01
I0408 21:16:42.678035  9048 solver.cpp:240] Iteration 847, loss = 5.99511
I0408 21:16:42.678064  9048 solver.cpp:256]     Train net output #0: loss = 5.99511 (* 1 = 5.99511 loss)
I0408 21:16:42.678071  9048 sgd_solver.cpp:106] Iteration 847, lr = 0.01
I0408 21:16:42.954502  9048 solver.cpp:240] Iteration 848, loss = 9.73897
I0408 21:16:42.954535  9048 solver.cpp:256]     Train net output #0: loss = 9.73898 (* 1 = 9.73898 loss)
I0408 21:16:42.954546  9048 sgd_solver.cpp:106] Iteration 848, lr = 0.01
I0408 21:16:43.230072  9048 solver.cpp:240] Iteration 849, loss = 5.30143
I0408 21:16:43.230114  9048 solver.cpp:256]     Train net output #0: loss = 5.30143 (* 1 = 5.30143 loss)
I0408 21:16:43.230123  9048 sgd_solver.cpp:106] Iteration 849, lr = 0.01
I0408 21:16:43.505365  9048 solver.cpp:240] Iteration 850, loss = 16.3336
I0408 21:16:43.505403  9048 solver.cpp:256]     Train net output #0: loss = 16.3336 (* 1 = 16.3336 loss)
I0408 21:16:43.505411  9048 sgd_solver.cpp:106] Iteration 850, lr = 0.01
I0408 21:16:43.781644  9048 solver.cpp:240] Iteration 851, loss = 8.96686
I0408 21:16:43.781678  9048 solver.cpp:256]     Train net output #0: loss = 8.96686 (* 1 = 8.96686 loss)
I0408 21:16:43.781687  9048 sgd_solver.cpp:106] Iteration 851, lr = 0.01
I0408 21:16:44.057327  9048 solver.cpp:240] Iteration 852, loss = 10.0101
I0408 21:16:44.057359  9048 solver.cpp:256]     Train net output #0: loss = 10.0101 (* 1 = 10.0101 loss)
I0408 21:16:44.057368  9048 sgd_solver.cpp:106] Iteration 852, lr = 0.01
I0408 21:16:44.332731  9048 solver.cpp:240] Iteration 853, loss = 10.3775
I0408 21:16:44.332775  9048 solver.cpp:256]     Train net output #0: loss = 10.3775 (* 1 = 10.3775 loss)
I0408 21:16:44.332783  9048 sgd_solver.cpp:106] Iteration 853, lr = 0.01
I0408 21:16:44.608762  9048 solver.cpp:240] Iteration 854, loss = 19.8792
I0408 21:16:44.608795  9048 solver.cpp:256]     Train net output #0: loss = 19.8792 (* 1 = 19.8792 loss)
I0408 21:16:44.608804  9048 sgd_solver.cpp:106] Iteration 854, lr = 0.01
I0408 21:16:44.885313  9048 solver.cpp:240] Iteration 855, loss = 10.7796
I0408 21:16:44.885351  9048 solver.cpp:256]     Train net output #0: loss = 10.7796 (* 1 = 10.7796 loss)
I0408 21:16:44.885360  9048 sgd_solver.cpp:106] Iteration 855, lr = 0.01
I0408 21:16:45.161281  9048 solver.cpp:240] Iteration 856, loss = 16.7989
I0408 21:16:45.161316  9048 solver.cpp:256]     Train net output #0: loss = 16.7989 (* 1 = 16.7989 loss)
I0408 21:16:45.161324  9048 sgd_solver.cpp:106] Iteration 856, lr = 0.01
I0408 21:16:45.437110  9048 solver.cpp:240] Iteration 857, loss = 27.186
I0408 21:16:45.437144  9048 solver.cpp:256]     Train net output #0: loss = 27.186 (* 1 = 27.186 loss)
I0408 21:16:45.437151  9048 sgd_solver.cpp:106] Iteration 857, lr = 0.01
I0408 21:16:45.712900  9048 solver.cpp:240] Iteration 858, loss = 15.3384
I0408 21:16:45.712944  9048 solver.cpp:256]     Train net output #0: loss = 15.3384 (* 1 = 15.3384 loss)
I0408 21:16:45.712951  9048 sgd_solver.cpp:106] Iteration 858, lr = 0.01
I0408 21:16:45.989397  9048 solver.cpp:240] Iteration 859, loss = 10.3431
I0408 21:16:45.989440  9048 solver.cpp:256]     Train net output #0: loss = 10.3431 (* 1 = 10.3431 loss)
I0408 21:16:45.989449  9048 sgd_solver.cpp:106] Iteration 859, lr = 0.01
I0408 21:16:46.265592  9048 solver.cpp:240] Iteration 860, loss = 10.9257
I0408 21:16:46.265626  9048 solver.cpp:256]     Train net output #0: loss = 10.9257 (* 1 = 10.9257 loss)
I0408 21:16:46.265635  9048 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0408 21:16:46.541498  9048 solver.cpp:240] Iteration 861, loss = 9.16708
I0408 21:16:46.541532  9048 solver.cpp:256]     Train net output #0: loss = 9.16708 (* 1 = 9.16708 loss)
I0408 21:16:46.541540  9048 sgd_solver.cpp:106] Iteration 861, lr = 0.01
I0408 21:16:46.817471  9048 solver.cpp:240] Iteration 862, loss = 12.1483
I0408 21:16:46.817507  9048 solver.cpp:256]     Train net output #0: loss = 12.1483 (* 1 = 12.1483 loss)
I0408 21:16:46.817514  9048 sgd_solver.cpp:106] Iteration 862, lr = 0.01
I0408 21:16:47.093260  9048 solver.cpp:240] Iteration 863, loss = 1.71675
I0408 21:16:47.093292  9048 solver.cpp:256]     Train net output #0: loss = 1.71675 (* 1 = 1.71675 loss)
I0408 21:16:47.093300  9048 sgd_solver.cpp:106] Iteration 863, lr = 0.01
I0408 21:16:47.369714  9048 solver.cpp:240] Iteration 864, loss = 14.5158
I0408 21:16:47.369745  9048 solver.cpp:256]     Train net output #0: loss = 14.5158 (* 1 = 14.5158 loss)
I0408 21:16:47.369753  9048 sgd_solver.cpp:106] Iteration 864, lr = 0.01
I0408 21:16:47.646157  9048 solver.cpp:240] Iteration 865, loss = 10.4992
I0408 21:16:47.646191  9048 solver.cpp:256]     Train net output #0: loss = 10.4992 (* 1 = 10.4992 loss)
I0408 21:16:47.646199  9048 sgd_solver.cpp:106] Iteration 865, lr = 0.01
I0408 21:16:47.922526  9048 solver.cpp:240] Iteration 866, loss = 5.92386
I0408 21:16:47.922557  9048 solver.cpp:256]     Train net output #0: loss = 5.92386 (* 1 = 5.92386 loss)
I0408 21:16:47.922564  9048 sgd_solver.cpp:106] Iteration 866, lr = 0.01
I0408 21:16:48.199041  9048 solver.cpp:240] Iteration 867, loss = 17.3279
I0408 21:16:48.199076  9048 solver.cpp:256]     Train net output #0: loss = 17.3279 (* 1 = 17.3279 loss)
I0408 21:16:48.199084  9048 sgd_solver.cpp:106] Iteration 867, lr = 0.01
I0408 21:16:48.474772  9048 solver.cpp:240] Iteration 868, loss = 6.51482
I0408 21:16:48.474807  9048 solver.cpp:256]     Train net output #0: loss = 6.51483 (* 1 = 6.51483 loss)
I0408 21:16:48.474817  9048 sgd_solver.cpp:106] Iteration 868, lr = 0.01
I0408 21:16:48.750859  9048 solver.cpp:240] Iteration 869, loss = 6.27161
I0408 21:16:48.750887  9048 solver.cpp:256]     Train net output #0: loss = 6.27162 (* 1 = 6.27162 loss)
I0408 21:16:48.750895  9048 sgd_solver.cpp:106] Iteration 869, lr = 0.01
I0408 21:16:49.026913  9048 solver.cpp:240] Iteration 870, loss = 10.7785
I0408 21:16:49.026945  9048 solver.cpp:256]     Train net output #0: loss = 10.7785 (* 1 = 10.7785 loss)
I0408 21:16:49.026954  9048 sgd_solver.cpp:106] Iteration 870, lr = 0.01
I0408 21:16:49.303221  9048 solver.cpp:240] Iteration 871, loss = 12.0369
I0408 21:16:49.303539  9048 solver.cpp:256]     Train net output #0: loss = 12.0369 (* 1 = 12.0369 loss)
I0408 21:16:49.303550  9048 sgd_solver.cpp:106] Iteration 871, lr = 0.01
I0408 21:16:49.578692  9048 solver.cpp:240] Iteration 872, loss = 29.4743
I0408 21:16:49.578727  9048 solver.cpp:256]     Train net output #0: loss = 29.4743 (* 1 = 29.4743 loss)
I0408 21:16:49.578734  9048 sgd_solver.cpp:106] Iteration 872, lr = 0.01
I0408 21:16:49.854795  9048 solver.cpp:240] Iteration 873, loss = 22.902
I0408 21:16:49.854832  9048 solver.cpp:256]     Train net output #0: loss = 22.902 (* 1 = 22.902 loss)
I0408 21:16:49.854841  9048 sgd_solver.cpp:106] Iteration 873, lr = 0.01
I0408 21:16:50.129582  9048 solver.cpp:240] Iteration 874, loss = 23.8247
I0408 21:16:50.129616  9048 solver.cpp:256]     Train net output #0: loss = 23.8247 (* 1 = 23.8247 loss)
I0408 21:16:50.129623  9048 sgd_solver.cpp:106] Iteration 874, lr = 0.01
I0408 21:16:50.405550  9048 solver.cpp:240] Iteration 875, loss = 1.44058
I0408 21:16:50.405582  9048 solver.cpp:256]     Train net output #0: loss = 1.44059 (* 1 = 1.44059 loss)
I0408 21:16:50.405591  9048 sgd_solver.cpp:106] Iteration 875, lr = 0.01
I0408 21:16:50.681550  9048 solver.cpp:240] Iteration 876, loss = 7.42236
I0408 21:16:50.681586  9048 solver.cpp:256]     Train net output #0: loss = 7.42237 (* 1 = 7.42237 loss)
I0408 21:16:50.681593  9048 sgd_solver.cpp:106] Iteration 876, lr = 0.01
I0408 21:16:50.958111  9048 solver.cpp:240] Iteration 877, loss = 1.66048
I0408 21:16:50.958148  9048 solver.cpp:256]     Train net output #0: loss = 1.66048 (* 1 = 1.66048 loss)
I0408 21:16:50.958158  9048 sgd_solver.cpp:106] Iteration 877, lr = 0.01
I0408 21:16:51.233381  9048 solver.cpp:240] Iteration 878, loss = 14.6165
I0408 21:16:51.233420  9048 solver.cpp:256]     Train net output #0: loss = 14.6165 (* 1 = 14.6165 loss)
I0408 21:16:51.233429  9048 sgd_solver.cpp:106] Iteration 878, lr = 0.01
I0408 21:16:51.510241  9048 solver.cpp:240] Iteration 879, loss = 30.4946
I0408 21:16:51.510275  9048 solver.cpp:256]     Train net output #0: loss = 30.4946 (* 1 = 30.4946 loss)
I0408 21:16:51.510283  9048 sgd_solver.cpp:106] Iteration 879, lr = 0.01
I0408 21:16:51.786670  9048 solver.cpp:240] Iteration 880, loss = 21.0439
I0408 21:16:51.786703  9048 solver.cpp:256]     Train net output #0: loss = 21.0439 (* 1 = 21.0439 loss)
I0408 21:16:51.786712  9048 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0408 21:16:52.063024  9048 solver.cpp:240] Iteration 881, loss = 16.7247
I0408 21:16:52.063057  9048 solver.cpp:256]     Train net output #0: loss = 16.7247 (* 1 = 16.7247 loss)
I0408 21:16:52.063066  9048 sgd_solver.cpp:106] Iteration 881, lr = 0.01
I0408 21:16:52.340049  9048 solver.cpp:240] Iteration 882, loss = 12.2106
I0408 21:16:52.340081  9048 solver.cpp:256]     Train net output #0: loss = 12.2106 (* 1 = 12.2106 loss)
I0408 21:16:52.340090  9048 sgd_solver.cpp:106] Iteration 882, lr = 0.01
I0408 21:16:52.616183  9048 solver.cpp:240] Iteration 883, loss = 8.62843
I0408 21:16:52.616250  9048 solver.cpp:256]     Train net output #0: loss = 8.62843 (* 1 = 8.62843 loss)
I0408 21:16:52.616256  9048 sgd_solver.cpp:106] Iteration 883, lr = 0.01
I0408 21:16:52.892663  9048 solver.cpp:240] Iteration 884, loss = 3.63128
I0408 21:16:52.892694  9048 solver.cpp:256]     Train net output #0: loss = 3.63128 (* 1 = 3.63128 loss)
I0408 21:16:52.892702  9048 sgd_solver.cpp:106] Iteration 884, lr = 0.01
I0408 21:16:53.169106  9048 solver.cpp:240] Iteration 885, loss = 4.62197
I0408 21:16:53.169137  9048 solver.cpp:256]     Train net output #0: loss = 4.62197 (* 1 = 4.62197 loss)
I0408 21:16:53.169144  9048 sgd_solver.cpp:106] Iteration 885, lr = 0.01
I0408 21:16:53.445803  9048 solver.cpp:240] Iteration 886, loss = 2.89591
I0408 21:16:53.445847  9048 solver.cpp:256]     Train net output #0: loss = 2.89591 (* 1 = 2.89591 loss)
I0408 21:16:53.445855  9048 sgd_solver.cpp:106] Iteration 886, lr = 0.01
I0408 21:16:53.721513  9048 solver.cpp:240] Iteration 887, loss = 6.90466
I0408 21:16:53.721547  9048 solver.cpp:256]     Train net output #0: loss = 6.90466 (* 1 = 6.90466 loss)
I0408 21:16:53.721575  9048 sgd_solver.cpp:106] Iteration 887, lr = 0.01
I0408 21:16:53.997845  9048 solver.cpp:240] Iteration 888, loss = 5.9874
I0408 21:16:53.997879  9048 solver.cpp:256]     Train net output #0: loss = 5.98741 (* 1 = 5.98741 loss)
I0408 21:16:53.997886  9048 sgd_solver.cpp:106] Iteration 888, lr = 0.01
I0408 21:16:54.273964  9048 solver.cpp:240] Iteration 889, loss = 14.7797
I0408 21:16:54.273998  9048 solver.cpp:256]     Train net output #0: loss = 14.7797 (* 1 = 14.7797 loss)
I0408 21:16:54.274006  9048 sgd_solver.cpp:106] Iteration 889, lr = 0.01
I0408 21:16:54.551211  9048 solver.cpp:240] Iteration 890, loss = 5.42611
I0408 21:16:54.551245  9048 solver.cpp:256]     Train net output #0: loss = 5.42611 (* 1 = 5.42611 loss)
I0408 21:16:54.551254  9048 sgd_solver.cpp:106] Iteration 890, lr = 0.01
I0408 21:16:54.828033  9048 solver.cpp:240] Iteration 891, loss = 5.84616
I0408 21:16:54.828070  9048 solver.cpp:256]     Train net output #0: loss = 5.84616 (* 1 = 5.84616 loss)
I0408 21:16:54.828079  9048 sgd_solver.cpp:106] Iteration 891, lr = 0.01
I0408 21:16:55.104094  9048 solver.cpp:240] Iteration 892, loss = 11.8894
I0408 21:16:55.104130  9048 solver.cpp:256]     Train net output #0: loss = 11.8894 (* 1 = 11.8894 loss)
I0408 21:16:55.104138  9048 sgd_solver.cpp:106] Iteration 892, lr = 0.01
I0408 21:16:55.380414  9048 solver.cpp:240] Iteration 893, loss = 12.6523
I0408 21:16:55.380450  9048 solver.cpp:256]     Train net output #0: loss = 12.6523 (* 1 = 12.6523 loss)
I0408 21:16:55.380457  9048 sgd_solver.cpp:106] Iteration 893, lr = 0.01
I0408 21:16:55.656378  9048 solver.cpp:240] Iteration 894, loss = 7.14905
I0408 21:16:55.656409  9048 solver.cpp:256]     Train net output #0: loss = 7.14905 (* 1 = 7.14905 loss)
I0408 21:16:55.656419  9048 sgd_solver.cpp:106] Iteration 894, lr = 0.01
I0408 21:16:55.933315  9048 solver.cpp:240] Iteration 895, loss = 21.2048
I0408 21:16:55.933347  9048 solver.cpp:256]     Train net output #0: loss = 21.2048 (* 1 = 21.2048 loss)
I0408 21:16:55.933357  9048 sgd_solver.cpp:106] Iteration 895, lr = 0.01
I0408 21:16:56.211019  9048 solver.cpp:240] Iteration 896, loss = 16.7824
I0408 21:16:56.211051  9048 solver.cpp:256]     Train net output #0: loss = 16.7824 (* 1 = 16.7824 loss)
I0408 21:16:56.211061  9048 sgd_solver.cpp:106] Iteration 896, lr = 0.01
I0408 21:16:56.488028  9048 solver.cpp:240] Iteration 897, loss = 14.6907
I0408 21:16:56.488062  9048 solver.cpp:256]     Train net output #0: loss = 14.6907 (* 1 = 14.6907 loss)
I0408 21:16:56.488077  9048 sgd_solver.cpp:106] Iteration 897, lr = 0.01
I0408 21:16:56.764035  9048 solver.cpp:240] Iteration 898, loss = 12.8448
I0408 21:16:56.764070  9048 solver.cpp:256]     Train net output #0: loss = 12.8448 (* 1 = 12.8448 loss)
I0408 21:16:56.764077  9048 sgd_solver.cpp:106] Iteration 898, lr = 0.01
I0408 21:16:57.040081  9048 solver.cpp:240] Iteration 899, loss = 15.1446
I0408 21:16:57.040112  9048 solver.cpp:256]     Train net output #0: loss = 15.1446 (* 1 = 15.1446 loss)
I0408 21:16:57.040120  9048 sgd_solver.cpp:106] Iteration 899, lr = 0.01
I0408 21:16:57.316902  9048 solver.cpp:240] Iteration 900, loss = 13.9399
I0408 21:16:57.316946  9048 solver.cpp:256]     Train net output #0: loss = 13.9399 (* 1 = 13.9399 loss)
I0408 21:16:57.316954  9048 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0408 21:16:57.593436  9048 solver.cpp:240] Iteration 901, loss = 4.67124
I0408 21:16:57.593466  9048 solver.cpp:256]     Train net output #0: loss = 4.67124 (* 1 = 4.67124 loss)
I0408 21:16:57.593474  9048 sgd_solver.cpp:106] Iteration 901, lr = 0.01
I0408 21:16:57.870405  9048 solver.cpp:240] Iteration 902, loss = 10.1541
I0408 21:16:57.870450  9048 solver.cpp:256]     Train net output #0: loss = 10.1541 (* 1 = 10.1541 loss)
I0408 21:16:57.870457  9048 sgd_solver.cpp:106] Iteration 902, lr = 0.01
I0408 21:16:58.146656  9048 solver.cpp:240] Iteration 903, loss = 3.64903
I0408 21:16:58.146689  9048 solver.cpp:256]     Train net output #0: loss = 3.64903 (* 1 = 3.64903 loss)
I0408 21:16:58.146697  9048 sgd_solver.cpp:106] Iteration 903, lr = 0.01
I0408 21:16:58.421331  9048 solver.cpp:240] Iteration 904, loss = 14.1497
I0408 21:16:58.421365  9048 solver.cpp:256]     Train net output #0: loss = 14.1497 (* 1 = 14.1497 loss)
I0408 21:16:58.421375  9048 sgd_solver.cpp:106] Iteration 904, lr = 0.01
I0408 21:16:58.697938  9048 solver.cpp:240] Iteration 905, loss = 6.92604
I0408 21:16:58.697973  9048 solver.cpp:256]     Train net output #0: loss = 6.92604 (* 1 = 6.92604 loss)
I0408 21:16:58.697979  9048 sgd_solver.cpp:106] Iteration 905, lr = 0.01
I0408 21:16:58.973718  9048 solver.cpp:240] Iteration 906, loss = 7.67152
I0408 21:16:58.973754  9048 solver.cpp:256]     Train net output #0: loss = 7.67152 (* 1 = 7.67152 loss)
I0408 21:16:58.973763  9048 sgd_solver.cpp:106] Iteration 906, lr = 0.01
I0408 21:16:59.249891  9048 solver.cpp:240] Iteration 907, loss = 6.18293
I0408 21:16:59.249933  9048 solver.cpp:256]     Train net output #0: loss = 6.18293 (* 1 = 6.18293 loss)
I0408 21:16:59.249941  9048 sgd_solver.cpp:106] Iteration 907, lr = 0.01
I0408 21:16:59.525635  9048 solver.cpp:240] Iteration 908, loss = 27.0271
I0408 21:16:59.525670  9048 solver.cpp:256]     Train net output #0: loss = 27.0271 (* 1 = 27.0271 loss)
I0408 21:16:59.525677  9048 sgd_solver.cpp:106] Iteration 908, lr = 0.01
I0408 21:16:59.802002  9048 solver.cpp:240] Iteration 909, loss = 25.152
I0408 21:16:59.802036  9048 solver.cpp:256]     Train net output #0: loss = 25.152 (* 1 = 25.152 loss)
I0408 21:16:59.802043  9048 sgd_solver.cpp:106] Iteration 909, lr = 0.01
I0408 21:17:00.078789  9048 solver.cpp:240] Iteration 910, loss = 22.5402
I0408 21:17:00.078822  9048 solver.cpp:256]     Train net output #0: loss = 22.5402 (* 1 = 22.5402 loss)
I0408 21:17:00.078831  9048 sgd_solver.cpp:106] Iteration 910, lr = 0.01
I0408 21:17:00.355274  9048 solver.cpp:240] Iteration 911, loss = 15.3849
I0408 21:17:00.355309  9048 solver.cpp:256]     Train net output #0: loss = 15.3849 (* 1 = 15.3849 loss)
I0408 21:17:00.355317  9048 sgd_solver.cpp:106] Iteration 911, lr = 0.01
I0408 21:17:00.632032  9048 solver.cpp:240] Iteration 912, loss = 9.54699
I0408 21:17:00.632064  9048 solver.cpp:256]     Train net output #0: loss = 9.54699 (* 1 = 9.54699 loss)
I0408 21:17:00.632072  9048 sgd_solver.cpp:106] Iteration 912, lr = 0.01
I0408 21:17:00.907922  9048 solver.cpp:240] Iteration 913, loss = 12.7901
I0408 21:17:00.907954  9048 solver.cpp:256]     Train net output #0: loss = 12.7901 (* 1 = 12.7901 loss)
I0408 21:17:00.907963  9048 sgd_solver.cpp:106] Iteration 913, lr = 0.01
I0408 21:17:01.185678  9048 solver.cpp:240] Iteration 914, loss = 6.5825
I0408 21:17:01.185708  9048 solver.cpp:256]     Train net output #0: loss = 6.5825 (* 1 = 6.5825 loss)
I0408 21:17:01.185716  9048 sgd_solver.cpp:106] Iteration 914, lr = 0.01
I0408 21:17:01.462278  9048 solver.cpp:240] Iteration 915, loss = 14.4966
I0408 21:17:01.462323  9048 solver.cpp:256]     Train net output #0: loss = 14.4966 (* 1 = 14.4966 loss)
I0408 21:17:01.462332  9048 sgd_solver.cpp:106] Iteration 915, lr = 0.01
I0408 21:17:01.738247  9048 solver.cpp:240] Iteration 916, loss = 20.749
I0408 21:17:01.738283  9048 solver.cpp:256]     Train net output #0: loss = 20.749 (* 1 = 20.749 loss)
I0408 21:17:01.738292  9048 sgd_solver.cpp:106] Iteration 916, lr = 0.01
I0408 21:17:02.014153  9048 solver.cpp:240] Iteration 917, loss = 28.2984
I0408 21:17:02.014186  9048 solver.cpp:256]     Train net output #0: loss = 28.2984 (* 1 = 28.2984 loss)
I0408 21:17:02.014194  9048 sgd_solver.cpp:106] Iteration 917, lr = 0.01
I0408 21:17:02.290815  9048 solver.cpp:240] Iteration 918, loss = 29.6396
I0408 21:17:02.290859  9048 solver.cpp:256]     Train net output #0: loss = 29.6396 (* 1 = 29.6396 loss)
I0408 21:17:02.290868  9048 sgd_solver.cpp:106] Iteration 918, lr = 0.01
I0408 21:17:02.568145  9048 solver.cpp:240] Iteration 919, loss = 27.872
I0408 21:17:02.568178  9048 solver.cpp:256]     Train net output #0: loss = 27.872 (* 1 = 27.872 loss)
I0408 21:17:02.568186  9048 sgd_solver.cpp:106] Iteration 919, lr = 0.01
I0408 21:17:02.844607  9048 solver.cpp:240] Iteration 920, loss = 14.3932
I0408 21:17:02.844666  9048 solver.cpp:256]     Train net output #0: loss = 14.3932 (* 1 = 14.3932 loss)
I0408 21:17:02.844674  9048 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0408 21:17:03.120398  9048 solver.cpp:240] Iteration 921, loss = 16.0992
I0408 21:17:03.120435  9048 solver.cpp:256]     Train net output #0: loss = 16.0992 (* 1 = 16.0992 loss)
I0408 21:17:03.120445  9048 sgd_solver.cpp:106] Iteration 921, lr = 0.01
I0408 21:17:03.396809  9048 solver.cpp:240] Iteration 922, loss = 14.9111
I0408 21:17:03.396843  9048 solver.cpp:256]     Train net output #0: loss = 14.9111 (* 1 = 14.9111 loss)
I0408 21:17:03.396852  9048 sgd_solver.cpp:106] Iteration 922, lr = 0.01
I0408 21:17:03.673411  9048 solver.cpp:240] Iteration 923, loss = 10.5418
I0408 21:17:03.673444  9048 solver.cpp:256]     Train net output #0: loss = 10.5418 (* 1 = 10.5418 loss)
I0408 21:17:03.673452  9048 sgd_solver.cpp:106] Iteration 923, lr = 0.01
I0408 21:17:03.950500  9048 solver.cpp:240] Iteration 924, loss = 12.0748
I0408 21:17:03.950534  9048 solver.cpp:256]     Train net output #0: loss = 12.0748 (* 1 = 12.0748 loss)
I0408 21:17:03.950543  9048 sgd_solver.cpp:106] Iteration 924, lr = 0.01
I0408 21:17:04.226567  9048 solver.cpp:240] Iteration 925, loss = 23.6191
I0408 21:17:04.226598  9048 solver.cpp:256]     Train net output #0: loss = 23.6191 (* 1 = 23.6191 loss)
I0408 21:17:04.226608  9048 sgd_solver.cpp:106] Iteration 925, lr = 0.01
I0408 21:17:04.503356  9048 solver.cpp:240] Iteration 926, loss = 30.2994
I0408 21:17:04.503389  9048 solver.cpp:256]     Train net output #0: loss = 30.2994 (* 1 = 30.2994 loss)
I0408 21:17:04.503398  9048 sgd_solver.cpp:106] Iteration 926, lr = 0.01
I0408 21:17:04.779500  9048 solver.cpp:240] Iteration 927, loss = 23.3519
I0408 21:17:04.779534  9048 solver.cpp:256]     Train net output #0: loss = 23.3519 (* 1 = 23.3519 loss)
I0408 21:17:04.779542  9048 sgd_solver.cpp:106] Iteration 927, lr = 0.01
I0408 21:17:05.054811  9048 solver.cpp:240] Iteration 928, loss = 18.6152
I0408 21:17:05.054841  9048 solver.cpp:256]     Train net output #0: loss = 18.6152 (* 1 = 18.6152 loss)
I0408 21:17:05.054850  9048 sgd_solver.cpp:106] Iteration 928, lr = 0.01
I0408 21:17:05.330818  9048 solver.cpp:240] Iteration 929, loss = 17.0881
I0408 21:17:05.330855  9048 solver.cpp:256]     Train net output #0: loss = 17.0881 (* 1 = 17.0881 loss)
I0408 21:17:05.330863  9048 sgd_solver.cpp:106] Iteration 929, lr = 0.01
I0408 21:17:05.607271  9048 solver.cpp:240] Iteration 930, loss = 23.2515
I0408 21:17:05.607308  9048 solver.cpp:256]     Train net output #0: loss = 23.2515 (* 1 = 23.2515 loss)
I0408 21:17:05.607316  9048 sgd_solver.cpp:106] Iteration 930, lr = 0.01
I0408 21:17:05.882097  9048 solver.cpp:240] Iteration 931, loss = 10.0293
I0408 21:17:05.882130  9048 solver.cpp:256]     Train net output #0: loss = 10.0293 (* 1 = 10.0293 loss)
I0408 21:17:05.882138  9048 sgd_solver.cpp:106] Iteration 931, lr = 0.01
I0408 21:17:06.158349  9048 solver.cpp:240] Iteration 932, loss = 11.43
I0408 21:17:06.158383  9048 solver.cpp:256]     Train net output #0: loss = 11.43 (* 1 = 11.43 loss)
I0408 21:17:06.158391  9048 sgd_solver.cpp:106] Iteration 932, lr = 0.01
I0408 21:17:06.434146  9048 solver.cpp:240] Iteration 933, loss = 15.5177
I0408 21:17:06.434180  9048 solver.cpp:256]     Train net output #0: loss = 15.5177 (* 1 = 15.5177 loss)
I0408 21:17:06.434193  9048 sgd_solver.cpp:106] Iteration 933, lr = 0.01
I0408 21:17:06.709635  9048 solver.cpp:240] Iteration 934, loss = 21.6026
I0408 21:17:06.709667  9048 solver.cpp:256]     Train net output #0: loss = 21.6026 (* 1 = 21.6026 loss)
I0408 21:17:06.709676  9048 sgd_solver.cpp:106] Iteration 934, lr = 0.01
I0408 21:17:06.984766  9048 solver.cpp:240] Iteration 935, loss = 20.5247
I0408 21:17:06.984817  9048 solver.cpp:256]     Train net output #0: loss = 20.5247 (* 1 = 20.5247 loss)
I0408 21:17:06.984827  9048 sgd_solver.cpp:106] Iteration 935, lr = 0.01
I0408 21:17:07.260105  9048 solver.cpp:240] Iteration 936, loss = 14.9315
I0408 21:17:07.260138  9048 solver.cpp:256]     Train net output #0: loss = 14.9315 (* 1 = 14.9315 loss)
I0408 21:17:07.260169  9048 sgd_solver.cpp:106] Iteration 936, lr = 0.01
I0408 21:17:07.536583  9048 solver.cpp:240] Iteration 937, loss = 17.6213
I0408 21:17:07.536615  9048 solver.cpp:256]     Train net output #0: loss = 17.6213 (* 1 = 17.6213 loss)
I0408 21:17:07.536623  9048 sgd_solver.cpp:106] Iteration 937, lr = 0.01
I0408 21:17:07.812467  9048 solver.cpp:240] Iteration 938, loss = 21.2619
I0408 21:17:07.812512  9048 solver.cpp:256]     Train net output #0: loss = 21.2619 (* 1 = 21.2619 loss)
I0408 21:17:07.812520  9048 sgd_solver.cpp:106] Iteration 938, lr = 0.01
I0408 21:17:08.087268  9048 solver.cpp:240] Iteration 939, loss = 6.69261
I0408 21:17:08.087299  9048 solver.cpp:256]     Train net output #0: loss = 6.69261 (* 1 = 6.69261 loss)
I0408 21:17:08.087308  9048 sgd_solver.cpp:106] Iteration 939, lr = 0.01
I0408 21:17:08.362082  9048 solver.cpp:240] Iteration 940, loss = 2.3855
I0408 21:17:08.362125  9048 solver.cpp:256]     Train net output #0: loss = 2.3855 (* 1 = 2.3855 loss)
I0408 21:17:08.362133  9048 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0408 21:17:08.638106  9048 solver.cpp:240] Iteration 941, loss = 7.5046
I0408 21:17:08.638149  9048 solver.cpp:256]     Train net output #0: loss = 7.5046 (* 1 = 7.5046 loss)
I0408 21:17:08.638156  9048 sgd_solver.cpp:106] Iteration 941, lr = 0.01
I0408 21:17:08.913199  9048 solver.cpp:240] Iteration 942, loss = 21.8129
I0408 21:17:08.913233  9048 solver.cpp:256]     Train net output #0: loss = 21.8129 (* 1 = 21.8129 loss)
I0408 21:17:08.913240  9048 sgd_solver.cpp:106] Iteration 942, lr = 0.01
I0408 21:17:09.189007  9048 solver.cpp:240] Iteration 943, loss = 20.3793
I0408 21:17:09.189039  9048 solver.cpp:256]     Train net output #0: loss = 20.3793 (* 1 = 20.3793 loss)
I0408 21:17:09.189047  9048 sgd_solver.cpp:106] Iteration 943, lr = 0.01
I0408 21:17:09.464761  9048 solver.cpp:240] Iteration 944, loss = 21.1088
I0408 21:17:09.464794  9048 solver.cpp:256]     Train net output #0: loss = 21.1088 (* 1 = 21.1088 loss)
I0408 21:17:09.464803  9048 sgd_solver.cpp:106] Iteration 944, lr = 0.01
I0408 21:17:09.740780  9048 solver.cpp:240] Iteration 945, loss = 11.3594
I0408 21:17:09.740813  9048 solver.cpp:256]     Train net output #0: loss = 11.3594 (* 1 = 11.3594 loss)
I0408 21:17:09.740820  9048 sgd_solver.cpp:106] Iteration 945, lr = 0.01
I0408 21:17:10.016275  9048 solver.cpp:240] Iteration 946, loss = 16.5654
I0408 21:17:10.016311  9048 solver.cpp:256]     Train net output #0: loss = 16.5654 (* 1 = 16.5654 loss)
I0408 21:17:10.016320  9048 sgd_solver.cpp:106] Iteration 946, lr = 0.01
I0408 21:17:10.292495  9048 solver.cpp:240] Iteration 947, loss = 24.9473
I0408 21:17:10.292527  9048 solver.cpp:256]     Train net output #0: loss = 24.9473 (* 1 = 24.9473 loss)
I0408 21:17:10.292536  9048 sgd_solver.cpp:106] Iteration 947, lr = 0.01
I0408 21:17:10.569226  9048 solver.cpp:240] Iteration 948, loss = 31.8849
I0408 21:17:10.569263  9048 solver.cpp:256]     Train net output #0: loss = 31.8849 (* 1 = 31.8849 loss)
I0408 21:17:10.569272  9048 sgd_solver.cpp:106] Iteration 948, lr = 0.01
I0408 21:17:10.844913  9048 solver.cpp:240] Iteration 949, loss = 18.7414
I0408 21:17:10.844947  9048 solver.cpp:256]     Train net output #0: loss = 18.7414 (* 1 = 18.7414 loss)
I0408 21:17:10.844955  9048 sgd_solver.cpp:106] Iteration 949, lr = 0.01
I0408 21:17:11.120591  9048 solver.cpp:240] Iteration 950, loss = 5.03797
I0408 21:17:11.120620  9048 solver.cpp:256]     Train net output #0: loss = 5.03797 (* 1 = 5.03797 loss)
I0408 21:17:11.120628  9048 sgd_solver.cpp:106] Iteration 950, lr = 0.01
I0408 21:17:11.395951  9048 solver.cpp:240] Iteration 951, loss = 7.12779
I0408 21:17:11.395998  9048 solver.cpp:256]     Train net output #0: loss = 7.12779 (* 1 = 7.12779 loss)
I0408 21:17:11.396011  9048 sgd_solver.cpp:106] Iteration 951, lr = 0.01
I0408 21:17:11.672096  9048 solver.cpp:240] Iteration 952, loss = 6.03085
I0408 21:17:11.672132  9048 solver.cpp:256]     Train net output #0: loss = 6.03085 (* 1 = 6.03085 loss)
I0408 21:17:11.672171  9048 sgd_solver.cpp:106] Iteration 952, lr = 0.01
I0408 21:17:11.947830  9048 solver.cpp:240] Iteration 953, loss = 10.2562
I0408 21:17:11.947865  9048 solver.cpp:256]     Train net output #0: loss = 10.2562 (* 1 = 10.2562 loss)
I0408 21:17:11.947888  9048 sgd_solver.cpp:106] Iteration 953, lr = 0.01
I0408 21:17:12.224311  9048 solver.cpp:240] Iteration 954, loss = 10.5467
I0408 21:17:12.224349  9048 solver.cpp:256]     Train net output #0: loss = 10.5467 (* 1 = 10.5467 loss)
I0408 21:17:12.224360  9048 sgd_solver.cpp:106] Iteration 954, lr = 0.01
I0408 21:17:12.500026  9048 solver.cpp:240] Iteration 955, loss = 24.1991
I0408 21:17:12.500066  9048 solver.cpp:256]     Train net output #0: loss = 24.1991 (* 1 = 24.1991 loss)
I0408 21:17:12.500077  9048 sgd_solver.cpp:106] Iteration 955, lr = 0.01
I0408 21:17:12.776259  9048 solver.cpp:240] Iteration 956, loss = 13.7515
I0408 21:17:12.776295  9048 solver.cpp:256]     Train net output #0: loss = 13.7515 (* 1 = 13.7515 loss)
I0408 21:17:12.776307  9048 sgd_solver.cpp:106] Iteration 956, lr = 0.01
I0408 21:17:13.052881  9048 solver.cpp:240] Iteration 957, loss = 24.6927
I0408 21:17:13.052922  9048 solver.cpp:256]     Train net output #0: loss = 24.6927 (* 1 = 24.6927 loss)
I0408 21:17:13.052934  9048 sgd_solver.cpp:106] Iteration 957, lr = 0.01
I0408 21:17:13.328371  9048 solver.cpp:240] Iteration 958, loss = 33.9185
I0408 21:17:13.328411  9048 solver.cpp:256]     Train net output #0: loss = 33.9185 (* 1 = 33.9185 loss)
I0408 21:17:13.328430  9048 sgd_solver.cpp:106] Iteration 958, lr = 0.01
I0408 21:17:13.604435  9048 solver.cpp:240] Iteration 959, loss = 40.9401
I0408 21:17:13.604472  9048 solver.cpp:256]     Train net output #0: loss = 40.9401 (* 1 = 40.9401 loss)
I0408 21:17:13.604496  9048 sgd_solver.cpp:106] Iteration 959, lr = 0.01
I0408 21:17:13.880484  9048 solver.cpp:240] Iteration 960, loss = 30.8354
I0408 21:17:13.880519  9048 solver.cpp:256]     Train net output #0: loss = 30.8354 (* 1 = 30.8354 loss)
I0408 21:17:13.880543  9048 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0408 21:17:14.157040  9048 solver.cpp:240] Iteration 961, loss = 35.6242
I0408 21:17:14.157074  9048 solver.cpp:256]     Train net output #0: loss = 35.6242 (* 1 = 35.6242 loss)
I0408 21:17:14.157097  9048 sgd_solver.cpp:106] Iteration 961, lr = 0.01
I0408 21:17:14.433581  9048 solver.cpp:240] Iteration 962, loss = 14.4274
I0408 21:17:14.433615  9048 solver.cpp:256]     Train net output #0: loss = 14.4274 (* 1 = 14.4274 loss)
I0408 21:17:14.433626  9048 sgd_solver.cpp:106] Iteration 962, lr = 0.01
I0408 21:17:14.709254  9048 solver.cpp:240] Iteration 963, loss = 19.3181
I0408 21:17:14.709295  9048 solver.cpp:256]     Train net output #0: loss = 19.3181 (* 1 = 19.3181 loss)
I0408 21:17:14.709318  9048 sgd_solver.cpp:106] Iteration 963, lr = 0.01
I0408 21:17:14.984673  9048 solver.cpp:240] Iteration 964, loss = 23.3865
I0408 21:17:14.984707  9048 solver.cpp:256]     Train net output #0: loss = 23.3865 (* 1 = 23.3865 loss)
I0408 21:17:14.984719  9048 sgd_solver.cpp:106] Iteration 964, lr = 0.01
I0408 21:17:15.260432  9048 solver.cpp:240] Iteration 965, loss = 18.125
I0408 21:17:15.260469  9048 solver.cpp:256]     Train net output #0: loss = 18.125 (* 1 = 18.125 loss)
I0408 21:17:15.260483  9048 sgd_solver.cpp:106] Iteration 965, lr = 0.01
I0408 21:17:15.535529  9048 solver.cpp:240] Iteration 966, loss = 29.0146
I0408 21:17:15.535564  9048 solver.cpp:256]     Train net output #0: loss = 29.0146 (* 1 = 29.0146 loss)
I0408 21:17:15.535575  9048 sgd_solver.cpp:106] Iteration 966, lr = 0.01
I0408 21:17:15.811244  9048 solver.cpp:240] Iteration 967, loss = 22.4425
I0408 21:17:15.811277  9048 solver.cpp:256]     Train net output #0: loss = 22.4425 (* 1 = 22.4425 loss)
I0408 21:17:15.811290  9048 sgd_solver.cpp:106] Iteration 967, lr = 0.01
I0408 21:17:16.087110  9048 solver.cpp:240] Iteration 968, loss = 20.1701
I0408 21:17:16.087147  9048 solver.cpp:256]     Train net output #0: loss = 20.1701 (* 1 = 20.1701 loss)
I0408 21:17:16.087159  9048 sgd_solver.cpp:106] Iteration 968, lr = 0.01
I0408 21:17:16.362793  9048 solver.cpp:240] Iteration 969, loss = 8.17538
I0408 21:17:16.362828  9048 solver.cpp:256]     Train net output #0: loss = 8.17538 (* 1 = 8.17538 loss)
I0408 21:17:16.362840  9048 sgd_solver.cpp:106] Iteration 969, lr = 0.01
I0408 21:17:16.639209  9048 solver.cpp:240] Iteration 970, loss = 7.95598
I0408 21:17:16.639243  9048 solver.cpp:256]     Train net output #0: loss = 7.95598 (* 1 = 7.95598 loss)
I0408 21:17:16.639255  9048 sgd_solver.cpp:106] Iteration 970, lr = 0.01
I0408 21:17:16.915303  9048 solver.cpp:240] Iteration 971, loss = 13.5255
I0408 21:17:16.915341  9048 solver.cpp:256]     Train net output #0: loss = 13.5255 (* 1 = 13.5255 loss)
I0408 21:17:16.915364  9048 sgd_solver.cpp:106] Iteration 971, lr = 0.01
I0408 21:17:17.191797  9048 solver.cpp:240] Iteration 972, loss = 25.4771
I0408 21:17:17.191834  9048 solver.cpp:256]     Train net output #0: loss = 25.4771 (* 1 = 25.4771 loss)
I0408 21:17:17.191846  9048 sgd_solver.cpp:106] Iteration 972, lr = 0.01
I0408 21:17:17.467166  9048 solver.cpp:240] Iteration 973, loss = 32.3469
I0408 21:17:17.467202  9048 solver.cpp:256]     Train net output #0: loss = 32.3469 (* 1 = 32.3469 loss)
I0408 21:17:17.467213  9048 sgd_solver.cpp:106] Iteration 973, lr = 0.01
I0408 21:17:17.743746  9048 solver.cpp:240] Iteration 974, loss = 15.2365
I0408 21:17:17.743782  9048 solver.cpp:256]     Train net output #0: loss = 15.2365 (* 1 = 15.2365 loss)
I0408 21:17:17.743793  9048 sgd_solver.cpp:106] Iteration 974, lr = 0.01
I0408 21:17:18.019712  9048 solver.cpp:240] Iteration 975, loss = 22.5567
I0408 21:17:18.019749  9048 solver.cpp:256]     Train net output #0: loss = 22.5567 (* 1 = 22.5567 loss)
I0408 21:17:18.019762  9048 sgd_solver.cpp:106] Iteration 975, lr = 0.01
I0408 21:17:18.296603  9048 solver.cpp:240] Iteration 976, loss = 7.66037
I0408 21:17:18.296638  9048 solver.cpp:256]     Train net output #0: loss = 7.66037 (* 1 = 7.66037 loss)
I0408 21:17:18.296649  9048 sgd_solver.cpp:106] Iteration 976, lr = 0.01
I0408 21:17:18.572599  9048 solver.cpp:240] Iteration 977, loss = 12.9778
I0408 21:17:18.572636  9048 solver.cpp:256]     Train net output #0: loss = 12.9778 (* 1 = 12.9778 loss)
I0408 21:17:18.572649  9048 sgd_solver.cpp:106] Iteration 977, lr = 0.01
I0408 21:17:18.848803  9048 solver.cpp:240] Iteration 978, loss = 35.1388
I0408 21:17:18.848840  9048 solver.cpp:256]     Train net output #0: loss = 35.1388 (* 1 = 35.1388 loss)
I0408 21:17:18.848851  9048 sgd_solver.cpp:106] Iteration 978, lr = 0.01
I0408 21:17:19.125587  9048 solver.cpp:240] Iteration 979, loss = 30.8809
I0408 21:17:19.125622  9048 solver.cpp:256]     Train net output #0: loss = 30.8809 (* 1 = 30.8809 loss)
I0408 21:17:19.125634  9048 sgd_solver.cpp:106] Iteration 979, lr = 0.01
I0408 21:17:19.401190  9048 solver.cpp:240] Iteration 980, loss = 3.42924
I0408 21:17:19.401480  9048 solver.cpp:256]     Train net output #0: loss = 3.42924 (* 1 = 3.42924 loss)
I0408 21:17:19.401496  9048 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0408 21:17:19.677204  9048 solver.cpp:240] Iteration 981, loss = 12.33
I0408 21:17:19.677239  9048 solver.cpp:256]     Train net output #0: loss = 12.33 (* 1 = 12.33 loss)
I0408 21:17:19.677263  9048 sgd_solver.cpp:106] Iteration 981, lr = 0.01
I0408 21:17:19.954113  9048 solver.cpp:240] Iteration 982, loss = 12.503
I0408 21:17:19.954151  9048 solver.cpp:256]     Train net output #0: loss = 12.503 (* 1 = 12.503 loss)
I0408 21:17:19.954164  9048 sgd_solver.cpp:106] Iteration 982, lr = 0.01
I0408 21:17:20.230204  9048 solver.cpp:240] Iteration 983, loss = 6.04169
I0408 21:17:20.230240  9048 solver.cpp:256]     Train net output #0: loss = 6.04169 (* 1 = 6.04169 loss)
I0408 21:17:20.230252  9048 sgd_solver.cpp:106] Iteration 983, lr = 0.01
I0408 21:17:20.505722  9048 solver.cpp:240] Iteration 984, loss = 4.56754
I0408 21:17:20.505758  9048 solver.cpp:256]     Train net output #0: loss = 4.56753 (* 1 = 4.56753 loss)
I0408 21:17:20.505780  9048 sgd_solver.cpp:106] Iteration 984, lr = 0.01
I0408 21:17:20.781852  9048 solver.cpp:240] Iteration 985, loss = 3.4952
I0408 21:17:20.781888  9048 solver.cpp:256]     Train net output #0: loss = 3.4952 (* 1 = 3.4952 loss)
I0408 21:17:20.781909  9048 sgd_solver.cpp:106] Iteration 985, lr = 0.01
I0408 21:17:21.056926  9048 solver.cpp:240] Iteration 986, loss = 3.47645
I0408 21:17:21.056962  9048 solver.cpp:256]     Train net output #0: loss = 3.47645 (* 1 = 3.47645 loss)
I0408 21:17:21.056983  9048 sgd_solver.cpp:106] Iteration 986, lr = 0.01
I0408 21:17:21.331599  9048 solver.cpp:240] Iteration 987, loss = 10.6467
I0408 21:17:21.331636  9048 solver.cpp:256]     Train net output #0: loss = 10.6467 (* 1 = 10.6467 loss)
I0408 21:17:21.331648  9048 sgd_solver.cpp:106] Iteration 987, lr = 0.01
I0408 21:17:21.607110  9048 solver.cpp:240] Iteration 988, loss = 26.8934
I0408 21:17:21.607146  9048 solver.cpp:256]     Train net output #0: loss = 26.8934 (* 1 = 26.8934 loss)
I0408 21:17:21.607169  9048 sgd_solver.cpp:106] Iteration 988, lr = 0.01
I0408 21:17:21.882489  9048 solver.cpp:240] Iteration 989, loss = 10.7795
I0408 21:17:21.882524  9048 solver.cpp:256]     Train net output #0: loss = 10.7795 (* 1 = 10.7795 loss)
I0408 21:17:21.882535  9048 sgd_solver.cpp:106] Iteration 989, lr = 0.01
I0408 21:17:22.157905  9048 solver.cpp:240] Iteration 990, loss = 1.5641
I0408 21:17:22.157938  9048 solver.cpp:256]     Train net output #0: loss = 1.5641 (* 1 = 1.5641 loss)
I0408 21:17:22.157949  9048 sgd_solver.cpp:106] Iteration 990, lr = 0.01
I0408 21:17:22.434154  9048 solver.cpp:240] Iteration 991, loss = 5.76069
I0408 21:17:22.434187  9048 solver.cpp:256]     Train net output #0: loss = 5.76069 (* 1 = 5.76069 loss)
I0408 21:17:22.434198  9048 sgd_solver.cpp:106] Iteration 991, lr = 0.01
I0408 21:17:22.710216  9048 solver.cpp:240] Iteration 992, loss = 12.0179
I0408 21:17:22.710253  9048 solver.cpp:256]     Train net output #0: loss = 12.0179 (* 1 = 12.0179 loss)
I0408 21:17:22.710266  9048 sgd_solver.cpp:106] Iteration 992, lr = 0.01
I0408 21:17:22.986538  9048 solver.cpp:240] Iteration 993, loss = 10.7551
I0408 21:17:22.986574  9048 solver.cpp:256]     Train net output #0: loss = 10.7551 (* 1 = 10.7551 loss)
I0408 21:17:22.986587  9048 sgd_solver.cpp:106] Iteration 993, lr = 0.01
I0408 21:17:23.262246  9048 solver.cpp:240] Iteration 994, loss = 14.3385
I0408 21:17:23.262285  9048 solver.cpp:256]     Train net output #0: loss = 14.3385 (* 1 = 14.3385 loss)
I0408 21:17:23.262297  9048 sgd_solver.cpp:106] Iteration 994, lr = 0.01
I0408 21:17:23.538391  9048 solver.cpp:240] Iteration 995, loss = 19.7256
I0408 21:17:23.538427  9048 solver.cpp:256]     Train net output #0: loss = 19.7256 (* 1 = 19.7256 loss)
I0408 21:17:23.538439  9048 sgd_solver.cpp:106] Iteration 995, lr = 0.01
I0408 21:17:23.814409  9048 solver.cpp:240] Iteration 996, loss = 30.5104
I0408 21:17:23.814445  9048 solver.cpp:256]     Train net output #0: loss = 30.5104 (* 1 = 30.5104 loss)
I0408 21:17:23.814496  9048 sgd_solver.cpp:106] Iteration 996, lr = 0.01
I0408 21:17:24.090651  9048 solver.cpp:240] Iteration 997, loss = 30.0032
I0408 21:17:24.090703  9048 solver.cpp:256]     Train net output #0: loss = 30.0032 (* 1 = 30.0032 loss)
I0408 21:17:24.090715  9048 sgd_solver.cpp:106] Iteration 997, lr = 0.01
I0408 21:17:24.366711  9048 solver.cpp:240] Iteration 998, loss = 14.0438
I0408 21:17:24.366745  9048 solver.cpp:256]     Train net output #0: loss = 14.0438 (* 1 = 14.0438 loss)
I0408 21:17:24.366755  9048 sgd_solver.cpp:106] Iteration 998, lr = 0.01
I0408 21:17:24.643626  9048 solver.cpp:240] Iteration 999, loss = 24.883
I0408 21:17:24.643661  9048 solver.cpp:256]     Train net output #0: loss = 24.8831 (* 1 = 24.8831 loss)
I0408 21:17:24.643669  9048 sgd_solver.cpp:106] Iteration 999, lr = 0.01
I0408 21:17:24.919849  9048 solver.cpp:240] Iteration 1000, loss = 22.2681
I0408 21:17:24.919894  9048 solver.cpp:256]     Train net output #0: loss = 22.2681 (* 1 = 22.2681 loss)
I0408 21:17:24.919903  9048 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0408 21:17:25.196482  9048 solver.cpp:240] Iteration 1001, loss = 17.4385
I0408 21:17:25.196512  9048 solver.cpp:256]     Train net output #0: loss = 17.4385 (* 1 = 17.4385 loss)
I0408 21:17:25.196521  9048 sgd_solver.cpp:106] Iteration 1001, lr = 0.01
I0408 21:17:25.472216  9048 solver.cpp:240] Iteration 1002, loss = 14.8072
I0408 21:17:25.472254  9048 solver.cpp:256]     Train net output #0: loss = 14.8072 (* 1 = 14.8072 loss)
I0408 21:17:25.472264  9048 sgd_solver.cpp:106] Iteration 1002, lr = 0.01
I0408 21:17:25.746856  9048 solver.cpp:240] Iteration 1003, loss = 22.8872
I0408 21:17:25.746891  9048 solver.cpp:256]     Train net output #0: loss = 22.8872 (* 1 = 22.8872 loss)
I0408 21:17:25.746899  9048 sgd_solver.cpp:106] Iteration 1003, lr = 0.01
I0408 21:17:26.022665  9048 solver.cpp:240] Iteration 1004, loss = 14.8903
I0408 21:17:26.022698  9048 solver.cpp:256]     Train net output #0: loss = 14.8903 (* 1 = 14.8903 loss)
I0408 21:17:26.022707  9048 sgd_solver.cpp:106] Iteration 1004, lr = 0.01
I0408 21:17:26.298581  9048 solver.cpp:240] Iteration 1005, loss = 16.1002
I0408 21:17:26.298626  9048 solver.cpp:256]     Train net output #0: loss = 16.1002 (* 1 = 16.1002 loss)
I0408 21:17:26.298635  9048 sgd_solver.cpp:106] Iteration 1005, lr = 0.01
I0408 21:17:26.574513  9048 solver.cpp:240] Iteration 1006, loss = 15.1754
I0408 21:17:26.574548  9048 solver.cpp:256]     Train net output #0: loss = 15.1754 (* 1 = 15.1754 loss)
I0408 21:17:26.574558  9048 sgd_solver.cpp:106] Iteration 1006, lr = 0.01
I0408 21:17:26.851215  9048 solver.cpp:240] Iteration 1007, loss = 7.64682
I0408 21:17:26.851255  9048 solver.cpp:256]     Train net output #0: loss = 7.64682 (* 1 = 7.64682 loss)
I0408 21:17:26.851263  9048 sgd_solver.cpp:106] Iteration 1007, lr = 0.01
I0408 21:17:27.127269  9048 solver.cpp:240] Iteration 1008, loss = 10.5909
I0408 21:17:27.127313  9048 solver.cpp:256]     Train net output #0: loss = 10.5909 (* 1 = 10.5909 loss)
I0408 21:17:27.127321  9048 sgd_solver.cpp:106] Iteration 1008, lr = 0.01
I0408 21:17:27.402881  9048 solver.cpp:240] Iteration 1009, loss = 29.4524
I0408 21:17:27.402915  9048 solver.cpp:256]     Train net output #0: loss = 29.4524 (* 1 = 29.4524 loss)
I0408 21:17:27.402923  9048 sgd_solver.cpp:106] Iteration 1009, lr = 0.01
I0408 21:17:27.678470  9048 solver.cpp:240] Iteration 1010, loss = 22.5749
I0408 21:17:27.678503  9048 solver.cpp:256]     Train net output #0: loss = 22.5749 (* 1 = 22.5749 loss)
I0408 21:17:27.678511  9048 sgd_solver.cpp:106] Iteration 1010, lr = 0.01
I0408 21:17:27.954568  9048 solver.cpp:240] Iteration 1011, loss = 9.04569
I0408 21:17:27.954614  9048 solver.cpp:256]     Train net output #0: loss = 9.04569 (* 1 = 9.04569 loss)
I0408 21:17:27.954622  9048 sgd_solver.cpp:106] Iteration 1011, lr = 0.01
I0408 21:17:28.230526  9048 solver.cpp:240] Iteration 1012, loss = 25.6152
I0408 21:17:28.230562  9048 solver.cpp:256]     Train net output #0: loss = 25.6152 (* 1 = 25.6152 loss)
I0408 21:17:28.230571  9048 sgd_solver.cpp:106] Iteration 1012, lr = 0.01
I0408 21:17:28.506726  9048 solver.cpp:240] Iteration 1013, loss = 7.64937
I0408 21:17:28.506768  9048 solver.cpp:256]     Train net output #0: loss = 7.64937 (* 1 = 7.64937 loss)
I0408 21:17:28.506777  9048 sgd_solver.cpp:106] Iteration 1013, lr = 0.01
I0408 21:17:28.782721  9048 solver.cpp:240] Iteration 1014, loss = 5.60408
I0408 21:17:28.782754  9048 solver.cpp:256]     Train net output #0: loss = 5.60408 (* 1 = 5.60408 loss)
I0408 21:17:28.782763  9048 sgd_solver.cpp:106] Iteration 1014, lr = 0.01
I0408 21:17:29.058583  9048 solver.cpp:240] Iteration 1015, loss = 13.1928
I0408 21:17:29.058615  9048 solver.cpp:256]     Train net output #0: loss = 13.1928 (* 1 = 13.1928 loss)
I0408 21:17:29.058624  9048 sgd_solver.cpp:106] Iteration 1015, lr = 0.01
I0408 21:17:29.335018  9048 solver.cpp:240] Iteration 1016, loss = 10.1596
I0408 21:17:29.335063  9048 solver.cpp:256]     Train net output #0: loss = 10.1596 (* 1 = 10.1596 loss)
I0408 21:17:29.335072  9048 sgd_solver.cpp:106] Iteration 1016, lr = 0.01
I0408 21:17:29.610564  9048 solver.cpp:240] Iteration 1017, loss = 15.2893
I0408 21:17:29.610610  9048 solver.cpp:256]     Train net output #0: loss = 15.2893 (* 1 = 15.2893 loss)
I0408 21:17:29.610620  9048 sgd_solver.cpp:106] Iteration 1017, lr = 0.01
I0408 21:17:29.885695  9048 solver.cpp:240] Iteration 1018, loss = 8.65738
I0408 21:17:29.885738  9048 solver.cpp:256]     Train net output #0: loss = 8.65738 (* 1 = 8.65738 loss)
I0408 21:17:29.885746  9048 sgd_solver.cpp:106] Iteration 1018, lr = 0.01
I0408 21:17:30.161805  9048 solver.cpp:240] Iteration 1019, loss = 5.72262
I0408 21:17:30.161847  9048 solver.cpp:256]     Train net output #0: loss = 5.72262 (* 1 = 5.72262 loss)
I0408 21:17:30.161855  9048 sgd_solver.cpp:106] Iteration 1019, lr = 0.01
I0408 21:17:30.437892  9048 solver.cpp:240] Iteration 1020, loss = 13.7881
I0408 21:17:30.437927  9048 solver.cpp:256]     Train net output #0: loss = 13.7881 (* 1 = 13.7881 loss)
I0408 21:17:30.437934  9048 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0408 21:17:30.713848  9048 solver.cpp:240] Iteration 1021, loss = 6.40011
I0408 21:17:30.713879  9048 solver.cpp:256]     Train net output #0: loss = 6.40011 (* 1 = 6.40011 loss)
I0408 21:17:30.713887  9048 sgd_solver.cpp:106] Iteration 1021, lr = 0.01
I0408 21:17:30.989719  9048 solver.cpp:240] Iteration 1022, loss = 7.88703
I0408 21:17:30.989750  9048 solver.cpp:256]     Train net output #0: loss = 7.88703 (* 1 = 7.88703 loss)
I0408 21:17:30.989758  9048 sgd_solver.cpp:106] Iteration 1022, lr = 0.01
I0408 21:17:31.265748  9048 solver.cpp:240] Iteration 1023, loss = 14.097
I0408 21:17:31.265777  9048 solver.cpp:256]     Train net output #0: loss = 14.097 (* 1 = 14.097 loss)
I0408 21:17:31.265785  9048 sgd_solver.cpp:106] Iteration 1023, lr = 0.01
I0408 21:17:31.541936  9048 solver.cpp:240] Iteration 1024, loss = 12.3365
I0408 21:17:31.541970  9048 solver.cpp:256]     Train net output #0: loss = 12.3365 (* 1 = 12.3365 loss)
I0408 21:17:31.541978  9048 sgd_solver.cpp:106] Iteration 1024, lr = 0.01
I0408 21:17:31.818361  9048 solver.cpp:240] Iteration 1025, loss = 10.8236
I0408 21:17:31.818399  9048 solver.cpp:256]     Train net output #0: loss = 10.8236 (* 1 = 10.8236 loss)
I0408 21:17:31.818409  9048 sgd_solver.cpp:106] Iteration 1025, lr = 0.01
I0408 21:17:32.093966  9048 solver.cpp:240] Iteration 1026, loss = 5.27449
I0408 21:17:32.094009  9048 solver.cpp:256]     Train net output #0: loss = 5.27449 (* 1 = 5.27449 loss)
I0408 21:17:32.094018  9048 sgd_solver.cpp:106] Iteration 1026, lr = 0.01
I0408 21:17:32.370757  9048 solver.cpp:240] Iteration 1027, loss = 8.58068
I0408 21:17:32.370791  9048 solver.cpp:256]     Train net output #0: loss = 8.58068 (* 1 = 8.58068 loss)
I0408 21:17:32.370798  9048 sgd_solver.cpp:106] Iteration 1027, lr = 0.01
I0408 21:17:32.647724  9048 solver.cpp:240] Iteration 1028, loss = 6.78629
I0408 21:17:32.647758  9048 solver.cpp:256]     Train net output #0: loss = 6.78628 (* 1 = 6.78628 loss)
I0408 21:17:32.647765  9048 sgd_solver.cpp:106] Iteration 1028, lr = 0.01
I0408 21:17:32.923511  9048 solver.cpp:240] Iteration 1029, loss = 19.423
I0408 21:17:32.923555  9048 solver.cpp:256]     Train net output #0: loss = 19.423 (* 1 = 19.423 loss)
I0408 21:17:32.923564  9048 sgd_solver.cpp:106] Iteration 1029, lr = 0.01
I0408 21:17:33.198869  9048 solver.cpp:240] Iteration 1030, loss = 7.73122
I0408 21:17:33.198904  9048 solver.cpp:256]     Train net output #0: loss = 7.73122 (* 1 = 7.73122 loss)
I0408 21:17:33.198914  9048 sgd_solver.cpp:106] Iteration 1030, lr = 0.01
I0408 21:17:33.473639  9048 solver.cpp:240] Iteration 1031, loss = 4.42547
I0408 21:17:33.473682  9048 solver.cpp:256]     Train net output #0: loss = 4.42547 (* 1 = 4.42547 loss)
I0408 21:17:33.473690  9048 sgd_solver.cpp:106] Iteration 1031, lr = 0.01
I0408 21:17:33.749086  9048 solver.cpp:240] Iteration 1032, loss = 9.23198
I0408 21:17:33.749130  9048 solver.cpp:256]     Train net output #0: loss = 9.23198 (* 1 = 9.23198 loss)
I0408 21:17:33.749137  9048 sgd_solver.cpp:106] Iteration 1032, lr = 0.01
I0408 21:17:34.025933  9048 solver.cpp:240] Iteration 1033, loss = 19.5866
I0408 21:17:34.025974  9048 solver.cpp:256]     Train net output #0: loss = 19.5866 (* 1 = 19.5866 loss)
I0408 21:17:34.025984  9048 sgd_solver.cpp:106] Iteration 1033, lr = 0.01
I0408 21:17:34.301419  9048 solver.cpp:240] Iteration 1034, loss = 9.34458
I0408 21:17:34.301450  9048 solver.cpp:256]     Train net output #0: loss = 9.34458 (* 1 = 9.34458 loss)
I0408 21:17:34.301458  9048 sgd_solver.cpp:106] Iteration 1034, lr = 0.01
I0408 21:17:34.576925  9048 solver.cpp:240] Iteration 1035, loss = 6.02383
I0408 21:17:34.576954  9048 solver.cpp:256]     Train net output #0: loss = 6.02383 (* 1 = 6.02383 loss)
I0408 21:17:34.576962  9048 sgd_solver.cpp:106] Iteration 1035, lr = 0.01
I0408 21:17:34.851950  9048 solver.cpp:240] Iteration 1036, loss = 15.6154
I0408 21:17:34.851984  9048 solver.cpp:256]     Train net output #0: loss = 15.6154 (* 1 = 15.6154 loss)
I0408 21:17:34.851994  9048 sgd_solver.cpp:106] Iteration 1036, lr = 0.01
I0408 21:17:35.127509  9048 solver.cpp:240] Iteration 1037, loss = 17.6818
I0408 21:17:35.127542  9048 solver.cpp:256]     Train net output #0: loss = 17.6818 (* 1 = 17.6818 loss)
I0408 21:17:35.127550  9048 sgd_solver.cpp:106] Iteration 1037, lr = 0.01
I0408 21:17:35.402839  9048 solver.cpp:240] Iteration 1038, loss = 20.4774
I0408 21:17:35.402876  9048 solver.cpp:256]     Train net output #0: loss = 20.4774 (* 1 = 20.4774 loss)
I0408 21:17:35.402886  9048 sgd_solver.cpp:106] Iteration 1038, lr = 0.01
I0408 21:17:35.678200  9048 solver.cpp:240] Iteration 1039, loss = 22.7147
I0408 21:17:35.678238  9048 solver.cpp:256]     Train net output #0: loss = 22.7147 (* 1 = 22.7147 loss)
I0408 21:17:35.678246  9048 sgd_solver.cpp:106] Iteration 1039, lr = 0.01
I0408 21:17:35.954100  9048 solver.cpp:240] Iteration 1040, loss = 8.00897
I0408 21:17:35.954144  9048 solver.cpp:256]     Train net output #0: loss = 8.00897 (* 1 = 8.00897 loss)
I0408 21:17:35.954152  9048 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0408 21:17:36.230353  9048 solver.cpp:240] Iteration 1041, loss = 13.3351
I0408 21:17:36.230386  9048 solver.cpp:256]     Train net output #0: loss = 13.3351 (* 1 = 13.3351 loss)
I0408 21:17:36.230394  9048 sgd_solver.cpp:106] Iteration 1041, lr = 0.01
I0408 21:17:36.506062  9048 solver.cpp:240] Iteration 1042, loss = 5.3546
I0408 21:17:36.506105  9048 solver.cpp:256]     Train net output #0: loss = 5.3546 (* 1 = 5.3546 loss)
I0408 21:17:36.506114  9048 sgd_solver.cpp:106] Iteration 1042, lr = 0.01
I0408 21:17:36.781456  9048 solver.cpp:240] Iteration 1043, loss = 10.7223
I0408 21:17:36.781493  9048 solver.cpp:256]     Train net output #0: loss = 10.7223 (* 1 = 10.7223 loss)
I0408 21:17:36.781502  9048 sgd_solver.cpp:106] Iteration 1043, lr = 0.01
I0408 21:17:37.057137  9048 solver.cpp:240] Iteration 1044, loss = 7.01123
I0408 21:17:37.057168  9048 solver.cpp:256]     Train net output #0: loss = 7.01123 (* 1 = 7.01123 loss)
I0408 21:17:37.057175  9048 sgd_solver.cpp:106] Iteration 1044, lr = 0.01
I0408 21:17:37.333065  9048 solver.cpp:240] Iteration 1045, loss = 28.9619
I0408 21:17:37.333114  9048 solver.cpp:256]     Train net output #0: loss = 28.9619 (* 1 = 28.9619 loss)
I0408 21:17:37.333123  9048 sgd_solver.cpp:106] Iteration 1045, lr = 0.01
I0408 21:17:37.609159  9048 solver.cpp:240] Iteration 1046, loss = 42.3868
I0408 21:17:37.609216  9048 solver.cpp:256]     Train net output #0: loss = 42.3868 (* 1 = 42.3868 loss)
I0408 21:17:37.609225  9048 sgd_solver.cpp:106] Iteration 1046, lr = 0.01
I0408 21:17:37.885555  9048 solver.cpp:240] Iteration 1047, loss = 35.8144
I0408 21:17:37.885589  9048 solver.cpp:256]     Train net output #0: loss = 35.8144 (* 1 = 35.8144 loss)
I0408 21:17:37.885597  9048 sgd_solver.cpp:106] Iteration 1047, lr = 0.01
I0408 21:17:38.161372  9048 solver.cpp:240] Iteration 1048, loss = 34.1417
I0408 21:17:38.161403  9048 solver.cpp:256]     Train net output #0: loss = 34.1417 (* 1 = 34.1417 loss)
I0408 21:17:38.161412  9048 sgd_solver.cpp:106] Iteration 1048, lr = 0.01
I0408 21:17:38.437111  9048 solver.cpp:240] Iteration 1049, loss = 15.0347
I0408 21:17:38.437144  9048 solver.cpp:256]     Train net output #0: loss = 15.0347 (* 1 = 15.0347 loss)
I0408 21:17:38.437153  9048 sgd_solver.cpp:106] Iteration 1049, lr = 0.01
I0408 21:17:38.713071  9048 solver.cpp:240] Iteration 1050, loss = 1.98328
I0408 21:17:38.713104  9048 solver.cpp:256]     Train net output #0: loss = 1.98328 (* 1 = 1.98328 loss)
I0408 21:17:38.713111  9048 sgd_solver.cpp:106] Iteration 1050, lr = 0.01
I0408 21:17:38.988561  9048 solver.cpp:240] Iteration 1051, loss = 4.68979
I0408 21:17:38.988592  9048 solver.cpp:256]     Train net output #0: loss = 4.68979 (* 1 = 4.68979 loss)
I0408 21:17:38.988600  9048 sgd_solver.cpp:106] Iteration 1051, lr = 0.01
I0408 21:17:39.263960  9048 solver.cpp:240] Iteration 1052, loss = 14.4923
I0408 21:17:39.263996  9048 solver.cpp:256]     Train net output #0: loss = 14.4923 (* 1 = 14.4923 loss)
I0408 21:17:39.264005  9048 sgd_solver.cpp:106] Iteration 1052, lr = 0.01
I0408 21:17:39.540212  9048 solver.cpp:240] Iteration 1053, loss = 2.31937
I0408 21:17:39.540244  9048 solver.cpp:256]     Train net output #0: loss = 2.31937 (* 1 = 2.31937 loss)
I0408 21:17:39.540252  9048 sgd_solver.cpp:106] Iteration 1053, lr = 0.01
I0408 21:17:39.816104  9048 solver.cpp:240] Iteration 1054, loss = 14.0255
I0408 21:17:39.816138  9048 solver.cpp:256]     Train net output #0: loss = 14.0255 (* 1 = 14.0255 loss)
I0408 21:17:39.816146  9048 sgd_solver.cpp:106] Iteration 1054, lr = 0.01
I0408 21:17:40.092466  9048 solver.cpp:240] Iteration 1055, loss = 4.37085
I0408 21:17:40.092499  9048 solver.cpp:256]     Train net output #0: loss = 4.37085 (* 1 = 4.37085 loss)
I0408 21:17:40.092506  9048 sgd_solver.cpp:106] Iteration 1055, lr = 0.01
I0408 21:17:40.368194  9048 solver.cpp:240] Iteration 1056, loss = 7.39733
I0408 21:17:40.368255  9048 solver.cpp:256]     Train net output #0: loss = 7.39733 (* 1 = 7.39733 loss)
I0408 21:17:40.368265  9048 sgd_solver.cpp:106] Iteration 1056, lr = 0.01
I0408 21:17:40.644420  9048 solver.cpp:240] Iteration 1057, loss = 4.80534
I0408 21:17:40.644462  9048 solver.cpp:256]     Train net output #0: loss = 4.80534 (* 1 = 4.80534 loss)
I0408 21:17:40.644470  9048 sgd_solver.cpp:106] Iteration 1057, lr = 0.01
I0408 21:17:40.920537  9048 solver.cpp:240] Iteration 1058, loss = 2.13327
I0408 21:17:40.920570  9048 solver.cpp:256]     Train net output #0: loss = 2.13327 (* 1 = 2.13327 loss)
I0408 21:17:40.920578  9048 sgd_solver.cpp:106] Iteration 1058, lr = 0.01
I0408 21:17:41.196722  9048 solver.cpp:240] Iteration 1059, loss = 2.76283
I0408 21:17:41.196750  9048 solver.cpp:256]     Train net output #0: loss = 2.76283 (* 1 = 2.76283 loss)
I0408 21:17:41.196758  9048 sgd_solver.cpp:106] Iteration 1059, lr = 0.01
I0408 21:17:41.472368  9048 solver.cpp:240] Iteration 1060, loss = 3.76866
I0408 21:17:41.472400  9048 solver.cpp:256]     Train net output #0: loss = 3.76866 (* 1 = 3.76866 loss)
I0408 21:17:41.472409  9048 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0408 21:17:41.748440  9048 solver.cpp:240] Iteration 1061, loss = 5.02073
I0408 21:17:41.748499  9048 solver.cpp:256]     Train net output #0: loss = 5.02073 (* 1 = 5.02073 loss)
I0408 21:17:41.748519  9048 sgd_solver.cpp:106] Iteration 1061, lr = 0.01
I0408 21:17:42.024493  9048 solver.cpp:240] Iteration 1062, loss = 4.08656
I0408 21:17:42.024524  9048 solver.cpp:256]     Train net output #0: loss = 4.08656 (* 1 = 4.08656 loss)
I0408 21:17:42.024533  9048 sgd_solver.cpp:106] Iteration 1062, lr = 0.01
I0408 21:17:42.300246  9048 solver.cpp:240] Iteration 1063, loss = 9.77741
I0408 21:17:42.300281  9048 solver.cpp:256]     Train net output #0: loss = 9.77741 (* 1 = 9.77741 loss)
I0408 21:17:42.300288  9048 sgd_solver.cpp:106] Iteration 1063, lr = 0.01
I0408 21:17:42.575742  9048 solver.cpp:240] Iteration 1064, loss = 4.15915
I0408 21:17:42.575773  9048 solver.cpp:256]     Train net output #0: loss = 4.15915 (* 1 = 4.15915 loss)
I0408 21:17:42.575780  9048 sgd_solver.cpp:106] Iteration 1064, lr = 0.01
I0408 21:17:42.852435  9048 solver.cpp:240] Iteration 1065, loss = 2.38518
I0408 21:17:42.852465  9048 solver.cpp:256]     Train net output #0: loss = 2.38518 (* 1 = 2.38518 loss)
I0408 21:17:42.852473  9048 sgd_solver.cpp:106] Iteration 1065, lr = 0.01
I0408 21:17:43.128285  9048 solver.cpp:240] Iteration 1066, loss = 16.8916
I0408 21:17:43.128319  9048 solver.cpp:256]     Train net output #0: loss = 16.8916 (* 1 = 16.8916 loss)
I0408 21:17:43.128327  9048 sgd_solver.cpp:106] Iteration 1066, lr = 0.01
I0408 21:17:43.402961  9048 solver.cpp:240] Iteration 1067, loss = 2.30804
I0408 21:17:43.402997  9048 solver.cpp:256]     Train net output #0: loss = 2.30804 (* 1 = 2.30804 loss)
I0408 21:17:43.403003  9048 sgd_solver.cpp:106] Iteration 1067, lr = 0.01
I0408 21:17:43.678867  9048 solver.cpp:240] Iteration 1068, loss = 2.57286
I0408 21:17:43.678900  9048 solver.cpp:256]     Train net output #0: loss = 2.57286 (* 1 = 2.57286 loss)
I0408 21:17:43.678908  9048 sgd_solver.cpp:106] Iteration 1068, lr = 0.01
I0408 21:17:43.955292  9048 solver.cpp:240] Iteration 1069, loss = 1.87088
I0408 21:17:43.955335  9048 solver.cpp:256]     Train net output #0: loss = 1.87088 (* 1 = 1.87088 loss)
I0408 21:17:43.955343  9048 sgd_solver.cpp:106] Iteration 1069, lr = 0.01
I0408 21:17:44.231458  9048 solver.cpp:240] Iteration 1070, loss = 4.2231
I0408 21:17:44.231487  9048 solver.cpp:256]     Train net output #0: loss = 4.2231 (* 1 = 4.2231 loss)
I0408 21:17:44.231495  9048 sgd_solver.cpp:106] Iteration 1070, lr = 0.01
I0408 21:17:44.507973  9048 solver.cpp:240] Iteration 1071, loss = 2.37099
I0408 21:17:44.508007  9048 solver.cpp:256]     Train net output #0: loss = 2.37099 (* 1 = 2.37099 loss)
I0408 21:17:44.508015  9048 sgd_solver.cpp:106] Iteration 1071, lr = 0.01
I0408 21:17:44.784040  9048 solver.cpp:240] Iteration 1072, loss = 1.25761
I0408 21:17:44.784075  9048 solver.cpp:256]     Train net output #0: loss = 1.25761 (* 1 = 1.25761 loss)
I0408 21:17:44.784082  9048 sgd_solver.cpp:106] Iteration 1072, lr = 0.01
I0408 21:17:45.059919  9048 solver.cpp:240] Iteration 1073, loss = 4.36533
I0408 21:17:45.059952  9048 solver.cpp:256]     Train net output #0: loss = 4.36533 (* 1 = 4.36533 loss)
I0408 21:17:45.059959  9048 sgd_solver.cpp:106] Iteration 1073, lr = 0.01
I0408 21:17:45.336086  9048 solver.cpp:240] Iteration 1074, loss = 6.14425
I0408 21:17:45.336120  9048 solver.cpp:256]     Train net output #0: loss = 6.14425 (* 1 = 6.14425 loss)
I0408 21:17:45.336129  9048 sgd_solver.cpp:106] Iteration 1074, lr = 0.01
I0408 21:17:45.611901  9048 solver.cpp:240] Iteration 1075, loss = 3.78045
I0408 21:17:45.611933  9048 solver.cpp:256]     Train net output #0: loss = 3.78045 (* 1 = 3.78045 loss)
I0408 21:17:45.611940  9048 sgd_solver.cpp:106] Iteration 1075, lr = 0.01
I0408 21:17:45.887579  9048 solver.cpp:240] Iteration 1076, loss = 1.6308
I0408 21:17:45.887614  9048 solver.cpp:256]     Train net output #0: loss = 1.6308 (* 1 = 1.6308 loss)
I0408 21:17:45.887620  9048 sgd_solver.cpp:106] Iteration 1076, lr = 0.01
I0408 21:17:46.162853  9048 solver.cpp:240] Iteration 1077, loss = 11.3174
I0408 21:17:46.162885  9048 solver.cpp:256]     Train net output #0: loss = 11.3174 (* 1 = 11.3174 loss)
I0408 21:17:46.162927  9048 sgd_solver.cpp:106] Iteration 1077, lr = 0.01
I0408 21:17:46.438756  9048 solver.cpp:240] Iteration 1078, loss = 2.38044
I0408 21:17:46.438787  9048 solver.cpp:256]     Train net output #0: loss = 2.38044 (* 1 = 2.38044 loss)
I0408 21:17:46.438794  9048 sgd_solver.cpp:106] Iteration 1078, lr = 0.01
I0408 21:17:46.715251  9048 solver.cpp:240] Iteration 1079, loss = 34.982
I0408 21:17:46.715291  9048 solver.cpp:256]     Train net output #0: loss = 34.982 (* 1 = 34.982 loss)
I0408 21:17:46.715299  9048 sgd_solver.cpp:106] Iteration 1079, lr = 0.01
I0408 21:17:46.991909  9048 solver.cpp:240] Iteration 1080, loss = 3.65871
I0408 21:17:46.991942  9048 solver.cpp:256]     Train net output #0: loss = 3.65871 (* 1 = 3.65871 loss)
I0408 21:17:46.991950  9048 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0408 21:17:47.267534  9048 solver.cpp:240] Iteration 1081, loss = 5.83013
I0408 21:17:47.267563  9048 solver.cpp:256]     Train net output #0: loss = 5.83013 (* 1 = 5.83013 loss)
I0408 21:17:47.267570  9048 sgd_solver.cpp:106] Iteration 1081, lr = 0.01
I0408 21:17:47.544656  9048 solver.cpp:240] Iteration 1082, loss = 26.8255
I0408 21:17:47.544690  9048 solver.cpp:256]     Train net output #0: loss = 26.8255 (* 1 = 26.8255 loss)
I0408 21:17:47.544698  9048 sgd_solver.cpp:106] Iteration 1082, lr = 0.01
I0408 21:17:47.820638  9048 solver.cpp:240] Iteration 1083, loss = 29.5567
I0408 21:17:47.820672  9048 solver.cpp:256]     Train net output #0: loss = 29.5567 (* 1 = 29.5567 loss)
I0408 21:17:47.820680  9048 sgd_solver.cpp:106] Iteration 1083, lr = 0.01
I0408 21:17:48.096386  9048 solver.cpp:240] Iteration 1084, loss = 25.7259
I0408 21:17:48.096437  9048 solver.cpp:256]     Train net output #0: loss = 25.7259 (* 1 = 25.7259 loss)
I0408 21:17:48.096446  9048 sgd_solver.cpp:106] Iteration 1084, lr = 0.01
I0408 21:17:48.372651  9048 solver.cpp:240] Iteration 1085, loss = 1.29125
I0408 21:17:48.372684  9048 solver.cpp:256]     Train net output #0: loss = 1.29125 (* 1 = 1.29125 loss)
I0408 21:17:48.372691  9048 sgd_solver.cpp:106] Iteration 1085, lr = 0.01
I0408 21:17:48.647557  9048 solver.cpp:240] Iteration 1086, loss = 3.72396
I0408 21:17:48.647590  9048 solver.cpp:256]     Train net output #0: loss = 3.72396 (* 1 = 3.72396 loss)
I0408 21:17:48.647598  9048 sgd_solver.cpp:106] Iteration 1086, lr = 0.01
I0408 21:17:48.923007  9048 solver.cpp:240] Iteration 1087, loss = 8.04046
I0408 21:17:48.923039  9048 solver.cpp:256]     Train net output #0: loss = 8.04046 (* 1 = 8.04046 loss)
I0408 21:17:48.923048  9048 sgd_solver.cpp:106] Iteration 1087, lr = 0.01
I0408 21:17:49.198413  9048 solver.cpp:240] Iteration 1088, loss = 1.69971
I0408 21:17:49.198447  9048 solver.cpp:256]     Train net output #0: loss = 1.69971 (* 1 = 1.69971 loss)
I0408 21:17:49.198456  9048 sgd_solver.cpp:106] Iteration 1088, lr = 0.01
I0408 21:17:49.473156  9048 solver.cpp:240] Iteration 1089, loss = 29.4069
I0408 21:17:49.473342  9048 solver.cpp:256]     Train net output #0: loss = 29.4069 (* 1 = 29.4069 loss)
I0408 21:17:49.473353  9048 sgd_solver.cpp:106] Iteration 1089, lr = 0.01
I0408 21:17:49.749217  9048 solver.cpp:240] Iteration 1090, loss = 4.80586
I0408 21:17:49.749250  9048 solver.cpp:256]     Train net output #0: loss = 4.80586 (* 1 = 4.80586 loss)
I0408 21:17:49.749258  9048 sgd_solver.cpp:106] Iteration 1090, lr = 0.01
I0408 21:17:50.024682  9048 solver.cpp:240] Iteration 1091, loss = 4.04172
I0408 21:17:50.024722  9048 solver.cpp:256]     Train net output #0: loss = 4.04172 (* 1 = 4.04172 loss)
I0408 21:17:50.024729  9048 sgd_solver.cpp:106] Iteration 1091, lr = 0.01
I0408 21:17:50.299625  9048 solver.cpp:240] Iteration 1092, loss = 21.7527
I0408 21:17:50.299660  9048 solver.cpp:256]     Train net output #0: loss = 21.7527 (* 1 = 21.7527 loss)
I0408 21:17:50.299669  9048 sgd_solver.cpp:106] Iteration 1092, lr = 0.01
I0408 21:17:50.575461  9048 solver.cpp:240] Iteration 1093, loss = 26.2998
I0408 21:17:50.575496  9048 solver.cpp:256]     Train net output #0: loss = 26.2998 (* 1 = 26.2998 loss)
I0408 21:17:50.575505  9048 sgd_solver.cpp:106] Iteration 1093, lr = 0.01
I0408 21:17:50.850963  9048 solver.cpp:240] Iteration 1094, loss = 19.9628
I0408 21:17:50.850997  9048 solver.cpp:256]     Train net output #0: loss = 19.9628 (* 1 = 19.9628 loss)
I0408 21:17:50.851006  9048 sgd_solver.cpp:106] Iteration 1094, lr = 0.01
I0408 21:17:51.126813  9048 solver.cpp:240] Iteration 1095, loss = 1.2886
I0408 21:17:51.126847  9048 solver.cpp:256]     Train net output #0: loss = 1.2886 (* 1 = 1.2886 loss)
I0408 21:17:51.126855  9048 sgd_solver.cpp:106] Iteration 1095, lr = 0.01
I0408 21:17:51.402312  9048 solver.cpp:240] Iteration 1096, loss = 9.47045
I0408 21:17:51.402345  9048 solver.cpp:256]     Train net output #0: loss = 9.47044 (* 1 = 9.47044 loss)
I0408 21:17:51.402354  9048 sgd_solver.cpp:106] Iteration 1096, lr = 0.01
I0408 21:17:51.678010  9048 solver.cpp:240] Iteration 1097, loss = 5.10848
I0408 21:17:51.678051  9048 solver.cpp:256]     Train net output #0: loss = 5.10848 (* 1 = 5.10848 loss)
I0408 21:17:51.678058  9048 sgd_solver.cpp:106] Iteration 1097, lr = 0.01
I0408 21:17:51.954362  9048 solver.cpp:240] Iteration 1098, loss = 4.12213
I0408 21:17:51.954396  9048 solver.cpp:256]     Train net output #0: loss = 4.12213 (* 1 = 4.12213 loss)
I0408 21:17:51.954404  9048 sgd_solver.cpp:106] Iteration 1098, lr = 0.01
I0408 21:17:52.230357  9048 solver.cpp:240] Iteration 1099, loss = 4.32443
I0408 21:17:52.230388  9048 solver.cpp:256]     Train net output #0: loss = 4.32443 (* 1 = 4.32443 loss)
I0408 21:17:52.230396  9048 sgd_solver.cpp:106] Iteration 1099, lr = 0.01
I0408 21:17:52.506007  9048 solver.cpp:240] Iteration 1100, loss = 17.9887
I0408 21:17:52.506039  9048 solver.cpp:256]     Train net output #0: loss = 17.9887 (* 1 = 17.9887 loss)
I0408 21:17:52.506047  9048 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0408 21:17:52.781831  9048 solver.cpp:240] Iteration 1101, loss = 18.6475
I0408 21:17:52.781893  9048 solver.cpp:256]     Train net output #0: loss = 18.6475 (* 1 = 18.6475 loss)
I0408 21:17:52.781903  9048 sgd_solver.cpp:106] Iteration 1101, lr = 0.01
I0408 21:17:53.057966  9048 solver.cpp:240] Iteration 1102, loss = 9.34448
I0408 21:17:53.058008  9048 solver.cpp:256]     Train net output #0: loss = 9.34447 (* 1 = 9.34447 loss)
I0408 21:17:53.058017  9048 sgd_solver.cpp:106] Iteration 1102, lr = 0.01
I0408 21:17:53.333884  9048 solver.cpp:240] Iteration 1103, loss = 8.47096
I0408 21:17:53.333925  9048 solver.cpp:256]     Train net output #0: loss = 8.47096 (* 1 = 8.47096 loss)
I0408 21:17:53.333938  9048 sgd_solver.cpp:106] Iteration 1103, lr = 0.01
I0408 21:17:53.609964  9048 solver.cpp:240] Iteration 1104, loss = 16.8168
I0408 21:17:53.609998  9048 solver.cpp:256]     Train net output #0: loss = 16.8168 (* 1 = 16.8168 loss)
I0408 21:17:53.610007  9048 sgd_solver.cpp:106] Iteration 1104, lr = 0.01
I0408 21:17:53.885334  9048 solver.cpp:240] Iteration 1105, loss = 8.60384
I0408 21:17:53.885367  9048 solver.cpp:256]     Train net output #0: loss = 8.60384 (* 1 = 8.60384 loss)
I0408 21:17:53.885411  9048 sgd_solver.cpp:106] Iteration 1105, lr = 0.01
I0408 21:17:54.162436  9048 solver.cpp:240] Iteration 1106, loss = 12.3128
I0408 21:17:54.162472  9048 solver.cpp:256]     Train net output #0: loss = 12.3128 (* 1 = 12.3128 loss)
I0408 21:17:54.162482  9048 sgd_solver.cpp:106] Iteration 1106, lr = 0.01
I0408 21:17:54.438441  9048 solver.cpp:240] Iteration 1107, loss = 19.389
I0408 21:17:54.438485  9048 solver.cpp:256]     Train net output #0: loss = 19.389 (* 1 = 19.389 loss)
I0408 21:17:54.438493  9048 sgd_solver.cpp:106] Iteration 1107, lr = 0.01
I0408 21:17:54.713687  9048 solver.cpp:240] Iteration 1108, loss = 14.5148
I0408 21:17:54.713721  9048 solver.cpp:256]     Train net output #0: loss = 14.5148 (* 1 = 14.5148 loss)
I0408 21:17:54.713729  9048 sgd_solver.cpp:106] Iteration 1108, lr = 0.01
I0408 21:17:54.989553  9048 solver.cpp:240] Iteration 1109, loss = 7.99031
I0408 21:17:54.989584  9048 solver.cpp:256]     Train net output #0: loss = 7.9903 (* 1 = 7.9903 loss)
I0408 21:17:54.989593  9048 sgd_solver.cpp:106] Iteration 1109, lr = 0.01
I0408 21:17:55.265465  9048 solver.cpp:240] Iteration 1110, loss = 14.7019
I0408 21:17:55.265498  9048 solver.cpp:256]     Train net output #0: loss = 14.7019 (* 1 = 14.7019 loss)
I0408 21:17:55.265506  9048 sgd_solver.cpp:106] Iteration 1110, lr = 0.01
I0408 21:17:55.541179  9048 solver.cpp:240] Iteration 1111, loss = 28.6601
I0408 21:17:55.541224  9048 solver.cpp:256]     Train net output #0: loss = 28.6601 (* 1 = 28.6601 loss)
I0408 21:17:55.541231  9048 sgd_solver.cpp:106] Iteration 1111, lr = 0.01
I0408 21:17:55.816915  9048 solver.cpp:240] Iteration 1112, loss = 10.3326
I0408 21:17:55.816949  9048 solver.cpp:256]     Train net output #0: loss = 10.3326 (* 1 = 10.3326 loss)
I0408 21:17:55.816957  9048 sgd_solver.cpp:106] Iteration 1112, lr = 0.01
I0408 21:17:56.092584  9048 solver.cpp:240] Iteration 1113, loss = 21.2497
I0408 21:17:56.092617  9048 solver.cpp:256]     Train net output #0: loss = 21.2497 (* 1 = 21.2497 loss)
I0408 21:17:56.092625  9048 sgd_solver.cpp:106] Iteration 1113, lr = 0.01
I0408 21:17:56.367655  9048 solver.cpp:240] Iteration 1114, loss = 29.3261
I0408 21:17:56.367687  9048 solver.cpp:256]     Train net output #0: loss = 29.3261 (* 1 = 29.3261 loss)
I0408 21:17:56.367696  9048 sgd_solver.cpp:106] Iteration 1114, lr = 0.01
I0408 21:17:56.643865  9048 solver.cpp:240] Iteration 1115, loss = 12.9359
I0408 21:17:56.643923  9048 solver.cpp:256]     Train net output #0: loss = 12.9359 (* 1 = 12.9359 loss)
I0408 21:17:56.643931  9048 sgd_solver.cpp:106] Iteration 1115, lr = 0.01
I0408 21:17:56.919138  9048 solver.cpp:240] Iteration 1116, loss = 22.4265
I0408 21:17:56.919173  9048 solver.cpp:256]     Train net output #0: loss = 22.4265 (* 1 = 22.4265 loss)
I0408 21:17:56.919181  9048 sgd_solver.cpp:106] Iteration 1116, lr = 0.01
I0408 21:17:57.194960  9048 solver.cpp:240] Iteration 1117, loss = 16.6213
I0408 21:17:57.194994  9048 solver.cpp:256]     Train net output #0: loss = 16.6212 (* 1 = 16.6212 loss)
I0408 21:17:57.195003  9048 sgd_solver.cpp:106] Iteration 1117, lr = 0.01
I0408 21:17:57.470924  9048 solver.cpp:240] Iteration 1118, loss = 27.6802
I0408 21:17:57.470963  9048 solver.cpp:256]     Train net output #0: loss = 27.6802 (* 1 = 27.6802 loss)
I0408 21:17:57.470973  9048 sgd_solver.cpp:106] Iteration 1118, lr = 0.01
I0408 21:17:57.746939  9048 solver.cpp:240] Iteration 1119, loss = 21.6042
I0408 21:17:57.746973  9048 solver.cpp:256]     Train net output #0: loss = 21.6042 (* 1 = 21.6042 loss)
I0408 21:17:57.746983  9048 sgd_solver.cpp:106] Iteration 1119, lr = 0.01
I0408 21:17:58.022320  9048 solver.cpp:240] Iteration 1120, loss = 6.79101
I0408 21:17:58.022353  9048 solver.cpp:256]     Train net output #0: loss = 6.79101 (* 1 = 6.79101 loss)
I0408 21:17:58.022361  9048 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0408 21:17:58.299499  9048 solver.cpp:240] Iteration 1121, loss = 1.60927
I0408 21:17:58.299532  9048 solver.cpp:256]     Train net output #0: loss = 1.60927 (* 1 = 1.60927 loss)
I0408 21:17:58.299561  9048 sgd_solver.cpp:106] Iteration 1121, lr = 0.01
I0408 21:17:58.574066  9048 solver.cpp:240] Iteration 1122, loss = 7.028
I0408 21:17:58.574100  9048 solver.cpp:256]     Train net output #0: loss = 7.028 (* 1 = 7.028 loss)
I0408 21:17:58.574107  9048 sgd_solver.cpp:106] Iteration 1122, lr = 0.01
I0408 21:17:58.850113  9048 solver.cpp:240] Iteration 1123, loss = 8.57572
I0408 21:17:58.850152  9048 solver.cpp:256]     Train net output #0: loss = 8.57571 (* 1 = 8.57571 loss)
I0408 21:17:58.850160  9048 sgd_solver.cpp:106] Iteration 1123, lr = 0.01
I0408 21:17:59.126449  9048 solver.cpp:240] Iteration 1124, loss = 10.4293
I0408 21:17:59.126480  9048 solver.cpp:256]     Train net output #0: loss = 10.4293 (* 1 = 10.4293 loss)
I0408 21:17:59.126489  9048 sgd_solver.cpp:106] Iteration 1124, lr = 0.01
I0408 21:17:59.401808  9048 solver.cpp:240] Iteration 1125, loss = 16.6016
I0408 21:17:59.401842  9048 solver.cpp:256]     Train net output #0: loss = 16.6016 (* 1 = 16.6016 loss)
I0408 21:17:59.401851  9048 sgd_solver.cpp:106] Iteration 1125, lr = 0.01
I0408 21:17:59.678158  9048 solver.cpp:240] Iteration 1126, loss = 15.3196
I0408 21:17:59.678194  9048 solver.cpp:256]     Train net output #0: loss = 15.3195 (* 1 = 15.3195 loss)
I0408 21:17:59.678202  9048 sgd_solver.cpp:106] Iteration 1126, lr = 0.01
I0408 21:17:59.953996  9048 solver.cpp:240] Iteration 1127, loss = 7.19402
I0408 21:17:59.954028  9048 solver.cpp:256]     Train net output #0: loss = 7.19402 (* 1 = 7.19402 loss)
I0408 21:17:59.954036  9048 sgd_solver.cpp:106] Iteration 1127, lr = 0.01
I0408 21:18:00.230078  9048 solver.cpp:240] Iteration 1128, loss = 6.08456
I0408 21:18:00.230123  9048 solver.cpp:256]     Train net output #0: loss = 6.08456 (* 1 = 6.08456 loss)
I0408 21:18:00.230130  9048 sgd_solver.cpp:106] Iteration 1128, lr = 0.01
I0408 21:18:00.506168  9048 solver.cpp:240] Iteration 1129, loss = 3.31653
I0408 21:18:00.506201  9048 solver.cpp:256]     Train net output #0: loss = 3.31653 (* 1 = 3.31653 loss)
I0408 21:18:00.506208  9048 sgd_solver.cpp:106] Iteration 1129, lr = 0.01
I0408 21:18:00.782721  9048 solver.cpp:240] Iteration 1130, loss = 28.0274
I0408 21:18:00.782769  9048 solver.cpp:256]     Train net output #0: loss = 28.0274 (* 1 = 28.0274 loss)
I0408 21:18:00.782778  9048 sgd_solver.cpp:106] Iteration 1130, lr = 0.01
I0408 21:18:01.058825  9048 solver.cpp:240] Iteration 1131, loss = 5.16569
I0408 21:18:01.058868  9048 solver.cpp:256]     Train net output #0: loss = 5.16568 (* 1 = 5.16568 loss)
I0408 21:18:01.058876  9048 sgd_solver.cpp:106] Iteration 1131, lr = 0.01
I0408 21:18:01.334332  9048 solver.cpp:240] Iteration 1132, loss = 16.0175
I0408 21:18:01.334364  9048 solver.cpp:256]     Train net output #0: loss = 16.0175 (* 1 = 16.0175 loss)
I0408 21:18:01.334372  9048 sgd_solver.cpp:106] Iteration 1132, lr = 0.01
I0408 21:18:01.610417  9048 solver.cpp:240] Iteration 1133, loss = 6.40677
I0408 21:18:01.610461  9048 solver.cpp:256]     Train net output #0: loss = 6.40677 (* 1 = 6.40677 loss)
I0408 21:18:01.610469  9048 sgd_solver.cpp:106] Iteration 1133, lr = 0.01
I0408 21:18:01.885572  9048 solver.cpp:240] Iteration 1134, loss = 3.64731
I0408 21:18:01.885604  9048 solver.cpp:256]     Train net output #0: loss = 3.6473 (* 1 = 3.6473 loss)
I0408 21:18:01.885612  9048 sgd_solver.cpp:106] Iteration 1134, lr = 0.01
I0408 21:18:02.161496  9048 solver.cpp:240] Iteration 1135, loss = 6.25432
I0408 21:18:02.161543  9048 solver.cpp:256]     Train net output #0: loss = 6.25431 (* 1 = 6.25431 loss)
I0408 21:18:02.161552  9048 sgd_solver.cpp:106] Iteration 1135, lr = 0.01
I0408 21:18:02.437194  9048 solver.cpp:240] Iteration 1136, loss = 19.5814
I0408 21:18:02.437238  9048 solver.cpp:256]     Train net output #0: loss = 19.5814 (* 1 = 19.5814 loss)
I0408 21:18:02.437247  9048 sgd_solver.cpp:106] Iteration 1136, lr = 0.01
I0408 21:18:02.713482  9048 solver.cpp:240] Iteration 1137, loss = 1.57743
I0408 21:18:02.713517  9048 solver.cpp:256]     Train net output #0: loss = 1.57743 (* 1 = 1.57743 loss)
I0408 21:18:02.713524  9048 sgd_solver.cpp:106] Iteration 1137, lr = 0.01
I0408 21:18:02.988049  9048 solver.cpp:240] Iteration 1138, loss = 17.5931
I0408 21:18:02.988083  9048 solver.cpp:256]     Train net output #0: loss = 17.5931 (* 1 = 17.5931 loss)
I0408 21:18:02.988091  9048 sgd_solver.cpp:106] Iteration 1138, lr = 0.01
I0408 21:18:03.264600  9048 solver.cpp:240] Iteration 1139, loss = 12.9288
I0408 21:18:03.264634  9048 solver.cpp:256]     Train net output #0: loss = 12.9288 (* 1 = 12.9288 loss)
I0408 21:18:03.264642  9048 sgd_solver.cpp:106] Iteration 1139, lr = 0.01
I0408 21:18:03.539875  9048 solver.cpp:240] Iteration 1140, loss = 2.6989
I0408 21:18:03.539916  9048 solver.cpp:256]     Train net output #0: loss = 2.69889 (* 1 = 2.69889 loss)
I0408 21:18:03.539923  9048 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0408 21:18:03.816701  9048 solver.cpp:240] Iteration 1141, loss = 1.67412
I0408 21:18:03.816731  9048 solver.cpp:256]     Train net output #0: loss = 1.67411 (* 1 = 1.67411 loss)
I0408 21:18:03.816740  9048 sgd_solver.cpp:106] Iteration 1141, lr = 0.01
I0408 21:18:04.091940  9048 solver.cpp:240] Iteration 1142, loss = 7.18086
I0408 21:18:04.091972  9048 solver.cpp:256]     Train net output #0: loss = 7.18085 (* 1 = 7.18085 loss)
I0408 21:18:04.091980  9048 sgd_solver.cpp:106] Iteration 1142, lr = 0.01
I0408 21:18:04.369647  9048 solver.cpp:240] Iteration 1143, loss = 25.5193
I0408 21:18:04.369680  9048 solver.cpp:256]     Train net output #0: loss = 25.5193 (* 1 = 25.5193 loss)
I0408 21:18:04.369688  9048 sgd_solver.cpp:106] Iteration 1143, lr = 0.01
I0408 21:18:04.644834  9048 solver.cpp:240] Iteration 1144, loss = 7.81304
I0408 21:18:04.644866  9048 solver.cpp:256]     Train net output #0: loss = 7.81303 (* 1 = 7.81303 loss)
I0408 21:18:04.644875  9048 sgd_solver.cpp:106] Iteration 1144, lr = 0.01
I0408 21:18:04.920806  9048 solver.cpp:240] Iteration 1145, loss = 6.39855
I0408 21:18:04.920850  9048 solver.cpp:256]     Train net output #0: loss = 6.39854 (* 1 = 6.39854 loss)
I0408 21:18:04.920857  9048 sgd_solver.cpp:106] Iteration 1145, lr = 0.01
I0408 21:18:05.197636  9048 solver.cpp:240] Iteration 1146, loss = 21.8678
I0408 21:18:05.197672  9048 solver.cpp:256]     Train net output #0: loss = 21.8678 (* 1 = 21.8678 loss)
I0408 21:18:05.197680  9048 sgd_solver.cpp:106] Iteration 1146, lr = 0.01
I0408 21:18:05.473716  9048 solver.cpp:240] Iteration 1147, loss = 8.80646
I0408 21:18:05.473765  9048 solver.cpp:256]     Train net output #0: loss = 8.80645 (* 1 = 8.80645 loss)
I0408 21:18:05.473774  9048 sgd_solver.cpp:106] Iteration 1147, lr = 0.01
I0408 21:18:05.749508  9048 solver.cpp:240] Iteration 1148, loss = 7.69969
I0408 21:18:05.749542  9048 solver.cpp:256]     Train net output #0: loss = 7.69968 (* 1 = 7.69968 loss)
I0408 21:18:05.749550  9048 sgd_solver.cpp:106] Iteration 1148, lr = 0.01
I0408 21:18:06.024775  9048 solver.cpp:240] Iteration 1149, loss = 1.60475
I0408 21:18:06.024806  9048 solver.cpp:256]     Train net output #0: loss = 1.60475 (* 1 = 1.60475 loss)
I0408 21:18:06.024814  9048 sgd_solver.cpp:106] Iteration 1149, lr = 0.01
I0408 21:18:06.300024  9048 solver.cpp:240] Iteration 1150, loss = 36.6142
I0408 21:18:06.300058  9048 solver.cpp:256]     Train net output #0: loss = 36.6142 (* 1 = 36.6142 loss)
I0408 21:18:06.300066  9048 sgd_solver.cpp:106] Iteration 1150, lr = 0.01
I0408 21:18:06.575512  9048 solver.cpp:240] Iteration 1151, loss = 20.9903
I0408 21:18:06.575546  9048 solver.cpp:256]     Train net output #0: loss = 20.9902 (* 1 = 20.9902 loss)
I0408 21:18:06.575554  9048 sgd_solver.cpp:106] Iteration 1151, lr = 0.01
I0408 21:18:06.851125  9048 solver.cpp:240] Iteration 1152, loss = 14.5919
I0408 21:18:06.851161  9048 solver.cpp:256]     Train net output #0: loss = 14.5919 (* 1 = 14.5919 loss)
I0408 21:18:06.851171  9048 sgd_solver.cpp:106] Iteration 1152, lr = 0.01
I0408 21:18:07.127084  9048 solver.cpp:240] Iteration 1153, loss = 24.1878
I0408 21:18:07.127120  9048 solver.cpp:256]     Train net output #0: loss = 24.1878 (* 1 = 24.1878 loss)
I0408 21:18:07.127128  9048 sgd_solver.cpp:106] Iteration 1153, lr = 0.01
I0408 21:18:07.403301  9048 solver.cpp:240] Iteration 1154, loss = 19.6532
I0408 21:18:07.403333  9048 solver.cpp:256]     Train net output #0: loss = 19.6531 (* 1 = 19.6531 loss)
I0408 21:18:07.403342  9048 sgd_solver.cpp:106] Iteration 1154, lr = 0.01
I0408 21:18:07.678915  9048 solver.cpp:240] Iteration 1155, loss = 10.0374
I0408 21:18:07.678948  9048 solver.cpp:256]     Train net output #0: loss = 10.0374 (* 1 = 10.0374 loss)
I0408 21:18:07.678957  9048 sgd_solver.cpp:106] Iteration 1155, lr = 0.01
I0408 21:18:07.954993  9048 solver.cpp:240] Iteration 1156, loss = 10.7945
I0408 21:18:07.955039  9048 solver.cpp:256]     Train net output #0: loss = 10.7945 (* 1 = 10.7945 loss)
I0408 21:18:07.955045  9048 sgd_solver.cpp:106] Iteration 1156, lr = 0.01
I0408 21:18:08.230978  9048 solver.cpp:240] Iteration 1157, loss = 29.8019
I0408 21:18:08.231012  9048 solver.cpp:256]     Train net output #0: loss = 29.8019 (* 1 = 29.8019 loss)
I0408 21:18:08.231021  9048 sgd_solver.cpp:106] Iteration 1157, lr = 0.01
I0408 21:18:08.506763  9048 solver.cpp:240] Iteration 1158, loss = 29.7733
I0408 21:18:08.506798  9048 solver.cpp:256]     Train net output #0: loss = 29.7733 (* 1 = 29.7733 loss)
I0408 21:18:08.506806  9048 sgd_solver.cpp:106] Iteration 1158, lr = 0.01
I0408 21:18:08.782445  9048 solver.cpp:240] Iteration 1159, loss = 26.743
I0408 21:18:08.782481  9048 solver.cpp:256]     Train net output #0: loss = 26.743 (* 1 = 26.743 loss)
I0408 21:18:08.782490  9048 sgd_solver.cpp:106] Iteration 1159, lr = 0.01
I0408 21:18:09.058624  9048 solver.cpp:240] Iteration 1160, loss = 34.1713
I0408 21:18:09.058656  9048 solver.cpp:256]     Train net output #0: loss = 34.1713 (* 1 = 34.1713 loss)
I0408 21:18:09.058665  9048 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0408 21:18:09.335394  9048 solver.cpp:240] Iteration 1161, loss = 29.0135
I0408 21:18:09.335428  9048 solver.cpp:256]     Train net output #0: loss = 29.0135 (* 1 = 29.0135 loss)
I0408 21:18:09.335436  9048 sgd_solver.cpp:106] Iteration 1161, lr = 0.01
I0408 21:18:09.611043  9048 solver.cpp:240] Iteration 1162, loss = 23.8262
I0408 21:18:09.611079  9048 solver.cpp:256]     Train net output #0: loss = 23.8262 (* 1 = 23.8262 loss)
I0408 21:18:09.611089  9048 sgd_solver.cpp:106] Iteration 1162, lr = 0.01
I0408 21:18:09.886962  9048 solver.cpp:240] Iteration 1163, loss = 23.9149
I0408 21:18:09.886996  9048 solver.cpp:256]     Train net output #0: loss = 23.9149 (* 1 = 23.9149 loss)
I0408 21:18:09.887003  9048 sgd_solver.cpp:106] Iteration 1163, lr = 0.01
I0408 21:18:10.163847  9048 solver.cpp:240] Iteration 1164, loss = 27.2438
I0408 21:18:10.163892  9048 solver.cpp:256]     Train net output #0: loss = 27.2438 (* 1 = 27.2438 loss)
I0408 21:18:10.163903  9048 sgd_solver.cpp:106] Iteration 1164, lr = 0.01
I0408 21:18:10.438550  9048 solver.cpp:240] Iteration 1165, loss = 25.3121
I0408 21:18:10.438582  9048 solver.cpp:256]     Train net output #0: loss = 25.3121 (* 1 = 25.3121 loss)
I0408 21:18:10.438591  9048 sgd_solver.cpp:106] Iteration 1165, lr = 0.01
I0408 21:18:10.713773  9048 solver.cpp:240] Iteration 1166, loss = 9.79488
I0408 21:18:10.713804  9048 solver.cpp:256]     Train net output #0: loss = 9.79488 (* 1 = 9.79488 loss)
I0408 21:18:10.713812  9048 sgd_solver.cpp:106] Iteration 1166, lr = 0.01
I0408 21:18:10.988359  9048 solver.cpp:240] Iteration 1167, loss = 15.0738
I0408 21:18:10.988391  9048 solver.cpp:256]     Train net output #0: loss = 15.0738 (* 1 = 15.0738 loss)
I0408 21:18:10.988399  9048 sgd_solver.cpp:106] Iteration 1167, lr = 0.01
I0408 21:18:11.263794  9048 solver.cpp:240] Iteration 1168, loss = 11.7126
I0408 21:18:11.263828  9048 solver.cpp:256]     Train net output #0: loss = 11.7126 (* 1 = 11.7126 loss)
I0408 21:18:11.263835  9048 sgd_solver.cpp:106] Iteration 1168, lr = 0.01
I0408 21:18:11.539597  9048 solver.cpp:240] Iteration 1169, loss = 10.9744
I0408 21:18:11.539630  9048 solver.cpp:256]     Train net output #0: loss = 10.9744 (* 1 = 10.9744 loss)
I0408 21:18:11.539639  9048 sgd_solver.cpp:106] Iteration 1169, lr = 0.01
I0408 21:18:11.815747  9048 solver.cpp:240] Iteration 1170, loss = 9.02229
I0408 21:18:11.815799  9048 solver.cpp:256]     Train net output #0: loss = 9.02229 (* 1 = 9.02229 loss)
I0408 21:18:11.815809  9048 sgd_solver.cpp:106] Iteration 1170, lr = 0.01
I0408 21:18:12.092252  9048 solver.cpp:240] Iteration 1171, loss = 8.79513
I0408 21:18:12.092281  9048 solver.cpp:256]     Train net output #0: loss = 8.79513 (* 1 = 8.79513 loss)
I0408 21:18:12.092289  9048 sgd_solver.cpp:106] Iteration 1171, lr = 0.01
I0408 21:18:12.369138  9048 solver.cpp:240] Iteration 1172, loss = 5.7766
I0408 21:18:12.369170  9048 solver.cpp:256]     Train net output #0: loss = 5.7766 (* 1 = 5.7766 loss)
I0408 21:18:12.369179  9048 sgd_solver.cpp:106] Iteration 1172, lr = 0.01
I0408 21:18:12.645398  9048 solver.cpp:240] Iteration 1173, loss = 7.72434
I0408 21:18:12.645429  9048 solver.cpp:256]     Train net output #0: loss = 7.72433 (* 1 = 7.72433 loss)
I0408 21:18:12.645438  9048 sgd_solver.cpp:106] Iteration 1173, lr = 0.01
I0408 21:18:12.921383  9048 solver.cpp:240] Iteration 1174, loss = 13.8204
I0408 21:18:12.921417  9048 solver.cpp:256]     Train net output #0: loss = 13.8204 (* 1 = 13.8204 loss)
I0408 21:18:12.921425  9048 sgd_solver.cpp:106] Iteration 1174, lr = 0.01
I0408 21:18:13.198078  9048 solver.cpp:240] Iteration 1175, loss = 22.8301
I0408 21:18:13.198110  9048 solver.cpp:256]     Train net output #0: loss = 22.8301 (* 1 = 22.8301 loss)
I0408 21:18:13.198117  9048 sgd_solver.cpp:106] Iteration 1175, lr = 0.01
I0408 21:18:13.474298  9048 solver.cpp:240] Iteration 1176, loss = 14.5612
I0408 21:18:13.474333  9048 solver.cpp:256]     Train net output #0: loss = 14.5612 (* 1 = 14.5612 loss)
I0408 21:18:13.474340  9048 sgd_solver.cpp:106] Iteration 1176, lr = 0.01
I0408 21:18:13.750445  9048 solver.cpp:240] Iteration 1177, loss = 12.0778
I0408 21:18:13.750478  9048 solver.cpp:256]     Train net output #0: loss = 12.0778 (* 1 = 12.0778 loss)
I0408 21:18:13.750488  9048 sgd_solver.cpp:106] Iteration 1177, lr = 0.01
I0408 21:18:14.026391  9048 solver.cpp:240] Iteration 1178, loss = 24.9181
I0408 21:18:14.026425  9048 solver.cpp:256]     Train net output #0: loss = 24.9181 (* 1 = 24.9181 loss)
I0408 21:18:14.026434  9048 sgd_solver.cpp:106] Iteration 1178, lr = 0.01
I0408 21:18:14.302705  9048 solver.cpp:240] Iteration 1179, loss = 20.6928
I0408 21:18:14.302742  9048 solver.cpp:256]     Train net output #0: loss = 20.6928 (* 1 = 20.6928 loss)
I0408 21:18:14.302752  9048 sgd_solver.cpp:106] Iteration 1179, lr = 0.01
I0408 21:18:14.578691  9048 solver.cpp:240] Iteration 1180, loss = 22.9046
I0408 21:18:14.578724  9048 solver.cpp:256]     Train net output #0: loss = 22.9046 (* 1 = 22.9046 loss)
I0408 21:18:14.578732  9048 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0408 21:18:14.855303  9048 solver.cpp:240] Iteration 1181, loss = 5.60266
I0408 21:18:14.855332  9048 solver.cpp:256]     Train net output #0: loss = 5.60265 (* 1 = 5.60265 loss)
I0408 21:18:14.855340  9048 sgd_solver.cpp:106] Iteration 1181, lr = 0.01
I0408 21:18:15.130725  9048 solver.cpp:240] Iteration 1182, loss = 9.6563
I0408 21:18:15.130759  9048 solver.cpp:256]     Train net output #0: loss = 9.65629 (* 1 = 9.65629 loss)
I0408 21:18:15.130765  9048 sgd_solver.cpp:106] Iteration 1182, lr = 0.01
I0408 21:18:15.406779  9048 solver.cpp:240] Iteration 1183, loss = 5.27375
I0408 21:18:15.406810  9048 solver.cpp:256]     Train net output #0: loss = 5.27375 (* 1 = 5.27375 loss)
I0408 21:18:15.406818  9048 sgd_solver.cpp:106] Iteration 1183, lr = 0.01
I0408 21:18:15.681926  9048 solver.cpp:240] Iteration 1184, loss = 3.71486
I0408 21:18:15.681957  9048 solver.cpp:256]     Train net output #0: loss = 3.71486 (* 1 = 3.71486 loss)
I0408 21:18:15.681964  9048 sgd_solver.cpp:106] Iteration 1184, lr = 0.01
I0408 21:18:15.957583  9048 solver.cpp:240] Iteration 1185, loss = 20.5255
I0408 21:18:15.957617  9048 solver.cpp:256]     Train net output #0: loss = 20.5255 (* 1 = 20.5255 loss)
I0408 21:18:15.957624  9048 sgd_solver.cpp:106] Iteration 1185, lr = 0.01
I0408 21:18:16.232841  9048 solver.cpp:240] Iteration 1186, loss = 6.52428
I0408 21:18:16.232894  9048 solver.cpp:256]     Train net output #0: loss = 6.52427 (* 1 = 6.52427 loss)
I0408 21:18:16.232903  9048 sgd_solver.cpp:106] Iteration 1186, lr = 0.01
I0408 21:18:16.508358  9048 solver.cpp:240] Iteration 1187, loss = 1.82057
I0408 21:18:16.508389  9048 solver.cpp:256]     Train net output #0: loss = 1.82056 (* 1 = 1.82056 loss)
I0408 21:18:16.508396  9048 sgd_solver.cpp:106] Iteration 1187, lr = 0.01
I0408 21:18:16.783548  9048 solver.cpp:240] Iteration 1188, loss = 1.97437
I0408 21:18:16.783581  9048 solver.cpp:256]     Train net output #0: loss = 1.97436 (* 1 = 1.97436 loss)
I0408 21:18:16.783588  9048 sgd_solver.cpp:106] Iteration 1188, lr = 0.01
I0408 21:18:17.059723  9048 solver.cpp:240] Iteration 1189, loss = 1.94754
I0408 21:18:17.059754  9048 solver.cpp:256]     Train net output #0: loss = 1.94753 (* 1 = 1.94753 loss)
I0408 21:18:17.059762  9048 sgd_solver.cpp:106] Iteration 1189, lr = 0.01
I0408 21:18:17.335366  9048 solver.cpp:240] Iteration 1190, loss = 1.63974
I0408 21:18:17.335409  9048 solver.cpp:256]     Train net output #0: loss = 1.63973 (* 1 = 1.63973 loss)
I0408 21:18:17.335417  9048 sgd_solver.cpp:106] Iteration 1190, lr = 0.01
I0408 21:18:17.610754  9048 solver.cpp:240] Iteration 1191, loss = 14.9906
I0408 21:18:17.610788  9048 solver.cpp:256]     Train net output #0: loss = 14.9906 (* 1 = 14.9906 loss)
I0408 21:18:17.610797  9048 sgd_solver.cpp:106] Iteration 1191, lr = 0.01
I0408 21:18:17.887122  9048 solver.cpp:240] Iteration 1192, loss = 28.4113
I0408 21:18:17.887156  9048 solver.cpp:256]     Train net output #0: loss = 28.4113 (* 1 = 28.4113 loss)
I0408 21:18:17.887163  9048 sgd_solver.cpp:106] Iteration 1192, lr = 0.01
I0408 21:18:18.163355  9048 solver.cpp:240] Iteration 1193, loss = 18.9504
I0408 21:18:18.163389  9048 solver.cpp:256]     Train net output #0: loss = 18.9503 (* 1 = 18.9503 loss)
I0408 21:18:18.163398  9048 sgd_solver.cpp:106] Iteration 1193, lr = 0.01
I0408 21:18:18.438905  9048 solver.cpp:240] Iteration 1194, loss = 6.18787
I0408 21:18:18.438938  9048 solver.cpp:256]     Train net output #0: loss = 6.18786 (* 1 = 6.18786 loss)
I0408 21:18:18.438946  9048 sgd_solver.cpp:106] Iteration 1194, lr = 0.01
I0408 21:18:18.714298  9048 solver.cpp:240] Iteration 1195, loss = 15.0245
I0408 21:18:18.714344  9048 solver.cpp:256]     Train net output #0: loss = 15.0245 (* 1 = 15.0245 loss)
I0408 21:18:18.714354  9048 sgd_solver.cpp:106] Iteration 1195, lr = 0.01
I0408 21:18:18.990469  9048 solver.cpp:240] Iteration 1196, loss = 9.76967
I0408 21:18:18.990506  9048 solver.cpp:256]     Train net output #0: loss = 9.76966 (* 1 = 9.76966 loss)
I0408 21:18:18.990515  9048 sgd_solver.cpp:106] Iteration 1196, lr = 0.01
I0408 21:18:19.266345  9048 solver.cpp:240] Iteration 1197, loss = 12.2395
I0408 21:18:19.266381  9048 solver.cpp:256]     Train net output #0: loss = 12.2395 (* 1 = 12.2395 loss)
I0408 21:18:19.266388  9048 sgd_solver.cpp:106] Iteration 1197, lr = 0.01
I0408 21:18:19.543097  9048 solver.cpp:240] Iteration 1198, loss = 18.323
I0408 21:18:19.543318  9048 solver.cpp:256]     Train net output #0: loss = 18.323 (* 1 = 18.323 loss)
I0408 21:18:19.543329  9048 sgd_solver.cpp:106] Iteration 1198, lr = 0.01
I0408 21:18:19.818507  9048 solver.cpp:240] Iteration 1199, loss = 19.2786
I0408 21:18:19.818542  9048 solver.cpp:256]     Train net output #0: loss = 19.2786 (* 1 = 19.2786 loss)
I0408 21:18:19.818549  9048 sgd_solver.cpp:106] Iteration 1199, lr = 0.01
I0408 21:18:20.094408  9048 solver.cpp:240] Iteration 1200, loss = 14.6015
I0408 21:18:20.094441  9048 solver.cpp:256]     Train net output #0: loss = 14.6015 (* 1 = 14.6015 loss)
I0408 21:18:20.094450  9048 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0408 21:18:20.370272  9048 solver.cpp:240] Iteration 1201, loss = 4.05521
I0408 21:18:20.370321  9048 solver.cpp:256]     Train net output #0: loss = 4.05521 (* 1 = 4.05521 loss)
I0408 21:18:20.370331  9048 sgd_solver.cpp:106] Iteration 1201, lr = 0.01
I0408 21:18:20.645902  9048 solver.cpp:240] Iteration 1202, loss = 9.44285
I0408 21:18:20.645936  9048 solver.cpp:256]     Train net output #0: loss = 9.44284 (* 1 = 9.44284 loss)
I0408 21:18:20.645944  9048 sgd_solver.cpp:106] Iteration 1202, lr = 0.01
I0408 21:18:20.921557  9048 solver.cpp:240] Iteration 1203, loss = 15.2399
I0408 21:18:20.921591  9048 solver.cpp:256]     Train net output #0: loss = 15.2399 (* 1 = 15.2399 loss)
I0408 21:18:20.921600  9048 sgd_solver.cpp:106] Iteration 1203, lr = 0.01
I0408 21:18:21.196697  9048 solver.cpp:240] Iteration 1204, loss = 16.7183
I0408 21:18:21.196732  9048 solver.cpp:256]     Train net output #0: loss = 16.7183 (* 1 = 16.7183 loss)
I0408 21:18:21.196739  9048 sgd_solver.cpp:106] Iteration 1204, lr = 0.01
I0408 21:18:21.472621  9048 solver.cpp:240] Iteration 1205, loss = 12.8858
I0408 21:18:21.472663  9048 solver.cpp:256]     Train net output #0: loss = 12.8858 (* 1 = 12.8858 loss)
I0408 21:18:21.472671  9048 sgd_solver.cpp:106] Iteration 1205, lr = 0.01
I0408 21:18:21.748757  9048 solver.cpp:240] Iteration 1206, loss = 11.3152
I0408 21:18:21.748798  9048 solver.cpp:256]     Train net output #0: loss = 11.3152 (* 1 = 11.3152 loss)
I0408 21:18:21.748807  9048 sgd_solver.cpp:106] Iteration 1206, lr = 0.01
I0408 21:18:22.024358  9048 solver.cpp:240] Iteration 1207, loss = 9.80376
I0408 21:18:22.024390  9048 solver.cpp:256]     Train net output #0: loss = 9.80375 (* 1 = 9.80375 loss)
I0408 21:18:22.024399  9048 sgd_solver.cpp:106] Iteration 1207, lr = 0.01
I0408 21:18:22.299379  9048 solver.cpp:240] Iteration 1208, loss = 6.84855
I0408 21:18:22.299412  9048 solver.cpp:256]     Train net output #0: loss = 6.84854 (* 1 = 6.84854 loss)
I0408 21:18:22.299420  9048 sgd_solver.cpp:106] Iteration 1208, lr = 0.01
I0408 21:18:22.574883  9048 solver.cpp:240] Iteration 1209, loss = 7.61536
I0408 21:18:22.574915  9048 solver.cpp:256]     Train net output #0: loss = 7.61536 (* 1 = 7.61536 loss)
I0408 21:18:22.574923  9048 sgd_solver.cpp:106] Iteration 1209, lr = 0.01
I0408 21:18:22.850870  9048 solver.cpp:240] Iteration 1210, loss = 24.203
I0408 21:18:22.850917  9048 solver.cpp:256]     Train net output #0: loss = 24.203 (* 1 = 24.203 loss)
I0408 21:18:22.850925  9048 sgd_solver.cpp:106] Iteration 1210, lr = 0.01
I0408 21:18:23.126760  9048 solver.cpp:240] Iteration 1211, loss = 27.7374
I0408 21:18:23.126801  9048 solver.cpp:256]     Train net output #0: loss = 27.7374 (* 1 = 27.7374 loss)
I0408 21:18:23.126809  9048 sgd_solver.cpp:106] Iteration 1211, lr = 0.01
I0408 21:18:23.402763  9048 solver.cpp:240] Iteration 1212, loss = 11.2147
I0408 21:18:23.402798  9048 solver.cpp:256]     Train net output #0: loss = 11.2147 (* 1 = 11.2147 loss)
I0408 21:18:23.402807  9048 sgd_solver.cpp:106] Iteration 1212, lr = 0.01
I0408 21:18:23.679116  9048 solver.cpp:240] Iteration 1213, loss = 8.09601
I0408 21:18:23.679163  9048 solver.cpp:256]     Train net output #0: loss = 8.096 (* 1 = 8.096 loss)
I0408 21:18:23.679172  9048 sgd_solver.cpp:106] Iteration 1213, lr = 0.01
I0408 21:18:23.954370  9048 solver.cpp:240] Iteration 1214, loss = 2.92476
I0408 21:18:23.954412  9048 solver.cpp:256]     Train net output #0: loss = 2.92476 (* 1 = 2.92476 loss)
I0408 21:18:23.954442  9048 sgd_solver.cpp:106] Iteration 1214, lr = 0.01
I0408 21:18:24.230150  9048 solver.cpp:240] Iteration 1215, loss = 2.74791
I0408 21:18:24.230182  9048 solver.cpp:256]     Train net output #0: loss = 2.7479 (* 1 = 2.7479 loss)
I0408 21:18:24.230190  9048 sgd_solver.cpp:106] Iteration 1215, lr = 0.01
I0408 21:18:24.505699  9048 solver.cpp:240] Iteration 1216, loss = 2.64671
I0408 21:18:24.505735  9048 solver.cpp:256]     Train net output #0: loss = 2.6467 (* 1 = 2.6467 loss)
I0408 21:18:24.505744  9048 sgd_solver.cpp:106] Iteration 1216, lr = 0.01
I0408 21:18:24.782667  9048 solver.cpp:240] Iteration 1217, loss = 7.97451
I0408 21:18:24.782712  9048 solver.cpp:256]     Train net output #0: loss = 7.97451 (* 1 = 7.97451 loss)
I0408 21:18:24.782721  9048 sgd_solver.cpp:106] Iteration 1217, lr = 0.01
I0408 21:18:25.058907  9048 solver.cpp:240] Iteration 1218, loss = 17.7933
I0408 21:18:25.058945  9048 solver.cpp:256]     Train net output #0: loss = 17.7933 (* 1 = 17.7933 loss)
I0408 21:18:25.058954  9048 sgd_solver.cpp:106] Iteration 1218, lr = 0.01
I0408 21:18:25.334604  9048 solver.cpp:240] Iteration 1219, loss = 21.0626
I0408 21:18:25.334636  9048 solver.cpp:256]     Train net output #0: loss = 21.0626 (* 1 = 21.0626 loss)
I0408 21:18:25.334645  9048 sgd_solver.cpp:106] Iteration 1219, lr = 0.01
I0408 21:18:25.610373  9048 solver.cpp:240] Iteration 1220, loss = 9.9963
I0408 21:18:25.610405  9048 solver.cpp:256]     Train net output #0: loss = 9.9963 (* 1 = 9.9963 loss)
I0408 21:18:25.610414  9048 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0408 21:18:25.887270  9048 solver.cpp:240] Iteration 1221, loss = 14.635
I0408 21:18:25.887310  9048 solver.cpp:256]     Train net output #0: loss = 14.635 (* 1 = 14.635 loss)
I0408 21:18:25.887318  9048 sgd_solver.cpp:106] Iteration 1221, lr = 0.01
I0408 21:18:26.163169  9048 solver.cpp:240] Iteration 1222, loss = 9.89731
I0408 21:18:26.163202  9048 solver.cpp:256]     Train net output #0: loss = 9.89731 (* 1 = 9.89731 loss)
I0408 21:18:26.163209  9048 sgd_solver.cpp:106] Iteration 1222, lr = 0.01
I0408 21:18:26.438899  9048 solver.cpp:240] Iteration 1223, loss = 1.58156
I0408 21:18:26.438935  9048 solver.cpp:256]     Train net output #0: loss = 1.58155 (* 1 = 1.58155 loss)
I0408 21:18:26.438956  9048 sgd_solver.cpp:106] Iteration 1223, lr = 0.01
I0408 21:18:26.713009  9048 solver.cpp:240] Iteration 1224, loss = 3.04359
I0408 21:18:26.713042  9048 solver.cpp:256]     Train net output #0: loss = 3.04359 (* 1 = 3.04359 loss)
I0408 21:18:26.713049  9048 sgd_solver.cpp:106] Iteration 1224, lr = 0.01
I0408 21:18:26.987746  9048 solver.cpp:240] Iteration 1225, loss = 22.6931
I0408 21:18:26.987776  9048 solver.cpp:256]     Train net output #0: loss = 22.6931 (* 1 = 22.6931 loss)
I0408 21:18:26.987784  9048 sgd_solver.cpp:106] Iteration 1225, lr = 0.01
I0408 21:18:27.265198  9048 solver.cpp:240] Iteration 1226, loss = 7.91169
I0408 21:18:27.265230  9048 solver.cpp:256]     Train net output #0: loss = 7.91169 (* 1 = 7.91169 loss)
I0408 21:18:27.265239  9048 sgd_solver.cpp:106] Iteration 1226, lr = 0.01
I0408 21:18:27.541508  9048 solver.cpp:240] Iteration 1227, loss = 17.6156
I0408 21:18:27.541541  9048 solver.cpp:256]     Train net output #0: loss = 17.6156 (* 1 = 17.6156 loss)
I0408 21:18:27.541549  9048 sgd_solver.cpp:106] Iteration 1227, lr = 0.01
I0408 21:18:27.817842  9048 solver.cpp:240] Iteration 1228, loss = 29.8036
I0408 21:18:27.817873  9048 solver.cpp:256]     Train net output #0: loss = 29.8036 (* 1 = 29.8036 loss)
I0408 21:18:27.817880  9048 sgd_solver.cpp:106] Iteration 1228, lr = 0.01
I0408 21:18:28.093457  9048 solver.cpp:240] Iteration 1229, loss = 17.9179
I0408 21:18:28.093492  9048 solver.cpp:256]     Train net output #0: loss = 17.9179 (* 1 = 17.9179 loss)
I0408 21:18:28.093500  9048 sgd_solver.cpp:106] Iteration 1229, lr = 0.01
I0408 21:18:28.369498  9048 solver.cpp:240] Iteration 1230, loss = 11.4468
I0408 21:18:28.369531  9048 solver.cpp:256]     Train net output #0: loss = 11.4467 (* 1 = 11.4467 loss)
I0408 21:18:28.369562  9048 sgd_solver.cpp:106] Iteration 1230, lr = 0.01
I0408 21:18:28.645449  9048 solver.cpp:240] Iteration 1231, loss = 11.2252
I0408 21:18:28.645493  9048 solver.cpp:256]     Train net output #0: loss = 11.2252 (* 1 = 11.2252 loss)
I0408 21:18:28.645500  9048 sgd_solver.cpp:106] Iteration 1231, lr = 0.01
I0408 21:18:28.920557  9048 solver.cpp:240] Iteration 1232, loss = 12.8862
I0408 21:18:28.920593  9048 solver.cpp:256]     Train net output #0: loss = 12.8862 (* 1 = 12.8862 loss)
I0408 21:18:28.920600  9048 sgd_solver.cpp:106] Iteration 1232, lr = 0.01
I0408 21:18:29.195794  9048 solver.cpp:240] Iteration 1233, loss = 27.6837
I0408 21:18:29.195832  9048 solver.cpp:256]     Train net output #0: loss = 27.6837 (* 1 = 27.6837 loss)
I0408 21:18:29.195840  9048 sgd_solver.cpp:106] Iteration 1233, lr = 0.01
I0408 21:18:29.469686  9048 solver.cpp:240] Iteration 1234, loss = 10.9843
I0408 21:18:29.469729  9048 solver.cpp:256]     Train net output #0: loss = 10.9843 (* 1 = 10.9843 loss)
I0408 21:18:29.469738  9048 sgd_solver.cpp:106] Iteration 1234, lr = 0.01
I0408 21:18:29.745491  9048 solver.cpp:240] Iteration 1235, loss = 20.1548
I0408 21:18:29.745524  9048 solver.cpp:256]     Train net output #0: loss = 20.1547 (* 1 = 20.1547 loss)
I0408 21:18:29.745532  9048 sgd_solver.cpp:106] Iteration 1235, lr = 0.01
I0408 21:18:30.020913  9048 solver.cpp:240] Iteration 1236, loss = 3.27802
I0408 21:18:30.020946  9048 solver.cpp:256]     Train net output #0: loss = 3.27801 (* 1 = 3.27801 loss)
I0408 21:18:30.020952  9048 sgd_solver.cpp:106] Iteration 1236, lr = 0.01
I0408 21:18:30.295631  9048 solver.cpp:240] Iteration 1237, loss = 5.80873
I0408 21:18:30.295663  9048 solver.cpp:256]     Train net output #0: loss = 5.80872 (* 1 = 5.80872 loss)
I0408 21:18:30.295671  9048 sgd_solver.cpp:106] Iteration 1237, lr = 0.01
I0408 21:18:30.571645  9048 solver.cpp:240] Iteration 1238, loss = 7.30668
I0408 21:18:30.571676  9048 solver.cpp:256]     Train net output #0: loss = 7.30668 (* 1 = 7.30668 loss)
I0408 21:18:30.571684  9048 sgd_solver.cpp:106] Iteration 1238, lr = 0.01
I0408 21:18:30.847256  9048 solver.cpp:240] Iteration 1239, loss = 2.85602
I0408 21:18:30.847302  9048 solver.cpp:256]     Train net output #0: loss = 2.85601 (* 1 = 2.85601 loss)
I0408 21:18:30.847311  9048 sgd_solver.cpp:106] Iteration 1239, lr = 0.01
I0408 21:18:31.122294  9048 solver.cpp:240] Iteration 1240, loss = 12.901
I0408 21:18:31.122339  9048 solver.cpp:256]     Train net output #0: loss = 12.901 (* 1 = 12.901 loss)
I0408 21:18:31.122347  9048 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0408 21:18:31.397784  9048 solver.cpp:240] Iteration 1241, loss = 5.60344
I0408 21:18:31.397816  9048 solver.cpp:256]     Train net output #0: loss = 5.60344 (* 1 = 5.60344 loss)
I0408 21:18:31.397825  9048 sgd_solver.cpp:106] Iteration 1241, lr = 0.01
I0408 21:18:31.672772  9048 solver.cpp:240] Iteration 1242, loss = 24.3436
I0408 21:18:31.672806  9048 solver.cpp:256]     Train net output #0: loss = 24.3436 (* 1 = 24.3436 loss)
I0408 21:18:31.672814  9048 sgd_solver.cpp:106] Iteration 1242, lr = 0.01
I0408 21:18:31.947468  9048 solver.cpp:240] Iteration 1243, loss = 13.9395
I0408 21:18:31.947504  9048 solver.cpp:256]     Train net output #0: loss = 13.9395 (* 1 = 13.9395 loss)
I0408 21:18:31.947512  9048 sgd_solver.cpp:106] Iteration 1243, lr = 0.01
I0408 21:18:32.221876  9048 solver.cpp:240] Iteration 1244, loss = 24.9768
I0408 21:18:32.221922  9048 solver.cpp:256]     Train net output #0: loss = 24.9768 (* 1 = 24.9768 loss)
I0408 21:18:32.221931  9048 sgd_solver.cpp:106] Iteration 1244, lr = 0.01
I0408 21:18:32.498416  9048 solver.cpp:240] Iteration 1245, loss = 3.9948
I0408 21:18:32.498450  9048 solver.cpp:256]     Train net output #0: loss = 3.99479 (* 1 = 3.99479 loss)
I0408 21:18:32.498457  9048 sgd_solver.cpp:106] Iteration 1245, lr = 0.01
I0408 21:18:32.773777  9048 solver.cpp:240] Iteration 1246, loss = 7.88917
I0408 21:18:32.773809  9048 solver.cpp:256]     Train net output #0: loss = 7.88916 (* 1 = 7.88916 loss)
I0408 21:18:32.773818  9048 sgd_solver.cpp:106] Iteration 1246, lr = 0.01
I0408 21:18:33.047096  9048 solver.cpp:240] Iteration 1247, loss = 3.08187
I0408 21:18:33.047138  9048 solver.cpp:256]     Train net output #0: loss = 3.08187 (* 1 = 3.08187 loss)
I0408 21:18:33.047147  9048 sgd_solver.cpp:106] Iteration 1247, lr = 0.01
I0408 21:18:33.321854  9048 solver.cpp:240] Iteration 1248, loss = 19.7281
I0408 21:18:33.321889  9048 solver.cpp:256]     Train net output #0: loss = 19.7281 (* 1 = 19.7281 loss)
I0408 21:18:33.321897  9048 sgd_solver.cpp:106] Iteration 1248, lr = 0.01
I0408 21:18:33.597393  9048 solver.cpp:240] Iteration 1249, loss = 25.723
I0408 21:18:33.597437  9048 solver.cpp:256]     Train net output #0: loss = 25.723 (* 1 = 25.723 loss)
I0408 21:18:33.597446  9048 sgd_solver.cpp:106] Iteration 1249, lr = 0.01
I0408 21:18:33.871731  9048 solver.cpp:240] Iteration 1250, loss = 21.7028
I0408 21:18:33.871763  9048 solver.cpp:256]     Train net output #0: loss = 21.7028 (* 1 = 21.7028 loss)
I0408 21:18:33.871773  9048 sgd_solver.cpp:106] Iteration 1250, lr = 0.01
I0408 21:18:34.146375  9048 solver.cpp:240] Iteration 1251, loss = 12.9916
I0408 21:18:34.146420  9048 solver.cpp:256]     Train net output #0: loss = 12.9916 (* 1 = 12.9916 loss)
I0408 21:18:34.146427  9048 sgd_solver.cpp:106] Iteration 1251, lr = 0.01
I0408 21:18:34.422426  9048 solver.cpp:240] Iteration 1252, loss = 6.05759
I0408 21:18:34.422459  9048 solver.cpp:256]     Train net output #0: loss = 6.05759 (* 1 = 6.05759 loss)
I0408 21:18:34.422466  9048 sgd_solver.cpp:106] Iteration 1252, lr = 0.01
I0408 21:18:34.698112  9048 solver.cpp:240] Iteration 1253, loss = 33.2286
I0408 21:18:34.698146  9048 solver.cpp:256]     Train net output #0: loss = 33.2286 (* 1 = 33.2286 loss)
I0408 21:18:34.698154  9048 sgd_solver.cpp:106] Iteration 1253, lr = 0.01
I0408 21:18:34.973058  9048 solver.cpp:240] Iteration 1254, loss = 35.006
I0408 21:18:34.973091  9048 solver.cpp:256]     Train net output #0: loss = 35.0059 (* 1 = 35.0059 loss)
I0408 21:18:34.973099  9048 sgd_solver.cpp:106] Iteration 1254, lr = 0.01
I0408 21:18:35.249752  9048 solver.cpp:240] Iteration 1255, loss = 26.5638
I0408 21:18:35.249785  9048 solver.cpp:256]     Train net output #0: loss = 26.5638 (* 1 = 26.5638 loss)
I0408 21:18:35.249794  9048 sgd_solver.cpp:106] Iteration 1255, lr = 0.01
I0408 21:18:35.524580  9048 solver.cpp:240] Iteration 1256, loss = 14.1635
I0408 21:18:35.524615  9048 solver.cpp:256]     Train net output #0: loss = 14.1635 (* 1 = 14.1635 loss)
I0408 21:18:35.524624  9048 sgd_solver.cpp:106] Iteration 1256, lr = 0.01
I0408 21:18:35.799377  9048 solver.cpp:240] Iteration 1257, loss = 9.32823
I0408 21:18:35.799414  9048 solver.cpp:256]     Train net output #0: loss = 9.32822 (* 1 = 9.32822 loss)
I0408 21:18:35.799423  9048 sgd_solver.cpp:106] Iteration 1257, lr = 0.01
I0408 21:18:36.074079  9048 solver.cpp:240] Iteration 1258, loss = 31.3915
I0408 21:18:36.074111  9048 solver.cpp:256]     Train net output #0: loss = 31.3914 (* 1 = 31.3914 loss)
I0408 21:18:36.074120  9048 sgd_solver.cpp:106] Iteration 1258, lr = 0.01
I0408 21:18:36.351337  9048 solver.cpp:240] Iteration 1259, loss = 5.83337
I0408 21:18:36.351380  9048 solver.cpp:256]     Train net output #0: loss = 5.83336 (* 1 = 5.83336 loss)
I0408 21:18:36.351388  9048 sgd_solver.cpp:106] Iteration 1259, lr = 0.01
I0408 21:18:36.626435  9048 solver.cpp:240] Iteration 1260, loss = 6.24937
I0408 21:18:36.626471  9048 solver.cpp:256]     Train net output #0: loss = 6.24936 (* 1 = 6.24936 loss)
I0408 21:18:36.626479  9048 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0408 21:18:36.901304  9048 solver.cpp:240] Iteration 1261, loss = 1.70925
I0408 21:18:36.901337  9048 solver.cpp:256]     Train net output #0: loss = 1.70924 (* 1 = 1.70924 loss)
I0408 21:18:36.901345  9048 sgd_solver.cpp:106] Iteration 1261, lr = 0.01
I0408 21:18:37.177374  9048 solver.cpp:240] Iteration 1262, loss = 18.0634
I0408 21:18:37.177407  9048 solver.cpp:256]     Train net output #0: loss = 18.0634 (* 1 = 18.0634 loss)
I0408 21:18:37.177417  9048 sgd_solver.cpp:106] Iteration 1262, lr = 0.01
I0408 21:18:37.453485  9048 solver.cpp:240] Iteration 1263, loss = 22.2452
I0408 21:18:37.453518  9048 solver.cpp:256]     Train net output #0: loss = 22.2452 (* 1 = 22.2452 loss)
I0408 21:18:37.453526  9048 sgd_solver.cpp:106] Iteration 1263, lr = 0.01
I0408 21:18:37.728006  9048 solver.cpp:240] Iteration 1264, loss = 15.916
I0408 21:18:37.728039  9048 solver.cpp:256]     Train net output #0: loss = 15.916 (* 1 = 15.916 loss)
I0408 21:18:37.728047  9048 sgd_solver.cpp:106] Iteration 1264, lr = 0.01
I0408 21:18:38.003932  9048 solver.cpp:240] Iteration 1265, loss = 9.00576
I0408 21:18:38.003968  9048 solver.cpp:256]     Train net output #0: loss = 9.00575 (* 1 = 9.00575 loss)
I0408 21:18:38.003976  9048 sgd_solver.cpp:106] Iteration 1265, lr = 0.01
I0408 21:18:38.278748  9048 solver.cpp:240] Iteration 1266, loss = 14.5994
I0408 21:18:38.278792  9048 solver.cpp:256]     Train net output #0: loss = 14.5994 (* 1 = 14.5994 loss)
I0408 21:18:38.278800  9048 sgd_solver.cpp:106] Iteration 1266, lr = 0.01
I0408 21:18:38.553547  9048 solver.cpp:240] Iteration 1267, loss = 15.0679
I0408 21:18:38.553592  9048 solver.cpp:256]     Train net output #0: loss = 15.0679 (* 1 = 15.0679 loss)
I0408 21:18:38.553601  9048 sgd_solver.cpp:106] Iteration 1267, lr = 0.01
I0408 21:18:38.828414  9048 solver.cpp:240] Iteration 1268, loss = 27.6205
I0408 21:18:38.828450  9048 solver.cpp:256]     Train net output #0: loss = 27.6205 (* 1 = 27.6205 loss)
I0408 21:18:38.828459  9048 sgd_solver.cpp:106] Iteration 1268, lr = 0.01
I0408 21:18:39.104256  9048 solver.cpp:240] Iteration 1269, loss = 18.4262
I0408 21:18:39.104301  9048 solver.cpp:256]     Train net output #0: loss = 18.4262 (* 1 = 18.4262 loss)
I0408 21:18:39.104310  9048 sgd_solver.cpp:106] Iteration 1269, lr = 0.01
I0408 21:18:39.379408  9048 solver.cpp:240] Iteration 1270, loss = 33.1261
I0408 21:18:39.379448  9048 solver.cpp:256]     Train net output #0: loss = 33.1261 (* 1 = 33.1261 loss)
I0408 21:18:39.379457  9048 sgd_solver.cpp:106] Iteration 1270, lr = 0.01
I0408 21:18:39.654981  9048 solver.cpp:240] Iteration 1271, loss = 34.6136
I0408 21:18:39.655015  9048 solver.cpp:256]     Train net output #0: loss = 34.6136 (* 1 = 34.6136 loss)
I0408 21:18:39.655024  9048 sgd_solver.cpp:106] Iteration 1271, lr = 0.01
I0408 21:18:39.930692  9048 solver.cpp:240] Iteration 1272, loss = 16.7889
I0408 21:18:39.930740  9048 solver.cpp:256]     Train net output #0: loss = 16.7889 (* 1 = 16.7889 loss)
I0408 21:18:39.930748  9048 sgd_solver.cpp:106] Iteration 1272, lr = 0.01
I0408 21:18:40.206287  9048 solver.cpp:240] Iteration 1273, loss = 2.49287
I0408 21:18:40.206318  9048 solver.cpp:256]     Train net output #0: loss = 2.49286 (* 1 = 2.49286 loss)
I0408 21:18:40.206326  9048 sgd_solver.cpp:106] Iteration 1273, lr = 0.01
I0408 21:18:40.481557  9048 solver.cpp:240] Iteration 1274, loss = 1.6002
I0408 21:18:40.481588  9048 solver.cpp:256]     Train net output #0: loss = 1.60019 (* 1 = 1.60019 loss)
I0408 21:18:40.481596  9048 sgd_solver.cpp:106] Iteration 1274, lr = 0.01
I0408 21:18:40.757205  9048 solver.cpp:240] Iteration 1275, loss = 23.267
I0408 21:18:40.757239  9048 solver.cpp:256]     Train net output #0: loss = 23.267 (* 1 = 23.267 loss)
I0408 21:18:40.757247  9048 sgd_solver.cpp:106] Iteration 1275, lr = 0.01
I0408 21:18:41.032045  9048 solver.cpp:240] Iteration 1276, loss = 21.4074
I0408 21:18:41.032078  9048 solver.cpp:256]     Train net output #0: loss = 21.4074 (* 1 = 21.4074 loss)
I0408 21:18:41.032086  9048 sgd_solver.cpp:106] Iteration 1276, lr = 0.01
I0408 21:18:41.307170  9048 solver.cpp:240] Iteration 1277, loss = 17.763
I0408 21:18:41.307219  9048 solver.cpp:256]     Train net output #0: loss = 17.763 (* 1 = 17.763 loss)
I0408 21:18:41.307227  9048 sgd_solver.cpp:106] Iteration 1277, lr = 0.01
I0408 21:18:41.582814  9048 solver.cpp:240] Iteration 1278, loss = 20.629
I0408 21:18:41.582849  9048 solver.cpp:256]     Train net output #0: loss = 20.629 (* 1 = 20.629 loss)
I0408 21:18:41.582857  9048 sgd_solver.cpp:106] Iteration 1278, lr = 0.01
I0408 21:18:41.857945  9048 solver.cpp:240] Iteration 1279, loss = 18.1109
I0408 21:18:41.858005  9048 solver.cpp:256]     Train net output #0: loss = 18.1109 (* 1 = 18.1109 loss)
I0408 21:18:41.858013  9048 sgd_solver.cpp:106] Iteration 1279, lr = 0.01
I0408 21:18:42.133667  9048 solver.cpp:240] Iteration 1280, loss = 14.8868
I0408 21:18:42.133704  9048 solver.cpp:256]     Train net output #0: loss = 14.8868 (* 1 = 14.8868 loss)
I0408 21:18:42.133713  9048 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0408 21:18:42.408998  9048 solver.cpp:240] Iteration 1281, loss = 14.1136
I0408 21:18:42.409031  9048 solver.cpp:256]     Train net output #0: loss = 14.1136 (* 1 = 14.1136 loss)
I0408 21:18:42.409039  9048 sgd_solver.cpp:106] Iteration 1281, lr = 0.01
I0408 21:18:42.684310  9048 solver.cpp:240] Iteration 1282, loss = 19.9978
I0408 21:18:42.684348  9048 solver.cpp:256]     Train net output #0: loss = 19.9978 (* 1 = 19.9978 loss)
I0408 21:18:42.684357  9048 sgd_solver.cpp:106] Iteration 1282, lr = 0.01
I0408 21:18:42.960557  9048 solver.cpp:240] Iteration 1283, loss = 24.4136
I0408 21:18:42.960592  9048 solver.cpp:256]     Train net output #0: loss = 24.4136 (* 1 = 24.4136 loss)
I0408 21:18:42.960599  9048 sgd_solver.cpp:106] Iteration 1283, lr = 0.01
I0408 21:18:43.235102  9048 solver.cpp:240] Iteration 1284, loss = 13.405
I0408 21:18:43.235134  9048 solver.cpp:256]     Train net output #0: loss = 13.405 (* 1 = 13.405 loss)
I0408 21:18:43.235142  9048 sgd_solver.cpp:106] Iteration 1284, lr = 0.01
I0408 21:18:43.510087  9048 solver.cpp:240] Iteration 1285, loss = 9.99906
I0408 21:18:43.510125  9048 solver.cpp:256]     Train net output #0: loss = 9.99905 (* 1 = 9.99905 loss)
I0408 21:18:43.510134  9048 sgd_solver.cpp:106] Iteration 1285, lr = 0.01
I0408 21:18:43.785486  9048 solver.cpp:240] Iteration 1286, loss = 6.50904
I0408 21:18:43.785518  9048 solver.cpp:256]     Train net output #0: loss = 6.50904 (* 1 = 6.50904 loss)
I0408 21:18:43.785527  9048 sgd_solver.cpp:106] Iteration 1286, lr = 0.01
I0408 21:18:44.059792  9048 solver.cpp:240] Iteration 1287, loss = 11.3916
I0408 21:18:44.059829  9048 solver.cpp:256]     Train net output #0: loss = 11.3916 (* 1 = 11.3916 loss)
I0408 21:18:44.059839  9048 sgd_solver.cpp:106] Iteration 1287, lr = 0.01
I0408 21:18:44.333869  9048 solver.cpp:240] Iteration 1288, loss = 19.386
I0408 21:18:44.333914  9048 solver.cpp:256]     Train net output #0: loss = 19.386 (* 1 = 19.386 loss)
I0408 21:18:44.333922  9048 sgd_solver.cpp:106] Iteration 1288, lr = 0.01
I0408 21:18:44.609560  9048 solver.cpp:240] Iteration 1289, loss = 17.8814
I0408 21:18:44.609592  9048 solver.cpp:256]     Train net output #0: loss = 17.8813 (* 1 = 17.8813 loss)
I0408 21:18:44.609601  9048 sgd_solver.cpp:106] Iteration 1289, lr = 0.01
I0408 21:18:44.884827  9048 solver.cpp:240] Iteration 1290, loss = 11.5779
I0408 21:18:44.884862  9048 solver.cpp:256]     Train net output #0: loss = 11.5779 (* 1 = 11.5779 loss)
I0408 21:18:44.884871  9048 sgd_solver.cpp:106] Iteration 1290, lr = 0.01
I0408 21:18:45.160078  9048 solver.cpp:240] Iteration 1291, loss = 13.0557
I0408 21:18:45.160110  9048 solver.cpp:256]     Train net output #0: loss = 13.0557 (* 1 = 13.0557 loss)
I0408 21:18:45.160118  9048 sgd_solver.cpp:106] Iteration 1291, lr = 0.01
I0408 21:18:45.434315  9048 solver.cpp:240] Iteration 1292, loss = 25.8036
I0408 21:18:45.434353  9048 solver.cpp:256]     Train net output #0: loss = 25.8036 (* 1 = 25.8036 loss)
I0408 21:18:45.434362  9048 sgd_solver.cpp:106] Iteration 1292, lr = 0.01
I0408 21:18:45.710741  9048 solver.cpp:240] Iteration 1293, loss = 13.2959
I0408 21:18:45.710775  9048 solver.cpp:256]     Train net output #0: loss = 13.2959 (* 1 = 13.2959 loss)
I0408 21:18:45.710783  9048 sgd_solver.cpp:106] Iteration 1293, lr = 0.01
I0408 21:18:45.986651  9048 solver.cpp:240] Iteration 1294, loss = 26.0527
I0408 21:18:45.986685  9048 solver.cpp:256]     Train net output #0: loss = 26.0527 (* 1 = 26.0527 loss)
I0408 21:18:45.986695  9048 sgd_solver.cpp:106] Iteration 1294, lr = 0.01
I0408 21:18:46.261783  9048 solver.cpp:240] Iteration 1295, loss = 10.6876
I0408 21:18:46.261837  9048 solver.cpp:256]     Train net output #0: loss = 10.6876 (* 1 = 10.6876 loss)
I0408 21:18:46.261847  9048 sgd_solver.cpp:106] Iteration 1295, lr = 0.01
I0408 21:18:46.538139  9048 solver.cpp:240] Iteration 1296, loss = 6.51315
I0408 21:18:46.538170  9048 solver.cpp:256]     Train net output #0: loss = 6.51314 (* 1 = 6.51314 loss)
I0408 21:18:46.538178  9048 sgd_solver.cpp:106] Iteration 1296, lr = 0.01
I0408 21:18:46.815069  9048 solver.cpp:240] Iteration 1297, loss = 7.43671
I0408 21:18:46.815101  9048 solver.cpp:256]     Train net output #0: loss = 7.4367 (* 1 = 7.4367 loss)
I0408 21:18:46.815109  9048 sgd_solver.cpp:106] Iteration 1297, lr = 0.01
I0408 21:18:47.091116  9048 solver.cpp:240] Iteration 1298, loss = 12.9106
I0408 21:18:47.091152  9048 solver.cpp:256]     Train net output #0: loss = 12.9105 (* 1 = 12.9105 loss)
I0408 21:18:47.091161  9048 sgd_solver.cpp:106] Iteration 1298, lr = 0.01
I0408 21:18:47.365629  9048 solver.cpp:240] Iteration 1299, loss = 13.3657
I0408 21:18:47.365664  9048 solver.cpp:256]     Train net output #0: loss = 13.3657 (* 1 = 13.3657 loss)
I0408 21:18:47.365671  9048 sgd_solver.cpp:106] Iteration 1299, lr = 0.01
I0408 21:18:47.640897  9048 solver.cpp:240] Iteration 1300, loss = 20.9829
I0408 21:18:47.640931  9048 solver.cpp:256]     Train net output #0: loss = 20.9829 (* 1 = 20.9829 loss)
I0408 21:18:47.640939  9048 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0408 21:18:47.916563  9048 solver.cpp:240] Iteration 1301, loss = 24.786
I0408 21:18:47.916596  9048 solver.cpp:256]     Train net output #0: loss = 24.786 (* 1 = 24.786 loss)
I0408 21:18:47.916604  9048 sgd_solver.cpp:106] Iteration 1301, lr = 0.01
I0408 21:18:48.192412  9048 solver.cpp:240] Iteration 1302, loss = 23.7679
I0408 21:18:48.192445  9048 solver.cpp:256]     Train net output #0: loss = 23.7679 (* 1 = 23.7679 loss)
I0408 21:18:48.192453  9048 sgd_solver.cpp:106] Iteration 1302, lr = 0.01
I0408 21:18:48.467720  9048 solver.cpp:240] Iteration 1303, loss = 11.5107
I0408 21:18:48.467752  9048 solver.cpp:256]     Train net output #0: loss = 11.5107 (* 1 = 11.5107 loss)
I0408 21:18:48.467761  9048 sgd_solver.cpp:106] Iteration 1303, lr = 0.01
I0408 21:18:48.743724  9048 solver.cpp:240] Iteration 1304, loss = 10.42
I0408 21:18:48.743757  9048 solver.cpp:256]     Train net output #0: loss = 10.42 (* 1 = 10.42 loss)
I0408 21:18:48.743763  9048 sgd_solver.cpp:106] Iteration 1304, lr = 0.01
I0408 21:18:49.019284  9048 solver.cpp:240] Iteration 1305, loss = 22.7064
I0408 21:18:49.019320  9048 solver.cpp:256]     Train net output #0: loss = 22.7064 (* 1 = 22.7064 loss)
I0408 21:18:49.019330  9048 sgd_solver.cpp:106] Iteration 1305, lr = 0.01
I0408 21:18:49.294463  9048 solver.cpp:240] Iteration 1306, loss = 19.3441
I0408 21:18:49.294495  9048 solver.cpp:256]     Train net output #0: loss = 19.3441 (* 1 = 19.3441 loss)
I0408 21:18:49.294503  9048 sgd_solver.cpp:106] Iteration 1306, lr = 0.01
I0408 21:18:49.568771  9048 solver.cpp:240] Iteration 1307, loss = 13.6501
I0408 21:18:49.569166  9048 solver.cpp:256]     Train net output #0: loss = 13.6501 (* 1 = 13.6501 loss)
I0408 21:18:49.569177  9048 sgd_solver.cpp:106] Iteration 1307, lr = 0.01
I0408 21:18:49.844764  9048 solver.cpp:240] Iteration 1308, loss = 6.90004
I0408 21:18:49.844807  9048 solver.cpp:256]     Train net output #0: loss = 6.90004 (* 1 = 6.90004 loss)
I0408 21:18:49.844815  9048 sgd_solver.cpp:106] Iteration 1308, lr = 0.01
I0408 21:18:50.120908  9048 solver.cpp:240] Iteration 1309, loss = 22.3531
I0408 21:18:50.120940  9048 solver.cpp:256]     Train net output #0: loss = 22.3531 (* 1 = 22.3531 loss)
I0408 21:18:50.120949  9048 sgd_solver.cpp:106] Iteration 1309, lr = 0.01
I0408 21:18:50.395651  9048 solver.cpp:240] Iteration 1310, loss = 9.41548
I0408 21:18:50.395704  9048 solver.cpp:256]     Train net output #0: loss = 9.41547 (* 1 = 9.41547 loss)
I0408 21:18:50.395714  9048 sgd_solver.cpp:106] Iteration 1310, lr = 0.01
I0408 21:18:50.671480  9048 solver.cpp:240] Iteration 1311, loss = 10.5409
I0408 21:18:50.671516  9048 solver.cpp:256]     Train net output #0: loss = 10.5409 (* 1 = 10.5409 loss)
I0408 21:18:50.671525  9048 sgd_solver.cpp:106] Iteration 1311, lr = 0.01
I0408 21:18:50.946089  9048 solver.cpp:240] Iteration 1312, loss = 6.77751
I0408 21:18:50.946130  9048 solver.cpp:256]     Train net output #0: loss = 6.7775 (* 1 = 6.7775 loss)
I0408 21:18:50.946138  9048 sgd_solver.cpp:106] Iteration 1312, lr = 0.01
I0408 21:18:51.222187  9048 solver.cpp:240] Iteration 1313, loss = 19.0166
I0408 21:18:51.222220  9048 solver.cpp:256]     Train net output #0: loss = 19.0166 (* 1 = 19.0166 loss)
I0408 21:18:51.222229  9048 sgd_solver.cpp:106] Iteration 1313, lr = 0.01
I0408 21:18:51.497844  9048 solver.cpp:240] Iteration 1314, loss = 9.41738
I0408 21:18:51.497879  9048 solver.cpp:256]     Train net output #0: loss = 9.41737 (* 1 = 9.41737 loss)
I0408 21:18:51.497885  9048 sgd_solver.cpp:106] Iteration 1314, lr = 0.01
I0408 21:18:51.773422  9048 solver.cpp:240] Iteration 1315, loss = 2.15631
I0408 21:18:51.773452  9048 solver.cpp:256]     Train net output #0: loss = 2.1563 (* 1 = 2.1563 loss)
I0408 21:18:51.773459  9048 sgd_solver.cpp:106] Iteration 1315, lr = 0.01
I0408 21:18:52.049181  9048 solver.cpp:240] Iteration 1316, loss = 17.224
I0408 21:18:52.049213  9048 solver.cpp:256]     Train net output #0: loss = 17.224 (* 1 = 17.224 loss)
I0408 21:18:52.049221  9048 sgd_solver.cpp:106] Iteration 1316, lr = 0.01
I0408 21:18:52.325767  9048 solver.cpp:240] Iteration 1317, loss = 10.3149
I0408 21:18:52.325799  9048 solver.cpp:256]     Train net output #0: loss = 10.3149 (* 1 = 10.3149 loss)
I0408 21:18:52.325808  9048 sgd_solver.cpp:106] Iteration 1317, lr = 0.01
I0408 21:18:52.601399  9048 solver.cpp:240] Iteration 1318, loss = 20.3868
I0408 21:18:52.601433  9048 solver.cpp:256]     Train net output #0: loss = 20.3868 (* 1 = 20.3868 loss)
I0408 21:18:52.601440  9048 sgd_solver.cpp:106] Iteration 1318, lr = 0.01
I0408 21:18:52.877596  9048 solver.cpp:240] Iteration 1319, loss = 7.4265
I0408 21:18:52.877629  9048 solver.cpp:256]     Train net output #0: loss = 7.42649 (* 1 = 7.42649 loss)
I0408 21:18:52.877636  9048 sgd_solver.cpp:106] Iteration 1319, lr = 0.01
I0408 21:18:53.154780  9048 solver.cpp:240] Iteration 1320, loss = 19.8625
I0408 21:18:53.154814  9048 solver.cpp:256]     Train net output #0: loss = 19.8625 (* 1 = 19.8625 loss)
I0408 21:18:53.154821  9048 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0408 21:18:53.430799  9048 solver.cpp:240] Iteration 1321, loss = 11.0759
I0408 21:18:53.430833  9048 solver.cpp:256]     Train net output #0: loss = 11.0759 (* 1 = 11.0759 loss)
I0408 21:18:53.430842  9048 sgd_solver.cpp:106] Iteration 1321, lr = 0.01
I0408 21:18:53.706310  9048 solver.cpp:240] Iteration 1322, loss = 14.3802
I0408 21:18:53.706346  9048 solver.cpp:256]     Train net output #0: loss = 14.3802 (* 1 = 14.3802 loss)
I0408 21:18:53.706353  9048 sgd_solver.cpp:106] Iteration 1322, lr = 0.01
I0408 21:18:53.981940  9048 solver.cpp:240] Iteration 1323, loss = 13.5018
I0408 21:18:53.981976  9048 solver.cpp:256]     Train net output #0: loss = 13.5018 (* 1 = 13.5018 loss)
I0408 21:18:53.982005  9048 sgd_solver.cpp:106] Iteration 1323, lr = 0.01
I0408 21:18:54.257848  9048 solver.cpp:240] Iteration 1324, loss = 13.3121
I0408 21:18:54.257882  9048 solver.cpp:256]     Train net output #0: loss = 13.312 (* 1 = 13.312 loss)
I0408 21:18:54.257890  9048 sgd_solver.cpp:106] Iteration 1324, lr = 0.01
I0408 21:18:54.535467  9048 solver.cpp:240] Iteration 1325, loss = 6.23186
I0408 21:18:54.535498  9048 solver.cpp:256]     Train net output #0: loss = 6.23185 (* 1 = 6.23185 loss)
I0408 21:18:54.535506  9048 sgd_solver.cpp:106] Iteration 1325, lr = 0.01
I0408 21:18:54.811270  9048 solver.cpp:240] Iteration 1326, loss = 30.6601
I0408 21:18:54.811301  9048 solver.cpp:256]     Train net output #0: loss = 30.6601 (* 1 = 30.6601 loss)
I0408 21:18:54.811309  9048 sgd_solver.cpp:106] Iteration 1326, lr = 0.01
I0408 21:18:55.087029  9048 solver.cpp:240] Iteration 1327, loss = 12.7934
I0408 21:18:55.087064  9048 solver.cpp:256]     Train net output #0: loss = 12.7934 (* 1 = 12.7934 loss)
I0408 21:18:55.087072  9048 sgd_solver.cpp:106] Iteration 1327, lr = 0.01
I0408 21:18:55.362701  9048 solver.cpp:240] Iteration 1328, loss = 19.1781
I0408 21:18:55.362738  9048 solver.cpp:256]     Train net output #0: loss = 19.1781 (* 1 = 19.1781 loss)
I0408 21:18:55.362747  9048 sgd_solver.cpp:106] Iteration 1328, lr = 0.01
I0408 21:18:55.638345  9048 solver.cpp:240] Iteration 1329, loss = 19.4958
I0408 21:18:55.638380  9048 solver.cpp:256]     Train net output #0: loss = 19.4958 (* 1 = 19.4958 loss)
I0408 21:18:55.638388  9048 sgd_solver.cpp:106] Iteration 1329, lr = 0.01
I0408 21:18:55.913167  9048 solver.cpp:240] Iteration 1330, loss = 15.262
I0408 21:18:55.913200  9048 solver.cpp:256]     Train net output #0: loss = 15.262 (* 1 = 15.262 loss)
I0408 21:18:55.913209  9048 sgd_solver.cpp:106] Iteration 1330, lr = 0.01
I0408 21:18:56.188292  9048 solver.cpp:240] Iteration 1331, loss = 9.8528
I0408 21:18:56.188325  9048 solver.cpp:256]     Train net output #0: loss = 9.8528 (* 1 = 9.8528 loss)
I0408 21:18:56.188333  9048 sgd_solver.cpp:106] Iteration 1331, lr = 0.01
I0408 21:18:56.464426  9048 solver.cpp:240] Iteration 1332, loss = 9.62823
I0408 21:18:56.464460  9048 solver.cpp:256]     Train net output #0: loss = 9.62823 (* 1 = 9.62823 loss)
I0408 21:18:56.464468  9048 sgd_solver.cpp:106] Iteration 1332, lr = 0.01
I0408 21:18:56.739816  9048 solver.cpp:240] Iteration 1333, loss = 10.5626
I0408 21:18:56.739855  9048 solver.cpp:256]     Train net output #0: loss = 10.5626 (* 1 = 10.5626 loss)
I0408 21:18:56.739863  9048 sgd_solver.cpp:106] Iteration 1333, lr = 0.01
I0408 21:18:57.015363  9048 solver.cpp:240] Iteration 1334, loss = 23.5586
I0408 21:18:57.015396  9048 solver.cpp:256]     Train net output #0: loss = 23.5586 (* 1 = 23.5586 loss)
I0408 21:18:57.015404  9048 sgd_solver.cpp:106] Iteration 1334, lr = 0.01
I0408 21:18:57.291008  9048 solver.cpp:240] Iteration 1335, loss = 17.5061
I0408 21:18:57.291043  9048 solver.cpp:256]     Train net output #0: loss = 17.5061 (* 1 = 17.5061 loss)
I0408 21:18:57.291050  9048 sgd_solver.cpp:106] Iteration 1335, lr = 0.01
I0408 21:18:57.566644  9048 solver.cpp:240] Iteration 1336, loss = 3.66017
I0408 21:18:57.566674  9048 solver.cpp:256]     Train net output #0: loss = 3.66017 (* 1 = 3.66017 loss)
I0408 21:18:57.566682  9048 sgd_solver.cpp:106] Iteration 1336, lr = 0.01
I0408 21:18:57.842376  9048 solver.cpp:240] Iteration 1337, loss = 11.1395
I0408 21:18:57.842409  9048 solver.cpp:256]     Train net output #0: loss = 11.1395 (* 1 = 11.1395 loss)
I0408 21:18:57.842417  9048 sgd_solver.cpp:106] Iteration 1337, lr = 0.01
I0408 21:18:58.117534  9048 solver.cpp:240] Iteration 1338, loss = 25.4177
I0408 21:18:58.117568  9048 solver.cpp:256]     Train net output #0: loss = 25.4177 (* 1 = 25.4177 loss)
I0408 21:18:58.117578  9048 sgd_solver.cpp:106] Iteration 1338, lr = 0.01
I0408 21:18:58.393218  9048 solver.cpp:240] Iteration 1339, loss = 12.6868
I0408 21:18:58.393250  9048 solver.cpp:256]     Train net output #0: loss = 12.6868 (* 1 = 12.6868 loss)
I0408 21:18:58.393280  9048 sgd_solver.cpp:106] Iteration 1339, lr = 0.01
I0408 21:18:58.668246  9048 solver.cpp:240] Iteration 1340, loss = 15.3105
I0408 21:18:58.668277  9048 solver.cpp:256]     Train net output #0: loss = 15.3105 (* 1 = 15.3105 loss)
I0408 21:18:58.668285  9048 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0408 21:18:58.945160  9048 solver.cpp:240] Iteration 1341, loss = 5.446
I0408 21:18:58.945202  9048 solver.cpp:256]     Train net output #0: loss = 5.44599 (* 1 = 5.44599 loss)
I0408 21:18:58.945210  9048 sgd_solver.cpp:106] Iteration 1341, lr = 0.01
I0408 21:18:59.219261  9048 solver.cpp:240] Iteration 1342, loss = 22.8799
I0408 21:18:59.219295  9048 solver.cpp:256]     Train net output #0: loss = 22.8799 (* 1 = 22.8799 loss)
I0408 21:18:59.219302  9048 sgd_solver.cpp:106] Iteration 1342, lr = 0.01
I0408 21:18:59.495149  9048 solver.cpp:240] Iteration 1343, loss = 23.9619
I0408 21:18:59.495184  9048 solver.cpp:256]     Train net output #0: loss = 23.9619 (* 1 = 23.9619 loss)
I0408 21:18:59.495193  9048 sgd_solver.cpp:106] Iteration 1343, lr = 0.01
I0408 21:18:59.770663  9048 solver.cpp:240] Iteration 1344, loss = 28.3848
I0408 21:18:59.770694  9048 solver.cpp:256]     Train net output #0: loss = 28.3848 (* 1 = 28.3848 loss)
I0408 21:18:59.770704  9048 sgd_solver.cpp:106] Iteration 1344, lr = 0.01
I0408 21:19:00.047375  9048 solver.cpp:240] Iteration 1345, loss = 40.2904
I0408 21:19:00.047406  9048 solver.cpp:256]     Train net output #0: loss = 40.2904 (* 1 = 40.2904 loss)
I0408 21:19:00.047415  9048 sgd_solver.cpp:106] Iteration 1345, lr = 0.01
I0408 21:19:00.322984  9048 solver.cpp:240] Iteration 1346, loss = 19.7897
I0408 21:19:00.323022  9048 solver.cpp:256]     Train net output #0: loss = 19.7897 (* 1 = 19.7897 loss)
I0408 21:19:00.323043  9048 sgd_solver.cpp:106] Iteration 1346, lr = 0.01
I0408 21:19:00.598712  9048 solver.cpp:240] Iteration 1347, loss = 12.7868
I0408 21:19:00.598744  9048 solver.cpp:256]     Train net output #0: loss = 12.7868 (* 1 = 12.7868 loss)
I0408 21:19:00.598752  9048 sgd_solver.cpp:106] Iteration 1347, lr = 0.01
I0408 21:19:00.874421  9048 solver.cpp:240] Iteration 1348, loss = 27.1534
I0408 21:19:00.874454  9048 solver.cpp:256]     Train net output #0: loss = 27.1534 (* 1 = 27.1534 loss)
I0408 21:19:00.874464  9048 sgd_solver.cpp:106] Iteration 1348, lr = 0.01
I0408 21:19:01.150684  9048 solver.cpp:240] Iteration 1349, loss = 12.7644
I0408 21:19:01.150727  9048 solver.cpp:256]     Train net output #0: loss = 12.7644 (* 1 = 12.7644 loss)
I0408 21:19:01.150735  9048 sgd_solver.cpp:106] Iteration 1349, lr = 0.01
I0408 21:19:01.426381  9048 solver.cpp:240] Iteration 1350, loss = 15.1544
I0408 21:19:01.426415  9048 solver.cpp:256]     Train net output #0: loss = 15.1544 (* 1 = 15.1544 loss)
I0408 21:19:01.426424  9048 sgd_solver.cpp:106] Iteration 1350, lr = 0.01
I0408 21:19:01.702019  9048 solver.cpp:240] Iteration 1351, loss = 19.5313
I0408 21:19:01.702052  9048 solver.cpp:256]     Train net output #0: loss = 19.5313 (* 1 = 19.5313 loss)
I0408 21:19:01.702061  9048 sgd_solver.cpp:106] Iteration 1351, lr = 0.01
I0408 21:19:01.977715  9048 solver.cpp:240] Iteration 1352, loss = 18.6779
I0408 21:19:01.977749  9048 solver.cpp:256]     Train net output #0: loss = 18.6779 (* 1 = 18.6779 loss)
I0408 21:19:01.977757  9048 sgd_solver.cpp:106] Iteration 1352, lr = 0.01
I0408 21:19:02.254423  9048 solver.cpp:240] Iteration 1353, loss = 10.8872
I0408 21:19:02.254458  9048 solver.cpp:256]     Train net output #0: loss = 10.8872 (* 1 = 10.8872 loss)
I0408 21:19:02.254467  9048 sgd_solver.cpp:106] Iteration 1353, lr = 0.01
I0408 21:19:02.530182  9048 solver.cpp:240] Iteration 1354, loss = 1.57612
I0408 21:19:02.530215  9048 solver.cpp:256]     Train net output #0: loss = 1.57611 (* 1 = 1.57611 loss)
I0408 21:19:02.530222  9048 sgd_solver.cpp:106] Iteration 1354, lr = 0.01
I0408 21:19:02.806180  9048 solver.cpp:240] Iteration 1355, loss = 1.61498
I0408 21:19:02.806212  9048 solver.cpp:256]     Train net output #0: loss = 1.61498 (* 1 = 1.61498 loss)
I0408 21:19:02.806221  9048 sgd_solver.cpp:106] Iteration 1355, lr = 0.01
I0408 21:19:03.081986  9048 solver.cpp:240] Iteration 1356, loss = 1.34621
I0408 21:19:03.082029  9048 solver.cpp:256]     Train net output #0: loss = 1.34621 (* 1 = 1.34621 loss)
I0408 21:19:03.082037  9048 sgd_solver.cpp:106] Iteration 1356, lr = 0.01
I0408 21:19:03.358027  9048 solver.cpp:240] Iteration 1357, loss = 14.2141
I0408 21:19:03.358060  9048 solver.cpp:256]     Train net output #0: loss = 14.2141 (* 1 = 14.2141 loss)
I0408 21:19:03.358069  9048 sgd_solver.cpp:106] Iteration 1357, lr = 0.01
I0408 21:19:03.633616  9048 solver.cpp:240] Iteration 1358, loss = 18.6254
I0408 21:19:03.633647  9048 solver.cpp:256]     Train net output #0: loss = 18.6254 (* 1 = 18.6254 loss)
I0408 21:19:03.633656  9048 sgd_solver.cpp:106] Iteration 1358, lr = 0.01
I0408 21:19:03.909737  9048 solver.cpp:240] Iteration 1359, loss = 8.38506
I0408 21:19:03.909773  9048 solver.cpp:256]     Train net output #0: loss = 8.38506 (* 1 = 8.38506 loss)
I0408 21:19:03.909782  9048 sgd_solver.cpp:106] Iteration 1359, lr = 0.01
I0408 21:19:04.185320  9048 solver.cpp:240] Iteration 1360, loss = 7.51436
I0408 21:19:04.185350  9048 solver.cpp:256]     Train net output #0: loss = 7.51436 (* 1 = 7.51436 loss)
I0408 21:19:04.185359  9048 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0408 21:19:04.461509  9048 solver.cpp:240] Iteration 1361, loss = 9.65949
I0408 21:19:04.461544  9048 solver.cpp:256]     Train net output #0: loss = 9.65949 (* 1 = 9.65949 loss)
I0408 21:19:04.461551  9048 sgd_solver.cpp:106] Iteration 1361, lr = 0.01
I0408 21:19:04.737112  9048 solver.cpp:240] Iteration 1362, loss = 2.08065
I0408 21:19:04.737143  9048 solver.cpp:256]     Train net output #0: loss = 2.08064 (* 1 = 2.08064 loss)
I0408 21:19:04.737152  9048 sgd_solver.cpp:106] Iteration 1362, lr = 0.01
I0408 21:19:05.013234  9048 solver.cpp:240] Iteration 1363, loss = 3.93409
I0408 21:19:05.013267  9048 solver.cpp:256]     Train net output #0: loss = 3.93408 (* 1 = 3.93408 loss)
I0408 21:19:05.013275  9048 sgd_solver.cpp:106] Iteration 1363, lr = 0.01
I0408 21:19:05.287828  9048 solver.cpp:240] Iteration 1364, loss = 4.14534
I0408 21:19:05.287863  9048 solver.cpp:256]     Train net output #0: loss = 4.14534 (* 1 = 4.14534 loss)
I0408 21:19:05.287870  9048 sgd_solver.cpp:106] Iteration 1364, lr = 0.01
I0408 21:19:05.563751  9048 solver.cpp:240] Iteration 1365, loss = 5.48519
I0408 21:19:05.563786  9048 solver.cpp:256]     Train net output #0: loss = 5.48519 (* 1 = 5.48519 loss)
I0408 21:19:05.563794  9048 sgd_solver.cpp:106] Iteration 1365, lr = 0.01
I0408 21:19:05.839126  9048 solver.cpp:240] Iteration 1366, loss = 9.77221
I0408 21:19:05.839159  9048 solver.cpp:256]     Train net output #0: loss = 9.7722 (* 1 = 9.7722 loss)
I0408 21:19:05.839167  9048 sgd_solver.cpp:106] Iteration 1366, lr = 0.01
I0408 21:19:06.115335  9048 solver.cpp:240] Iteration 1367, loss = 23.7191
I0408 21:19:06.115377  9048 solver.cpp:256]     Train net output #0: loss = 23.7191 (* 1 = 23.7191 loss)
I0408 21:19:06.115387  9048 sgd_solver.cpp:106] Iteration 1367, lr = 0.01
I0408 21:19:06.390475  9048 solver.cpp:240] Iteration 1368, loss = 15.0425
I0408 21:19:06.390521  9048 solver.cpp:256]     Train net output #0: loss = 15.0425 (* 1 = 15.0425 loss)
I0408 21:19:06.390529  9048 sgd_solver.cpp:106] Iteration 1368, lr = 0.01
I0408 21:19:06.666477  9048 solver.cpp:240] Iteration 1369, loss = 13.113
I0408 21:19:06.666510  9048 solver.cpp:256]     Train net output #0: loss = 13.113 (* 1 = 13.113 loss)
I0408 21:19:06.666519  9048 sgd_solver.cpp:106] Iteration 1369, lr = 0.01
I0408 21:19:06.942184  9048 solver.cpp:240] Iteration 1370, loss = 2.25506
I0408 21:19:06.942229  9048 solver.cpp:256]     Train net output #0: loss = 2.25506 (* 1 = 2.25506 loss)
I0408 21:19:06.942237  9048 sgd_solver.cpp:106] Iteration 1370, lr = 0.01
I0408 21:19:07.216956  9048 solver.cpp:240] Iteration 1371, loss = 5.0371
I0408 21:19:07.216987  9048 solver.cpp:256]     Train net output #0: loss = 5.0371 (* 1 = 5.0371 loss)
I0408 21:19:07.216995  9048 sgd_solver.cpp:106] Iteration 1371, lr = 0.01
I0408 21:19:07.492841  9048 solver.cpp:240] Iteration 1372, loss = 3.49093
I0408 21:19:07.492872  9048 solver.cpp:256]     Train net output #0: loss = 3.49092 (* 1 = 3.49092 loss)
I0408 21:19:07.492880  9048 sgd_solver.cpp:106] Iteration 1372, lr = 0.01
I0408 21:19:07.769166  9048 solver.cpp:240] Iteration 1373, loss = 5.55916
I0408 21:19:07.769199  9048 solver.cpp:256]     Train net output #0: loss = 5.55916 (* 1 = 5.55916 loss)
I0408 21:19:07.769207  9048 sgd_solver.cpp:106] Iteration 1373, lr = 0.01
I0408 21:19:08.044880  9048 solver.cpp:240] Iteration 1374, loss = 15.4212
I0408 21:19:08.044919  9048 solver.cpp:256]     Train net output #0: loss = 15.4212 (* 1 = 15.4212 loss)
I0408 21:19:08.044927  9048 sgd_solver.cpp:106] Iteration 1374, lr = 0.01
I0408 21:19:08.320066  9048 solver.cpp:240] Iteration 1375, loss = 14.5207
I0408 21:19:08.320106  9048 solver.cpp:256]     Train net output #0: loss = 14.5206 (* 1 = 14.5206 loss)
I0408 21:19:08.320114  9048 sgd_solver.cpp:106] Iteration 1375, lr = 0.01
I0408 21:19:08.595456  9048 solver.cpp:240] Iteration 1376, loss = 11.3463
I0408 21:19:08.595489  9048 solver.cpp:256]     Train net output #0: loss = 11.3463 (* 1 = 11.3463 loss)
I0408 21:19:08.595497  9048 sgd_solver.cpp:106] Iteration 1376, lr = 0.01
I0408 21:19:08.871345  9048 solver.cpp:240] Iteration 1377, loss = 9.92888
I0408 21:19:08.871376  9048 solver.cpp:256]     Train net output #0: loss = 9.92887 (* 1 = 9.92887 loss)
I0408 21:19:08.871384  9048 sgd_solver.cpp:106] Iteration 1377, lr = 0.01
I0408 21:19:09.147207  9048 solver.cpp:240] Iteration 1378, loss = 13.9622
I0408 21:19:09.147241  9048 solver.cpp:256]     Train net output #0: loss = 13.9622 (* 1 = 13.9622 loss)
I0408 21:19:09.147249  9048 sgd_solver.cpp:106] Iteration 1378, lr = 0.01
I0408 21:19:09.422013  9048 solver.cpp:240] Iteration 1379, loss = 12.5253
I0408 21:19:09.422046  9048 solver.cpp:256]     Train net output #0: loss = 12.5253 (* 1 = 12.5253 loss)
I0408 21:19:09.422055  9048 sgd_solver.cpp:106] Iteration 1379, lr = 0.01
I0408 21:19:09.698000  9048 solver.cpp:240] Iteration 1380, loss = 5.59961
I0408 21:19:09.698031  9048 solver.cpp:256]     Train net output #0: loss = 5.59961 (* 1 = 5.59961 loss)
I0408 21:19:09.698038  9048 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0408 21:19:09.973441  9048 solver.cpp:240] Iteration 1381, loss = 15.5045
I0408 21:19:09.973487  9048 solver.cpp:256]     Train net output #0: loss = 15.5045 (* 1 = 15.5045 loss)
I0408 21:19:09.973496  9048 sgd_solver.cpp:106] Iteration 1381, lr = 0.01
I0408 21:19:10.249572  9048 solver.cpp:240] Iteration 1382, loss = 9.9606
I0408 21:19:10.249604  9048 solver.cpp:256]     Train net output #0: loss = 9.9606 (* 1 = 9.9606 loss)
I0408 21:19:10.249613  9048 sgd_solver.cpp:106] Iteration 1382, lr = 0.01
I0408 21:19:10.524598  9048 solver.cpp:240] Iteration 1383, loss = 18.7956
I0408 21:19:10.524631  9048 solver.cpp:256]     Train net output #0: loss = 18.7956 (* 1 = 18.7956 loss)
I0408 21:19:10.524639  9048 sgd_solver.cpp:106] Iteration 1383, lr = 0.01
I0408 21:19:10.799958  9048 solver.cpp:240] Iteration 1384, loss = 25.2502
I0408 21:19:10.799995  9048 solver.cpp:256]     Train net output #0: loss = 25.2502 (* 1 = 25.2502 loss)
I0408 21:19:10.800004  9048 sgd_solver.cpp:106] Iteration 1384, lr = 0.01
I0408 21:19:11.076221  9048 solver.cpp:240] Iteration 1385, loss = 5.02014
I0408 21:19:11.076253  9048 solver.cpp:256]     Train net output #0: loss = 5.02013 (* 1 = 5.02013 loss)
I0408 21:19:11.076261  9048 sgd_solver.cpp:106] Iteration 1385, lr = 0.01
I0408 21:19:11.351419  9048 solver.cpp:240] Iteration 1386, loss = 12.51
I0408 21:19:11.351454  9048 solver.cpp:256]     Train net output #0: loss = 12.51 (* 1 = 12.51 loss)
I0408 21:19:11.351461  9048 sgd_solver.cpp:106] Iteration 1386, lr = 0.01
I0408 21:19:11.627684  9048 solver.cpp:240] Iteration 1387, loss = 18.3743
I0408 21:19:11.627722  9048 solver.cpp:256]     Train net output #0: loss = 18.3743 (* 1 = 18.3743 loss)
I0408 21:19:11.627730  9048 sgd_solver.cpp:106] Iteration 1387, lr = 0.01
I0408 21:19:11.903715  9048 solver.cpp:240] Iteration 1388, loss = 21.3558
I0408 21:19:11.903782  9048 solver.cpp:256]     Train net output #0: loss = 21.3558 (* 1 = 21.3558 loss)
I0408 21:19:11.903791  9048 sgd_solver.cpp:106] Iteration 1388, lr = 0.01
I0408 21:19:12.179636  9048 solver.cpp:240] Iteration 1389, loss = 24.3091
I0408 21:19:12.179678  9048 solver.cpp:256]     Train net output #0: loss = 24.3091 (* 1 = 24.3091 loss)
I0408 21:19:12.179687  9048 sgd_solver.cpp:106] Iteration 1389, lr = 0.01
I0408 21:19:12.454797  9048 solver.cpp:240] Iteration 1390, loss = 9.83368
I0408 21:19:12.454829  9048 solver.cpp:256]     Train net output #0: loss = 9.83368 (* 1 = 9.83368 loss)
I0408 21:19:12.454838  9048 sgd_solver.cpp:106] Iteration 1390, lr = 0.01
I0408 21:19:12.730895  9048 solver.cpp:240] Iteration 1391, loss = 23.0329
I0408 21:19:12.730926  9048 solver.cpp:256]     Train net output #0: loss = 23.0329 (* 1 = 23.0329 loss)
I0408 21:19:12.730934  9048 sgd_solver.cpp:106] Iteration 1391, lr = 0.01
I0408 21:19:13.006952  9048 solver.cpp:240] Iteration 1392, loss = 15.4241
I0408 21:19:13.006984  9048 solver.cpp:256]     Train net output #0: loss = 15.4241 (* 1 = 15.4241 loss)
I0408 21:19:13.006992  9048 sgd_solver.cpp:106] Iteration 1392, lr = 0.01
I0408 21:19:13.281641  9048 solver.cpp:240] Iteration 1393, loss = 11.5892
I0408 21:19:13.281679  9048 solver.cpp:256]     Train net output #0: loss = 11.5892 (* 1 = 11.5892 loss)
I0408 21:19:13.281692  9048 sgd_solver.cpp:106] Iteration 1393, lr = 0.01
I0408 21:19:13.557818  9048 solver.cpp:240] Iteration 1394, loss = 33.7611
I0408 21:19:13.557854  9048 solver.cpp:256]     Train net output #0: loss = 33.7611 (* 1 = 33.7611 loss)
I0408 21:19:13.557867  9048 sgd_solver.cpp:106] Iteration 1394, lr = 0.01
I0408 21:19:13.833009  9048 solver.cpp:240] Iteration 1395, loss = 2.31661
I0408 21:19:13.833045  9048 solver.cpp:256]     Train net output #0: loss = 2.31661 (* 1 = 2.31661 loss)
I0408 21:19:13.833056  9048 sgd_solver.cpp:106] Iteration 1395, lr = 0.01
I0408 21:19:14.109020  9048 solver.cpp:240] Iteration 1396, loss = 2.7423
I0408 21:19:14.109061  9048 solver.cpp:256]     Train net output #0: loss = 2.74229 (* 1 = 2.74229 loss)
I0408 21:19:14.109072  9048 sgd_solver.cpp:106] Iteration 1396, lr = 0.01
I0408 21:19:14.385870  9048 solver.cpp:240] Iteration 1397, loss = 2.06382
I0408 21:19:14.385905  9048 solver.cpp:256]     Train net output #0: loss = 2.06381 (* 1 = 2.06381 loss)
I0408 21:19:14.385915  9048 sgd_solver.cpp:106] Iteration 1397, lr = 0.01
I0408 21:19:14.662300  9048 solver.cpp:240] Iteration 1398, loss = 4.80778
I0408 21:19:14.662334  9048 solver.cpp:256]     Train net output #0: loss = 4.80777 (* 1 = 4.80777 loss)
I0408 21:19:14.662346  9048 sgd_solver.cpp:106] Iteration 1398, lr = 0.01
I0408 21:19:14.938241  9048 solver.cpp:240] Iteration 1399, loss = 1.60944
I0408 21:19:14.938272  9048 solver.cpp:256]     Train net output #0: loss = 1.60944 (* 1 = 1.60944 loss)
I0408 21:19:14.938283  9048 sgd_solver.cpp:106] Iteration 1399, lr = 0.01
I0408 21:19:15.214071  9048 solver.cpp:240] Iteration 1400, loss = 11.7666
I0408 21:19:15.214107  9048 solver.cpp:256]     Train net output #0: loss = 11.7666 (* 1 = 11.7666 loss)
I0408 21:19:15.214118  9048 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0408 21:19:15.490125  9048 solver.cpp:240] Iteration 1401, loss = 15.0348
I0408 21:19:15.490165  9048 solver.cpp:256]     Train net output #0: loss = 15.0348 (* 1 = 15.0348 loss)
I0408 21:19:15.490177  9048 sgd_solver.cpp:106] Iteration 1401, lr = 0.01
I0408 21:19:15.766135  9048 solver.cpp:240] Iteration 1402, loss = 18.8218
I0408 21:19:15.766172  9048 solver.cpp:256]     Train net output #0: loss = 18.8218 (* 1 = 18.8218 loss)
I0408 21:19:15.766185  9048 sgd_solver.cpp:106] Iteration 1402, lr = 0.01
I0408 21:19:16.042407  9048 solver.cpp:240] Iteration 1403, loss = 16.2694
I0408 21:19:16.042443  9048 solver.cpp:256]     Train net output #0: loss = 16.2694 (* 1 = 16.2694 loss)
I0408 21:19:16.042456  9048 sgd_solver.cpp:106] Iteration 1403, lr = 0.01
I0408 21:19:16.318061  9048 solver.cpp:240] Iteration 1404, loss = 7.66414
I0408 21:19:16.318115  9048 solver.cpp:256]     Train net output #0: loss = 7.66413 (* 1 = 7.66413 loss)
I0408 21:19:16.318127  9048 sgd_solver.cpp:106] Iteration 1404, lr = 0.01
I0408 21:19:16.594374  9048 solver.cpp:240] Iteration 1405, loss = 5.23947
I0408 21:19:16.594410  9048 solver.cpp:256]     Train net output #0: loss = 5.23946 (* 1 = 5.23946 loss)
I0408 21:19:16.594422  9048 sgd_solver.cpp:106] Iteration 1405, lr = 0.01
I0408 21:19:16.870242  9048 solver.cpp:240] Iteration 1406, loss = 4.17344
I0408 21:19:16.870277  9048 solver.cpp:256]     Train net output #0: loss = 4.17343 (* 1 = 4.17343 loss)
I0408 21:19:16.870288  9048 sgd_solver.cpp:106] Iteration 1406, lr = 0.01
I0408 21:19:17.146397  9048 solver.cpp:240] Iteration 1407, loss = 3.78538
I0408 21:19:17.146432  9048 solver.cpp:256]     Train net output #0: loss = 3.78537 (* 1 = 3.78537 loss)
I0408 21:19:17.146445  9048 sgd_solver.cpp:106] Iteration 1407, lr = 0.01
I0408 21:19:17.421849  9048 solver.cpp:240] Iteration 1408, loss = 3.29899
I0408 21:19:17.421882  9048 solver.cpp:256]     Train net output #0: loss = 3.29898 (* 1 = 3.29898 loss)
I0408 21:19:17.421895  9048 sgd_solver.cpp:106] Iteration 1408, lr = 0.01
I0408 21:19:17.697706  9048 solver.cpp:240] Iteration 1409, loss = 24.0115
I0408 21:19:17.697744  9048 solver.cpp:256]     Train net output #0: loss = 24.0115 (* 1 = 24.0115 loss)
I0408 21:19:17.697767  9048 sgd_solver.cpp:106] Iteration 1409, lr = 0.01
I0408 21:19:17.973803  9048 solver.cpp:240] Iteration 1410, loss = 5.28709
I0408 21:19:17.973836  9048 solver.cpp:256]     Train net output #0: loss = 5.28708 (* 1 = 5.28708 loss)
I0408 21:19:17.973860  9048 sgd_solver.cpp:106] Iteration 1410, lr = 0.01
I0408 21:19:18.249264  9048 solver.cpp:240] Iteration 1411, loss = 11.3644
I0408 21:19:18.249305  9048 solver.cpp:256]     Train net output #0: loss = 11.3644 (* 1 = 11.3644 loss)
I0408 21:19:18.249318  9048 sgd_solver.cpp:106] Iteration 1411, lr = 0.01
I0408 21:19:18.524350  9048 solver.cpp:240] Iteration 1412, loss = 5.4142
I0408 21:19:18.524384  9048 solver.cpp:256]     Train net output #0: loss = 5.4142 (* 1 = 5.4142 loss)
I0408 21:19:18.524395  9048 sgd_solver.cpp:106] Iteration 1412, lr = 0.01
I0408 21:19:18.800326  9048 solver.cpp:240] Iteration 1413, loss = 13.498
I0408 21:19:18.800365  9048 solver.cpp:256]     Train net output #0: loss = 13.498 (* 1 = 13.498 loss)
I0408 21:19:18.800376  9048 sgd_solver.cpp:106] Iteration 1413, lr = 0.01
I0408 21:19:19.077065  9048 solver.cpp:240] Iteration 1414, loss = 17.4587
I0408 21:19:19.077101  9048 solver.cpp:256]     Train net output #0: loss = 17.4587 (* 1 = 17.4587 loss)
I0408 21:19:19.077114  9048 sgd_solver.cpp:106] Iteration 1414, lr = 0.01
I0408 21:19:19.353662  9048 solver.cpp:240] Iteration 1415, loss = 5.14059
I0408 21:19:19.353696  9048 solver.cpp:256]     Train net output #0: loss = 5.14058 (* 1 = 5.14058 loss)
I0408 21:19:19.353708  9048 sgd_solver.cpp:106] Iteration 1415, lr = 0.01
I0408 21:19:19.629667  9048 solver.cpp:240] Iteration 1416, loss = 39.2536
I0408 21:19:19.629907  9048 solver.cpp:256]     Train net output #0: loss = 39.2536 (* 1 = 39.2536 loss)
I0408 21:19:19.629935  9048 sgd_solver.cpp:106] Iteration 1416, lr = 0.01
I0408 21:19:19.904916  9048 solver.cpp:240] Iteration 1417, loss = 9.87304
I0408 21:19:19.904952  9048 solver.cpp:256]     Train net output #0: loss = 9.87303 (* 1 = 9.87303 loss)
I0408 21:19:19.904963  9048 sgd_solver.cpp:106] Iteration 1417, lr = 0.01
I0408 21:19:20.181694  9048 solver.cpp:240] Iteration 1418, loss = 1.45045
I0408 21:19:20.181728  9048 solver.cpp:256]     Train net output #0: loss = 1.45044 (* 1 = 1.45044 loss)
I0408 21:19:20.181740  9048 sgd_solver.cpp:106] Iteration 1418, lr = 0.01
I0408 21:19:20.457336  9048 solver.cpp:240] Iteration 1419, loss = 8.55245
I0408 21:19:20.457372  9048 solver.cpp:256]     Train net output #0: loss = 8.55244 (* 1 = 8.55244 loss)
I0408 21:19:20.457384  9048 sgd_solver.cpp:106] Iteration 1419, lr = 0.01
I0408 21:19:20.731775  9048 solver.cpp:240] Iteration 1420, loss = 16.4459
I0408 21:19:20.731813  9048 solver.cpp:256]     Train net output #0: loss = 16.4459 (* 1 = 16.4459 loss)
I0408 21:19:20.731825  9048 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0408 21:19:21.008769  9048 solver.cpp:240] Iteration 1421, loss = 10.8498
I0408 21:19:21.008810  9048 solver.cpp:256]     Train net output #0: loss = 10.8498 (* 1 = 10.8498 loss)
I0408 21:19:21.008822  9048 sgd_solver.cpp:106] Iteration 1421, lr = 0.01
I0408 21:19:21.284967  9048 solver.cpp:240] Iteration 1422, loss = 20.8475
I0408 21:19:21.285003  9048 solver.cpp:256]     Train net output #0: loss = 20.8475 (* 1 = 20.8475 loss)
I0408 21:19:21.285015  9048 sgd_solver.cpp:106] Iteration 1422, lr = 0.01
I0408 21:19:21.561136  9048 solver.cpp:240] Iteration 1423, loss = 1.91762
I0408 21:19:21.561173  9048 solver.cpp:256]     Train net output #0: loss = 1.91761 (* 1 = 1.91761 loss)
I0408 21:19:21.561197  9048 sgd_solver.cpp:106] Iteration 1423, lr = 0.01
I0408 21:19:21.836284  9048 solver.cpp:240] Iteration 1424, loss = 41.3688
I0408 21:19:21.836321  9048 solver.cpp:256]     Train net output #0: loss = 41.3688 (* 1 = 41.3688 loss)
I0408 21:19:21.836333  9048 sgd_solver.cpp:106] Iteration 1424, lr = 0.01
I0408 21:19:22.110994  9048 solver.cpp:240] Iteration 1425, loss = 18.244
I0408 21:19:22.111032  9048 solver.cpp:256]     Train net output #0: loss = 18.244 (* 1 = 18.244 loss)
I0408 21:19:22.111053  9048 sgd_solver.cpp:106] Iteration 1425, lr = 0.01
I0408 21:19:22.386422  9048 solver.cpp:240] Iteration 1426, loss = 1.44073
I0408 21:19:22.386461  9048 solver.cpp:256]     Train net output #0: loss = 1.44072 (* 1 = 1.44072 loss)
I0408 21:19:22.386473  9048 sgd_solver.cpp:106] Iteration 1426, lr = 0.01
I0408 21:19:22.662997  9048 solver.cpp:240] Iteration 1427, loss = 5.36972
I0408 21:19:22.663031  9048 solver.cpp:256]     Train net output #0: loss = 5.36971 (* 1 = 5.36971 loss)
I0408 21:19:22.663043  9048 sgd_solver.cpp:106] Iteration 1427, lr = 0.01
I0408 21:19:22.938810  9048 solver.cpp:240] Iteration 1428, loss = 29.2153
I0408 21:19:22.938853  9048 solver.cpp:256]     Train net output #0: loss = 29.2153 (* 1 = 29.2153 loss)
I0408 21:19:22.938877  9048 sgd_solver.cpp:106] Iteration 1428, lr = 0.01
I0408 21:19:23.215159  9048 solver.cpp:240] Iteration 1429, loss = 41.6299
I0408 21:19:23.215198  9048 solver.cpp:256]     Train net output #0: loss = 41.6298 (* 1 = 41.6298 loss)
I0408 21:19:23.215220  9048 sgd_solver.cpp:106] Iteration 1429, lr = 0.01
I0408 21:19:23.491982  9048 solver.cpp:240] Iteration 1430, loss = 32.679
I0408 21:19:23.492027  9048 solver.cpp:256]     Train net output #0: loss = 32.679 (* 1 = 32.679 loss)
I0408 21:19:23.492039  9048 sgd_solver.cpp:106] Iteration 1430, lr = 0.01
I0408 21:19:23.767236  9048 solver.cpp:240] Iteration 1431, loss = 19.96
I0408 21:19:23.767272  9048 solver.cpp:256]     Train net output #0: loss = 19.96 (* 1 = 19.96 loss)
I0408 21:19:23.767284  9048 sgd_solver.cpp:106] Iteration 1431, lr = 0.01
I0408 21:19:24.042822  9048 solver.cpp:240] Iteration 1432, loss = 19.5826
I0408 21:19:24.042857  9048 solver.cpp:256]     Train net output #0: loss = 19.5826 (* 1 = 19.5826 loss)
I0408 21:19:24.042896  9048 sgd_solver.cpp:106] Iteration 1432, lr = 0.01
I0408 21:19:24.318498  9048 solver.cpp:240] Iteration 1433, loss = 12.9381
I0408 21:19:24.318536  9048 solver.cpp:256]     Train net output #0: loss = 12.9381 (* 1 = 12.9381 loss)
I0408 21:19:24.318558  9048 sgd_solver.cpp:106] Iteration 1433, lr = 0.01
I0408 21:19:24.593577  9048 solver.cpp:240] Iteration 1434, loss = 7.86656
I0408 21:19:24.593611  9048 solver.cpp:256]     Train net output #0: loss = 7.86656 (* 1 = 7.86656 loss)
I0408 21:19:24.593623  9048 sgd_solver.cpp:106] Iteration 1434, lr = 0.01
I0408 21:19:24.868973  9048 solver.cpp:240] Iteration 1435, loss = 4.36211
I0408 21:19:24.869009  9048 solver.cpp:256]     Train net output #0: loss = 4.3621 (* 1 = 4.3621 loss)
I0408 21:19:24.869031  9048 sgd_solver.cpp:106] Iteration 1435, lr = 0.01
I0408 21:19:25.144934  9048 solver.cpp:240] Iteration 1436, loss = 14.4511
I0408 21:19:25.144968  9048 solver.cpp:256]     Train net output #0: loss = 14.4511 (* 1 = 14.4511 loss)
I0408 21:19:25.144991  9048 sgd_solver.cpp:106] Iteration 1436, lr = 0.01
I0408 21:19:25.420312  9048 solver.cpp:240] Iteration 1437, loss = 3.7476
I0408 21:19:25.420346  9048 solver.cpp:256]     Train net output #0: loss = 3.74759 (* 1 = 3.74759 loss)
I0408 21:19:25.420358  9048 sgd_solver.cpp:106] Iteration 1437, lr = 0.01
I0408 21:19:25.695510  9048 solver.cpp:240] Iteration 1438, loss = 2.63742
I0408 21:19:25.695545  9048 solver.cpp:256]     Train net output #0: loss = 2.63741 (* 1 = 2.63741 loss)
I0408 21:19:25.695556  9048 sgd_solver.cpp:106] Iteration 1438, lr = 0.01
I0408 21:19:25.971127  9048 solver.cpp:240] Iteration 1439, loss = 26.1293
I0408 21:19:25.971163  9048 solver.cpp:256]     Train net output #0: loss = 26.1293 (* 1 = 26.1293 loss)
I0408 21:19:25.971174  9048 sgd_solver.cpp:106] Iteration 1439, lr = 0.01
I0408 21:19:26.245745  9048 solver.cpp:240] Iteration 1440, loss = 28.7299
I0408 21:19:26.245789  9048 solver.cpp:256]     Train net output #0: loss = 28.7299 (* 1 = 28.7299 loss)
I0408 21:19:26.245812  9048 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0408 21:19:26.521059  9048 solver.cpp:240] Iteration 1441, loss = 32.9483
I0408 21:19:26.521096  9048 solver.cpp:256]     Train net output #0: loss = 32.9483 (* 1 = 32.9483 loss)
I0408 21:19:26.521108  9048 sgd_solver.cpp:106] Iteration 1441, lr = 0.01
I0408 21:19:26.796880  9048 solver.cpp:240] Iteration 1442, loss = 14.6665
I0408 21:19:26.796914  9048 solver.cpp:256]     Train net output #0: loss = 14.6665 (* 1 = 14.6665 loss)
I0408 21:19:26.796938  9048 sgd_solver.cpp:106] Iteration 1442, lr = 0.01
I0408 21:19:27.072866  9048 solver.cpp:240] Iteration 1443, loss = 29.6225
I0408 21:19:27.072907  9048 solver.cpp:256]     Train net output #0: loss = 29.6225 (* 1 = 29.6225 loss)
I0408 21:19:27.072919  9048 sgd_solver.cpp:106] Iteration 1443, lr = 0.01
I0408 21:19:27.348234  9048 solver.cpp:240] Iteration 1444, loss = 17.1346
I0408 21:19:27.348273  9048 solver.cpp:256]     Train net output #0: loss = 17.1346 (* 1 = 17.1346 loss)
I0408 21:19:27.348284  9048 sgd_solver.cpp:106] Iteration 1444, lr = 0.01
I0408 21:19:27.624617  9048 solver.cpp:240] Iteration 1445, loss = 7.11486
I0408 21:19:27.624652  9048 solver.cpp:256]     Train net output #0: loss = 7.11486 (* 1 = 7.11486 loss)
I0408 21:19:27.624663  9048 sgd_solver.cpp:106] Iteration 1445, lr = 0.01
I0408 21:19:27.899667  9048 solver.cpp:240] Iteration 1446, loss = 18.2821
I0408 21:19:27.899703  9048 solver.cpp:256]     Train net output #0: loss = 18.2821 (* 1 = 18.2821 loss)
I0408 21:19:27.899716  9048 sgd_solver.cpp:106] Iteration 1446, lr = 0.01
I0408 21:19:28.176050  9048 solver.cpp:240] Iteration 1447, loss = 27.9469
I0408 21:19:28.176086  9048 solver.cpp:256]     Train net output #0: loss = 27.9469 (* 1 = 27.9469 loss)
I0408 21:19:28.176098  9048 sgd_solver.cpp:106] Iteration 1447, lr = 0.01
I0408 21:19:28.451087  9048 solver.cpp:240] Iteration 1448, loss = 13.7668
I0408 21:19:28.451123  9048 solver.cpp:256]     Train net output #0: loss = 13.7668 (* 1 = 13.7668 loss)
I0408 21:19:28.451160  9048 sgd_solver.cpp:106] Iteration 1448, lr = 0.01
I0408 21:19:28.726205  9048 solver.cpp:240] Iteration 1449, loss = 11.2913
I0408 21:19:28.726243  9048 solver.cpp:256]     Train net output #0: loss = 11.2912 (* 1 = 11.2912 loss)
I0408 21:19:28.726253  9048 sgd_solver.cpp:106] Iteration 1449, lr = 0.01
I0408 21:19:29.002527  9048 solver.cpp:240] Iteration 1450, loss = 10.4712
I0408 21:19:29.002563  9048 solver.cpp:256]     Train net output #0: loss = 10.4712 (* 1 = 10.4712 loss)
I0408 21:19:29.002574  9048 sgd_solver.cpp:106] Iteration 1450, lr = 0.01
I0408 21:19:29.278352  9048 solver.cpp:240] Iteration 1451, loss = 3.44273
I0408 21:19:29.278388  9048 solver.cpp:256]     Train net output #0: loss = 3.44272 (* 1 = 3.44272 loss)
I0408 21:19:29.278398  9048 sgd_solver.cpp:106] Iteration 1451, lr = 0.01
I0408 21:19:29.553143  9048 solver.cpp:240] Iteration 1452, loss = 36.3935
I0408 21:19:29.553180  9048 solver.cpp:256]     Train net output #0: loss = 36.3935 (* 1 = 36.3935 loss)
I0408 21:19:29.553192  9048 sgd_solver.cpp:106] Iteration 1452, lr = 0.01
I0408 21:19:29.829588  9048 solver.cpp:240] Iteration 1453, loss = 16.53
I0408 21:19:29.829624  9048 solver.cpp:256]     Train net output #0: loss = 16.5299 (* 1 = 16.5299 loss)
I0408 21:19:29.829637  9048 sgd_solver.cpp:106] Iteration 1453, lr = 0.01
I0408 21:19:30.104773  9048 solver.cpp:240] Iteration 1454, loss = 24.4498
I0408 21:19:30.104809  9048 solver.cpp:256]     Train net output #0: loss = 24.4498 (* 1 = 24.4498 loss)
I0408 21:19:30.104820  9048 sgd_solver.cpp:106] Iteration 1454, lr = 0.01
I0408 21:19:30.380120  9048 solver.cpp:240] Iteration 1455, loss = 36.0253
I0408 21:19:30.380156  9048 solver.cpp:256]     Train net output #0: loss = 36.0253 (* 1 = 36.0253 loss)
I0408 21:19:30.380168  9048 sgd_solver.cpp:106] Iteration 1455, lr = 0.01
I0408 21:19:30.654706  9048 solver.cpp:240] Iteration 1456, loss = 15.1181
I0408 21:19:30.654742  9048 solver.cpp:256]     Train net output #0: loss = 15.1181 (* 1 = 15.1181 loss)
I0408 21:19:30.654753  9048 sgd_solver.cpp:106] Iteration 1456, lr = 0.01
I0408 21:19:30.930200  9048 solver.cpp:240] Iteration 1457, loss = 23.8135
I0408 21:19:30.930241  9048 solver.cpp:256]     Train net output #0: loss = 23.8135 (* 1 = 23.8135 loss)
I0408 21:19:30.930254  9048 sgd_solver.cpp:106] Iteration 1457, lr = 0.01
I0408 21:19:31.205904  9048 solver.cpp:240] Iteration 1458, loss = 27.3057
I0408 21:19:31.205940  9048 solver.cpp:256]     Train net output #0: loss = 27.3057 (* 1 = 27.3057 loss)
I0408 21:19:31.205953  9048 sgd_solver.cpp:106] Iteration 1458, lr = 0.01
I0408 21:19:31.480615  9048 solver.cpp:240] Iteration 1459, loss = 27.0599
I0408 21:19:31.480651  9048 solver.cpp:256]     Train net output #0: loss = 27.0599 (* 1 = 27.0599 loss)
I0408 21:19:31.480664  9048 sgd_solver.cpp:106] Iteration 1459, lr = 0.01
I0408 21:19:31.755188  9048 solver.cpp:240] Iteration 1460, loss = 18.7376
I0408 21:19:31.755229  9048 solver.cpp:256]     Train net output #0: loss = 18.7376 (* 1 = 18.7376 loss)
I0408 21:19:31.755252  9048 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0408 21:19:32.031117  9048 solver.cpp:240] Iteration 1461, loss = 13.8488
I0408 21:19:32.031154  9048 solver.cpp:256]     Train net output #0: loss = 13.8488 (* 1 = 13.8488 loss)
I0408 21:19:32.031167  9048 sgd_solver.cpp:106] Iteration 1461, lr = 0.01
I0408 21:19:32.306622  9048 solver.cpp:240] Iteration 1462, loss = 19.5745
I0408 21:19:32.306658  9048 solver.cpp:256]     Train net output #0: loss = 19.5745 (* 1 = 19.5745 loss)
I0408 21:19:32.306671  9048 sgd_solver.cpp:106] Iteration 1462, lr = 0.01
I0408 21:19:32.582890  9048 solver.cpp:240] Iteration 1463, loss = 0.994343
I0408 21:19:32.582926  9048 solver.cpp:256]     Train net output #0: loss = 0.994335 (* 1 = 0.994335 loss)
I0408 21:19:32.582937  9048 sgd_solver.cpp:106] Iteration 1463, lr = 0.01
I0408 21:19:32.858660  9048 solver.cpp:240] Iteration 1464, loss = 1.10117
I0408 21:19:32.858695  9048 solver.cpp:256]     Train net output #0: loss = 1.10116 (* 1 = 1.10116 loss)
I0408 21:19:32.858706  9048 sgd_solver.cpp:106] Iteration 1464, lr = 0.01
I0408 21:19:33.134455  9048 solver.cpp:240] Iteration 1465, loss = 8.70623
I0408 21:19:33.134500  9048 solver.cpp:256]     Train net output #0: loss = 8.70622 (* 1 = 8.70622 loss)
I0408 21:19:33.134515  9048 sgd_solver.cpp:106] Iteration 1465, lr = 0.01
I0408 21:19:33.410387  9048 solver.cpp:240] Iteration 1466, loss = 12.6725
I0408 21:19:33.410424  9048 solver.cpp:256]     Train net output #0: loss = 12.6725 (* 1 = 12.6725 loss)
I0408 21:19:33.410436  9048 sgd_solver.cpp:106] Iteration 1466, lr = 0.01
I0408 21:19:33.686506  9048 solver.cpp:240] Iteration 1467, loss = 6.83933
I0408 21:19:33.686540  9048 solver.cpp:256]     Train net output #0: loss = 6.83932 (* 1 = 6.83932 loss)
I0408 21:19:33.686553  9048 sgd_solver.cpp:106] Iteration 1467, lr = 0.01
I0408 21:19:33.960902  9048 solver.cpp:240] Iteration 1468, loss = 16.2906
I0408 21:19:33.960937  9048 solver.cpp:256]     Train net output #0: loss = 16.2906 (* 1 = 16.2906 loss)
I0408 21:19:33.960949  9048 sgd_solver.cpp:106] Iteration 1468, lr = 0.01
I0408 21:19:34.237148  9048 solver.cpp:240] Iteration 1469, loss = 4.78558
I0408 21:19:34.237180  9048 solver.cpp:256]     Train net output #0: loss = 4.78557 (* 1 = 4.78557 loss)
I0408 21:19:34.237191  9048 sgd_solver.cpp:106] Iteration 1469, lr = 0.01
I0408 21:19:34.512804  9048 solver.cpp:240] Iteration 1470, loss = 2.56425
I0408 21:19:34.512837  9048 solver.cpp:256]     Train net output #0: loss = 2.56424 (* 1 = 2.56424 loss)
I0408 21:19:34.512850  9048 sgd_solver.cpp:106] Iteration 1470, lr = 0.01
I0408 21:19:34.788914  9048 solver.cpp:240] Iteration 1471, loss = 4.68666
I0408 21:19:34.788949  9048 solver.cpp:256]     Train net output #0: loss = 4.68665 (* 1 = 4.68665 loss)
I0408 21:19:34.788960  9048 sgd_solver.cpp:106] Iteration 1471, lr = 0.01
I0408 21:19:35.064203  9048 solver.cpp:240] Iteration 1472, loss = 24.8437
I0408 21:19:35.064237  9048 solver.cpp:256]     Train net output #0: loss = 24.8437 (* 1 = 24.8437 loss)
I0408 21:19:35.064250  9048 sgd_solver.cpp:106] Iteration 1472, lr = 0.01
I0408 21:19:35.340996  9048 solver.cpp:240] Iteration 1473, loss = 14.7751
I0408 21:19:35.341033  9048 solver.cpp:256]     Train net output #0: loss = 14.7751 (* 1 = 14.7751 loss)
I0408 21:19:35.341045  9048 sgd_solver.cpp:106] Iteration 1473, lr = 0.01
I0408 21:19:35.616708  9048 solver.cpp:240] Iteration 1474, loss = 19.4444
I0408 21:19:35.616745  9048 solver.cpp:256]     Train net output #0: loss = 19.4444 (* 1 = 19.4444 loss)
I0408 21:19:35.616757  9048 sgd_solver.cpp:106] Iteration 1474, lr = 0.01
I0408 21:19:35.893517  9048 solver.cpp:240] Iteration 1475, loss = 15.0291
I0408 21:19:35.893555  9048 solver.cpp:256]     Train net output #0: loss = 15.0291 (* 1 = 15.0291 loss)
I0408 21:19:35.893566  9048 sgd_solver.cpp:106] Iteration 1475, lr = 0.01
I0408 21:19:36.169838  9048 solver.cpp:240] Iteration 1476, loss = 12.1875
I0408 21:19:36.169874  9048 solver.cpp:256]     Train net output #0: loss = 12.1875 (* 1 = 12.1875 loss)
I0408 21:19:36.169886  9048 sgd_solver.cpp:106] Iteration 1476, lr = 0.01
I0408 21:19:36.446851  9048 solver.cpp:240] Iteration 1477, loss = 28.3652
I0408 21:19:36.446890  9048 solver.cpp:256]     Train net output #0: loss = 28.3651 (* 1 = 28.3651 loss)
I0408 21:19:36.446914  9048 sgd_solver.cpp:106] Iteration 1477, lr = 0.01
I0408 21:19:36.722410  9048 solver.cpp:240] Iteration 1478, loss = 10.4259
I0408 21:19:36.722447  9048 solver.cpp:256]     Train net output #0: loss = 10.4258 (* 1 = 10.4258 loss)
I0408 21:19:36.722460  9048 sgd_solver.cpp:106] Iteration 1478, lr = 0.01
I0408 21:19:36.997413  9048 solver.cpp:240] Iteration 1479, loss = 8.08277
I0408 21:19:36.997450  9048 solver.cpp:256]     Train net output #0: loss = 8.08276 (* 1 = 8.08276 loss)
I0408 21:19:36.997462  9048 sgd_solver.cpp:106] Iteration 1479, lr = 0.01
I0408 21:19:37.273011  9048 solver.cpp:240] Iteration 1480, loss = 14.053
I0408 21:19:37.273047  9048 solver.cpp:256]     Train net output #0: loss = 14.053 (* 1 = 14.053 loss)
I0408 21:19:37.273058  9048 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0408 21:19:37.549468  9048 solver.cpp:240] Iteration 1481, loss = 40.7233
I0408 21:19:37.549502  9048 solver.cpp:256]     Train net output #0: loss = 40.7233 (* 1 = 40.7233 loss)
I0408 21:19:37.549515  9048 sgd_solver.cpp:106] Iteration 1481, lr = 0.01
I0408 21:19:37.824934  9048 solver.cpp:240] Iteration 1482, loss = 18.5816
I0408 21:19:37.824970  9048 solver.cpp:256]     Train net output #0: loss = 18.5816 (* 1 = 18.5816 loss)
I0408 21:19:37.824992  9048 sgd_solver.cpp:106] Iteration 1482, lr = 0.01
I0408 21:19:38.100800  9048 solver.cpp:240] Iteration 1483, loss = 15.2975
I0408 21:19:38.100836  9048 solver.cpp:256]     Train net output #0: loss = 15.2975 (* 1 = 15.2975 loss)
I0408 21:19:38.100847  9048 sgd_solver.cpp:106] Iteration 1483, lr = 0.01
I0408 21:19:38.376523  9048 solver.cpp:240] Iteration 1484, loss = 2.19833
I0408 21:19:38.376555  9048 solver.cpp:256]     Train net output #0: loss = 2.19833 (* 1 = 2.19833 loss)
I0408 21:19:38.376579  9048 sgd_solver.cpp:106] Iteration 1484, lr = 0.01
I0408 21:19:38.653939  9048 solver.cpp:240] Iteration 1485, loss = 1.6782
I0408 21:19:38.653972  9048 solver.cpp:256]     Train net output #0: loss = 1.67819 (* 1 = 1.67819 loss)
I0408 21:19:38.653983  9048 sgd_solver.cpp:106] Iteration 1485, lr = 0.01
I0408 21:19:38.929931  9048 solver.cpp:240] Iteration 1486, loss = 1.71125
I0408 21:19:38.929967  9048 solver.cpp:256]     Train net output #0: loss = 1.71124 (* 1 = 1.71124 loss)
I0408 21:19:38.929978  9048 sgd_solver.cpp:106] Iteration 1486, lr = 0.01
I0408 21:19:39.206316  9048 solver.cpp:240] Iteration 1487, loss = 4.40705
I0408 21:19:39.206357  9048 solver.cpp:256]     Train net output #0: loss = 4.40704 (* 1 = 4.40704 loss)
I0408 21:19:39.206380  9048 sgd_solver.cpp:106] Iteration 1487, lr = 0.01
I0408 21:19:39.481819  9048 solver.cpp:240] Iteration 1488, loss = 1.6077
I0408 21:19:39.481854  9048 solver.cpp:256]     Train net output #0: loss = 1.6077 (* 1 = 1.6077 loss)
I0408 21:19:39.481865  9048 sgd_solver.cpp:106] Iteration 1488, lr = 0.01
I0408 21:19:39.757375  9048 solver.cpp:240] Iteration 1489, loss = 2.24099
I0408 21:19:39.757410  9048 solver.cpp:256]     Train net output #0: loss = 2.24098 (* 1 = 2.24098 loss)
I0408 21:19:39.757421  9048 sgd_solver.cpp:106] Iteration 1489, lr = 0.01
I0408 21:19:40.033740  9048 solver.cpp:240] Iteration 1490, loss = 9.8945
I0408 21:19:40.033776  9048 solver.cpp:256]     Train net output #0: loss = 9.8945 (* 1 = 9.8945 loss)
I0408 21:19:40.033788  9048 sgd_solver.cpp:106] Iteration 1490, lr = 0.01
I0408 21:19:40.309588  9048 solver.cpp:240] Iteration 1491, loss = 5.69655
I0408 21:19:40.309623  9048 solver.cpp:256]     Train net output #0: loss = 5.69655 (* 1 = 5.69655 loss)
I0408 21:19:40.309634  9048 sgd_solver.cpp:106] Iteration 1491, lr = 0.01
I0408 21:19:40.584477  9048 solver.cpp:240] Iteration 1492, loss = 1.60462
I0408 21:19:40.584512  9048 solver.cpp:256]     Train net output #0: loss = 1.60461 (* 1 = 1.60461 loss)
I0408 21:19:40.584523  9048 sgd_solver.cpp:106] Iteration 1492, lr = 0.01
I0408 21:19:40.860465  9048 solver.cpp:240] Iteration 1493, loss = 3.439
I0408 21:19:40.860502  9048 solver.cpp:256]     Train net output #0: loss = 3.43899 (* 1 = 3.43899 loss)
I0408 21:19:40.860525  9048 sgd_solver.cpp:106] Iteration 1493, lr = 0.01
I0408 21:19:41.135318  9048 solver.cpp:240] Iteration 1494, loss = 1.60944
I0408 21:19:41.135354  9048 solver.cpp:256]     Train net output #0: loss = 1.60943 (* 1 = 1.60943 loss)
I0408 21:19:41.135365  9048 sgd_solver.cpp:106] Iteration 1494, lr = 0.01
I0408 21:19:41.410955  9048 solver.cpp:240] Iteration 1495, loss = 27.3902
I0408 21:19:41.410993  9048 solver.cpp:256]     Train net output #0: loss = 27.3902 (* 1 = 27.3902 loss)
I0408 21:19:41.411005  9048 sgd_solver.cpp:106] Iteration 1495, lr = 0.01
I0408 21:19:41.686452  9048 solver.cpp:240] Iteration 1496, loss = 15.8811
I0408 21:19:41.686488  9048 solver.cpp:256]     Train net output #0: loss = 15.8811 (* 1 = 15.8811 loss)
I0408 21:19:41.686501  9048 sgd_solver.cpp:106] Iteration 1496, lr = 0.01
I0408 21:19:41.962132  9048 solver.cpp:240] Iteration 1497, loss = 17.3625
I0408 21:19:41.962195  9048 solver.cpp:256]     Train net output #0: loss = 17.3625 (* 1 = 17.3625 loss)
I0408 21:19:41.962208  9048 sgd_solver.cpp:106] Iteration 1497, lr = 0.01
I0408 21:19:42.237296  9048 solver.cpp:240] Iteration 1498, loss = 16.9402
I0408 21:19:42.237331  9048 solver.cpp:256]     Train net output #0: loss = 16.9402 (* 1 = 16.9402 loss)
I0408 21:19:42.237354  9048 sgd_solver.cpp:106] Iteration 1498, lr = 0.01
I0408 21:19:42.512138  9048 solver.cpp:240] Iteration 1499, loss = 2.26705
I0408 21:19:42.512182  9048 solver.cpp:256]     Train net output #0: loss = 2.26704 (* 1 = 2.26704 loss)
I0408 21:19:42.512194  9048 sgd_solver.cpp:106] Iteration 1499, lr = 0.01
I0408 21:19:42.788517  9048 solver.cpp:240] Iteration 1500, loss = 1.99556
I0408 21:19:42.788552  9048 solver.cpp:256]     Train net output #0: loss = 1.99555 (* 1 = 1.99555 loss)
I0408 21:19:42.788563  9048 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0408 21:19:43.065466  9048 solver.cpp:240] Iteration 1501, loss = 3.11835
I0408 21:19:43.065502  9048 solver.cpp:256]     Train net output #0: loss = 3.11834 (* 1 = 3.11834 loss)
I0408 21:19:43.065513  9048 sgd_solver.cpp:106] Iteration 1501, lr = 0.01
I0408 21:19:43.341745  9048 solver.cpp:240] Iteration 1502, loss = 1.7199
I0408 21:19:43.341784  9048 solver.cpp:256]     Train net output #0: loss = 1.71989 (* 1 = 1.71989 loss)
I0408 21:19:43.341794  9048 sgd_solver.cpp:106] Iteration 1502, lr = 0.01
I0408 21:19:43.617723  9048 solver.cpp:240] Iteration 1503, loss = 1.61503
I0408 21:19:43.617759  9048 solver.cpp:256]     Train net output #0: loss = 1.61502 (* 1 = 1.61502 loss)
I0408 21:19:43.617770  9048 sgd_solver.cpp:106] Iteration 1503, lr = 0.01
I0408 21:19:43.893067  9048 solver.cpp:240] Iteration 1504, loss = 1.63395
I0408 21:19:43.893102  9048 solver.cpp:256]     Train net output #0: loss = 1.63394 (* 1 = 1.63394 loss)
I0408 21:19:43.893113  9048 sgd_solver.cpp:106] Iteration 1504, lr = 0.01
I0408 21:19:44.168344  9048 solver.cpp:240] Iteration 1505, loss = 1.57819
I0408 21:19:44.168378  9048 solver.cpp:256]     Train net output #0: loss = 1.57818 (* 1 = 1.57818 loss)
I0408 21:19:44.168390  9048 sgd_solver.cpp:106] Iteration 1505, lr = 0.01
I0408 21:19:44.443434  9048 solver.cpp:240] Iteration 1506, loss = 2.28649
I0408 21:19:44.443469  9048 solver.cpp:256]     Train net output #0: loss = 2.28648 (* 1 = 2.28648 loss)
I0408 21:19:44.443480  9048 sgd_solver.cpp:106] Iteration 1506, lr = 0.01
I0408 21:19:44.719490  9048 solver.cpp:240] Iteration 1507, loss = 3.01254
I0408 21:19:44.719522  9048 solver.cpp:256]     Train net output #0: loss = 3.01253 (* 1 = 3.01253 loss)
I0408 21:19:44.719544  9048 sgd_solver.cpp:106] Iteration 1507, lr = 0.01
I0408 21:19:44.995194  9048 solver.cpp:240] Iteration 1508, loss = 12.9409
I0408 21:19:44.995231  9048 solver.cpp:256]     Train net output #0: loss = 12.9409 (* 1 = 12.9409 loss)
I0408 21:19:44.995242  9048 sgd_solver.cpp:106] Iteration 1508, lr = 0.01
I0408 21:19:45.271167  9048 solver.cpp:240] Iteration 1509, loss = 9.62977
I0408 21:19:45.271203  9048 solver.cpp:256]     Train net output #0: loss = 9.62976 (* 1 = 9.62976 loss)
I0408 21:19:45.271215  9048 sgd_solver.cpp:106] Iteration 1509, lr = 0.01
I0408 21:19:45.546875  9048 solver.cpp:240] Iteration 1510, loss = 29.6634
I0408 21:19:45.546911  9048 solver.cpp:256]     Train net output #0: loss = 29.6634 (* 1 = 29.6634 loss)
I0408 21:19:45.546922  9048 sgd_solver.cpp:106] Iteration 1510, lr = 0.01
I0408 21:19:45.822648  9048 solver.cpp:240] Iteration 1511, loss = 38.3207
I0408 21:19:45.822685  9048 solver.cpp:256]     Train net output #0: loss = 38.3206 (* 1 = 38.3206 loss)
I0408 21:19:45.822697  9048 sgd_solver.cpp:106] Iteration 1511, lr = 0.01
I0408 21:19:46.098932  9048 solver.cpp:240] Iteration 1512, loss = 15.245
I0408 21:19:46.098968  9048 solver.cpp:256]     Train net output #0: loss = 15.245 (* 1 = 15.245 loss)
I0408 21:19:46.098978  9048 sgd_solver.cpp:106] Iteration 1512, lr = 0.01
I0408 21:19:46.374640  9048 solver.cpp:240] Iteration 1513, loss = 2.18363
I0408 21:19:46.374701  9048 solver.cpp:256]     Train net output #0: loss = 2.18362 (* 1 = 2.18362 loss)
I0408 21:19:46.374709  9048 sgd_solver.cpp:106] Iteration 1513, lr = 0.01
I0408 21:19:46.649629  9048 solver.cpp:240] Iteration 1514, loss = 28.6266
I0408 21:19:46.649663  9048 solver.cpp:256]     Train net output #0: loss = 28.6266 (* 1 = 28.6266 loss)
I0408 21:19:46.649672  9048 sgd_solver.cpp:106] Iteration 1514, lr = 0.01
I0408 21:19:46.925792  9048 solver.cpp:240] Iteration 1515, loss = 20.3529
I0408 21:19:46.925825  9048 solver.cpp:256]     Train net output #0: loss = 20.3529 (* 1 = 20.3529 loss)
I0408 21:19:46.925834  9048 sgd_solver.cpp:106] Iteration 1515, lr = 0.01
I0408 21:19:47.201771  9048 solver.cpp:240] Iteration 1516, loss = 20.8847
I0408 21:19:47.201817  9048 solver.cpp:256]     Train net output #0: loss = 20.8847 (* 1 = 20.8847 loss)
I0408 21:19:47.201823  9048 sgd_solver.cpp:106] Iteration 1516, lr = 0.01
I0408 21:19:47.477452  9048 solver.cpp:240] Iteration 1517, loss = 21.3924
I0408 21:19:47.477502  9048 solver.cpp:256]     Train net output #0: loss = 21.3924 (* 1 = 21.3924 loss)
I0408 21:19:47.477512  9048 sgd_solver.cpp:106] Iteration 1517, lr = 0.01
I0408 21:19:47.753830  9048 solver.cpp:240] Iteration 1518, loss = 7.63567
I0408 21:19:47.753865  9048 solver.cpp:256]     Train net output #0: loss = 7.63566 (* 1 = 7.63566 loss)
I0408 21:19:47.753872  9048 sgd_solver.cpp:106] Iteration 1518, lr = 0.01
I0408 21:19:48.029420  9048 solver.cpp:240] Iteration 1519, loss = 26.2979
I0408 21:19:48.029464  9048 solver.cpp:256]     Train net output #0: loss = 26.2979 (* 1 = 26.2979 loss)
I0408 21:19:48.029472  9048 sgd_solver.cpp:106] Iteration 1519, lr = 0.01
I0408 21:19:48.305270  9048 solver.cpp:240] Iteration 1520, loss = 1.60944
I0408 21:19:48.305304  9048 solver.cpp:256]     Train net output #0: loss = 1.60944 (* 1 = 1.60944 loss)
I0408 21:19:48.305311  9048 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0408 21:19:48.581514  9048 solver.cpp:240] Iteration 1521, loss = 3.40507
I0408 21:19:48.581547  9048 solver.cpp:256]     Train net output #0: loss = 3.40506 (* 1 = 3.40506 loss)
I0408 21:19:48.581555  9048 sgd_solver.cpp:106] Iteration 1521, lr = 0.01
I0408 21:19:48.857972  9048 solver.cpp:240] Iteration 1522, loss = 18.9695
I0408 21:19:48.858023  9048 solver.cpp:256]     Train net output #0: loss = 18.9695 (* 1 = 18.9695 loss)
I0408 21:19:48.858033  9048 sgd_solver.cpp:106] Iteration 1522, lr = 0.01
I0408 21:19:49.135112  9048 solver.cpp:240] Iteration 1523, loss = 19.7655
I0408 21:19:49.135146  9048 solver.cpp:256]     Train net output #0: loss = 19.7655 (* 1 = 19.7655 loss)
I0408 21:19:49.135154  9048 sgd_solver.cpp:106] Iteration 1523, lr = 0.01
I0408 21:19:49.411296  9048 solver.cpp:240] Iteration 1524, loss = 20.2663
I0408 21:19:49.411330  9048 solver.cpp:256]     Train net output #0: loss = 20.2663 (* 1 = 20.2663 loss)
I0408 21:19:49.411339  9048 sgd_solver.cpp:106] Iteration 1524, lr = 0.01
I0408 21:19:49.686719  9048 solver.cpp:240] Iteration 1525, loss = 11.0613
I0408 21:19:49.686877  9048 solver.cpp:256]     Train net output #0: loss = 11.0612 (* 1 = 11.0612 loss)
I0408 21:19:49.686887  9048 sgd_solver.cpp:106] Iteration 1525, lr = 0.01
I0408 21:19:49.964558  9048 solver.cpp:240] Iteration 1526, loss = 2.32623
I0408 21:19:49.964601  9048 solver.cpp:256]     Train net output #0: loss = 2.32622 (* 1 = 2.32622 loss)
I0408 21:19:49.964608  9048 sgd_solver.cpp:106] Iteration 1526, lr = 0.01
I0408 21:19:50.238548  9048 solver.cpp:240] Iteration 1527, loss = 3.4493
I0408 21:19:50.238580  9048 solver.cpp:256]     Train net output #0: loss = 3.4493 (* 1 = 3.4493 loss)
I0408 21:19:50.238589  9048 sgd_solver.cpp:106] Iteration 1527, lr = 0.01
I0408 21:19:50.513769  9048 solver.cpp:240] Iteration 1528, loss = 16.1666
I0408 21:19:50.513816  9048 solver.cpp:256]     Train net output #0: loss = 16.1666 (* 1 = 16.1666 loss)
I0408 21:19:50.513825  9048 sgd_solver.cpp:106] Iteration 1528, lr = 0.01
I0408 21:19:50.790500  9048 solver.cpp:240] Iteration 1529, loss = 29.4461
I0408 21:19:50.790539  9048 solver.cpp:256]     Train net output #0: loss = 29.4461 (* 1 = 29.4461 loss)
I0408 21:19:50.790547  9048 sgd_solver.cpp:106] Iteration 1529, lr = 0.01
I0408 21:19:51.065390  9048 solver.cpp:240] Iteration 1530, loss = 41.0704
I0408 21:19:51.065423  9048 solver.cpp:256]     Train net output #0: loss = 41.0703 (* 1 = 41.0703 loss)
I0408 21:19:51.065431  9048 sgd_solver.cpp:106] Iteration 1530, lr = 0.01
I0408 21:19:51.341787  9048 solver.cpp:240] Iteration 1531, loss = 29.4168
I0408 21:19:51.341821  9048 solver.cpp:256]     Train net output #0: loss = 29.4168 (* 1 = 29.4168 loss)
I0408 21:19:51.341830  9048 sgd_solver.cpp:106] Iteration 1531, lr = 0.01
I0408 21:19:51.618002  9048 solver.cpp:240] Iteration 1532, loss = 32.6851
I0408 21:19:51.618036  9048 solver.cpp:256]     Train net output #0: loss = 32.6851 (* 1 = 32.6851 loss)
I0408 21:19:51.618043  9048 sgd_solver.cpp:106] Iteration 1532, lr = 0.01
I0408 21:19:51.893887  9048 solver.cpp:240] Iteration 1533, loss = 29.5673
I0408 21:19:51.893921  9048 solver.cpp:256]     Train net output #0: loss = 29.5673 (* 1 = 29.5673 loss)
I0408 21:19:51.893929  9048 sgd_solver.cpp:106] Iteration 1533, lr = 0.01
I0408 21:19:52.169885  9048 solver.cpp:240] Iteration 1534, loss = 35.6301
I0408 21:19:52.169917  9048 solver.cpp:256]     Train net output #0: loss = 35.6301 (* 1 = 35.6301 loss)
I0408 21:19:52.169925  9048 sgd_solver.cpp:106] Iteration 1534, lr = 0.01
I0408 21:19:52.444381  9048 solver.cpp:240] Iteration 1535, loss = 19.9239
I0408 21:19:52.444418  9048 solver.cpp:256]     Train net output #0: loss = 19.9239 (* 1 = 19.9239 loss)
I0408 21:19:52.444427  9048 sgd_solver.cpp:106] Iteration 1535, lr = 0.01
I0408 21:19:52.719921  9048 solver.cpp:240] Iteration 1536, loss = 9.75336
I0408 21:19:52.719954  9048 solver.cpp:256]     Train net output #0: loss = 9.75335 (* 1 = 9.75335 loss)
I0408 21:19:52.719962  9048 sgd_solver.cpp:106] Iteration 1536, lr = 0.01
I0408 21:19:52.995677  9048 solver.cpp:240] Iteration 1537, loss = 4.14133
I0408 21:19:52.995708  9048 solver.cpp:256]     Train net output #0: loss = 4.14132 (* 1 = 4.14132 loss)
I0408 21:19:52.995717  9048 sgd_solver.cpp:106] Iteration 1537, lr = 0.01
I0408 21:19:53.272795  9048 solver.cpp:240] Iteration 1538, loss = 3.06535
I0408 21:19:53.272826  9048 solver.cpp:256]     Train net output #0: loss = 3.06535 (* 1 = 3.06535 loss)
I0408 21:19:53.272835  9048 sgd_solver.cpp:106] Iteration 1538, lr = 0.01
I0408 21:19:53.549015  9048 solver.cpp:240] Iteration 1539, loss = 5.40469
I0408 21:19:53.549046  9048 solver.cpp:256]     Train net output #0: loss = 5.40469 (* 1 = 5.40469 loss)
I0408 21:19:53.549054  9048 sgd_solver.cpp:106] Iteration 1539, lr = 0.01
I0408 21:19:53.824815  9048 solver.cpp:240] Iteration 1540, loss = 3.61172
I0408 21:19:53.824854  9048 solver.cpp:256]     Train net output #0: loss = 3.61171 (* 1 = 3.61171 loss)
I0408 21:19:53.824863  9048 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0408 21:19:54.100857  9048 solver.cpp:240] Iteration 1541, loss = 7.32026
I0408 21:19:54.100888  9048 solver.cpp:256]     Train net output #0: loss = 7.32025 (* 1 = 7.32025 loss)
I0408 21:19:54.100927  9048 sgd_solver.cpp:106] Iteration 1541, lr = 0.01
I0408 21:19:54.375923  9048 solver.cpp:240] Iteration 1542, loss = 10.8894
I0408 21:19:54.375957  9048 solver.cpp:256]     Train net output #0: loss = 10.8894 (* 1 = 10.8894 loss)
I0408 21:19:54.375965  9048 sgd_solver.cpp:106] Iteration 1542, lr = 0.01
I0408 21:19:54.650754  9048 solver.cpp:240] Iteration 1543, loss = 8.70054
I0408 21:19:54.650785  9048 solver.cpp:256]     Train net output #0: loss = 8.70053 (* 1 = 8.70053 loss)
I0408 21:19:54.650794  9048 sgd_solver.cpp:106] Iteration 1543, lr = 0.01
I0408 21:19:54.925415  9048 solver.cpp:240] Iteration 1544, loss = 11.4414
I0408 21:19:54.925449  9048 solver.cpp:256]     Train net output #0: loss = 11.4414 (* 1 = 11.4414 loss)
I0408 21:19:54.925458  9048 sgd_solver.cpp:106] Iteration 1544, lr = 0.01
I0408 21:19:55.201056  9048 solver.cpp:240] Iteration 1545, loss = 13.9965
I0408 21:19:55.201093  9048 solver.cpp:256]     Train net output #0: loss = 13.9965 (* 1 = 13.9965 loss)
I0408 21:19:55.201102  9048 sgd_solver.cpp:106] Iteration 1545, lr = 0.01
I0408 21:19:55.477366  9048 solver.cpp:240] Iteration 1546, loss = 28.4052
I0408 21:19:55.477411  9048 solver.cpp:256]     Train net output #0: loss = 28.4052 (* 1 = 28.4052 loss)
I0408 21:19:55.477421  9048 sgd_solver.cpp:106] Iteration 1546, lr = 0.01
I0408 21:19:55.753265  9048 solver.cpp:240] Iteration 1547, loss = 14.7516
I0408 21:19:55.753301  9048 solver.cpp:256]     Train net output #0: loss = 14.7516 (* 1 = 14.7516 loss)
I0408 21:19:55.753309  9048 sgd_solver.cpp:106] Iteration 1547, lr = 0.01
I0408 21:19:56.029166  9048 solver.cpp:240] Iteration 1548, loss = 7.93738
I0408 21:19:56.029197  9048 solver.cpp:256]     Train net output #0: loss = 7.93737 (* 1 = 7.93737 loss)
I0408 21:19:56.029206  9048 sgd_solver.cpp:106] Iteration 1548, lr = 0.01
I0408 21:19:56.305995  9048 solver.cpp:240] Iteration 1549, loss = 10.7486
I0408 21:19:56.306035  9048 solver.cpp:256]     Train net output #0: loss = 10.7486 (* 1 = 10.7486 loss)
I0408 21:19:56.306046  9048 sgd_solver.cpp:106] Iteration 1549, lr = 0.01
I0408 21:19:56.582833  9048 solver.cpp:240] Iteration 1550, loss = 18.7725
I0408 21:19:56.582865  9048 solver.cpp:256]     Train net output #0: loss = 18.7725 (* 1 = 18.7725 loss)
I0408 21:19:56.582875  9048 sgd_solver.cpp:106] Iteration 1550, lr = 0.01
I0408 21:19:56.859238  9048 solver.cpp:240] Iteration 1551, loss = 13.3143
I0408 21:19:56.859272  9048 solver.cpp:256]     Train net output #0: loss = 13.3143 (* 1 = 13.3143 loss)
I0408 21:19:56.859282  9048 sgd_solver.cpp:106] Iteration 1551, lr = 0.01
I0408 21:19:57.135025  9048 solver.cpp:240] Iteration 1552, loss = 15.3424
I0408 21:19:57.135061  9048 solver.cpp:256]     Train net output #0: loss = 15.3424 (* 1 = 15.3424 loss)
I0408 21:19:57.135068  9048 sgd_solver.cpp:106] Iteration 1552, lr = 0.01
I0408 21:19:57.410773  9048 solver.cpp:240] Iteration 1553, loss = 10.8836
I0408 21:19:57.410806  9048 solver.cpp:256]     Train net output #0: loss = 10.8836 (* 1 = 10.8836 loss)
I0408 21:19:57.410815  9048 sgd_solver.cpp:106] Iteration 1553, lr = 0.01
I0408 21:19:57.686830  9048 solver.cpp:240] Iteration 1554, loss = 14.5511
I0408 21:19:57.686862  9048 solver.cpp:256]     Train net output #0: loss = 14.551 (* 1 = 14.551 loss)
I0408 21:19:57.686870  9048 sgd_solver.cpp:106] Iteration 1554, lr = 0.01
I0408 21:19:57.963057  9048 solver.cpp:240] Iteration 1555, loss = 14.079
I0408 21:19:57.963091  9048 solver.cpp:256]     Train net output #0: loss = 14.0789 (* 1 = 14.0789 loss)
I0408 21:19:57.963099  9048 sgd_solver.cpp:106] Iteration 1555, lr = 0.01
I0408 21:19:58.239923  9048 solver.cpp:240] Iteration 1556, loss = 9.08778
I0408 21:19:58.239959  9048 solver.cpp:256]     Train net output #0: loss = 9.08778 (* 1 = 9.08778 loss)
I0408 21:19:58.239966  9048 sgd_solver.cpp:106] Iteration 1556, lr = 0.01
I0408 21:19:58.516059  9048 solver.cpp:240] Iteration 1557, loss = 5.30941
I0408 21:19:58.516090  9048 solver.cpp:256]     Train net output #0: loss = 5.3094 (* 1 = 5.3094 loss)
I0408 21:19:58.516124  9048 sgd_solver.cpp:106] Iteration 1557, lr = 0.01
I0408 21:19:58.791772  9048 solver.cpp:240] Iteration 1558, loss = 2.66621
I0408 21:19:58.791808  9048 solver.cpp:256]     Train net output #0: loss = 2.66621 (* 1 = 2.66621 loss)
I0408 21:19:58.791817  9048 sgd_solver.cpp:106] Iteration 1558, lr = 0.01
I0408 21:19:59.068558  9048 solver.cpp:240] Iteration 1559, loss = 2.18932
I0408 21:19:59.068589  9048 solver.cpp:256]     Train net output #0: loss = 2.18931 (* 1 = 2.18931 loss)
I0408 21:19:59.068598  9048 sgd_solver.cpp:106] Iteration 1559, lr = 0.01
I0408 21:19:59.344616  9048 solver.cpp:240] Iteration 1560, loss = 34.555
I0408 21:19:59.344655  9048 solver.cpp:256]     Train net output #0: loss = 34.555 (* 1 = 34.555 loss)
I0408 21:19:59.344662  9048 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0408 21:19:59.620508  9048 solver.cpp:240] Iteration 1561, loss = 21.8727
I0408 21:19:59.620543  9048 solver.cpp:256]     Train net output #0: loss = 21.8727 (* 1 = 21.8727 loss)
I0408 21:19:59.620550  9048 sgd_solver.cpp:106] Iteration 1561, lr = 0.01
I0408 21:19:59.896049  9048 solver.cpp:240] Iteration 1562, loss = 26.6827
I0408 21:19:59.896082  9048 solver.cpp:256]     Train net output #0: loss = 26.6827 (* 1 = 26.6827 loss)
I0408 21:19:59.896090  9048 sgd_solver.cpp:106] Iteration 1562, lr = 0.01
I0408 21:20:00.172518  9048 solver.cpp:240] Iteration 1563, loss = 23.5682
I0408 21:20:00.172559  9048 solver.cpp:256]     Train net output #0: loss = 23.5682 (* 1 = 23.5682 loss)
I0408 21:20:00.172566  9048 sgd_solver.cpp:106] Iteration 1563, lr = 0.01
I0408 21:20:00.449235  9048 solver.cpp:240] Iteration 1564, loss = 19.8229
I0408 21:20:00.449270  9048 solver.cpp:256]     Train net output #0: loss = 19.8229 (* 1 = 19.8229 loss)
I0408 21:20:00.449278  9048 sgd_solver.cpp:106] Iteration 1564, lr = 0.01
I0408 21:20:00.725651  9048 solver.cpp:240] Iteration 1565, loss = 29.6163
I0408 21:20:00.725684  9048 solver.cpp:256]     Train net output #0: loss = 29.6163 (* 1 = 29.6163 loss)
I0408 21:20:00.725693  9048 sgd_solver.cpp:106] Iteration 1565, lr = 0.01
I0408 21:20:01.002316  9048 solver.cpp:240] Iteration 1566, loss = 27.756
I0408 21:20:01.002351  9048 solver.cpp:256]     Train net output #0: loss = 27.756 (* 1 = 27.756 loss)
I0408 21:20:01.002359  9048 sgd_solver.cpp:106] Iteration 1566, lr = 0.01
I0408 21:20:01.278041  9048 solver.cpp:240] Iteration 1567, loss = 31.2197
I0408 21:20:01.278074  9048 solver.cpp:256]     Train net output #0: loss = 31.2197 (* 1 = 31.2197 loss)
I0408 21:20:01.278081  9048 sgd_solver.cpp:106] Iteration 1567, lr = 0.01
I0408 21:20:01.554625  9048 solver.cpp:240] Iteration 1568, loss = 22.0941
I0408 21:20:01.554677  9048 solver.cpp:256]     Train net output #0: loss = 22.0941 (* 1 = 22.0941 loss)
I0408 21:20:01.554685  9048 sgd_solver.cpp:106] Iteration 1568, lr = 0.01
I0408 21:20:01.830929  9048 solver.cpp:240] Iteration 1569, loss = 16.0027
I0408 21:20:01.830963  9048 solver.cpp:256]     Train net output #0: loss = 16.0027 (* 1 = 16.0027 loss)
I0408 21:20:01.830971  9048 sgd_solver.cpp:106] Iteration 1569, lr = 0.01
I0408 21:20:02.106371  9048 solver.cpp:240] Iteration 1570, loss = 13.0313
I0408 21:20:02.106417  9048 solver.cpp:256]     Train net output #0: loss = 13.0313 (* 1 = 13.0313 loss)
I0408 21:20:02.106426  9048 sgd_solver.cpp:106] Iteration 1570, lr = 0.01
I0408 21:20:02.382444  9048 solver.cpp:240] Iteration 1571, loss = 8.66046
I0408 21:20:02.382478  9048 solver.cpp:256]     Train net output #0: loss = 8.66045 (* 1 = 8.66045 loss)
I0408 21:20:02.382485  9048 sgd_solver.cpp:106] Iteration 1571, lr = 0.01
I0408 21:20:02.658061  9048 solver.cpp:240] Iteration 1572, loss = 21.2811
I0408 21:20:02.658097  9048 solver.cpp:256]     Train net output #0: loss = 21.2811 (* 1 = 21.2811 loss)
I0408 21:20:02.658105  9048 sgd_solver.cpp:106] Iteration 1572, lr = 0.01
I0408 21:20:02.934336  9048 solver.cpp:240] Iteration 1573, loss = 22.9381
I0408 21:20:02.934368  9048 solver.cpp:256]     Train net output #0: loss = 22.9381 (* 1 = 22.9381 loss)
I0408 21:20:02.934376  9048 sgd_solver.cpp:106] Iteration 1573, lr = 0.01
I0408 21:20:03.209687  9048 solver.cpp:240] Iteration 1574, loss = 17.6565
I0408 21:20:03.209722  9048 solver.cpp:256]     Train net output #0: loss = 17.6565 (* 1 = 17.6565 loss)
I0408 21:20:03.209731  9048 sgd_solver.cpp:106] Iteration 1574, lr = 0.01
I0408 21:20:03.485617  9048 solver.cpp:240] Iteration 1575, loss = 16.6591
I0408 21:20:03.485652  9048 solver.cpp:256]     Train net output #0: loss = 16.659 (* 1 = 16.659 loss)
I0408 21:20:03.485661  9048 sgd_solver.cpp:106] Iteration 1575, lr = 0.01
I0408 21:20:03.761261  9048 solver.cpp:240] Iteration 1576, loss = 16.6449
I0408 21:20:03.761298  9048 solver.cpp:256]     Train net output #0: loss = 16.6449 (* 1 = 16.6449 loss)
I0408 21:20:03.761307  9048 sgd_solver.cpp:106] Iteration 1576, lr = 0.01
I0408 21:20:04.037776  9048 solver.cpp:240] Iteration 1577, loss = 23.9067
I0408 21:20:04.037811  9048 solver.cpp:256]     Train net output #0: loss = 23.9067 (* 1 = 23.9067 loss)
I0408 21:20:04.037819  9048 sgd_solver.cpp:106] Iteration 1577, lr = 0.01
I0408 21:20:04.314209  9048 solver.cpp:240] Iteration 1578, loss = 33.3198
I0408 21:20:04.314244  9048 solver.cpp:256]     Train net output #0: loss = 33.3198 (* 1 = 33.3198 loss)
I0408 21:20:04.314252  9048 sgd_solver.cpp:106] Iteration 1578, lr = 0.01
I0408 21:20:04.589699  9048 solver.cpp:240] Iteration 1579, loss = 17.5019
I0408 21:20:04.589733  9048 solver.cpp:256]     Train net output #0: loss = 17.5019 (* 1 = 17.5019 loss)
I0408 21:20:04.589742  9048 sgd_solver.cpp:106] Iteration 1579, lr = 0.01
I0408 21:20:04.865939  9048 solver.cpp:240] Iteration 1580, loss = 8.93336
I0408 21:20:04.865975  9048 solver.cpp:256]     Train net output #0: loss = 8.93335 (* 1 = 8.93335 loss)
I0408 21:20:04.865983  9048 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0408 21:20:05.143291  9048 solver.cpp:240] Iteration 1581, loss = 8.44064
I0408 21:20:05.143323  9048 solver.cpp:256]     Train net output #0: loss = 8.44063 (* 1 = 8.44063 loss)
I0408 21:20:05.143332  9048 sgd_solver.cpp:106] Iteration 1581, lr = 0.01
I0408 21:20:05.418777  9048 solver.cpp:240] Iteration 1582, loss = 4.23061
I0408 21:20:05.418815  9048 solver.cpp:256]     Train net output #0: loss = 4.2306 (* 1 = 4.2306 loss)
I0408 21:20:05.418824  9048 sgd_solver.cpp:106] Iteration 1582, lr = 0.01
I0408 21:20:05.694957  9048 solver.cpp:240] Iteration 1583, loss = 4.16678
I0408 21:20:05.694993  9048 solver.cpp:256]     Train net output #0: loss = 4.16677 (* 1 = 4.16677 loss)
I0408 21:20:05.695000  9048 sgd_solver.cpp:106] Iteration 1583, lr = 0.01
I0408 21:20:05.971287  9048 solver.cpp:240] Iteration 1584, loss = 7.56338
I0408 21:20:05.971320  9048 solver.cpp:256]     Train net output #0: loss = 7.56337 (* 1 = 7.56337 loss)
I0408 21:20:05.971328  9048 sgd_solver.cpp:106] Iteration 1584, lr = 0.01
I0408 21:20:06.247805  9048 solver.cpp:240] Iteration 1585, loss = 11.8148
I0408 21:20:06.247840  9048 solver.cpp:256]     Train net output #0: loss = 11.8148 (* 1 = 11.8148 loss)
I0408 21:20:06.247848  9048 sgd_solver.cpp:106] Iteration 1585, lr = 0.01
I0408 21:20:06.525110  9048 solver.cpp:240] Iteration 1586, loss = 18.226
I0408 21:20:06.525143  9048 solver.cpp:256]     Train net output #0: loss = 18.226 (* 1 = 18.226 loss)
I0408 21:20:06.525151  9048 sgd_solver.cpp:106] Iteration 1586, lr = 0.01
I0408 21:20:06.800871  9048 solver.cpp:240] Iteration 1587, loss = 12.2365
I0408 21:20:06.800915  9048 solver.cpp:256]     Train net output #0: loss = 12.2365 (* 1 = 12.2365 loss)
I0408 21:20:06.800923  9048 sgd_solver.cpp:106] Iteration 1587, lr = 0.01
I0408 21:20:07.075412  9048 solver.cpp:240] Iteration 1588, loss = 37.7024
I0408 21:20:07.075445  9048 solver.cpp:256]     Train net output #0: loss = 37.7024 (* 1 = 37.7024 loss)
I0408 21:20:07.075454  9048 sgd_solver.cpp:106] Iteration 1588, lr = 0.01
I0408 21:20:07.351366  9048 solver.cpp:240] Iteration 1589, loss = 25.9366
I0408 21:20:07.351404  9048 solver.cpp:256]     Train net output #0: loss = 25.9366 (* 1 = 25.9366 loss)
I0408 21:20:07.351413  9048 sgd_solver.cpp:106] Iteration 1589, lr = 0.01
I0408 21:20:07.627254  9048 solver.cpp:240] Iteration 1590, loss = 5.02208
I0408 21:20:07.627297  9048 solver.cpp:256]     Train net output #0: loss = 5.02207 (* 1 = 5.02207 loss)
I0408 21:20:07.627305  9048 sgd_solver.cpp:106] Iteration 1590, lr = 0.01
I0408 21:20:07.903369  9048 solver.cpp:240] Iteration 1591, loss = 11.9827
I0408 21:20:07.903403  9048 solver.cpp:256]     Train net output #0: loss = 11.9827 (* 1 = 11.9827 loss)
I0408 21:20:07.903411  9048 sgd_solver.cpp:106] Iteration 1591, lr = 0.01
I0408 21:20:08.178704  9048 solver.cpp:240] Iteration 1592, loss = 8.5604
I0408 21:20:08.178736  9048 solver.cpp:256]     Train net output #0: loss = 8.56039 (* 1 = 8.56039 loss)
I0408 21:20:08.178745  9048 sgd_solver.cpp:106] Iteration 1592, lr = 0.01
I0408 21:20:08.455386  9048 solver.cpp:240] Iteration 1593, loss = 9.7
I0408 21:20:08.455432  9048 solver.cpp:256]     Train net output #0: loss = 9.7 (* 1 = 9.7 loss)
I0408 21:20:08.455440  9048 sgd_solver.cpp:106] Iteration 1593, lr = 0.01
I0408 21:20:08.731181  9048 solver.cpp:240] Iteration 1594, loss = 12.2987
I0408 21:20:08.731221  9048 solver.cpp:256]     Train net output #0: loss = 12.2987 (* 1 = 12.2987 loss)
I0408 21:20:08.731230  9048 sgd_solver.cpp:106] Iteration 1594, lr = 0.01
I0408 21:20:09.007376  9048 solver.cpp:240] Iteration 1595, loss = 17.6249
I0408 21:20:09.007422  9048 solver.cpp:256]     Train net output #0: loss = 17.6249 (* 1 = 17.6249 loss)
I0408 21:20:09.007432  9048 sgd_solver.cpp:106] Iteration 1595, lr = 0.01
I0408 21:20:09.283164  9048 solver.cpp:240] Iteration 1596, loss = 18.6262
I0408 21:20:09.283198  9048 solver.cpp:256]     Train net output #0: loss = 18.6262 (* 1 = 18.6262 loss)
I0408 21:20:09.283207  9048 sgd_solver.cpp:106] Iteration 1596, lr = 0.01
I0408 21:20:09.558702  9048 solver.cpp:240] Iteration 1597, loss = 22.3677
I0408 21:20:09.558737  9048 solver.cpp:256]     Train net output #0: loss = 22.3677 (* 1 = 22.3677 loss)
I0408 21:20:09.558745  9048 sgd_solver.cpp:106] Iteration 1597, lr = 0.01
I0408 21:20:09.834882  9048 solver.cpp:240] Iteration 1598, loss = 25.0158
I0408 21:20:09.834915  9048 solver.cpp:256]     Train net output #0: loss = 25.0158 (* 1 = 25.0158 loss)
I0408 21:20:09.834923  9048 sgd_solver.cpp:106] Iteration 1598, lr = 0.01
I0408 21:20:10.110743  9048 solver.cpp:240] Iteration 1599, loss = 30.8896
I0408 21:20:10.110780  9048 solver.cpp:256]     Train net output #0: loss = 30.8896 (* 1 = 30.8896 loss)
I0408 21:20:10.110790  9048 sgd_solver.cpp:106] Iteration 1599, lr = 0.01
I0408 21:20:10.385958  9048 solver.cpp:240] Iteration 1600, loss = 31.4233
I0408 21:20:10.385992  9048 solver.cpp:256]     Train net output #0: loss = 31.4233 (* 1 = 31.4233 loss)
I0408 21:20:10.385999  9048 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0408 21:20:10.662540  9048 solver.cpp:240] Iteration 1601, loss = 13.6842
I0408 21:20:10.662573  9048 solver.cpp:256]     Train net output #0: loss = 13.6842 (* 1 = 13.6842 loss)
I0408 21:20:10.662582  9048 sgd_solver.cpp:106] Iteration 1601, lr = 0.01
I0408 21:20:10.938452  9048 solver.cpp:240] Iteration 1602, loss = 7.89914
I0408 21:20:10.938484  9048 solver.cpp:256]     Train net output #0: loss = 7.89913 (* 1 = 7.89913 loss)
I0408 21:20:10.938491  9048 sgd_solver.cpp:106] Iteration 1602, lr = 0.01
I0408 21:20:11.214617  9048 solver.cpp:240] Iteration 1603, loss = 7.62038
I0408 21:20:11.214648  9048 solver.cpp:256]     Train net output #0: loss = 7.62037 (* 1 = 7.62037 loss)
I0408 21:20:11.214656  9048 sgd_solver.cpp:106] Iteration 1603, lr = 0.01
I0408 21:20:11.490393  9048 solver.cpp:240] Iteration 1604, loss = 26.6905
I0408 21:20:11.490427  9048 solver.cpp:256]     Train net output #0: loss = 26.6904 (* 1 = 26.6904 loss)
I0408 21:20:11.490437  9048 sgd_solver.cpp:106] Iteration 1604, lr = 0.01
I0408 21:20:11.766852  9048 solver.cpp:240] Iteration 1605, loss = 25.0387
I0408 21:20:11.766896  9048 solver.cpp:256]     Train net output #0: loss = 25.0387 (* 1 = 25.0387 loss)
I0408 21:20:11.766904  9048 sgd_solver.cpp:106] Iteration 1605, lr = 0.01
I0408 21:20:12.043802  9048 solver.cpp:240] Iteration 1606, loss = 10.5644
I0408 21:20:12.043866  9048 solver.cpp:256]     Train net output #0: loss = 10.5644 (* 1 = 10.5644 loss)
I0408 21:20:12.043875  9048 sgd_solver.cpp:106] Iteration 1606, lr = 0.01
I0408 21:20:12.319630  9048 solver.cpp:240] Iteration 1607, loss = 27.1297
I0408 21:20:12.319669  9048 solver.cpp:256]     Train net output #0: loss = 27.1297 (* 1 = 27.1297 loss)
I0408 21:20:12.319679  9048 sgd_solver.cpp:106] Iteration 1607, lr = 0.01
I0408 21:20:12.595522  9048 solver.cpp:240] Iteration 1608, loss = 13.8289
I0408 21:20:12.595556  9048 solver.cpp:256]     Train net output #0: loss = 13.8289 (* 1 = 13.8289 loss)
I0408 21:20:12.595566  9048 sgd_solver.cpp:106] Iteration 1608, lr = 0.01
I0408 21:20:12.871763  9048 solver.cpp:240] Iteration 1609, loss = 11.8156
I0408 21:20:12.871810  9048 solver.cpp:256]     Train net output #0: loss = 11.8155 (* 1 = 11.8155 loss)
I0408 21:20:12.871819  9048 sgd_solver.cpp:106] Iteration 1609, lr = 0.01
I0408 21:20:13.147166  9048 solver.cpp:240] Iteration 1610, loss = 18.8441
I0408 21:20:13.147200  9048 solver.cpp:256]     Train net output #0: loss = 18.8441 (* 1 = 18.8441 loss)
I0408 21:20:13.147208  9048 sgd_solver.cpp:106] Iteration 1610, lr = 0.01
I0408 21:20:13.423221  9048 solver.cpp:240] Iteration 1611, loss = 8.32876
I0408 21:20:13.423254  9048 solver.cpp:256]     Train net output #0: loss = 8.32875 (* 1 = 8.32875 loss)
I0408 21:20:13.423261  9048 sgd_solver.cpp:106] Iteration 1611, lr = 0.01
I0408 21:20:13.697752  9048 solver.cpp:240] Iteration 1612, loss = 4.06315
I0408 21:20:13.697784  9048 solver.cpp:256]     Train net output #0: loss = 4.06314 (* 1 = 4.06314 loss)
I0408 21:20:13.697793  9048 sgd_solver.cpp:106] Iteration 1612, lr = 0.01
I0408 21:20:13.973862  9048 solver.cpp:240] Iteration 1613, loss = 3.26304
I0408 21:20:13.973896  9048 solver.cpp:256]     Train net output #0: loss = 3.26303 (* 1 = 3.26303 loss)
I0408 21:20:13.973903  9048 sgd_solver.cpp:106] Iteration 1613, lr = 0.01
I0408 21:20:14.250321  9048 solver.cpp:240] Iteration 1614, loss = 10.2866
I0408 21:20:14.250355  9048 solver.cpp:256]     Train net output #0: loss = 10.2866 (* 1 = 10.2866 loss)
I0408 21:20:14.250365  9048 sgd_solver.cpp:106] Iteration 1614, lr = 0.01
I0408 21:20:14.526221  9048 solver.cpp:240] Iteration 1615, loss = 17.8754
I0408 21:20:14.526255  9048 solver.cpp:256]     Train net output #0: loss = 17.8754 (* 1 = 17.8754 loss)
I0408 21:20:14.526264  9048 sgd_solver.cpp:106] Iteration 1615, lr = 0.01
I0408 21:20:14.800930  9048 solver.cpp:240] Iteration 1616, loss = 34.4236
I0408 21:20:14.800976  9048 solver.cpp:256]     Train net output #0: loss = 34.4236 (* 1 = 34.4236 loss)
I0408 21:20:14.800983  9048 sgd_solver.cpp:106] Iteration 1616, lr = 0.01
I0408 21:20:15.076407  9048 solver.cpp:240] Iteration 1617, loss = 31.1958
I0408 21:20:15.076445  9048 solver.cpp:256]     Train net output #0: loss = 31.1957 (* 1 = 31.1957 loss)
I0408 21:20:15.076453  9048 sgd_solver.cpp:106] Iteration 1617, lr = 0.01
I0408 21:20:15.352218  9048 solver.cpp:240] Iteration 1618, loss = 28.1808
I0408 21:20:15.352252  9048 solver.cpp:256]     Train net output #0: loss = 28.1808 (* 1 = 28.1808 loss)
I0408 21:20:15.352260  9048 sgd_solver.cpp:106] Iteration 1618, lr = 0.01
I0408 21:20:15.627946  9048 solver.cpp:240] Iteration 1619, loss = 25.3821
I0408 21:20:15.627980  9048 solver.cpp:256]     Train net output #0: loss = 25.3821 (* 1 = 25.3821 loss)
I0408 21:20:15.627988  9048 sgd_solver.cpp:106] Iteration 1619, lr = 0.01
I0408 21:20:15.903847  9048 solver.cpp:240] Iteration 1620, loss = 28.4386
I0408 21:20:15.903895  9048 solver.cpp:256]     Train net output #0: loss = 28.4386 (* 1 = 28.4386 loss)
I0408 21:20:15.903904  9048 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0408 21:20:16.179118  9048 solver.cpp:240] Iteration 1621, loss = 12.0451
I0408 21:20:16.179162  9048 solver.cpp:256]     Train net output #0: loss = 12.0451 (* 1 = 12.0451 loss)
I0408 21:20:16.179170  9048 sgd_solver.cpp:106] Iteration 1621, lr = 0.01
I0408 21:20:16.454865  9048 solver.cpp:240] Iteration 1622, loss = 26.5288
I0408 21:20:16.454924  9048 solver.cpp:256]     Train net output #0: loss = 26.5288 (* 1 = 26.5288 loss)
I0408 21:20:16.454933  9048 sgd_solver.cpp:106] Iteration 1622, lr = 0.01
I0408 21:20:16.730994  9048 solver.cpp:240] Iteration 1623, loss = 7.97834
I0408 21:20:16.731039  9048 solver.cpp:256]     Train net output #0: loss = 7.97834 (* 1 = 7.97834 loss)
I0408 21:20:16.731046  9048 sgd_solver.cpp:106] Iteration 1623, lr = 0.01
I0408 21:20:17.006276  9048 solver.cpp:240] Iteration 1624, loss = 12.4678
I0408 21:20:17.006325  9048 solver.cpp:256]     Train net output #0: loss = 12.4678 (* 1 = 12.4678 loss)
I0408 21:20:17.006332  9048 sgd_solver.cpp:106] Iteration 1624, lr = 0.01
I0408 21:20:17.280694  9048 solver.cpp:240] Iteration 1625, loss = 24.5625
I0408 21:20:17.280726  9048 solver.cpp:256]     Train net output #0: loss = 24.5624 (* 1 = 24.5624 loss)
I0408 21:20:17.280745  9048 sgd_solver.cpp:106] Iteration 1625, lr = 0.01
I0408 21:20:17.555431  9048 solver.cpp:240] Iteration 1626, loss = 24.6984
I0408 21:20:17.555466  9048 solver.cpp:256]     Train net output #0: loss = 24.6984 (* 1 = 24.6984 loss)
I0408 21:20:17.555475  9048 sgd_solver.cpp:106] Iteration 1626, lr = 0.01
I0408 21:20:17.831050  9048 solver.cpp:240] Iteration 1627, loss = 27.6696
I0408 21:20:17.831084  9048 solver.cpp:256]     Train net output #0: loss = 27.6696 (* 1 = 27.6696 loss)
I0408 21:20:17.831094  9048 sgd_solver.cpp:106] Iteration 1627, lr = 0.01
I0408 21:20:18.106604  9048 solver.cpp:240] Iteration 1628, loss = 15.9408
I0408 21:20:18.106638  9048 solver.cpp:256]     Train net output #0: loss = 15.9408 (* 1 = 15.9408 loss)
I0408 21:20:18.106647  9048 sgd_solver.cpp:106] Iteration 1628, lr = 0.01
I0408 21:20:18.381386  9048 solver.cpp:240] Iteration 1629, loss = 20.7408
I0408 21:20:18.381433  9048 solver.cpp:256]     Train net output #0: loss = 20.7408 (* 1 = 20.7408 loss)
I0408 21:20:18.381441  9048 sgd_solver.cpp:106] Iteration 1629, lr = 0.01
I0408 21:20:18.656286  9048 solver.cpp:240] Iteration 1630, loss = 18.9799
I0408 21:20:18.656332  9048 solver.cpp:256]     Train net output #0: loss = 18.9799 (* 1 = 18.9799 loss)
I0408 21:20:18.656339  9048 sgd_solver.cpp:106] Iteration 1630, lr = 0.01
I0408 21:20:18.930711  9048 solver.cpp:240] Iteration 1631, loss = 35.3632
I0408 21:20:18.930768  9048 solver.cpp:256]     Train net output #0: loss = 35.3632 (* 1 = 35.3632 loss)
I0408 21:20:18.930778  9048 sgd_solver.cpp:106] Iteration 1631, lr = 0.01
I0408 21:20:19.205868  9048 solver.cpp:240] Iteration 1632, loss = 30.5774
I0408 21:20:19.205901  9048 solver.cpp:256]     Train net output #0: loss = 30.5774 (* 1 = 30.5774 loss)
I0408 21:20:19.205909  9048 sgd_solver.cpp:106] Iteration 1632, lr = 0.01
I0408 21:20:19.481343  9048 solver.cpp:240] Iteration 1633, loss = 19.913
I0408 21:20:19.481376  9048 solver.cpp:256]     Train net output #0: loss = 19.913 (* 1 = 19.913 loss)
I0408 21:20:19.481385  9048 sgd_solver.cpp:106] Iteration 1633, lr = 0.01
I0408 21:20:19.757730  9048 solver.cpp:240] Iteration 1634, loss = 23.2567
I0408 21:20:19.758000  9048 solver.cpp:256]     Train net output #0: loss = 23.2567 (* 1 = 23.2567 loss)
I0408 21:20:19.758011  9048 sgd_solver.cpp:106] Iteration 1634, lr = 0.01
I0408 21:20:20.034639  9048 solver.cpp:240] Iteration 1635, loss = 18.7711
I0408 21:20:20.034673  9048 solver.cpp:256]     Train net output #0: loss = 18.771 (* 1 = 18.771 loss)
I0408 21:20:20.034682  9048 sgd_solver.cpp:106] Iteration 1635, lr = 0.01
I0408 21:20:20.308935  9048 solver.cpp:240] Iteration 1636, loss = 11.9515
I0408 21:20:20.308974  9048 solver.cpp:256]     Train net output #0: loss = 11.9515 (* 1 = 11.9515 loss)
I0408 21:20:20.308984  9048 sgd_solver.cpp:106] Iteration 1636, lr = 0.01
I0408 21:20:20.585649  9048 solver.cpp:240] Iteration 1637, loss = 7.18126
I0408 21:20:20.585683  9048 solver.cpp:256]     Train net output #0: loss = 7.18125 (* 1 = 7.18125 loss)
I0408 21:20:20.585691  9048 sgd_solver.cpp:106] Iteration 1637, lr = 0.01
I0408 21:20:20.861191  9048 solver.cpp:240] Iteration 1638, loss = 9.89825
I0408 21:20:20.861224  9048 solver.cpp:256]     Train net output #0: loss = 9.89824 (* 1 = 9.89824 loss)
I0408 21:20:20.861232  9048 sgd_solver.cpp:106] Iteration 1638, lr = 0.01
I0408 21:20:21.135254  9048 solver.cpp:240] Iteration 1639, loss = 15.1265
I0408 21:20:21.135293  9048 solver.cpp:256]     Train net output #0: loss = 15.1264 (* 1 = 15.1264 loss)
I0408 21:20:21.135303  9048 sgd_solver.cpp:106] Iteration 1639, lr = 0.01
I0408 21:20:21.410125  9048 solver.cpp:240] Iteration 1640, loss = 11.3169
I0408 21:20:21.410171  9048 solver.cpp:256]     Train net output #0: loss = 11.3169 (* 1 = 11.3169 loss)
I0408 21:20:21.410179  9048 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0408 21:20:21.684986  9048 solver.cpp:240] Iteration 1641, loss = 5.6308
I0408 21:20:21.685034  9048 solver.cpp:256]     Train net output #0: loss = 5.63079 (* 1 = 5.63079 loss)
I0408 21:20:21.685042  9048 sgd_solver.cpp:106] Iteration 1641, lr = 0.01
I0408 21:20:21.959233  9048 solver.cpp:240] Iteration 1642, loss = 1.5515
I0408 21:20:21.959266  9048 solver.cpp:256]     Train net output #0: loss = 1.55149 (* 1 = 1.55149 loss)
I0408 21:20:21.959275  9048 sgd_solver.cpp:106] Iteration 1642, lr = 0.01
I0408 21:20:22.234701  9048 solver.cpp:240] Iteration 1643, loss = 1.59495
I0408 21:20:22.234733  9048 solver.cpp:256]     Train net output #0: loss = 1.59494 (* 1 = 1.59494 loss)
I0408 21:20:22.234741  9048 sgd_solver.cpp:106] Iteration 1643, lr = 0.01
I0408 21:20:22.509591  9048 solver.cpp:240] Iteration 1644, loss = 1.57833
I0408 21:20:22.509624  9048 solver.cpp:256]     Train net output #0: loss = 1.57833 (* 1 = 1.57833 loss)
I0408 21:20:22.509632  9048 sgd_solver.cpp:106] Iteration 1644, lr = 0.01
I0408 21:20:22.784682  9048 solver.cpp:240] Iteration 1645, loss = 8.5283
I0408 21:20:22.784716  9048 solver.cpp:256]     Train net output #0: loss = 8.5283 (* 1 = 8.5283 loss)
I0408 21:20:22.784724  9048 sgd_solver.cpp:106] Iteration 1645, lr = 0.01
I0408 21:20:23.059453  9048 solver.cpp:240] Iteration 1646, loss = 4.98775
I0408 21:20:23.059489  9048 solver.cpp:256]     Train net output #0: loss = 4.98774 (* 1 = 4.98774 loss)
I0408 21:20:23.059499  9048 sgd_solver.cpp:106] Iteration 1646, lr = 0.01
I0408 21:20:23.333426  9048 solver.cpp:240] Iteration 1647, loss = 21.9762
I0408 21:20:23.333461  9048 solver.cpp:256]     Train net output #0: loss = 21.9762 (* 1 = 21.9762 loss)
I0408 21:20:23.333469  9048 sgd_solver.cpp:106] Iteration 1647, lr = 0.01
I0408 21:20:23.608127  9048 solver.cpp:240] Iteration 1648, loss = 23.0311
I0408 21:20:23.608168  9048 solver.cpp:256]     Train net output #0: loss = 23.0311 (* 1 = 23.0311 loss)
I0408 21:20:23.608177  9048 sgd_solver.cpp:106] Iteration 1648, lr = 0.01
I0408 21:20:23.883083  9048 solver.cpp:240] Iteration 1649, loss = 36.042
I0408 21:20:23.883118  9048 solver.cpp:256]     Train net output #0: loss = 36.042 (* 1 = 36.042 loss)
I0408 21:20:23.883127  9048 sgd_solver.cpp:106] Iteration 1649, lr = 0.01
I0408 21:20:24.157853  9048 solver.cpp:240] Iteration 1650, loss = 15.4835
I0408 21:20:24.157888  9048 solver.cpp:256]     Train net output #0: loss = 15.4835 (* 1 = 15.4835 loss)
I0408 21:20:24.157922  9048 sgd_solver.cpp:106] Iteration 1650, lr = 0.01
I0408 21:20:24.433873  9048 solver.cpp:240] Iteration 1651, loss = 9.74279
I0408 21:20:24.433907  9048 solver.cpp:256]     Train net output #0: loss = 9.74278 (* 1 = 9.74278 loss)
I0408 21:20:24.433914  9048 sgd_solver.cpp:106] Iteration 1651, lr = 0.01
I0408 21:20:24.709581  9048 solver.cpp:240] Iteration 1652, loss = 2.89568
I0408 21:20:24.709619  9048 solver.cpp:256]     Train net output #0: loss = 2.89567 (* 1 = 2.89567 loss)
I0408 21:20:24.709626  9048 sgd_solver.cpp:106] Iteration 1652, lr = 0.01
I0408 21:20:24.984885  9048 solver.cpp:240] Iteration 1653, loss = 12.8632
I0408 21:20:24.984925  9048 solver.cpp:256]     Train net output #0: loss = 12.8632 (* 1 = 12.8632 loss)
I0408 21:20:24.984935  9048 sgd_solver.cpp:106] Iteration 1653, lr = 0.01
I0408 21:20:25.259613  9048 solver.cpp:240] Iteration 1654, loss = 16.7868
I0408 21:20:25.259655  9048 solver.cpp:256]     Train net output #0: loss = 16.7868 (* 1 = 16.7868 loss)
I0408 21:20:25.259665  9048 sgd_solver.cpp:106] Iteration 1654, lr = 0.01
I0408 21:20:25.535092  9048 solver.cpp:240] Iteration 1655, loss = 20.3113
I0408 21:20:25.535126  9048 solver.cpp:256]     Train net output #0: loss = 20.3113 (* 1 = 20.3113 loss)
I0408 21:20:25.535135  9048 sgd_solver.cpp:106] Iteration 1655, lr = 0.01
I0408 21:20:25.810255  9048 solver.cpp:240] Iteration 1656, loss = 31.6784
I0408 21:20:25.810290  9048 solver.cpp:256]     Train net output #0: loss = 31.6784 (* 1 = 31.6784 loss)
I0408 21:20:25.810299  9048 sgd_solver.cpp:106] Iteration 1656, lr = 0.01
I0408 21:20:26.085193  9048 solver.cpp:240] Iteration 1657, loss = 27.1445
I0408 21:20:26.085228  9048 solver.cpp:256]     Train net output #0: loss = 27.1445 (* 1 = 27.1445 loss)
I0408 21:20:26.085237  9048 sgd_solver.cpp:106] Iteration 1657, lr = 0.01
I0408 21:20:26.361227  9048 solver.cpp:240] Iteration 1658, loss = 32.3223
I0408 21:20:26.361266  9048 solver.cpp:256]     Train net output #0: loss = 32.3223 (* 1 = 32.3223 loss)
I0408 21:20:26.361274  9048 sgd_solver.cpp:106] Iteration 1658, lr = 0.01
I0408 21:20:26.636663  9048 solver.cpp:240] Iteration 1659, loss = 14.9879
I0408 21:20:26.636698  9048 solver.cpp:256]     Train net output #0: loss = 14.9879 (* 1 = 14.9879 loss)
I0408 21:20:26.636708  9048 sgd_solver.cpp:106] Iteration 1659, lr = 0.01
I0408 21:20:26.911532  9048 solver.cpp:240] Iteration 1660, loss = 30.703
I0408 21:20:26.911567  9048 solver.cpp:256]     Train net output #0: loss = 30.703 (* 1 = 30.703 loss)
I0408 21:20:26.911576  9048 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0408 21:20:27.186916  9048 solver.cpp:240] Iteration 1661, loss = 30.4343
I0408 21:20:27.186951  9048 solver.cpp:256]     Train net output #0: loss = 30.4343 (* 1 = 30.4343 loss)
I0408 21:20:27.186959  9048 sgd_solver.cpp:106] Iteration 1661, lr = 0.01
I0408 21:20:27.462713  9048 solver.cpp:240] Iteration 1662, loss = 10.517
I0408 21:20:27.462759  9048 solver.cpp:256]     Train net output #0: loss = 10.5169 (* 1 = 10.5169 loss)
I0408 21:20:27.462767  9048 sgd_solver.cpp:106] Iteration 1662, lr = 0.01
I0408 21:20:27.739156  9048 solver.cpp:240] Iteration 1663, loss = 12.1922
I0408 21:20:27.739190  9048 solver.cpp:256]     Train net output #0: loss = 12.1922 (* 1 = 12.1922 loss)
I0408 21:20:27.739198  9048 sgd_solver.cpp:106] Iteration 1663, lr = 0.01
I0408 21:20:28.015118  9048 solver.cpp:240] Iteration 1664, loss = 14.8063
I0408 21:20:28.015153  9048 solver.cpp:256]     Train net output #0: loss = 14.8063 (* 1 = 14.8063 loss)
I0408 21:20:28.015162  9048 sgd_solver.cpp:106] Iteration 1664, lr = 0.01
I0408 21:20:28.290524  9048 solver.cpp:240] Iteration 1665, loss = 7.52515
I0408 21:20:28.290556  9048 solver.cpp:256]     Train net output #0: loss = 7.52514 (* 1 = 7.52514 loss)
I0408 21:20:28.290565  9048 sgd_solver.cpp:106] Iteration 1665, lr = 0.01
I0408 21:20:28.566571  9048 solver.cpp:240] Iteration 1666, loss = 11.7844
I0408 21:20:28.566617  9048 solver.cpp:256]     Train net output #0: loss = 11.7844 (* 1 = 11.7844 loss)
I0408 21:20:28.566648  9048 sgd_solver.cpp:106] Iteration 1666, lr = 0.01
I0408 21:20:28.842304  9048 solver.cpp:240] Iteration 1667, loss = 7.94792
I0408 21:20:28.842347  9048 solver.cpp:256]     Train net output #0: loss = 7.94791 (* 1 = 7.94791 loss)
I0408 21:20:28.842355  9048 sgd_solver.cpp:106] Iteration 1667, lr = 0.01
I0408 21:20:29.118050  9048 solver.cpp:240] Iteration 1668, loss = 17.9978
I0408 21:20:29.118083  9048 solver.cpp:256]     Train net output #0: loss = 17.9978 (* 1 = 17.9978 loss)
I0408 21:20:29.118091  9048 sgd_solver.cpp:106] Iteration 1668, lr = 0.01
I0408 21:20:29.393412  9048 solver.cpp:240] Iteration 1669, loss = 23.381
I0408 21:20:29.393458  9048 solver.cpp:256]     Train net output #0: loss = 23.381 (* 1 = 23.381 loss)
I0408 21:20:29.393467  9048 sgd_solver.cpp:106] Iteration 1669, lr = 0.01
I0408 21:20:29.669705  9048 solver.cpp:240] Iteration 1670, loss = 20.8815
I0408 21:20:29.669739  9048 solver.cpp:256]     Train net output #0: loss = 20.8815 (* 1 = 20.8815 loss)
I0408 21:20:29.669747  9048 sgd_solver.cpp:106] Iteration 1670, lr = 0.01
I0408 21:20:29.944803  9048 solver.cpp:240] Iteration 1671, loss = 7.34057
I0408 21:20:29.944836  9048 solver.cpp:256]     Train net output #0: loss = 7.34056 (* 1 = 7.34056 loss)
I0408 21:20:29.944844  9048 sgd_solver.cpp:106] Iteration 1671, lr = 0.01
I0408 21:20:30.219789  9048 solver.cpp:240] Iteration 1672, loss = 9.75738
I0408 21:20:30.219820  9048 solver.cpp:256]     Train net output #0: loss = 9.75737 (* 1 = 9.75737 loss)
I0408 21:20:30.219830  9048 sgd_solver.cpp:106] Iteration 1672, lr = 0.01
I0408 21:20:30.495643  9048 solver.cpp:240] Iteration 1673, loss = 16.8605
I0408 21:20:30.495678  9048 solver.cpp:256]     Train net output #0: loss = 16.8605 (* 1 = 16.8605 loss)
I0408 21:20:30.495687  9048 sgd_solver.cpp:106] Iteration 1673, lr = 0.01
I0408 21:20:30.770552  9048 solver.cpp:240] Iteration 1674, loss = 23.2152
I0408 21:20:30.770586  9048 solver.cpp:256]     Train net output #0: loss = 23.2152 (* 1 = 23.2152 loss)
I0408 21:20:30.770594  9048 sgd_solver.cpp:106] Iteration 1674, lr = 0.01
I0408 21:20:31.043862  9048 solver.cpp:240] Iteration 1675, loss = 24.5183
I0408 21:20:31.043911  9048 solver.cpp:256]     Train net output #0: loss = 24.5183 (* 1 = 24.5183 loss)
I0408 21:20:31.043920  9048 sgd_solver.cpp:106] Iteration 1675, lr = 0.01
I0408 21:20:31.317980  9048 solver.cpp:240] Iteration 1676, loss = 9.57738
I0408 21:20:31.318011  9048 solver.cpp:256]     Train net output #0: loss = 9.57737 (* 1 = 9.57737 loss)
I0408 21:20:31.318019  9048 sgd_solver.cpp:106] Iteration 1676, lr = 0.01
I0408 21:20:31.593824  9048 solver.cpp:240] Iteration 1677, loss = 14.6651
I0408 21:20:31.593858  9048 solver.cpp:256]     Train net output #0: loss = 14.6651 (* 1 = 14.6651 loss)
I0408 21:20:31.593866  9048 sgd_solver.cpp:106] Iteration 1677, lr = 0.01
I0408 21:20:31.869712  9048 solver.cpp:240] Iteration 1678, loss = 9.87082
I0408 21:20:31.869746  9048 solver.cpp:256]     Train net output #0: loss = 9.87081 (* 1 = 9.87081 loss)
I0408 21:20:31.869755  9048 sgd_solver.cpp:106] Iteration 1678, lr = 0.01
I0408 21:20:32.145920  9048 solver.cpp:240] Iteration 1679, loss = 5.2769
I0408 21:20:32.145952  9048 solver.cpp:256]     Train net output #0: loss = 5.27689 (* 1 = 5.27689 loss)
I0408 21:20:32.145959  9048 sgd_solver.cpp:106] Iteration 1679, lr = 0.01
I0408 21:20:32.420729  9048 solver.cpp:240] Iteration 1680, loss = 3.63006
I0408 21:20:32.420763  9048 solver.cpp:256]     Train net output #0: loss = 3.63005 (* 1 = 3.63005 loss)
I0408 21:20:32.420770  9048 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0408 21:20:32.696951  9048 solver.cpp:240] Iteration 1681, loss = 17.6573
I0408 21:20:32.696985  9048 solver.cpp:256]     Train net output #0: loss = 17.6573 (* 1 = 17.6573 loss)
I0408 21:20:32.696993  9048 sgd_solver.cpp:106] Iteration 1681, lr = 0.01
I0408 21:20:32.972363  9048 solver.cpp:240] Iteration 1682, loss = 14.4655
I0408 21:20:32.972398  9048 solver.cpp:256]     Train net output #0: loss = 14.4655 (* 1 = 14.4655 loss)
I0408 21:20:32.972406  9048 sgd_solver.cpp:106] Iteration 1682, lr = 0.01
I0408 21:20:33.247875  9048 solver.cpp:240] Iteration 1683, loss = 11.3429
I0408 21:20:33.247920  9048 solver.cpp:256]     Train net output #0: loss = 11.3429 (* 1 = 11.3429 loss)
I0408 21:20:33.247930  9048 sgd_solver.cpp:106] Iteration 1683, lr = 0.01
I0408 21:20:33.521054  9048 solver.cpp:240] Iteration 1684, loss = 13.7226
I0408 21:20:33.521086  9048 solver.cpp:256]     Train net output #0: loss = 13.7226 (* 1 = 13.7226 loss)
I0408 21:20:33.521095  9048 sgd_solver.cpp:106] Iteration 1684, lr = 0.01
I0408 21:20:33.797253  9048 solver.cpp:240] Iteration 1685, loss = 9.61597
I0408 21:20:33.797296  9048 solver.cpp:256]     Train net output #0: loss = 9.61596 (* 1 = 9.61596 loss)
I0408 21:20:33.797302  9048 sgd_solver.cpp:106] Iteration 1685, lr = 0.01
I0408 21:20:34.072211  9048 solver.cpp:240] Iteration 1686, loss = 17.2707
I0408 21:20:34.072245  9048 solver.cpp:256]     Train net output #0: loss = 17.2707 (* 1 = 17.2707 loss)
I0408 21:20:34.072253  9048 sgd_solver.cpp:106] Iteration 1686, lr = 0.01
I0408 21:20:34.346448  9048 solver.cpp:240] Iteration 1687, loss = 30.6428
I0408 21:20:34.346482  9048 solver.cpp:256]     Train net output #0: loss = 30.6428 (* 1 = 30.6428 loss)
I0408 21:20:34.346490  9048 sgd_solver.cpp:106] Iteration 1687, lr = 0.01
I0408 21:20:34.622612  9048 solver.cpp:240] Iteration 1688, loss = 9.46322
I0408 21:20:34.622655  9048 solver.cpp:256]     Train net output #0: loss = 9.46321 (* 1 = 9.46321 loss)
I0408 21:20:34.622663  9048 sgd_solver.cpp:106] Iteration 1688, lr = 0.01
I0408 21:20:34.897630  9048 solver.cpp:240] Iteration 1689, loss = 15.1519
I0408 21:20:34.897665  9048 solver.cpp:256]     Train net output #0: loss = 15.1519 (* 1 = 15.1519 loss)
I0408 21:20:34.897672  9048 sgd_solver.cpp:106] Iteration 1689, lr = 0.01
I0408 21:20:35.172909  9048 solver.cpp:240] Iteration 1690, loss = 17.3329
I0408 21:20:35.172950  9048 solver.cpp:256]     Train net output #0: loss = 17.3329 (* 1 = 17.3329 loss)
I0408 21:20:35.172957  9048 sgd_solver.cpp:106] Iteration 1690, lr = 0.01
I0408 21:20:35.448679  9048 solver.cpp:240] Iteration 1691, loss = 11.3427
I0408 21:20:35.448716  9048 solver.cpp:256]     Train net output #0: loss = 11.3427 (* 1 = 11.3427 loss)
I0408 21:20:35.448725  9048 sgd_solver.cpp:106] Iteration 1691, lr = 0.01
I0408 21:20:35.724488  9048 solver.cpp:240] Iteration 1692, loss = 20.1882
I0408 21:20:35.724529  9048 solver.cpp:256]     Train net output #0: loss = 20.1882 (* 1 = 20.1882 loss)
I0408 21:20:35.724539  9048 sgd_solver.cpp:106] Iteration 1692, lr = 0.01
I0408 21:20:36.000277  9048 solver.cpp:240] Iteration 1693, loss = 20.306
I0408 21:20:36.000311  9048 solver.cpp:256]     Train net output #0: loss = 20.306 (* 1 = 20.306 loss)
I0408 21:20:36.000320  9048 sgd_solver.cpp:106] Iteration 1693, lr = 0.01
I0408 21:20:36.275931  9048 solver.cpp:240] Iteration 1694, loss = 26.5998
I0408 21:20:36.275966  9048 solver.cpp:256]     Train net output #0: loss = 26.5998 (* 1 = 26.5998 loss)
I0408 21:20:36.275975  9048 sgd_solver.cpp:106] Iteration 1694, lr = 0.01
I0408 21:20:36.551601  9048 solver.cpp:240] Iteration 1695, loss = 22.7892
I0408 21:20:36.551635  9048 solver.cpp:256]     Train net output #0: loss = 22.7892 (* 1 = 22.7892 loss)
I0408 21:20:36.551642  9048 sgd_solver.cpp:106] Iteration 1695, lr = 0.01
I0408 21:20:36.827486  9048 solver.cpp:240] Iteration 1696, loss = 25.2936
I0408 21:20:36.827519  9048 solver.cpp:256]     Train net output #0: loss = 25.2936 (* 1 = 25.2936 loss)
I0408 21:20:36.827527  9048 sgd_solver.cpp:106] Iteration 1696, lr = 0.01
I0408 21:20:37.103682  9048 solver.cpp:240] Iteration 1697, loss = 30.0528
I0408 21:20:37.103720  9048 solver.cpp:256]     Train net output #0: loss = 30.0528 (* 1 = 30.0528 loss)
I0408 21:20:37.103729  9048 sgd_solver.cpp:106] Iteration 1697, lr = 0.01
I0408 21:20:37.378756  9048 solver.cpp:240] Iteration 1698, loss = 31.8983
I0408 21:20:37.378789  9048 solver.cpp:256]     Train net output #0: loss = 31.8983 (* 1 = 31.8983 loss)
I0408 21:20:37.378798  9048 sgd_solver.cpp:106] Iteration 1698, lr = 0.01
I0408 21:20:37.654422  9048 solver.cpp:240] Iteration 1699, loss = 18.0245
I0408 21:20:37.654454  9048 solver.cpp:256]     Train net output #0: loss = 18.0245 (* 1 = 18.0245 loss)
I0408 21:20:37.654462  9048 sgd_solver.cpp:106] Iteration 1699, lr = 0.01
I0408 21:20:37.931074  9048 solver.cpp:240] Iteration 1700, loss = 15.7797
I0408 21:20:37.931107  9048 solver.cpp:256]     Train net output #0: loss = 15.7797 (* 1 = 15.7797 loss)
I0408 21:20:37.931115  9048 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0408 21:20:38.207060  9048 solver.cpp:240] Iteration 1701, loss = 4.7643
I0408 21:20:38.207093  9048 solver.cpp:256]     Train net output #0: loss = 4.76429 (* 1 = 4.76429 loss)
I0408 21:20:38.207101  9048 sgd_solver.cpp:106] Iteration 1701, lr = 0.01
I0408 21:20:38.481928  9048 solver.cpp:240] Iteration 1702, loss = 17.7897
I0408 21:20:38.481968  9048 solver.cpp:256]     Train net output #0: loss = 17.7897 (* 1 = 17.7897 loss)
I0408 21:20:38.481977  9048 sgd_solver.cpp:106] Iteration 1702, lr = 0.01
I0408 21:20:38.757174  9048 solver.cpp:240] Iteration 1703, loss = 22.4597
I0408 21:20:38.757211  9048 solver.cpp:256]     Train net output #0: loss = 22.4597 (* 1 = 22.4597 loss)
I0408 21:20:38.757220  9048 sgd_solver.cpp:106] Iteration 1703, lr = 0.01
I0408 21:20:39.033149  9048 solver.cpp:240] Iteration 1704, loss = 16.6871
I0408 21:20:39.033180  9048 solver.cpp:256]     Train net output #0: loss = 16.6871 (* 1 = 16.6871 loss)
I0408 21:20:39.033190  9048 sgd_solver.cpp:106] Iteration 1704, lr = 0.01
I0408 21:20:39.309031  9048 solver.cpp:240] Iteration 1705, loss = 15.1763
I0408 21:20:39.309077  9048 solver.cpp:256]     Train net output #0: loss = 15.1763 (* 1 = 15.1763 loss)
I0408 21:20:39.309085  9048 sgd_solver.cpp:106] Iteration 1705, lr = 0.01
I0408 21:20:39.583901  9048 solver.cpp:240] Iteration 1706, loss = 19.9359
I0408 21:20:39.583935  9048 solver.cpp:256]     Train net output #0: loss = 19.9359 (* 1 = 19.9359 loss)
I0408 21:20:39.583942  9048 sgd_solver.cpp:106] Iteration 1706, lr = 0.01
I0408 21:20:39.859026  9048 solver.cpp:240] Iteration 1707, loss = 13.4289
I0408 21:20:39.859067  9048 solver.cpp:256]     Train net output #0: loss = 13.4289 (* 1 = 13.4289 loss)
I0408 21:20:39.859076  9048 sgd_solver.cpp:106] Iteration 1707, lr = 0.01
I0408 21:20:40.134362  9048 solver.cpp:240] Iteration 1708, loss = 13.4338
I0408 21:20:40.134397  9048 solver.cpp:256]     Train net output #0: loss = 13.4338 (* 1 = 13.4338 loss)
I0408 21:20:40.134405  9048 sgd_solver.cpp:106] Iteration 1708, lr = 0.01
I0408 21:20:40.410111  9048 solver.cpp:240] Iteration 1709, loss = 26.9038
I0408 21:20:40.410157  9048 solver.cpp:256]     Train net output #0: loss = 26.9038 (* 1 = 26.9038 loss)
I0408 21:20:40.410166  9048 sgd_solver.cpp:106] Iteration 1709, lr = 0.01
I0408 21:20:40.685776  9048 solver.cpp:240] Iteration 1710, loss = 25.9507
I0408 21:20:40.685822  9048 solver.cpp:256]     Train net output #0: loss = 25.9507 (* 1 = 25.9507 loss)
I0408 21:20:40.685832  9048 sgd_solver.cpp:106] Iteration 1710, lr = 0.01
I0408 21:20:40.961174  9048 solver.cpp:240] Iteration 1711, loss = 22.6295
I0408 21:20:40.961207  9048 solver.cpp:256]     Train net output #0: loss = 22.6294 (* 1 = 22.6294 loss)
I0408 21:20:40.961216  9048 sgd_solver.cpp:106] Iteration 1711, lr = 0.01
I0408 21:20:41.236498  9048 solver.cpp:240] Iteration 1712, loss = 13.2788
I0408 21:20:41.236534  9048 solver.cpp:256]     Train net output #0: loss = 13.2787 (* 1 = 13.2787 loss)
I0408 21:20:41.236542  9048 sgd_solver.cpp:106] Iteration 1712, lr = 0.01
I0408 21:20:41.511543  9048 solver.cpp:240] Iteration 1713, loss = 37.2871
I0408 21:20:41.511577  9048 solver.cpp:256]     Train net output #0: loss = 37.2871 (* 1 = 37.2871 loss)
I0408 21:20:41.511586  9048 sgd_solver.cpp:106] Iteration 1713, lr = 0.01
I0408 21:20:41.786494  9048 solver.cpp:240] Iteration 1714, loss = 24.1951
I0408 21:20:41.786528  9048 solver.cpp:256]     Train net output #0: loss = 24.1951 (* 1 = 24.1951 loss)
I0408 21:20:41.786536  9048 sgd_solver.cpp:106] Iteration 1714, lr = 0.01
I0408 21:20:42.062809  9048 solver.cpp:240] Iteration 1715, loss = 19.722
I0408 21:20:42.062866  9048 solver.cpp:256]     Train net output #0: loss = 19.722 (* 1 = 19.722 loss)
I0408 21:20:42.062875  9048 sgd_solver.cpp:106] Iteration 1715, lr = 0.01
I0408 21:20:42.339494  9048 solver.cpp:240] Iteration 1716, loss = 32.936
I0408 21:20:42.339531  9048 solver.cpp:256]     Train net output #0: loss = 32.936 (* 1 = 32.936 loss)
I0408 21:20:42.339540  9048 sgd_solver.cpp:106] Iteration 1716, lr = 0.01
I0408 21:20:42.615077  9048 solver.cpp:240] Iteration 1717, loss = 24.0681
I0408 21:20:42.615111  9048 solver.cpp:256]     Train net output #0: loss = 24.0681 (* 1 = 24.0681 loss)
I0408 21:20:42.615119  9048 sgd_solver.cpp:106] Iteration 1717, lr = 0.01
I0408 21:20:42.890449  9048 solver.cpp:240] Iteration 1718, loss = 17.3319
I0408 21:20:42.890485  9048 solver.cpp:256]     Train net output #0: loss = 17.3319 (* 1 = 17.3319 loss)
I0408 21:20:42.890492  9048 sgd_solver.cpp:106] Iteration 1718, lr = 0.01
I0408 21:20:43.166429  9048 solver.cpp:240] Iteration 1719, loss = 23.6751
I0408 21:20:43.166468  9048 solver.cpp:256]     Train net output #0: loss = 23.6751 (* 1 = 23.6751 loss)
I0408 21:20:43.166477  9048 sgd_solver.cpp:106] Iteration 1719, lr = 0.01
I0408 21:20:43.441975  9048 solver.cpp:240] Iteration 1720, loss = 13.4217
I0408 21:20:43.442013  9048 solver.cpp:256]     Train net output #0: loss = 13.4217 (* 1 = 13.4217 loss)
I0408 21:20:43.442023  9048 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0408 21:20:43.717769  9048 solver.cpp:240] Iteration 1721, loss = 14.908
I0408 21:20:43.717803  9048 solver.cpp:256]     Train net output #0: loss = 14.908 (* 1 = 14.908 loss)
I0408 21:20:43.717818  9048 sgd_solver.cpp:106] Iteration 1721, lr = 0.01
I0408 21:20:43.993990  9048 solver.cpp:240] Iteration 1722, loss = 15.7263
I0408 21:20:43.994029  9048 solver.cpp:256]     Train net output #0: loss = 15.7263 (* 1 = 15.7263 loss)
I0408 21:20:43.994040  9048 sgd_solver.cpp:106] Iteration 1722, lr = 0.01
I0408 21:20:44.268718  9048 solver.cpp:240] Iteration 1723, loss = 18.751
I0408 21:20:44.268764  9048 solver.cpp:256]     Train net output #0: loss = 18.751 (* 1 = 18.751 loss)
I0408 21:20:44.268774  9048 sgd_solver.cpp:106] Iteration 1723, lr = 0.01
I0408 21:20:44.545459  9048 solver.cpp:240] Iteration 1724, loss = 10.459
I0408 21:20:44.545493  9048 solver.cpp:256]     Train net output #0: loss = 10.459 (* 1 = 10.459 loss)
I0408 21:20:44.545502  9048 sgd_solver.cpp:106] Iteration 1724, lr = 0.01
I0408 21:20:44.821014  9048 solver.cpp:240] Iteration 1725, loss = 10.2619
I0408 21:20:44.821048  9048 solver.cpp:256]     Train net output #0: loss = 10.2619 (* 1 = 10.2619 loss)
I0408 21:20:44.821056  9048 sgd_solver.cpp:106] Iteration 1725, lr = 0.01
I0408 21:20:45.097084  9048 solver.cpp:240] Iteration 1726, loss = 12.5674
I0408 21:20:45.097116  9048 solver.cpp:256]     Train net output #0: loss = 12.5673 (* 1 = 12.5673 loss)
I0408 21:20:45.097124  9048 sgd_solver.cpp:106] Iteration 1726, lr = 0.01
I0408 21:20:45.372849  9048 solver.cpp:240] Iteration 1727, loss = 16.5254
I0408 21:20:45.372889  9048 solver.cpp:256]     Train net output #0: loss = 16.5253 (* 1 = 16.5253 loss)
I0408 21:20:45.372897  9048 sgd_solver.cpp:106] Iteration 1727, lr = 0.01
I0408 21:20:45.648972  9048 solver.cpp:240] Iteration 1728, loss = 20.6283
I0408 21:20:45.649008  9048 solver.cpp:256]     Train net output #0: loss = 20.6283 (* 1 = 20.6283 loss)
I0408 21:20:45.649015  9048 sgd_solver.cpp:106] Iteration 1728, lr = 0.01
I0408 21:20:45.924437  9048 solver.cpp:240] Iteration 1729, loss = 17.9051
I0408 21:20:45.924470  9048 solver.cpp:256]     Train net output #0: loss = 17.9051 (* 1 = 17.9051 loss)
I0408 21:20:45.924479  9048 sgd_solver.cpp:106] Iteration 1729, lr = 0.01
I0408 21:20:46.200304  9048 solver.cpp:240] Iteration 1730, loss = 8.2237
I0408 21:20:46.200336  9048 solver.cpp:256]     Train net output #0: loss = 8.22369 (* 1 = 8.22369 loss)
I0408 21:20:46.200345  9048 sgd_solver.cpp:106] Iteration 1730, lr = 0.01
I0408 21:20:46.476649  9048 solver.cpp:240] Iteration 1731, loss = 17.8803
I0408 21:20:46.476721  9048 solver.cpp:256]     Train net output #0: loss = 17.8803 (* 1 = 17.8803 loss)
I0408 21:20:46.476732  9048 sgd_solver.cpp:106] Iteration 1731, lr = 0.01
I0408 21:20:46.752353  9048 solver.cpp:240] Iteration 1732, loss = 9.54603
I0408 21:20:46.752393  9048 solver.cpp:256]     Train net output #0: loss = 9.54602 (* 1 = 9.54602 loss)
I0408 21:20:46.752401  9048 sgd_solver.cpp:106] Iteration 1732, lr = 0.01
I0408 21:20:47.028839  9048 solver.cpp:240] Iteration 1733, loss = 11.6376
I0408 21:20:47.028873  9048 solver.cpp:256]     Train net output #0: loss = 11.6375 (* 1 = 11.6375 loss)
I0408 21:20:47.028882  9048 sgd_solver.cpp:106] Iteration 1733, lr = 0.01
I0408 21:20:47.304201  9048 solver.cpp:240] Iteration 1734, loss = 24.2515
I0408 21:20:47.304234  9048 solver.cpp:256]     Train net output #0: loss = 24.2515 (* 1 = 24.2515 loss)
I0408 21:20:47.304242  9048 sgd_solver.cpp:106] Iteration 1734, lr = 0.01
I0408 21:20:47.580229  9048 solver.cpp:240] Iteration 1735, loss = 12.0776
I0408 21:20:47.580262  9048 solver.cpp:256]     Train net output #0: loss = 12.0776 (* 1 = 12.0776 loss)
I0408 21:20:47.580271  9048 sgd_solver.cpp:106] Iteration 1735, lr = 0.01
I0408 21:20:47.856274  9048 solver.cpp:240] Iteration 1736, loss = 24.3355
I0408 21:20:47.856310  9048 solver.cpp:256]     Train net output #0: loss = 24.3355 (* 1 = 24.3355 loss)
I0408 21:20:47.856318  9048 sgd_solver.cpp:106] Iteration 1736, lr = 0.01
I0408 21:20:48.131044  9048 solver.cpp:240] Iteration 1737, loss = 22.6193
I0408 21:20:48.131078  9048 solver.cpp:256]     Train net output #0: loss = 22.6193 (* 1 = 22.6193 loss)
I0408 21:20:48.131085  9048 sgd_solver.cpp:106] Iteration 1737, lr = 0.01
I0408 21:20:48.406312  9048 solver.cpp:240] Iteration 1738, loss = 16.0439
I0408 21:20:48.406343  9048 solver.cpp:256]     Train net output #0: loss = 16.0439 (* 1 = 16.0439 loss)
I0408 21:20:48.406352  9048 sgd_solver.cpp:106] Iteration 1738, lr = 0.01
I0408 21:20:48.681718  9048 solver.cpp:240] Iteration 1739, loss = 19.0836
I0408 21:20:48.681751  9048 solver.cpp:256]     Train net output #0: loss = 19.0836 (* 1 = 19.0836 loss)
I0408 21:20:48.681759  9048 sgd_solver.cpp:106] Iteration 1739, lr = 0.01
I0408 21:20:48.956853  9048 solver.cpp:240] Iteration 1740, loss = 18.3433
I0408 21:20:48.956887  9048 solver.cpp:256]     Train net output #0: loss = 18.3433 (* 1 = 18.3433 loss)
I0408 21:20:48.956895  9048 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0408 21:20:49.232791  9048 solver.cpp:240] Iteration 1741, loss = 15.4397
I0408 21:20:49.232825  9048 solver.cpp:256]     Train net output #0: loss = 15.4397 (* 1 = 15.4397 loss)
I0408 21:20:49.232833  9048 sgd_solver.cpp:106] Iteration 1741, lr = 0.01
I0408 21:20:49.507897  9048 solver.cpp:240] Iteration 1742, loss = 19.255
I0408 21:20:49.507928  9048 solver.cpp:256]     Train net output #0: loss = 19.255 (* 1 = 19.255 loss)
I0408 21:20:49.507936  9048 sgd_solver.cpp:106] Iteration 1742, lr = 0.01
I0408 21:20:49.783504  9048 solver.cpp:240] Iteration 1743, loss = 16.7115
I0408 21:20:49.783833  9048 solver.cpp:256]     Train net output #0: loss = 16.7115 (* 1 = 16.7115 loss)
I0408 21:20:49.783843  9048 sgd_solver.cpp:106] Iteration 1743, lr = 0.01
I0408 21:20:50.060024  9048 solver.cpp:240] Iteration 1744, loss = 26.3872
I0408 21:20:50.060057  9048 solver.cpp:256]     Train net output #0: loss = 26.3872 (* 1 = 26.3872 loss)
I0408 21:20:50.060065  9048 sgd_solver.cpp:106] Iteration 1744, lr = 0.01
I0408 21:20:50.336086  9048 solver.cpp:240] Iteration 1745, loss = 19.9738
I0408 21:20:50.336120  9048 solver.cpp:256]     Train net output #0: loss = 19.9738 (* 1 = 19.9738 loss)
I0408 21:20:50.336128  9048 sgd_solver.cpp:106] Iteration 1745, lr = 0.01
I0408 21:20:50.611544  9048 solver.cpp:240] Iteration 1746, loss = 7.41948
I0408 21:20:50.611582  9048 solver.cpp:256]     Train net output #0: loss = 7.41947 (* 1 = 7.41947 loss)
I0408 21:20:50.611590  9048 sgd_solver.cpp:106] Iteration 1746, lr = 0.01
I0408 21:20:50.888799  9048 solver.cpp:240] Iteration 1747, loss = 3.97999
I0408 21:20:50.888837  9048 solver.cpp:256]     Train net output #0: loss = 3.97998 (* 1 = 3.97998 loss)
I0408 21:20:50.888845  9048 sgd_solver.cpp:106] Iteration 1747, lr = 0.01
I0408 21:20:51.166175  9048 solver.cpp:240] Iteration 1748, loss = 6.44153
I0408 21:20:51.166219  9048 solver.cpp:256]     Train net output #0: loss = 6.44152 (* 1 = 6.44152 loss)
I0408 21:20:51.166227  9048 sgd_solver.cpp:106] Iteration 1748, lr = 0.01
I0408 21:20:51.442073  9048 solver.cpp:240] Iteration 1749, loss = 12.8504
I0408 21:20:51.442119  9048 solver.cpp:256]     Train net output #0: loss = 12.8504 (* 1 = 12.8504 loss)
I0408 21:20:51.442127  9048 sgd_solver.cpp:106] Iteration 1749, lr = 0.01
I0408 21:20:51.718269  9048 solver.cpp:240] Iteration 1750, loss = 15.3431
I0408 21:20:51.718303  9048 solver.cpp:256]     Train net output #0: loss = 15.3431 (* 1 = 15.3431 loss)
I0408 21:20:51.718312  9048 sgd_solver.cpp:106] Iteration 1750, lr = 0.01
I0408 21:20:51.994436  9048 solver.cpp:240] Iteration 1751, loss = 11.2959
I0408 21:20:51.994472  9048 solver.cpp:256]     Train net output #0: loss = 11.2959 (* 1 = 11.2959 loss)
I0408 21:20:51.994479  9048 sgd_solver.cpp:106] Iteration 1751, lr = 0.01
I0408 21:20:52.270133  9048 solver.cpp:240] Iteration 1752, loss = 8.08439
I0408 21:20:52.270167  9048 solver.cpp:256]     Train net output #0: loss = 8.08439 (* 1 = 8.08439 loss)
I0408 21:20:52.270175  9048 sgd_solver.cpp:106] Iteration 1752, lr = 0.01
I0408 21:20:52.546681  9048 solver.cpp:240] Iteration 1753, loss = 3.91435
I0408 21:20:52.546711  9048 solver.cpp:256]     Train net output #0: loss = 3.91434 (* 1 = 3.91434 loss)
I0408 21:20:52.546720  9048 sgd_solver.cpp:106] Iteration 1753, lr = 0.01
I0408 21:20:52.823051  9048 solver.cpp:240] Iteration 1754, loss = 14.2723
I0408 21:20:52.823086  9048 solver.cpp:256]     Train net output #0: loss = 14.2723 (* 1 = 14.2723 loss)
I0408 21:20:52.823093  9048 sgd_solver.cpp:106] Iteration 1754, lr = 0.01
I0408 21:20:53.100112  9048 solver.cpp:240] Iteration 1755, loss = 19.7569
I0408 21:20:53.100150  9048 solver.cpp:256]     Train net output #0: loss = 19.7569 (* 1 = 19.7569 loss)
I0408 21:20:53.100162  9048 sgd_solver.cpp:106] Iteration 1755, lr = 0.01
I0408 21:20:53.375211  9048 solver.cpp:240] Iteration 1756, loss = 21.9694
I0408 21:20:53.375244  9048 solver.cpp:256]     Train net output #0: loss = 21.9693 (* 1 = 21.9693 loss)
I0408 21:20:53.375252  9048 sgd_solver.cpp:106] Iteration 1756, lr = 0.01
I0408 21:20:53.652721  9048 solver.cpp:240] Iteration 1757, loss = 23.4215
I0408 21:20:53.652755  9048 solver.cpp:256]     Train net output #0: loss = 23.4215 (* 1 = 23.4215 loss)
I0408 21:20:53.652763  9048 sgd_solver.cpp:106] Iteration 1757, lr = 0.01
I0408 21:20:53.928526  9048 solver.cpp:240] Iteration 1758, loss = 12.8167
I0408 21:20:53.928558  9048 solver.cpp:256]     Train net output #0: loss = 12.8167 (* 1 = 12.8167 loss)
I0408 21:20:53.928566  9048 sgd_solver.cpp:106] Iteration 1758, lr = 0.01
I0408 21:20:54.205458  9048 solver.cpp:240] Iteration 1759, loss = 26.5728
I0408 21:20:54.205497  9048 solver.cpp:256]     Train net output #0: loss = 26.5728 (* 1 = 26.5728 loss)
I0408 21:20:54.205529  9048 sgd_solver.cpp:106] Iteration 1759, lr = 0.01
I0408 21:20:54.481287  9048 solver.cpp:240] Iteration 1760, loss = 21.2337
I0408 21:20:54.481319  9048 solver.cpp:256]     Train net output #0: loss = 21.2337 (* 1 = 21.2337 loss)
I0408 21:20:54.481328  9048 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0408 21:20:54.757349  9048 solver.cpp:240] Iteration 1761, loss = 21.5295
I0408 21:20:54.757382  9048 solver.cpp:256]     Train net output #0: loss = 21.5295 (* 1 = 21.5295 loss)
I0408 21:20:54.757390  9048 sgd_solver.cpp:106] Iteration 1761, lr = 0.01
I0408 21:20:55.034262  9048 solver.cpp:240] Iteration 1762, loss = 21.5069
I0408 21:20:55.034296  9048 solver.cpp:256]     Train net output #0: loss = 21.5069 (* 1 = 21.5069 loss)
I0408 21:20:55.034304  9048 sgd_solver.cpp:106] Iteration 1762, lr = 0.01
I0408 21:20:55.310526  9048 solver.cpp:240] Iteration 1763, loss = 2.51497
I0408 21:20:55.310559  9048 solver.cpp:256]     Train net output #0: loss = 2.51496 (* 1 = 2.51496 loss)
I0408 21:20:55.310566  9048 sgd_solver.cpp:106] Iteration 1763, lr = 0.01
I0408 21:20:55.586810  9048 solver.cpp:240] Iteration 1764, loss = 3.74165
I0408 21:20:55.586848  9048 solver.cpp:256]     Train net output #0: loss = 3.74164 (* 1 = 3.74164 loss)
I0408 21:20:55.586855  9048 sgd_solver.cpp:106] Iteration 1764, lr = 0.01
I0408 21:20:55.863081  9048 solver.cpp:240] Iteration 1765, loss = 7.60123
I0408 21:20:55.863111  9048 solver.cpp:256]     Train net output #0: loss = 7.60122 (* 1 = 7.60122 loss)
I0408 21:20:55.863119  9048 sgd_solver.cpp:106] Iteration 1765, lr = 0.01
I0408 21:20:56.139690  9048 solver.cpp:240] Iteration 1766, loss = 3.21077
I0408 21:20:56.139721  9048 solver.cpp:256]     Train net output #0: loss = 3.21076 (* 1 = 3.21076 loss)
I0408 21:20:56.139730  9048 sgd_solver.cpp:106] Iteration 1766, lr = 0.01
I0408 21:20:56.415833  9048 solver.cpp:240] Iteration 1767, loss = 2.32468
I0408 21:20:56.415866  9048 solver.cpp:256]     Train net output #0: loss = 2.32467 (* 1 = 2.32467 loss)
I0408 21:20:56.415874  9048 sgd_solver.cpp:106] Iteration 1767, lr = 0.01
I0408 21:20:56.692195  9048 solver.cpp:240] Iteration 1768, loss = 1.55761
I0408 21:20:56.692227  9048 solver.cpp:256]     Train net output #0: loss = 1.5576 (* 1 = 1.5576 loss)
I0408 21:20:56.692235  9048 sgd_solver.cpp:106] Iteration 1768, lr = 0.01
I0408 21:20:56.968711  9048 solver.cpp:240] Iteration 1769, loss = 4.59722
I0408 21:20:56.968747  9048 solver.cpp:256]     Train net output #0: loss = 4.59721 (* 1 = 4.59721 loss)
I0408 21:20:56.968755  9048 sgd_solver.cpp:106] Iteration 1769, lr = 0.01
I0408 21:20:57.245263  9048 solver.cpp:240] Iteration 1770, loss = 6.60104
I0408 21:20:57.245297  9048 solver.cpp:256]     Train net output #0: loss = 6.60103 (* 1 = 6.60103 loss)
I0408 21:20:57.245306  9048 sgd_solver.cpp:106] Iteration 1770, lr = 0.01
I0408 21:20:57.522481  9048 solver.cpp:240] Iteration 1771, loss = 14.7597
I0408 21:20:57.522527  9048 solver.cpp:256]     Train net output #0: loss = 14.7597 (* 1 = 14.7597 loss)
I0408 21:20:57.522536  9048 sgd_solver.cpp:106] Iteration 1771, lr = 0.01
I0408 21:20:57.799700  9048 solver.cpp:240] Iteration 1772, loss = 19.2043
I0408 21:20:57.799748  9048 solver.cpp:256]     Train net output #0: loss = 19.2043 (* 1 = 19.2043 loss)
I0408 21:20:57.799760  9048 sgd_solver.cpp:106] Iteration 1772, lr = 0.01
I0408 21:20:58.075037  9048 solver.cpp:240] Iteration 1773, loss = 15.6903
I0408 21:20:58.075072  9048 solver.cpp:256]     Train net output #0: loss = 15.6903 (* 1 = 15.6903 loss)
I0408 21:20:58.075080  9048 sgd_solver.cpp:106] Iteration 1773, lr = 0.01
I0408 21:20:58.350538  9048 solver.cpp:240] Iteration 1774, loss = 12.8513
I0408 21:20:58.350570  9048 solver.cpp:256]     Train net output #0: loss = 12.8513 (* 1 = 12.8513 loss)
I0408 21:20:58.350579  9048 sgd_solver.cpp:106] Iteration 1774, lr = 0.01
I0408 21:20:58.627069  9048 solver.cpp:240] Iteration 1775, loss = 16.3716
I0408 21:20:58.627102  9048 solver.cpp:256]     Train net output #0: loss = 16.3716 (* 1 = 16.3716 loss)
I0408 21:20:58.627144  9048 sgd_solver.cpp:106] Iteration 1775, lr = 0.01
I0408 21:20:58.903492  9048 solver.cpp:240] Iteration 1776, loss = 5.35961
I0408 21:20:58.903524  9048 solver.cpp:256]     Train net output #0: loss = 5.3596 (* 1 = 5.3596 loss)
I0408 21:20:58.903533  9048 sgd_solver.cpp:106] Iteration 1776, lr = 0.01
I0408 21:20:59.180243  9048 solver.cpp:240] Iteration 1777, loss = 8.7684
I0408 21:20:59.180275  9048 solver.cpp:256]     Train net output #0: loss = 8.7684 (* 1 = 8.7684 loss)
I0408 21:20:59.180284  9048 sgd_solver.cpp:106] Iteration 1777, lr = 0.01
I0408 21:20:59.456980  9048 solver.cpp:240] Iteration 1778, loss = 7.48833
I0408 21:20:59.457025  9048 solver.cpp:256]     Train net output #0: loss = 7.48832 (* 1 = 7.48832 loss)
I0408 21:20:59.457032  9048 sgd_solver.cpp:106] Iteration 1778, lr = 0.01
I0408 21:20:59.732571  9048 solver.cpp:240] Iteration 1779, loss = 18.565
I0408 21:20:59.732616  9048 solver.cpp:256]     Train net output #0: loss = 18.565 (* 1 = 18.565 loss)
I0408 21:20:59.732625  9048 sgd_solver.cpp:106] Iteration 1779, lr = 0.01
I0408 21:21:00.009336  9048 solver.cpp:240] Iteration 1780, loss = 5.70635
I0408 21:21:00.009366  9048 solver.cpp:256]     Train net output #0: loss = 5.70635 (* 1 = 5.70635 loss)
I0408 21:21:00.009374  9048 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0408 21:21:00.286325  9048 solver.cpp:240] Iteration 1781, loss = 17.9063
I0408 21:21:00.286365  9048 solver.cpp:256]     Train net output #0: loss = 17.9063 (* 1 = 17.9063 loss)
I0408 21:21:00.286379  9048 sgd_solver.cpp:106] Iteration 1781, lr = 0.01
I0408 21:21:00.562324  9048 solver.cpp:240] Iteration 1782, loss = 18.6517
I0408 21:21:00.562366  9048 solver.cpp:256]     Train net output #0: loss = 18.6517 (* 1 = 18.6517 loss)
I0408 21:21:00.562377  9048 sgd_solver.cpp:106] Iteration 1782, lr = 0.01
I0408 21:21:00.837883  9048 solver.cpp:240] Iteration 1783, loss = 12.9729
I0408 21:21:00.837915  9048 solver.cpp:256]     Train net output #0: loss = 12.9729 (* 1 = 12.9729 loss)
I0408 21:21:00.837924  9048 sgd_solver.cpp:106] Iteration 1783, lr = 0.01
I0408 21:21:01.114135  9048 solver.cpp:240] Iteration 1784, loss = 15.3684
I0408 21:21:01.114167  9048 solver.cpp:256]     Train net output #0: loss = 15.3684 (* 1 = 15.3684 loss)
I0408 21:21:01.114176  9048 sgd_solver.cpp:106] Iteration 1784, lr = 0.01
I0408 21:21:01.391139  9048 solver.cpp:240] Iteration 1785, loss = 13.6113
I0408 21:21:01.391172  9048 solver.cpp:256]     Train net output #0: loss = 13.6113 (* 1 = 13.6113 loss)
I0408 21:21:01.391181  9048 sgd_solver.cpp:106] Iteration 1785, lr = 0.01
I0408 21:21:01.666635  9048 solver.cpp:240] Iteration 1786, loss = 7.58286
I0408 21:21:01.666679  9048 solver.cpp:256]     Train net output #0: loss = 7.58285 (* 1 = 7.58285 loss)
I0408 21:21:01.666687  9048 sgd_solver.cpp:106] Iteration 1786, lr = 0.01
I0408 21:21:01.942770  9048 solver.cpp:240] Iteration 1787, loss = 10.0142
I0408 21:21:01.942807  9048 solver.cpp:256]     Train net output #0: loss = 10.0142 (* 1 = 10.0142 loss)
I0408 21:21:01.942816  9048 sgd_solver.cpp:106] Iteration 1787, lr = 0.01
I0408 21:21:02.218870  9048 solver.cpp:240] Iteration 1788, loss = 9.47309
I0408 21:21:02.218902  9048 solver.cpp:256]     Train net output #0: loss = 9.47308 (* 1 = 9.47308 loss)
I0408 21:21:02.218910  9048 sgd_solver.cpp:106] Iteration 1788, lr = 0.01
I0408 21:21:02.495682  9048 solver.cpp:240] Iteration 1789, loss = 4.10534
I0408 21:21:02.495724  9048 solver.cpp:256]     Train net output #0: loss = 4.10534 (* 1 = 4.10534 loss)
I0408 21:21:02.495733  9048 sgd_solver.cpp:106] Iteration 1789, lr = 0.01
I0408 21:21:02.772406  9048 solver.cpp:240] Iteration 1790, loss = 8.20827
I0408 21:21:02.772439  9048 solver.cpp:256]     Train net output #0: loss = 8.20826 (* 1 = 8.20826 loss)
I0408 21:21:02.772447  9048 sgd_solver.cpp:106] Iteration 1790, lr = 0.01
I0408 21:21:03.048825  9048 solver.cpp:240] Iteration 1791, loss = 9.30872
I0408 21:21:03.048859  9048 solver.cpp:256]     Train net output #0: loss = 9.30871 (* 1 = 9.30871 loss)
I0408 21:21:03.048867  9048 sgd_solver.cpp:106] Iteration 1791, lr = 0.01
I0408 21:21:03.323845  9048 solver.cpp:240] Iteration 1792, loss = 9.23268
I0408 21:21:03.323887  9048 solver.cpp:256]     Train net output #0: loss = 9.23267 (* 1 = 9.23267 loss)
I0408 21:21:03.323896  9048 sgd_solver.cpp:106] Iteration 1792, lr = 0.01
I0408 21:21:03.600698  9048 solver.cpp:240] Iteration 1793, loss = 22.7818
I0408 21:21:03.600744  9048 solver.cpp:256]     Train net output #0: loss = 22.7818 (* 1 = 22.7818 loss)
I0408 21:21:03.600751  9048 sgd_solver.cpp:106] Iteration 1793, lr = 0.01
I0408 21:21:03.877125  9048 solver.cpp:240] Iteration 1794, loss = 11.8984
I0408 21:21:03.877171  9048 solver.cpp:256]     Train net output #0: loss = 11.8984 (* 1 = 11.8984 loss)
I0408 21:21:03.877178  9048 sgd_solver.cpp:106] Iteration 1794, lr = 0.01
I0408 21:21:04.153074  9048 solver.cpp:240] Iteration 1795, loss = 18.3528
I0408 21:21:04.153108  9048 solver.cpp:256]     Train net output #0: loss = 18.3528 (* 1 = 18.3528 loss)
I0408 21:21:04.153116  9048 sgd_solver.cpp:106] Iteration 1795, lr = 0.01
I0408 21:21:04.430652  9048 solver.cpp:240] Iteration 1796, loss = 7.35853
I0408 21:21:04.430683  9048 solver.cpp:256]     Train net output #0: loss = 7.35852 (* 1 = 7.35852 loss)
I0408 21:21:04.430691  9048 sgd_solver.cpp:106] Iteration 1796, lr = 0.01
I0408 21:21:04.707761  9048 solver.cpp:240] Iteration 1797, loss = 7.71306
I0408 21:21:04.707793  9048 solver.cpp:256]     Train net output #0: loss = 7.71306 (* 1 = 7.71306 loss)
I0408 21:21:04.707801  9048 sgd_solver.cpp:106] Iteration 1797, lr = 0.01
I0408 21:21:04.983268  9048 solver.cpp:240] Iteration 1798, loss = 10.6026
I0408 21:21:04.983312  9048 solver.cpp:256]     Train net output #0: loss = 10.6026 (* 1 = 10.6026 loss)
I0408 21:21:04.983320  9048 sgd_solver.cpp:106] Iteration 1798, lr = 0.01
I0408 21:21:05.259387  9048 solver.cpp:240] Iteration 1799, loss = 8.76466
I0408 21:21:05.259421  9048 solver.cpp:256]     Train net output #0: loss = 8.76465 (* 1 = 8.76465 loss)
I0408 21:21:05.259430  9048 sgd_solver.cpp:106] Iteration 1799, lr = 0.01
I0408 21:21:05.535950  9048 solver.cpp:240] Iteration 1800, loss = 12.9035
I0408 21:21:05.535989  9048 solver.cpp:256]     Train net output #0: loss = 12.9035 (* 1 = 12.9035 loss)
I0408 21:21:05.536000  9048 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0408 21:21:05.812093  9048 solver.cpp:240] Iteration 1801, loss = 6.92232
I0408 21:21:05.812125  9048 solver.cpp:256]     Train net output #0: loss = 6.92231 (* 1 = 6.92231 loss)
I0408 21:21:05.812134  9048 sgd_solver.cpp:106] Iteration 1801, lr = 0.01
I0408 21:21:06.088047  9048 solver.cpp:240] Iteration 1802, loss = 18.1974
I0408 21:21:06.088080  9048 solver.cpp:256]     Train net output #0: loss = 18.1974 (* 1 = 18.1974 loss)
I0408 21:21:06.088088  9048 sgd_solver.cpp:106] Iteration 1802, lr = 0.01
I0408 21:21:06.365061  9048 solver.cpp:240] Iteration 1803, loss = 12.5757
I0408 21:21:06.365097  9048 solver.cpp:256]     Train net output #0: loss = 12.5757 (* 1 = 12.5757 loss)
I0408 21:21:06.365104  9048 sgd_solver.cpp:106] Iteration 1803, lr = 0.01
I0408 21:21:06.641031  9048 solver.cpp:240] Iteration 1804, loss = 8.11057
I0408 21:21:06.641063  9048 solver.cpp:256]     Train net output #0: loss = 8.11056 (* 1 = 8.11056 loss)
I0408 21:21:06.641072  9048 sgd_solver.cpp:106] Iteration 1804, lr = 0.01
I0408 21:21:06.916838  9048 solver.cpp:240] Iteration 1805, loss = 6.40914
I0408 21:21:06.916874  9048 solver.cpp:256]     Train net output #0: loss = 6.40913 (* 1 = 6.40913 loss)
I0408 21:21:06.916883  9048 sgd_solver.cpp:106] Iteration 1805, lr = 0.01
I0408 21:21:07.191709  9048 solver.cpp:240] Iteration 1806, loss = 20.9545
I0408 21:21:07.191742  9048 solver.cpp:256]     Train net output #0: loss = 20.9545 (* 1 = 20.9545 loss)
I0408 21:21:07.191751  9048 sgd_solver.cpp:106] Iteration 1806, lr = 0.01
I0408 21:21:07.468137  9048 solver.cpp:240] Iteration 1807, loss = 13.497
I0408 21:21:07.468175  9048 solver.cpp:256]     Train net output #0: loss = 13.497 (* 1 = 13.497 loss)
I0408 21:21:07.468183  9048 sgd_solver.cpp:106] Iteration 1807, lr = 0.01
I0408 21:21:07.745353  9048 solver.cpp:240] Iteration 1808, loss = 11.0744
I0408 21:21:07.745385  9048 solver.cpp:256]     Train net output #0: loss = 11.0743 (* 1 = 11.0743 loss)
I0408 21:21:07.745394  9048 sgd_solver.cpp:106] Iteration 1808, lr = 0.01
I0408 21:21:08.021265  9048 solver.cpp:240] Iteration 1809, loss = 11.7988
I0408 21:21:08.021299  9048 solver.cpp:256]     Train net output #0: loss = 11.7988 (* 1 = 11.7988 loss)
I0408 21:21:08.021307  9048 sgd_solver.cpp:106] Iteration 1809, lr = 0.01
I0408 21:21:08.296406  9048 solver.cpp:240] Iteration 1810, loss = 4.39729
I0408 21:21:08.296443  9048 solver.cpp:256]     Train net output #0: loss = 4.39728 (* 1 = 4.39728 loss)
I0408 21:21:08.296452  9048 sgd_solver.cpp:106] Iteration 1810, lr = 0.01
I0408 21:21:08.573364  9048 solver.cpp:240] Iteration 1811, loss = 7.41717
I0408 21:21:08.573396  9048 solver.cpp:256]     Train net output #0: loss = 7.41716 (* 1 = 7.41716 loss)
I0408 21:21:08.573403  9048 sgd_solver.cpp:106] Iteration 1811, lr = 0.01
I0408 21:21:08.848767  9048 solver.cpp:240] Iteration 1812, loss = 4.73096
I0408 21:21:08.848799  9048 solver.cpp:256]     Train net output #0: loss = 4.73095 (* 1 = 4.73095 loss)
I0408 21:21:08.848806  9048 sgd_solver.cpp:106] Iteration 1812, lr = 0.01
I0408 21:21:09.124344  9048 solver.cpp:240] Iteration 1813, loss = 17.5463
I0408 21:21:09.124377  9048 solver.cpp:256]     Train net output #0: loss = 17.5463 (* 1 = 17.5463 loss)
I0408 21:21:09.124385  9048 sgd_solver.cpp:106] Iteration 1813, lr = 0.01
I0408 21:21:09.399925  9048 solver.cpp:240] Iteration 1814, loss = 25.9072
I0408 21:21:09.399958  9048 solver.cpp:256]     Train net output #0: loss = 25.9072 (* 1 = 25.9072 loss)
I0408 21:21:09.399966  9048 sgd_solver.cpp:106] Iteration 1814, lr = 0.01
I0408 21:21:09.675848  9048 solver.cpp:240] Iteration 1815, loss = 11.8391
I0408 21:21:09.675890  9048 solver.cpp:256]     Train net output #0: loss = 11.8391 (* 1 = 11.8391 loss)
I0408 21:21:09.675899  9048 sgd_solver.cpp:106] Iteration 1815, lr = 0.01
I0408 21:21:09.951907  9048 solver.cpp:240] Iteration 1816, loss = 3.36308
I0408 21:21:09.951941  9048 solver.cpp:256]     Train net output #0: loss = 3.36307 (* 1 = 3.36307 loss)
I0408 21:21:09.951947  9048 sgd_solver.cpp:106] Iteration 1816, lr = 0.01
I0408 21:21:10.228235  9048 solver.cpp:240] Iteration 1817, loss = 5.55484
I0408 21:21:10.228266  9048 solver.cpp:256]     Train net output #0: loss = 5.55483 (* 1 = 5.55483 loss)
I0408 21:21:10.228273  9048 sgd_solver.cpp:106] Iteration 1817, lr = 0.01
I0408 21:21:10.503301  9048 solver.cpp:240] Iteration 1818, loss = 21.3345
I0408 21:21:10.503334  9048 solver.cpp:256]     Train net output #0: loss = 21.3345 (* 1 = 21.3345 loss)
I0408 21:21:10.503342  9048 sgd_solver.cpp:106] Iteration 1818, lr = 0.01
I0408 21:21:10.779162  9048 solver.cpp:240] Iteration 1819, loss = 18.6192
I0408 21:21:10.779194  9048 solver.cpp:256]     Train net output #0: loss = 18.6191 (* 1 = 18.6191 loss)
I0408 21:21:10.779202  9048 sgd_solver.cpp:106] Iteration 1819, lr = 0.01
I0408 21:21:11.054287  9048 solver.cpp:240] Iteration 1820, loss = 24.1229
I0408 21:21:11.054322  9048 solver.cpp:256]     Train net output #0: loss = 24.1229 (* 1 = 24.1229 loss)
I0408 21:21:11.054330  9048 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0408 21:21:11.329982  9048 solver.cpp:240] Iteration 1821, loss = 13.0815
I0408 21:21:11.330013  9048 solver.cpp:256]     Train net output #0: loss = 13.0815 (* 1 = 13.0815 loss)
I0408 21:21:11.330021  9048 sgd_solver.cpp:106] Iteration 1821, lr = 0.01
I0408 21:21:11.605839  9048 solver.cpp:240] Iteration 1822, loss = 13.7044
I0408 21:21:11.605871  9048 solver.cpp:256]     Train net output #0: loss = 13.7044 (* 1 = 13.7044 loss)
I0408 21:21:11.605880  9048 sgd_solver.cpp:106] Iteration 1822, lr = 0.01
I0408 21:21:11.882253  9048 solver.cpp:240] Iteration 1823, loss = 5.91583
I0408 21:21:11.882292  9048 solver.cpp:256]     Train net output #0: loss = 5.91582 (* 1 = 5.91582 loss)
I0408 21:21:11.882302  9048 sgd_solver.cpp:106] Iteration 1823, lr = 0.01
I0408 21:21:12.158483  9048 solver.cpp:240] Iteration 1824, loss = 21.6875
I0408 21:21:12.158517  9048 solver.cpp:256]     Train net output #0: loss = 21.6875 (* 1 = 21.6875 loss)
I0408 21:21:12.158525  9048 sgd_solver.cpp:106] Iteration 1824, lr = 0.01
I0408 21:21:12.433755  9048 solver.cpp:240] Iteration 1825, loss = 18.858
I0408 21:21:12.433799  9048 solver.cpp:256]     Train net output #0: loss = 18.858 (* 1 = 18.858 loss)
I0408 21:21:12.433809  9048 sgd_solver.cpp:106] Iteration 1825, lr = 0.01
I0408 21:21:12.709101  9048 solver.cpp:240] Iteration 1826, loss = 15.4393
I0408 21:21:12.709144  9048 solver.cpp:256]     Train net output #0: loss = 15.4393 (* 1 = 15.4393 loss)
I0408 21:21:12.709152  9048 sgd_solver.cpp:106] Iteration 1826, lr = 0.01
I0408 21:21:12.985579  9048 solver.cpp:240] Iteration 1827, loss = 2.15938
I0408 21:21:12.985612  9048 solver.cpp:256]     Train net output #0: loss = 2.15938 (* 1 = 2.15938 loss)
I0408 21:21:12.985621  9048 sgd_solver.cpp:106] Iteration 1827, lr = 0.01
I0408 21:21:13.260226  9048 solver.cpp:240] Iteration 1828, loss = 2.08547
I0408 21:21:13.260262  9048 solver.cpp:256]     Train net output #0: loss = 2.08547 (* 1 = 2.08547 loss)
I0408 21:21:13.260270  9048 sgd_solver.cpp:106] Iteration 1828, lr = 0.01
I0408 21:21:13.535660  9048 solver.cpp:240] Iteration 1829, loss = 5.78934
I0408 21:21:13.535692  9048 solver.cpp:256]     Train net output #0: loss = 5.78933 (* 1 = 5.78933 loss)
I0408 21:21:13.535701  9048 sgd_solver.cpp:106] Iteration 1829, lr = 0.01
I0408 21:21:13.810849  9048 solver.cpp:240] Iteration 1830, loss = 9.80167
I0408 21:21:13.810880  9048 solver.cpp:256]     Train net output #0: loss = 9.80166 (* 1 = 9.80166 loss)
I0408 21:21:13.810889  9048 sgd_solver.cpp:106] Iteration 1830, lr = 0.01
I0408 21:21:14.087594  9048 solver.cpp:240] Iteration 1831, loss = 8.60981
I0408 21:21:14.087636  9048 solver.cpp:256]     Train net output #0: loss = 8.6098 (* 1 = 8.6098 loss)
I0408 21:21:14.087644  9048 sgd_solver.cpp:106] Iteration 1831, lr = 0.01
I0408 21:21:14.363713  9048 solver.cpp:240] Iteration 1832, loss = 34.07
I0408 21:21:14.363745  9048 solver.cpp:256]     Train net output #0: loss = 34.07 (* 1 = 34.07 loss)
I0408 21:21:14.363754  9048 sgd_solver.cpp:106] Iteration 1832, lr = 0.01
I0408 21:21:14.639433  9048 solver.cpp:240] Iteration 1833, loss = 5.07024
I0408 21:21:14.639469  9048 solver.cpp:256]     Train net output #0: loss = 5.07023 (* 1 = 5.07023 loss)
I0408 21:21:14.639477  9048 sgd_solver.cpp:106] Iteration 1833, lr = 0.01
I0408 21:21:14.914502  9048 solver.cpp:240] Iteration 1834, loss = 6.83526
I0408 21:21:14.914535  9048 solver.cpp:256]     Train net output #0: loss = 6.83526 (* 1 = 6.83526 loss)
I0408 21:21:14.914542  9048 sgd_solver.cpp:106] Iteration 1834, lr = 0.01
I0408 21:21:15.190573  9048 solver.cpp:240] Iteration 1835, loss = 24.969
I0408 21:21:15.190608  9048 solver.cpp:256]     Train net output #0: loss = 24.969 (* 1 = 24.969 loss)
I0408 21:21:15.190615  9048 sgd_solver.cpp:106] Iteration 1835, lr = 0.01
I0408 21:21:15.465701  9048 solver.cpp:240] Iteration 1836, loss = 26.8318
I0408 21:21:15.465734  9048 solver.cpp:256]     Train net output #0: loss = 26.8318 (* 1 = 26.8318 loss)
I0408 21:21:15.465741  9048 sgd_solver.cpp:106] Iteration 1836, lr = 0.01
I0408 21:21:15.741825  9048 solver.cpp:240] Iteration 1837, loss = 25.0865
I0408 21:21:15.741858  9048 solver.cpp:256]     Train net output #0: loss = 25.0865 (* 1 = 25.0865 loss)
I0408 21:21:15.741866  9048 sgd_solver.cpp:106] Iteration 1837, lr = 0.01
I0408 21:21:16.018554  9048 solver.cpp:240] Iteration 1838, loss = 11.2512
I0408 21:21:16.018589  9048 solver.cpp:256]     Train net output #0: loss = 11.2512 (* 1 = 11.2512 loss)
I0408 21:21:16.018596  9048 sgd_solver.cpp:106] Iteration 1838, lr = 0.01
I0408 21:21:16.294308  9048 solver.cpp:240] Iteration 1839, loss = 1.60057
I0408 21:21:16.294345  9048 solver.cpp:256]     Train net output #0: loss = 1.60056 (* 1 = 1.60056 loss)
I0408 21:21:16.294356  9048 sgd_solver.cpp:106] Iteration 1839, lr = 0.01
I0408 21:21:16.569022  9048 solver.cpp:240] Iteration 1840, loss = 2.59338
I0408 21:21:16.569080  9048 solver.cpp:256]     Train net output #0: loss = 2.59338 (* 1 = 2.59338 loss)
I0408 21:21:16.569092  9048 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0408 21:21:16.844763  9048 solver.cpp:240] Iteration 1841, loss = 6.72134
I0408 21:21:16.844799  9048 solver.cpp:256]     Train net output #0: loss = 6.72133 (* 1 = 6.72133 loss)
I0408 21:21:16.844810  9048 sgd_solver.cpp:106] Iteration 1841, lr = 0.01
I0408 21:21:17.120195  9048 solver.cpp:240] Iteration 1842, loss = 14.8181
I0408 21:21:17.120231  9048 solver.cpp:256]     Train net output #0: loss = 14.8181 (* 1 = 14.8181 loss)
I0408 21:21:17.120242  9048 sgd_solver.cpp:106] Iteration 1842, lr = 0.01
I0408 21:21:17.395648  9048 solver.cpp:240] Iteration 1843, loss = 24.1892
I0408 21:21:17.395684  9048 solver.cpp:256]     Train net output #0: loss = 24.1892 (* 1 = 24.1892 loss)
I0408 21:21:17.395709  9048 sgd_solver.cpp:106] Iteration 1843, lr = 0.01
I0408 21:21:17.672019  9048 solver.cpp:240] Iteration 1844, loss = 8.6483
I0408 21:21:17.672056  9048 solver.cpp:256]     Train net output #0: loss = 8.64829 (* 1 = 8.64829 loss)
I0408 21:21:17.672068  9048 sgd_solver.cpp:106] Iteration 1844, lr = 0.01
I0408 21:21:17.947921  9048 solver.cpp:240] Iteration 1845, loss = 14.9795
I0408 21:21:17.947962  9048 solver.cpp:256]     Train net output #0: loss = 14.9795 (* 1 = 14.9795 loss)
I0408 21:21:17.947973  9048 sgd_solver.cpp:106] Iteration 1845, lr = 0.01
I0408 21:21:18.223068  9048 solver.cpp:240] Iteration 1846, loss = 7.97305
I0408 21:21:18.223106  9048 solver.cpp:256]     Train net output #0: loss = 7.97305 (* 1 = 7.97305 loss)
I0408 21:21:18.223129  9048 sgd_solver.cpp:106] Iteration 1846, lr = 0.01
I0408 21:21:18.499111  9048 solver.cpp:240] Iteration 1847, loss = 17.2883
I0408 21:21:18.499145  9048 solver.cpp:256]     Train net output #0: loss = 17.2883 (* 1 = 17.2883 loss)
I0408 21:21:18.499157  9048 sgd_solver.cpp:106] Iteration 1847, lr = 0.01
I0408 21:21:18.775029  9048 solver.cpp:240] Iteration 1848, loss = 23.1142
I0408 21:21:18.775066  9048 solver.cpp:256]     Train net output #0: loss = 23.1142 (* 1 = 23.1142 loss)
I0408 21:21:18.775077  9048 sgd_solver.cpp:106] Iteration 1848, lr = 0.01
I0408 21:21:19.049068  9048 solver.cpp:240] Iteration 1849, loss = 6.56677
I0408 21:21:19.049104  9048 solver.cpp:256]     Train net output #0: loss = 6.56676 (* 1 = 6.56676 loss)
I0408 21:21:19.049116  9048 sgd_solver.cpp:106] Iteration 1849, lr = 0.01
I0408 21:21:19.324496  9048 solver.cpp:240] Iteration 1850, loss = 21.3602
I0408 21:21:19.324532  9048 solver.cpp:256]     Train net output #0: loss = 21.3602 (* 1 = 21.3602 loss)
I0408 21:21:19.324543  9048 sgd_solver.cpp:106] Iteration 1850, lr = 0.01
I0408 21:21:19.601064  9048 solver.cpp:240] Iteration 1851, loss = 18.8997
I0408 21:21:19.601105  9048 solver.cpp:256]     Train net output #0: loss = 18.8997 (* 1 = 18.8997 loss)
I0408 21:21:19.601130  9048 sgd_solver.cpp:106] Iteration 1851, lr = 0.01
I0408 21:21:19.876796  9048 solver.cpp:240] Iteration 1852, loss = 25.203
I0408 21:21:19.878190  9048 solver.cpp:256]     Train net output #0: loss = 25.203 (* 1 = 25.203 loss)
I0408 21:21:19.878226  9048 sgd_solver.cpp:106] Iteration 1852, lr = 0.01
I0408 21:21:20.152220  9048 solver.cpp:240] Iteration 1853, loss = 14.7902
I0408 21:21:20.152254  9048 solver.cpp:256]     Train net output #0: loss = 14.7902 (* 1 = 14.7902 loss)
I0408 21:21:20.152266  9048 sgd_solver.cpp:106] Iteration 1853, lr = 0.01
I0408 21:21:20.427072  9048 solver.cpp:240] Iteration 1854, loss = 22.3561
I0408 21:21:20.427114  9048 solver.cpp:256]     Train net output #0: loss = 22.3561 (* 1 = 22.3561 loss)
I0408 21:21:20.427126  9048 sgd_solver.cpp:106] Iteration 1854, lr = 0.01
I0408 21:21:20.703822  9048 solver.cpp:240] Iteration 1855, loss = 16.5325
I0408 21:21:20.703862  9048 solver.cpp:256]     Train net output #0: loss = 16.5324 (* 1 = 16.5324 loss)
I0408 21:21:20.703874  9048 sgd_solver.cpp:106] Iteration 1855, lr = 0.01
I0408 21:21:20.979454  9048 solver.cpp:240] Iteration 1856, loss = 16.3146
I0408 21:21:20.979490  9048 solver.cpp:256]     Train net output #0: loss = 16.3146 (* 1 = 16.3146 loss)
I0408 21:21:20.979512  9048 sgd_solver.cpp:106] Iteration 1856, lr = 0.01
I0408 21:21:21.254359  9048 solver.cpp:240] Iteration 1857, loss = 29.0037
I0408 21:21:21.254395  9048 solver.cpp:256]     Train net output #0: loss = 29.0036 (* 1 = 29.0036 loss)
I0408 21:21:21.254407  9048 sgd_solver.cpp:106] Iteration 1857, lr = 0.01
I0408 21:21:21.529505  9048 solver.cpp:240] Iteration 1858, loss = 20.2213
I0408 21:21:21.529546  9048 solver.cpp:256]     Train net output #0: loss = 20.2213 (* 1 = 20.2213 loss)
I0408 21:21:21.529558  9048 sgd_solver.cpp:106] Iteration 1858, lr = 0.01
I0408 21:21:21.804603  9048 solver.cpp:240] Iteration 1859, loss = 17.1664
I0408 21:21:21.804641  9048 solver.cpp:256]     Train net output #0: loss = 17.1664 (* 1 = 17.1664 loss)
I0408 21:21:21.804652  9048 sgd_solver.cpp:106] Iteration 1859, lr = 0.01
I0408 21:21:22.079552  9048 solver.cpp:240] Iteration 1860, loss = 15.7014
I0408 21:21:22.079589  9048 solver.cpp:256]     Train net output #0: loss = 15.7014 (* 1 = 15.7014 loss)
I0408 21:21:22.079602  9048 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0408 21:21:22.355375  9048 solver.cpp:240] Iteration 1861, loss = 20.7398
I0408 21:21:22.355412  9048 solver.cpp:256]     Train net output #0: loss = 20.7398 (* 1 = 20.7398 loss)
I0408 21:21:22.355423  9048 sgd_solver.cpp:106] Iteration 1861, lr = 0.01
I0408 21:21:22.631328  9048 solver.cpp:240] Iteration 1862, loss = 16.9776
I0408 21:21:22.631366  9048 solver.cpp:256]     Train net output #0: loss = 16.9776 (* 1 = 16.9776 loss)
I0408 21:21:22.631377  9048 sgd_solver.cpp:106] Iteration 1862, lr = 0.01
I0408 21:21:22.907222  9048 solver.cpp:240] Iteration 1863, loss = 23.6047
I0408 21:21:22.907259  9048 solver.cpp:256]     Train net output #0: loss = 23.6047 (* 1 = 23.6047 loss)
I0408 21:21:22.907271  9048 sgd_solver.cpp:106] Iteration 1863, lr = 0.01
I0408 21:21:23.182903  9048 solver.cpp:240] Iteration 1864, loss = 10.8565
I0408 21:21:23.182950  9048 solver.cpp:256]     Train net output #0: loss = 10.8565 (* 1 = 10.8565 loss)
I0408 21:21:23.182961  9048 sgd_solver.cpp:106] Iteration 1864, lr = 0.01
I0408 21:21:23.458940  9048 solver.cpp:240] Iteration 1865, loss = 19.992
I0408 21:21:23.458976  9048 solver.cpp:256]     Train net output #0: loss = 19.992 (* 1 = 19.992 loss)
I0408 21:21:23.458988  9048 sgd_solver.cpp:106] Iteration 1865, lr = 0.01
I0408 21:21:23.733563  9048 solver.cpp:240] Iteration 1866, loss = 18.3328
I0408 21:21:23.733600  9048 solver.cpp:256]     Train net output #0: loss = 18.3328 (* 1 = 18.3328 loss)
I0408 21:21:23.733613  9048 sgd_solver.cpp:106] Iteration 1866, lr = 0.01
I0408 21:21:24.009439  9048 solver.cpp:240] Iteration 1867, loss = 10.1692
I0408 21:21:24.009474  9048 solver.cpp:256]     Train net output #0: loss = 10.1692 (* 1 = 10.1692 loss)
I0408 21:21:24.009486  9048 sgd_solver.cpp:106] Iteration 1867, lr = 0.01
I0408 21:21:24.284432  9048 solver.cpp:240] Iteration 1868, loss = 11.153
I0408 21:21:24.284468  9048 solver.cpp:256]     Train net output #0: loss = 11.153 (* 1 = 11.153 loss)
I0408 21:21:24.284519  9048 sgd_solver.cpp:106] Iteration 1868, lr = 0.01
I0408 21:21:24.559741  9048 solver.cpp:240] Iteration 1869, loss = 16.6183
I0408 21:21:24.559780  9048 solver.cpp:256]     Train net output #0: loss = 16.6183 (* 1 = 16.6183 loss)
I0408 21:21:24.559793  9048 sgd_solver.cpp:106] Iteration 1869, lr = 0.01
I0408 21:21:24.834077  9048 solver.cpp:240] Iteration 1870, loss = 18.3829
I0408 21:21:24.834115  9048 solver.cpp:256]     Train net output #0: loss = 18.3828 (* 1 = 18.3828 loss)
I0408 21:21:24.834126  9048 sgd_solver.cpp:106] Iteration 1870, lr = 0.01
I0408 21:21:25.109781  9048 solver.cpp:240] Iteration 1871, loss = 34.9964
I0408 21:21:25.109817  9048 solver.cpp:256]     Train net output #0: loss = 34.9963 (* 1 = 34.9963 loss)
I0408 21:21:25.109827  9048 sgd_solver.cpp:106] Iteration 1871, lr = 0.01
I0408 21:21:25.385304  9048 solver.cpp:240] Iteration 1872, loss = 28.167
I0408 21:21:25.385341  9048 solver.cpp:256]     Train net output #0: loss = 28.167 (* 1 = 28.167 loss)
I0408 21:21:25.385352  9048 sgd_solver.cpp:106] Iteration 1872, lr = 0.01
I0408 21:21:25.659926  9048 solver.cpp:240] Iteration 1873, loss = 31.8876
I0408 21:21:25.659962  9048 solver.cpp:256]     Train net output #0: loss = 31.8876 (* 1 = 31.8876 loss)
I0408 21:21:25.659974  9048 sgd_solver.cpp:106] Iteration 1873, lr = 0.01
I0408 21:21:25.935534  9048 solver.cpp:240] Iteration 1874, loss = 17.3808
I0408 21:21:25.935575  9048 solver.cpp:256]     Train net output #0: loss = 17.3808 (* 1 = 17.3808 loss)
I0408 21:21:25.935587  9048 sgd_solver.cpp:106] Iteration 1874, lr = 0.01
I0408 21:21:26.210706  9048 solver.cpp:240] Iteration 1875, loss = 11.8937
I0408 21:21:26.210742  9048 solver.cpp:256]     Train net output #0: loss = 11.8937 (* 1 = 11.8937 loss)
I0408 21:21:26.210754  9048 sgd_solver.cpp:106] Iteration 1875, lr = 0.01
I0408 21:21:26.485340  9048 solver.cpp:240] Iteration 1876, loss = 13.4237
I0408 21:21:26.485379  9048 solver.cpp:256]     Train net output #0: loss = 13.4237 (* 1 = 13.4237 loss)
I0408 21:21:26.485390  9048 sgd_solver.cpp:106] Iteration 1876, lr = 0.01
I0408 21:21:26.759853  9048 solver.cpp:240] Iteration 1877, loss = 21.5775
I0408 21:21:26.759912  9048 solver.cpp:256]     Train net output #0: loss = 21.5775 (* 1 = 21.5775 loss)
I0408 21:21:26.759925  9048 sgd_solver.cpp:106] Iteration 1877, lr = 0.01
I0408 21:21:27.036489  9048 solver.cpp:240] Iteration 1878, loss = 18.7983
I0408 21:21:27.036528  9048 solver.cpp:256]     Train net output #0: loss = 18.7983 (* 1 = 18.7983 loss)
I0408 21:21:27.036551  9048 sgd_solver.cpp:106] Iteration 1878, lr = 0.01
I0408 21:21:27.310988  9048 solver.cpp:240] Iteration 1879, loss = 20.5528
I0408 21:21:27.311025  9048 solver.cpp:256]     Train net output #0: loss = 20.5528 (* 1 = 20.5528 loss)
I0408 21:21:27.311038  9048 sgd_solver.cpp:106] Iteration 1879, lr = 0.01
I0408 21:21:27.585821  9048 solver.cpp:240] Iteration 1880, loss = 32.7296
I0408 21:21:27.585857  9048 solver.cpp:256]     Train net output #0: loss = 32.7296 (* 1 = 32.7296 loss)
I0408 21:21:27.585870  9048 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0408 21:21:27.861987  9048 solver.cpp:240] Iteration 1881, loss = 23.8125
I0408 21:21:27.862025  9048 solver.cpp:256]     Train net output #0: loss = 23.8125 (* 1 = 23.8125 loss)
I0408 21:21:27.862037  9048 sgd_solver.cpp:106] Iteration 1881, lr = 0.01
I0408 21:21:28.137794  9048 solver.cpp:240] Iteration 1882, loss = 22.003
I0408 21:21:28.137828  9048 solver.cpp:256]     Train net output #0: loss = 22.003 (* 1 = 22.003 loss)
I0408 21:21:28.137840  9048 sgd_solver.cpp:106] Iteration 1882, lr = 0.01
I0408 21:21:28.413439  9048 solver.cpp:240] Iteration 1883, loss = 9.38973
I0408 21:21:28.413471  9048 solver.cpp:256]     Train net output #0: loss = 9.38972 (* 1 = 9.38972 loss)
I0408 21:21:28.413483  9048 sgd_solver.cpp:106] Iteration 1883, lr = 0.01
I0408 21:21:28.689203  9048 solver.cpp:240] Iteration 1884, loss = 8.06269
I0408 21:21:28.689239  9048 solver.cpp:256]     Train net output #0: loss = 8.06268 (* 1 = 8.06268 loss)
I0408 21:21:28.689278  9048 sgd_solver.cpp:106] Iteration 1884, lr = 0.01
I0408 21:21:28.966033  9048 solver.cpp:240] Iteration 1885, loss = 32.5807
I0408 21:21:28.966068  9048 solver.cpp:256]     Train net output #0: loss = 32.5807 (* 1 = 32.5807 loss)
I0408 21:21:28.966092  9048 sgd_solver.cpp:106] Iteration 1885, lr = 0.01
I0408 21:21:29.241534  9048 solver.cpp:240] Iteration 1886, loss = 19.1496
I0408 21:21:29.241570  9048 solver.cpp:256]     Train net output #0: loss = 19.1496 (* 1 = 19.1496 loss)
I0408 21:21:29.241595  9048 sgd_solver.cpp:106] Iteration 1886, lr = 0.01
I0408 21:21:29.516098  9048 solver.cpp:240] Iteration 1887, loss = 28.355
I0408 21:21:29.516139  9048 solver.cpp:256]     Train net output #0: loss = 28.355 (* 1 = 28.355 loss)
I0408 21:21:29.516151  9048 sgd_solver.cpp:106] Iteration 1887, lr = 0.01
I0408 21:21:29.791040  9048 solver.cpp:240] Iteration 1888, loss = 33.7908
I0408 21:21:29.791077  9048 solver.cpp:256]     Train net output #0: loss = 33.7908 (* 1 = 33.7908 loss)
I0408 21:21:29.791088  9048 sgd_solver.cpp:106] Iteration 1888, lr = 0.01
I0408 21:21:30.068080  9048 solver.cpp:240] Iteration 1889, loss = 26.3575
I0408 21:21:30.068114  9048 solver.cpp:256]     Train net output #0: loss = 26.3575 (* 1 = 26.3575 loss)
I0408 21:21:30.068127  9048 sgd_solver.cpp:106] Iteration 1889, lr = 0.01
I0408 21:21:30.345163  9048 solver.cpp:240] Iteration 1890, loss = 15.2261
I0408 21:21:30.345201  9048 solver.cpp:256]     Train net output #0: loss = 15.2261 (* 1 = 15.2261 loss)
I0408 21:21:30.345211  9048 sgd_solver.cpp:106] Iteration 1890, lr = 0.01
I0408 21:21:30.619931  9048 solver.cpp:240] Iteration 1891, loss = 24.1512
I0408 21:21:30.619966  9048 solver.cpp:256]     Train net output #0: loss = 24.1512 (* 1 = 24.1512 loss)
I0408 21:21:30.619978  9048 sgd_solver.cpp:106] Iteration 1891, lr = 0.01
I0408 21:21:30.894613  9048 solver.cpp:240] Iteration 1892, loss = 19.115
I0408 21:21:30.894654  9048 solver.cpp:256]     Train net output #0: loss = 19.115 (* 1 = 19.115 loss)
I0408 21:21:30.894666  9048 sgd_solver.cpp:106] Iteration 1892, lr = 0.01
I0408 21:21:31.169956  9048 solver.cpp:240] Iteration 1893, loss = 14.3081
I0408 21:21:31.169993  9048 solver.cpp:256]     Train net output #0: loss = 14.3081 (* 1 = 14.3081 loss)
I0408 21:21:31.170006  9048 sgd_solver.cpp:106] Iteration 1893, lr = 0.01
I0408 21:21:31.445061  9048 solver.cpp:240] Iteration 1894, loss = 12.0754
I0408 21:21:31.445098  9048 solver.cpp:256]     Train net output #0: loss = 12.0754 (* 1 = 12.0754 loss)
I0408 21:21:31.445111  9048 sgd_solver.cpp:106] Iteration 1894, lr = 0.01
I0408 21:21:31.720520  9048 solver.cpp:240] Iteration 1895, loss = 14.9869
I0408 21:21:31.720556  9048 solver.cpp:256]     Train net output #0: loss = 14.9869 (* 1 = 14.9869 loss)
I0408 21:21:31.720568  9048 sgd_solver.cpp:106] Iteration 1895, lr = 0.01
I0408 21:21:31.995913  9048 solver.cpp:240] Iteration 1896, loss = 2.61493
I0408 21:21:31.995945  9048 solver.cpp:256]     Train net output #0: loss = 2.61492 (* 1 = 2.61492 loss)
I0408 21:21:31.995956  9048 sgd_solver.cpp:106] Iteration 1896, lr = 0.01
I0408 21:21:32.270998  9048 solver.cpp:240] Iteration 1897, loss = 11.042
I0408 21:21:32.271037  9048 solver.cpp:256]     Train net output #0: loss = 11.042 (* 1 = 11.042 loss)
I0408 21:21:32.271049  9048 sgd_solver.cpp:106] Iteration 1897, lr = 0.01
I0408 21:21:32.546464  9048 solver.cpp:240] Iteration 1898, loss = 15.7823
I0408 21:21:32.546499  9048 solver.cpp:256]     Train net output #0: loss = 15.7822 (* 1 = 15.7822 loss)
I0408 21:21:32.546512  9048 sgd_solver.cpp:106] Iteration 1898, lr = 0.01
I0408 21:21:32.820663  9048 solver.cpp:240] Iteration 1899, loss = 5.84935
I0408 21:21:32.820698  9048 solver.cpp:256]     Train net output #0: loss = 5.84934 (* 1 = 5.84934 loss)
I0408 21:21:32.820709  9048 sgd_solver.cpp:106] Iteration 1899, lr = 0.01
I0408 21:21:33.095835  9048 solver.cpp:240] Iteration 1900, loss = 4.62426
I0408 21:21:33.095870  9048 solver.cpp:256]     Train net output #0: loss = 4.62425 (* 1 = 4.62425 loss)
I0408 21:21:33.095893  9048 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0408 21:21:33.370996  9048 solver.cpp:240] Iteration 1901, loss = 19.0151
I0408 21:21:33.371034  9048 solver.cpp:256]     Train net output #0: loss = 19.0151 (* 1 = 19.0151 loss)
I0408 21:21:33.371047  9048 sgd_solver.cpp:106] Iteration 1901, lr = 0.01
I0408 21:21:33.646935  9048 solver.cpp:240] Iteration 1902, loss = 11.2474
I0408 21:21:33.646975  9048 solver.cpp:256]     Train net output #0: loss = 11.2474 (* 1 = 11.2474 loss)
I0408 21:21:33.646986  9048 sgd_solver.cpp:106] Iteration 1902, lr = 0.01
I0408 21:21:33.922317  9048 solver.cpp:240] Iteration 1903, loss = 13.6982
I0408 21:21:33.922351  9048 solver.cpp:256]     Train net output #0: loss = 13.6982 (* 1 = 13.6982 loss)
I0408 21:21:33.922364  9048 sgd_solver.cpp:106] Iteration 1903, lr = 0.01
I0408 21:21:34.198665  9048 solver.cpp:240] Iteration 1904, loss = 6.43755
I0408 21:21:34.198699  9048 solver.cpp:256]     Train net output #0: loss = 6.43754 (* 1 = 6.43754 loss)
I0408 21:21:34.198710  9048 sgd_solver.cpp:106] Iteration 1904, lr = 0.01
I0408 21:21:34.474675  9048 solver.cpp:240] Iteration 1905, loss = 14.9721
I0408 21:21:34.474712  9048 solver.cpp:256]     Train net output #0: loss = 14.9721 (* 1 = 14.9721 loss)
I0408 21:21:34.474735  9048 sgd_solver.cpp:106] Iteration 1905, lr = 0.01
I0408 21:21:34.749858  9048 solver.cpp:240] Iteration 1906, loss = 2.51431
I0408 21:21:34.749896  9048 solver.cpp:256]     Train net output #0: loss = 2.5143 (* 1 = 2.5143 loss)
I0408 21:21:34.749907  9048 sgd_solver.cpp:106] Iteration 1906, lr = 0.01
I0408 21:21:35.025136  9048 solver.cpp:240] Iteration 1907, loss = 7.91683
I0408 21:21:35.025171  9048 solver.cpp:256]     Train net output #0: loss = 7.91682 (* 1 = 7.91682 loss)
I0408 21:21:35.025182  9048 sgd_solver.cpp:106] Iteration 1907, lr = 0.01
I0408 21:21:35.300437  9048 solver.cpp:240] Iteration 1908, loss = 11.5983
I0408 21:21:35.300474  9048 solver.cpp:256]     Train net output #0: loss = 11.5983 (* 1 = 11.5983 loss)
I0408 21:21:35.300487  9048 sgd_solver.cpp:106] Iteration 1908, lr = 0.01
I0408 21:21:35.576529  9048 solver.cpp:240] Iteration 1909, loss = 14.1772
I0408 21:21:35.576568  9048 solver.cpp:256]     Train net output #0: loss = 14.1771 (* 1 = 14.1771 loss)
I0408 21:21:35.576581  9048 sgd_solver.cpp:106] Iteration 1909, lr = 0.01
I0408 21:21:35.852032  9048 solver.cpp:240] Iteration 1910, loss = 9.5448
I0408 21:21:35.852073  9048 solver.cpp:256]     Train net output #0: loss = 9.54479 (* 1 = 9.54479 loss)
I0408 21:21:35.852087  9048 sgd_solver.cpp:106] Iteration 1910, lr = 0.01
I0408 21:21:36.126505  9048 solver.cpp:240] Iteration 1911, loss = 5.52203
I0408 21:21:36.126541  9048 solver.cpp:256]     Train net output #0: loss = 5.52202 (* 1 = 5.52202 loss)
I0408 21:21:36.126552  9048 sgd_solver.cpp:106] Iteration 1911, lr = 0.01
I0408 21:21:36.402808  9048 solver.cpp:240] Iteration 1912, loss = 2.09117
I0408 21:21:36.402844  9048 solver.cpp:256]     Train net output #0: loss = 2.09116 (* 1 = 2.09116 loss)
I0408 21:21:36.402855  9048 sgd_solver.cpp:106] Iteration 1912, lr = 0.01
I0408 21:21:36.677388  9048 solver.cpp:240] Iteration 1913, loss = 6.60194
I0408 21:21:36.677423  9048 solver.cpp:256]     Train net output #0: loss = 6.60193 (* 1 = 6.60193 loss)
I0408 21:21:36.677434  9048 sgd_solver.cpp:106] Iteration 1913, lr = 0.01
I0408 21:21:36.951485  9048 solver.cpp:240] Iteration 1914, loss = 9.04696
I0408 21:21:36.951522  9048 solver.cpp:256]     Train net output #0: loss = 9.04695 (* 1 = 9.04695 loss)
I0408 21:21:36.951534  9048 sgd_solver.cpp:106] Iteration 1914, lr = 0.01
I0408 21:21:37.226686  9048 solver.cpp:240] Iteration 1915, loss = 9.44637
I0408 21:21:37.226727  9048 solver.cpp:256]     Train net output #0: loss = 9.44637 (* 1 = 9.44637 loss)
I0408 21:21:37.226738  9048 sgd_solver.cpp:106] Iteration 1915, lr = 0.01
I0408 21:21:37.502745  9048 solver.cpp:240] Iteration 1916, loss = 6.2637
I0408 21:21:37.502780  9048 solver.cpp:256]     Train net output #0: loss = 6.26369 (* 1 = 6.26369 loss)
I0408 21:21:37.502791  9048 sgd_solver.cpp:106] Iteration 1916, lr = 0.01
I0408 21:21:37.778750  9048 solver.cpp:240] Iteration 1917, loss = 27.6866
I0408 21:21:37.778789  9048 solver.cpp:256]     Train net output #0: loss = 27.6866 (* 1 = 27.6866 loss)
I0408 21:21:37.778800  9048 sgd_solver.cpp:106] Iteration 1917, lr = 0.01
I0408 21:21:38.055027  9048 solver.cpp:240] Iteration 1918, loss = 24.5987
I0408 21:21:38.055063  9048 solver.cpp:256]     Train net output #0: loss = 24.5987 (* 1 = 24.5987 loss)
I0408 21:21:38.055075  9048 sgd_solver.cpp:106] Iteration 1918, lr = 0.01
I0408 21:21:38.331037  9048 solver.cpp:240] Iteration 1919, loss = 13.6567
I0408 21:21:38.331073  9048 solver.cpp:256]     Train net output #0: loss = 13.6567 (* 1 = 13.6567 loss)
I0408 21:21:38.331085  9048 sgd_solver.cpp:106] Iteration 1919, lr = 0.01
I0408 21:21:38.606622  9048 solver.cpp:240] Iteration 1920, loss = 25.1323
I0408 21:21:38.606657  9048 solver.cpp:256]     Train net output #0: loss = 25.1323 (* 1 = 25.1323 loss)
I0408 21:21:38.606681  9048 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0408 21:21:38.882241  9048 solver.cpp:240] Iteration 1921, loss = 15.2788
I0408 21:21:38.882277  9048 solver.cpp:256]     Train net output #0: loss = 15.2788 (* 1 = 15.2788 loss)
I0408 21:21:38.882287  9048 sgd_solver.cpp:106] Iteration 1921, lr = 0.01
I0408 21:21:39.157951  9048 solver.cpp:240] Iteration 1922, loss = 5.47783
I0408 21:21:39.157986  9048 solver.cpp:256]     Train net output #0: loss = 5.47782 (* 1 = 5.47782 loss)
I0408 21:21:39.157997  9048 sgd_solver.cpp:106] Iteration 1922, lr = 0.01
I0408 21:21:39.433890  9048 solver.cpp:240] Iteration 1923, loss = 18.4734
I0408 21:21:39.433928  9048 solver.cpp:256]     Train net output #0: loss = 18.4734 (* 1 = 18.4734 loss)
I0408 21:21:39.433939  9048 sgd_solver.cpp:106] Iteration 1923, lr = 0.01
I0408 21:21:39.710361  9048 solver.cpp:240] Iteration 1924, loss = 12.4455
I0408 21:21:39.710399  9048 solver.cpp:256]     Train net output #0: loss = 12.4455 (* 1 = 12.4455 loss)
I0408 21:21:39.710410  9048 sgd_solver.cpp:106] Iteration 1924, lr = 0.01
I0408 21:21:39.984798  9048 solver.cpp:240] Iteration 1925, loss = 12.6554
I0408 21:21:39.984834  9048 solver.cpp:256]     Train net output #0: loss = 12.6554 (* 1 = 12.6554 loss)
I0408 21:21:39.984848  9048 sgd_solver.cpp:106] Iteration 1925, lr = 0.01
I0408 21:21:40.260479  9048 solver.cpp:240] Iteration 1926, loss = 29.8593
I0408 21:21:40.260514  9048 solver.cpp:256]     Train net output #0: loss = 29.8593 (* 1 = 29.8593 loss)
I0408 21:21:40.260526  9048 sgd_solver.cpp:106] Iteration 1926, lr = 0.01
I0408 21:21:40.535590  9048 solver.cpp:240] Iteration 1927, loss = 12.4141
I0408 21:21:40.535626  9048 solver.cpp:256]     Train net output #0: loss = 12.4141 (* 1 = 12.4141 loss)
I0408 21:21:40.535637  9048 sgd_solver.cpp:106] Iteration 1927, lr = 0.01
I0408 21:21:40.810803  9048 solver.cpp:240] Iteration 1928, loss = 20.2075
I0408 21:21:40.810845  9048 solver.cpp:256]     Train net output #0: loss = 20.2075 (* 1 = 20.2075 loss)
I0408 21:21:40.810858  9048 sgd_solver.cpp:106] Iteration 1928, lr = 0.01
I0408 21:21:41.086555  9048 solver.cpp:240] Iteration 1929, loss = 10.8033
I0408 21:21:41.086591  9048 solver.cpp:256]     Train net output #0: loss = 10.8033 (* 1 = 10.8033 loss)
I0408 21:21:41.086602  9048 sgd_solver.cpp:106] Iteration 1929, lr = 0.01
I0408 21:21:41.361320  9048 solver.cpp:240] Iteration 1930, loss = 18.9246
I0408 21:21:41.361356  9048 solver.cpp:256]     Train net output #0: loss = 18.9246 (* 1 = 18.9246 loss)
I0408 21:21:41.361367  9048 sgd_solver.cpp:106] Iteration 1930, lr = 0.01
I0408 21:21:41.638720  9048 solver.cpp:240] Iteration 1931, loss = 8.26395
I0408 21:21:41.638756  9048 solver.cpp:256]     Train net output #0: loss = 8.26394 (* 1 = 8.26394 loss)
I0408 21:21:41.638767  9048 sgd_solver.cpp:106] Iteration 1931, lr = 0.01
I0408 21:21:41.915123  9048 solver.cpp:240] Iteration 1932, loss = 7.48453
I0408 21:21:41.915156  9048 solver.cpp:256]     Train net output #0: loss = 7.48453 (* 1 = 7.48453 loss)
I0408 21:21:41.915168  9048 sgd_solver.cpp:106] Iteration 1932, lr = 0.01
I0408 21:21:42.190809  9048 solver.cpp:240] Iteration 1933, loss = 11.1739
I0408 21:21:42.190871  9048 solver.cpp:256]     Train net output #0: loss = 11.1739 (* 1 = 11.1739 loss)
I0408 21:21:42.190896  9048 sgd_solver.cpp:106] Iteration 1933, lr = 0.01
I0408 21:21:42.466866  9048 solver.cpp:240] Iteration 1934, loss = 15.808
I0408 21:21:42.466902  9048 solver.cpp:256]     Train net output #0: loss = 15.808 (* 1 = 15.808 loss)
I0408 21:21:42.466924  9048 sgd_solver.cpp:106] Iteration 1934, lr = 0.01
I0408 21:21:42.742220  9048 solver.cpp:240] Iteration 1935, loss = 12.0368
I0408 21:21:42.742256  9048 solver.cpp:256]     Train net output #0: loss = 12.0368 (* 1 = 12.0368 loss)
I0408 21:21:42.742267  9048 sgd_solver.cpp:106] Iteration 1935, lr = 0.01
I0408 21:21:43.017161  9048 solver.cpp:240] Iteration 1936, loss = 8.8758
I0408 21:21:43.017195  9048 solver.cpp:256]     Train net output #0: loss = 8.87579 (* 1 = 8.87579 loss)
I0408 21:21:43.017206  9048 sgd_solver.cpp:106] Iteration 1936, lr = 0.01
I0408 21:21:43.292666  9048 solver.cpp:240] Iteration 1937, loss = 7.09235
I0408 21:21:43.292701  9048 solver.cpp:256]     Train net output #0: loss = 7.09235 (* 1 = 7.09235 loss)
I0408 21:21:43.292711  9048 sgd_solver.cpp:106] Iteration 1937, lr = 0.01
I0408 21:21:43.567517  9048 solver.cpp:240] Iteration 1938, loss = 17.9821
I0408 21:21:43.567560  9048 solver.cpp:256]     Train net output #0: loss = 17.9821 (* 1 = 17.9821 loss)
I0408 21:21:43.567574  9048 sgd_solver.cpp:106] Iteration 1938, lr = 0.01
I0408 21:21:43.843240  9048 solver.cpp:240] Iteration 1939, loss = 4.27799
I0408 21:21:43.843276  9048 solver.cpp:256]     Train net output #0: loss = 4.27798 (* 1 = 4.27798 loss)
I0408 21:21:43.843286  9048 sgd_solver.cpp:106] Iteration 1939, lr = 0.01
I0408 21:21:44.118208  9048 solver.cpp:240] Iteration 1940, loss = 11.4036
I0408 21:21:44.118243  9048 solver.cpp:256]     Train net output #0: loss = 11.4036 (* 1 = 11.4036 loss)
I0408 21:21:44.118266  9048 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0408 21:21:44.393980  9048 solver.cpp:240] Iteration 1941, loss = 17.7966
I0408 21:21:44.394028  9048 solver.cpp:256]     Train net output #0: loss = 17.7966 (* 1 = 17.7966 loss)
I0408 21:21:44.394050  9048 sgd_solver.cpp:106] Iteration 1941, lr = 0.01
I0408 21:21:44.669824  9048 solver.cpp:240] Iteration 1942, loss = 4.61632
I0408 21:21:44.669859  9048 solver.cpp:256]     Train net output #0: loss = 4.61631 (* 1 = 4.61631 loss)
I0408 21:21:44.669870  9048 sgd_solver.cpp:106] Iteration 1942, lr = 0.01
I0408 21:21:44.946842  9048 solver.cpp:240] Iteration 1943, loss = 15.824
I0408 21:21:44.946890  9048 solver.cpp:256]     Train net output #0: loss = 15.824 (* 1 = 15.824 loss)
I0408 21:21:44.946902  9048 sgd_solver.cpp:106] Iteration 1943, lr = 0.01
I0408 21:21:45.223042  9048 solver.cpp:240] Iteration 1944, loss = 3.19037
I0408 21:21:45.223076  9048 solver.cpp:256]     Train net output #0: loss = 3.19036 (* 1 = 3.19036 loss)
I0408 21:21:45.223088  9048 sgd_solver.cpp:106] Iteration 1944, lr = 0.01
I0408 21:21:45.498699  9048 solver.cpp:240] Iteration 1945, loss = 11.1291
I0408 21:21:45.498733  9048 solver.cpp:256]     Train net output #0: loss = 11.1291 (* 1 = 11.1291 loss)
I0408 21:21:45.498756  9048 sgd_solver.cpp:106] Iteration 1945, lr = 0.01
I0408 21:21:45.773922  9048 solver.cpp:240] Iteration 1946, loss = 5.28202
I0408 21:21:45.773957  9048 solver.cpp:256]     Train net output #0: loss = 5.28201 (* 1 = 5.28201 loss)
I0408 21:21:45.773968  9048 sgd_solver.cpp:106] Iteration 1946, lr = 0.01
I0408 21:21:46.050390  9048 solver.cpp:240] Iteration 1947, loss = 15.3178
I0408 21:21:46.050426  9048 solver.cpp:256]     Train net output #0: loss = 15.3178 (* 1 = 15.3178 loss)
I0408 21:21:46.050451  9048 sgd_solver.cpp:106] Iteration 1947, lr = 0.01
I0408 21:21:46.325770  9048 solver.cpp:240] Iteration 1948, loss = 4.70315
I0408 21:21:46.325805  9048 solver.cpp:256]     Train net output #0: loss = 4.70314 (* 1 = 4.70314 loss)
I0408 21:21:46.325816  9048 sgd_solver.cpp:106] Iteration 1948, lr = 0.01
I0408 21:21:46.601852  9048 solver.cpp:240] Iteration 1949, loss = 3.54637
I0408 21:21:46.601900  9048 solver.cpp:256]     Train net output #0: loss = 3.54636 (* 1 = 3.54636 loss)
I0408 21:21:46.601913  9048 sgd_solver.cpp:106] Iteration 1949, lr = 0.01
I0408 21:21:46.877158  9048 solver.cpp:240] Iteration 1950, loss = 8.95153
I0408 21:21:46.877192  9048 solver.cpp:256]     Train net output #0: loss = 8.95152 (* 1 = 8.95152 loss)
I0408 21:21:46.877202  9048 sgd_solver.cpp:106] Iteration 1950, lr = 0.01
I0408 21:21:47.152770  9048 solver.cpp:240] Iteration 1951, loss = 5.31428
I0408 21:21:47.152811  9048 solver.cpp:256]     Train net output #0: loss = 5.31427 (* 1 = 5.31427 loss)
I0408 21:21:47.152823  9048 sgd_solver.cpp:106] Iteration 1951, lr = 0.01
I0408 21:21:47.428537  9048 solver.cpp:240] Iteration 1952, loss = 7.30417
I0408 21:21:47.428573  9048 solver.cpp:256]     Train net output #0: loss = 7.30416 (* 1 = 7.30416 loss)
I0408 21:21:47.428586  9048 sgd_solver.cpp:106] Iteration 1952, lr = 0.01
I0408 21:21:47.703382  9048 solver.cpp:240] Iteration 1953, loss = 7.88659
I0408 21:21:47.703416  9048 solver.cpp:256]     Train net output #0: loss = 7.88658 (* 1 = 7.88658 loss)
I0408 21:21:47.703428  9048 sgd_solver.cpp:106] Iteration 1953, lr = 0.01
I0408 21:21:47.978826  9048 solver.cpp:240] Iteration 1954, loss = 6.79206
I0408 21:21:47.978863  9048 solver.cpp:256]     Train net output #0: loss = 6.79205 (* 1 = 6.79205 loss)
I0408 21:21:47.978873  9048 sgd_solver.cpp:106] Iteration 1954, lr = 0.01
I0408 21:21:48.254840  9048 solver.cpp:240] Iteration 1955, loss = 6.82143
I0408 21:21:48.254874  9048 solver.cpp:256]     Train net output #0: loss = 6.82142 (* 1 = 6.82142 loss)
I0408 21:21:48.254886  9048 sgd_solver.cpp:106] Iteration 1955, lr = 0.01
I0408 21:21:48.530237  9048 solver.cpp:240] Iteration 1956, loss = 4.1279
I0408 21:21:48.530278  9048 solver.cpp:256]     Train net output #0: loss = 4.12789 (* 1 = 4.12789 loss)
I0408 21:21:48.530290  9048 sgd_solver.cpp:106] Iteration 1956, lr = 0.01
I0408 21:21:48.806040  9048 solver.cpp:240] Iteration 1957, loss = 10.6079
I0408 21:21:48.806074  9048 solver.cpp:256]     Train net output #0: loss = 10.6078 (* 1 = 10.6078 loss)
I0408 21:21:48.806087  9048 sgd_solver.cpp:106] Iteration 1957, lr = 0.01
I0408 21:21:49.080819  9048 solver.cpp:240] Iteration 1958, loss = 11.2356
I0408 21:21:49.080855  9048 solver.cpp:256]     Train net output #0: loss = 11.2356 (* 1 = 11.2356 loss)
I0408 21:21:49.080868  9048 sgd_solver.cpp:106] Iteration 1958, lr = 0.01
I0408 21:21:49.356551  9048 solver.cpp:240] Iteration 1959, loss = 1.59103
I0408 21:21:49.356585  9048 solver.cpp:256]     Train net output #0: loss = 1.59102 (* 1 = 1.59102 loss)
I0408 21:21:49.356596  9048 sgd_solver.cpp:106] Iteration 1959, lr = 0.01
I0408 21:21:49.631819  9048 solver.cpp:240] Iteration 1960, loss = 3.04063
I0408 21:21:49.631853  9048 solver.cpp:256]     Train net output #0: loss = 3.04062 (* 1 = 3.04062 loss)
I0408 21:21:49.631865  9048 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0408 21:21:49.907673  9048 solver.cpp:240] Iteration 1961, loss = 3.31369
I0408 21:21:49.907833  9048 solver.cpp:256]     Train net output #0: loss = 3.31368 (* 1 = 3.31368 loss)
I0408 21:21:49.907851  9048 sgd_solver.cpp:106] Iteration 1961, lr = 0.01
I0408 21:21:50.183043  9048 solver.cpp:240] Iteration 1962, loss = 5.39364
I0408 21:21:50.183076  9048 solver.cpp:256]     Train net output #0: loss = 5.39363 (* 1 = 5.39363 loss)
I0408 21:21:50.183087  9048 sgd_solver.cpp:106] Iteration 1962, lr = 0.01
I0408 21:21:50.459146  9048 solver.cpp:240] Iteration 1963, loss = 3.43316
I0408 21:21:50.459188  9048 solver.cpp:256]     Train net output #0: loss = 3.43315 (* 1 = 3.43315 loss)
I0408 21:21:50.459199  9048 sgd_solver.cpp:106] Iteration 1963, lr = 0.01
I0408 21:21:50.734966  9048 solver.cpp:240] Iteration 1964, loss = 6.74041
I0408 21:21:50.735002  9048 solver.cpp:256]     Train net output #0: loss = 6.7404 (* 1 = 6.7404 loss)
I0408 21:21:50.735018  9048 sgd_solver.cpp:106] Iteration 1964, lr = 0.01
I0408 21:21:51.009587  9048 solver.cpp:240] Iteration 1965, loss = 5.67793
I0408 21:21:51.009621  9048 solver.cpp:256]     Train net output #0: loss = 5.67792 (* 1 = 5.67792 loss)
I0408 21:21:51.009634  9048 sgd_solver.cpp:106] Iteration 1965, lr = 0.01
I0408 21:21:51.285280  9048 solver.cpp:240] Iteration 1966, loss = 2.55583
I0408 21:21:51.285316  9048 solver.cpp:256]     Train net output #0: loss = 2.55582 (* 1 = 2.55582 loss)
I0408 21:21:51.285327  9048 sgd_solver.cpp:106] Iteration 1966, lr = 0.01
I0408 21:21:51.560683  9048 solver.cpp:240] Iteration 1967, loss = 13.7343
I0408 21:21:51.560719  9048 solver.cpp:256]     Train net output #0: loss = 13.7343 (* 1 = 13.7343 loss)
I0408 21:21:51.560744  9048 sgd_solver.cpp:106] Iteration 1967, lr = 0.01
I0408 21:21:51.835918  9048 solver.cpp:240] Iteration 1968, loss = 9.23859
I0408 21:21:51.835953  9048 solver.cpp:256]     Train net output #0: loss = 9.23858 (* 1 = 9.23858 loss)
I0408 21:21:51.835965  9048 sgd_solver.cpp:106] Iteration 1968, lr = 0.01
I0408 21:21:52.110945  9048 solver.cpp:240] Iteration 1969, loss = 5.36327
I0408 21:21:52.110980  9048 solver.cpp:256]     Train net output #0: loss = 5.36326 (* 1 = 5.36326 loss)
I0408 21:21:52.110991  9048 sgd_solver.cpp:106] Iteration 1969, lr = 0.01
I0408 21:21:52.385924  9048 solver.cpp:240] Iteration 1970, loss = 7.70524
I0408 21:21:52.385958  9048 solver.cpp:256]     Train net output #0: loss = 7.70523 (* 1 = 7.70523 loss)
I0408 21:21:52.385969  9048 sgd_solver.cpp:106] Iteration 1970, lr = 0.01
I0408 21:21:52.661197  9048 solver.cpp:240] Iteration 1971, loss = 2.96225
I0408 21:21:52.661231  9048 solver.cpp:256]     Train net output #0: loss = 2.96224 (* 1 = 2.96224 loss)
I0408 21:21:52.661242  9048 sgd_solver.cpp:106] Iteration 1971, lr = 0.01
I0408 21:21:52.936877  9048 solver.cpp:240] Iteration 1972, loss = 1.89561
I0408 21:21:52.936911  9048 solver.cpp:256]     Train net output #0: loss = 1.8956 (* 1 = 1.8956 loss)
I0408 21:21:52.936923  9048 sgd_solver.cpp:106] Iteration 1972, lr = 0.01
I0408 21:21:53.212154  9048 solver.cpp:240] Iteration 1973, loss = 4.27815
I0408 21:21:53.212188  9048 solver.cpp:256]     Train net output #0: loss = 4.27814 (* 1 = 4.27814 loss)
I0408 21:21:53.212198  9048 sgd_solver.cpp:106] Iteration 1973, lr = 0.01
I0408 21:21:53.489480  9048 solver.cpp:240] Iteration 1974, loss = 33.1103
I0408 21:21:53.489521  9048 solver.cpp:256]     Train net output #0: loss = 33.1103 (* 1 = 33.1103 loss)
I0408 21:21:53.489533  9048 sgd_solver.cpp:106] Iteration 1974, lr = 0.01
I0408 21:21:53.765193  9048 solver.cpp:240] Iteration 1975, loss = 31.9712
I0408 21:21:53.765231  9048 solver.cpp:256]     Train net output #0: loss = 31.9711 (* 1 = 31.9711 loss)
I0408 21:21:53.765244  9048 sgd_solver.cpp:106] Iteration 1975, lr = 0.01
I0408 21:21:54.040773  9048 solver.cpp:240] Iteration 1976, loss = 27.4575
I0408 21:21:54.040810  9048 solver.cpp:256]     Train net output #0: loss = 27.4575 (* 1 = 27.4575 loss)
I0408 21:21:54.040822  9048 sgd_solver.cpp:106] Iteration 1976, lr = 0.01
I0408 21:21:54.316123  9048 solver.cpp:240] Iteration 1977, loss = 36.2773
I0408 21:21:54.316160  9048 solver.cpp:256]     Train net output #0: loss = 36.2773 (* 1 = 36.2773 loss)
I0408 21:21:54.316197  9048 sgd_solver.cpp:106] Iteration 1977, lr = 0.01
I0408 21:21:54.592605  9048 solver.cpp:240] Iteration 1978, loss = 29.3985
I0408 21:21:54.592643  9048 solver.cpp:256]     Train net output #0: loss = 29.3985 (* 1 = 29.3985 loss)
I0408 21:21:54.592654  9048 sgd_solver.cpp:106] Iteration 1978, lr = 0.01
I0408 21:21:54.867947  9048 solver.cpp:240] Iteration 1979, loss = 33.0175
I0408 21:21:54.867996  9048 solver.cpp:256]     Train net output #0: loss = 33.0175 (* 1 = 33.0175 loss)
I0408 21:21:54.868008  9048 sgd_solver.cpp:106] Iteration 1979, lr = 0.01
I0408 21:21:55.143697  9048 solver.cpp:240] Iteration 1980, loss = 15.4427
I0408 21:21:55.143734  9048 solver.cpp:256]     Train net output #0: loss = 15.4427 (* 1 = 15.4427 loss)
I0408 21:21:55.143746  9048 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0408 21:21:55.419143  9048 solver.cpp:240] Iteration 1981, loss = 17.7809
I0408 21:21:55.419180  9048 solver.cpp:256]     Train net output #0: loss = 17.7809 (* 1 = 17.7809 loss)
I0408 21:21:55.419191  9048 sgd_solver.cpp:106] Iteration 1981, lr = 0.01
I0408 21:21:55.696007  9048 solver.cpp:240] Iteration 1982, loss = 33.2299
I0408 21:21:55.696044  9048 solver.cpp:256]     Train net output #0: loss = 33.2299 (* 1 = 33.2299 loss)
I0408 21:21:55.696056  9048 sgd_solver.cpp:106] Iteration 1982, lr = 0.01
I0408 21:21:55.970963  9048 solver.cpp:240] Iteration 1983, loss = 34.5715
I0408 21:21:55.970999  9048 solver.cpp:256]     Train net output #0: loss = 34.5715 (* 1 = 34.5715 loss)
I0408 21:21:55.971011  9048 sgd_solver.cpp:106] Iteration 1983, lr = 0.01
I0408 21:21:56.246450  9048 solver.cpp:240] Iteration 1984, loss = 12.166
I0408 21:21:56.246495  9048 solver.cpp:256]     Train net output #0: loss = 12.166 (* 1 = 12.166 loss)
I0408 21:21:56.246508  9048 sgd_solver.cpp:106] Iteration 1984, lr = 0.01
I0408 21:21:56.522989  9048 solver.cpp:240] Iteration 1985, loss = 3.66992
I0408 21:21:56.523027  9048 solver.cpp:256]     Train net output #0: loss = 3.66991 (* 1 = 3.66991 loss)
I0408 21:21:56.523039  9048 sgd_solver.cpp:106] Iteration 1985, lr = 0.01
I0408 21:21:56.798477  9048 solver.cpp:240] Iteration 1986, loss = 14.0794
I0408 21:21:56.798519  9048 solver.cpp:256]     Train net output #0: loss = 14.0794 (* 1 = 14.0794 loss)
I0408 21:21:56.798532  9048 sgd_solver.cpp:106] Iteration 1986, lr = 0.01
I0408 21:21:57.074440  9048 solver.cpp:240] Iteration 1987, loss = 7.49859
I0408 21:21:57.074484  9048 solver.cpp:256]     Train net output #0: loss = 7.49858 (* 1 = 7.49858 loss)
I0408 21:21:57.074496  9048 sgd_solver.cpp:106] Iteration 1987, lr = 0.01
I0408 21:21:57.350495  9048 solver.cpp:240] Iteration 1988, loss = 3.5247
I0408 21:21:57.350531  9048 solver.cpp:256]     Train net output #0: loss = 3.52469 (* 1 = 3.52469 loss)
I0408 21:21:57.350543  9048 sgd_solver.cpp:106] Iteration 1988, lr = 0.01
I0408 21:21:57.625648  9048 solver.cpp:240] Iteration 1989, loss = 7.26881
I0408 21:21:57.625684  9048 solver.cpp:256]     Train net output #0: loss = 7.26879 (* 1 = 7.26879 loss)
I0408 21:21:57.625696  9048 sgd_solver.cpp:106] Iteration 1989, lr = 0.01
I0408 21:21:57.901888  9048 solver.cpp:240] Iteration 1990, loss = 1.56029
I0408 21:21:57.901923  9048 solver.cpp:256]     Train net output #0: loss = 1.56027 (* 1 = 1.56027 loss)
I0408 21:21:57.901935  9048 sgd_solver.cpp:106] Iteration 1990, lr = 0.01
I0408 21:21:58.177279  9048 solver.cpp:240] Iteration 1991, loss = 6.03291
I0408 21:21:58.177314  9048 solver.cpp:256]     Train net output #0: loss = 6.0329 (* 1 = 6.0329 loss)
I0408 21:21:58.177326  9048 sgd_solver.cpp:106] Iteration 1991, lr = 0.01
I0408 21:21:58.452785  9048 solver.cpp:240] Iteration 1992, loss = 3.47524
I0408 21:21:58.452821  9048 solver.cpp:256]     Train net output #0: loss = 3.47523 (* 1 = 3.47523 loss)
I0408 21:21:58.452843  9048 sgd_solver.cpp:106] Iteration 1992, lr = 0.01
I0408 21:21:58.728204  9048 solver.cpp:240] Iteration 1993, loss = 15.7713
I0408 21:21:58.728238  9048 solver.cpp:256]     Train net output #0: loss = 15.7713 (* 1 = 15.7713 loss)
I0408 21:21:58.728282  9048 sgd_solver.cpp:106] Iteration 1993, lr = 0.01
I0408 21:21:59.004652  9048 solver.cpp:240] Iteration 1994, loss = 3.2921
I0408 21:21:59.004689  9048 solver.cpp:256]     Train net output #0: loss = 3.29208 (* 1 = 3.29208 loss)
I0408 21:21:59.004701  9048 sgd_solver.cpp:106] Iteration 1994, lr = 0.01
I0408 21:21:59.280459  9048 solver.cpp:240] Iteration 1995, loss = 22.3934
I0408 21:21:59.280495  9048 solver.cpp:256]     Train net output #0: loss = 22.3934 (* 1 = 22.3934 loss)
I0408 21:21:59.280508  9048 sgd_solver.cpp:106] Iteration 1995, lr = 0.01
I0408 21:21:59.556169  9048 solver.cpp:240] Iteration 1996, loss = 22.0387
I0408 21:21:59.556205  9048 solver.cpp:256]     Train net output #0: loss = 22.0387 (* 1 = 22.0387 loss)
I0408 21:21:59.556217  9048 sgd_solver.cpp:106] Iteration 1996, lr = 0.01
I0408 21:21:59.832203  9048 solver.cpp:240] Iteration 1997, loss = 14.0719
I0408 21:21:59.832244  9048 solver.cpp:256]     Train net output #0: loss = 14.0719 (* 1 = 14.0719 loss)
I0408 21:21:59.832257  9048 sgd_solver.cpp:106] Iteration 1997, lr = 0.01
I0408 21:22:00.108436  9048 solver.cpp:240] Iteration 1998, loss = 17.0368
I0408 21:22:00.108472  9048 solver.cpp:256]     Train net output #0: loss = 17.0368 (* 1 = 17.0368 loss)
I0408 21:22:00.108484  9048 sgd_solver.cpp:106] Iteration 1998, lr = 0.01
I0408 21:22:00.384341  9048 solver.cpp:240] Iteration 1999, loss = 24.023
I0408 21:22:00.384382  9048 solver.cpp:256]     Train net output #0: loss = 24.023 (* 1 = 24.023 loss)
I0408 21:22:00.384394  9048 sgd_solver.cpp:106] Iteration 1999, lr = 0.01
I0408 21:22:00.660497  9048 solver.cpp:240] Iteration 2000, loss = 22.7735
I0408 21:22:00.660532  9048 solver.cpp:256]     Train net output #0: loss = 22.7735 (* 1 = 22.7735 loss)
I0408 21:22:00.660557  9048 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0408 21:22:00.936477  9048 solver.cpp:240] Iteration 2001, loss = 25.101
I0408 21:22:00.936514  9048 solver.cpp:256]     Train net output #0: loss = 25.101 (* 1 = 25.101 loss)
I0408 21:22:00.936527  9048 sgd_solver.cpp:106] Iteration 2001, lr = 0.01
I0408 21:22:01.211711  9048 solver.cpp:240] Iteration 2002, loss = 8.93887
I0408 21:22:01.211746  9048 solver.cpp:256]     Train net output #0: loss = 8.93886 (* 1 = 8.93886 loss)
I0408 21:22:01.211758  9048 sgd_solver.cpp:106] Iteration 2002, lr = 0.01
I0408 21:22:01.487663  9048 solver.cpp:240] Iteration 2003, loss = 28.3822
I0408 21:22:01.487700  9048 solver.cpp:256]     Train net output #0: loss = 28.3821 (* 1 = 28.3821 loss)
I0408 21:22:01.487712  9048 sgd_solver.cpp:106] Iteration 2003, lr = 0.01
I0408 21:22:01.763644  9048 solver.cpp:240] Iteration 2004, loss = 29.6236
I0408 21:22:01.763686  9048 solver.cpp:256]     Train net output #0: loss = 29.6235 (* 1 = 29.6235 loss)
I0408 21:22:01.763698  9048 sgd_solver.cpp:106] Iteration 2004, lr = 0.01
I0408 21:22:02.040000  9048 solver.cpp:240] Iteration 2005, loss = 25.3269
I0408 21:22:02.040037  9048 solver.cpp:256]     Train net output #0: loss = 25.3269 (* 1 = 25.3269 loss)
I0408 21:22:02.040050  9048 sgd_solver.cpp:106] Iteration 2005, lr = 0.01
I0408 21:22:02.316048  9048 solver.cpp:240] Iteration 2006, loss = 23.366
I0408 21:22:02.316085  9048 solver.cpp:256]     Train net output #0: loss = 23.3659 (* 1 = 23.3659 loss)
I0408 21:22:02.316097  9048 sgd_solver.cpp:106] Iteration 2006, lr = 0.01
I0408 21:22:02.591601  9048 solver.cpp:240] Iteration 2007, loss = 19.7786
I0408 21:22:02.591639  9048 solver.cpp:256]     Train net output #0: loss = 19.7786 (* 1 = 19.7786 loss)
I0408 21:22:02.591650  9048 sgd_solver.cpp:106] Iteration 2007, lr = 0.01
I0408 21:22:02.867254  9048 solver.cpp:240] Iteration 2008, loss = 16.971
I0408 21:22:02.867290  9048 solver.cpp:256]     Train net output #0: loss = 16.971 (* 1 = 16.971 loss)
I0408 21:22:02.867312  9048 sgd_solver.cpp:106] Iteration 2008, lr = 0.01
I0408 21:22:03.143249  9048 solver.cpp:240] Iteration 2009, loss = 21.4115
I0408 21:22:03.143290  9048 solver.cpp:256]     Train net output #0: loss = 21.4115 (* 1 = 21.4115 loss)
I0408 21:22:03.143302  9048 sgd_solver.cpp:106] Iteration 2009, lr = 0.01
I0408 21:22:03.419644  9048 solver.cpp:240] Iteration 2010, loss = 25.2192
I0408 21:22:03.419678  9048 solver.cpp:256]     Train net output #0: loss = 25.2192 (* 1 = 25.2192 loss)
I0408 21:22:03.419690  9048 sgd_solver.cpp:106] Iteration 2010, lr = 0.01
I0408 21:22:03.696233  9048 solver.cpp:240] Iteration 2011, loss = 23.7507
I0408 21:22:03.696269  9048 solver.cpp:256]     Train net output #0: loss = 23.7507 (* 1 = 23.7507 loss)
I0408 21:22:03.696280  9048 sgd_solver.cpp:106] Iteration 2011, lr = 0.01
I0408 21:22:03.972753  9048 solver.cpp:240] Iteration 2012, loss = 12.9582
I0408 21:22:03.972789  9048 solver.cpp:256]     Train net output #0: loss = 12.9581 (* 1 = 12.9581 loss)
I0408 21:22:03.972800  9048 sgd_solver.cpp:106] Iteration 2012, lr = 0.01
I0408 21:22:04.247838  9048 solver.cpp:240] Iteration 2013, loss = 27.0611
I0408 21:22:04.247874  9048 solver.cpp:256]     Train net output #0: loss = 27.0611 (* 1 = 27.0611 loss)
I0408 21:22:04.247901  9048 sgd_solver.cpp:106] Iteration 2013, lr = 0.01
I0408 21:22:04.523572  9048 solver.cpp:240] Iteration 2014, loss = 7.74487
I0408 21:22:04.523614  9048 solver.cpp:256]     Train net output #0: loss = 7.74485 (* 1 = 7.74485 loss)
I0408 21:22:04.523627  9048 sgd_solver.cpp:106] Iteration 2014, lr = 0.01
