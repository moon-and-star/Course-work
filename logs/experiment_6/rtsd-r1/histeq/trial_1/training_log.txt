I0409 02:44:23.445677  5147 caffe.cpp:217] Using GPUs 1
I0409 02:44:23.743459  5147 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0409 02:44:24.501133  5147 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_6/rtsd-r1/histeq/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_6/rtsd-r1/histeq/trial_1/test.prototxt"
test_iter: 74
test_interval: 249
base_lr: 0.1
display: 1
max_iter: 24900
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 4980
snapshot: 2490
snapshot_prefix: "./snapshots/experiment_6/rtsd-r1/histeq/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0409 02:44:24.501267  5147 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_6/rtsd-r1/histeq/trial_1/train.prototxt
I0409 02:44:24.501570  5147 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0409 02:44:24.501581  5147 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0409 02:44:24.501724  5147 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 122
    mean_value: 115
    mean_value: 128
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/histeq/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
I0409 02:44:24.501827  5147 layer_factory.hpp:77] Creating layer data
I0409 02:44:24.502882  5147 net.cpp:100] Creating Layer data
I0409 02:44:24.502897  5147 net.cpp:408] data -> data
I0409 02:44:24.502919  5147 net.cpp:408] data -> label
I0409 02:44:24.504259  5252 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/histeq/train/lmdb
I0409 02:44:24.520753  5147 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 02:44:24.565263  5147 net.cpp:150] Setting up data
I0409 02:44:24.565304  5147 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 02:44:24.565311  5147 net.cpp:157] Top shape: 1024 (1024)
I0409 02:44:24.565315  5147 net.cpp:165] Memory required for data: 28315648
I0409 02:44:24.565325  5147 layer_factory.hpp:77] Creating layer conv1
I0409 02:44:24.565347  5147 net.cpp:100] Creating Layer conv1
I0409 02:44:24.565354  5147 net.cpp:434] conv1 <- data
I0409 02:44:24.565367  5147 net.cpp:408] conv1 -> conv1
I0409 02:44:24.911088  5147 net.cpp:150] Setting up conv1
I0409 02:44:24.911116  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.911120  5147 net.cpp:165] Memory required for data: 750850048
I0409 02:44:24.911141  5147 layer_factory.hpp:77] Creating layer conv1_prescale
I0409 02:44:24.911166  5147 net.cpp:100] Creating Layer conv1_prescale
I0409 02:44:24.911171  5147 net.cpp:434] conv1_prescale <- conv1
I0409 02:44:24.911177  5147 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0409 02:44:24.911293  5147 net.cpp:150] Setting up conv1_prescale
I0409 02:44:24.911303  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.911306  5147 net.cpp:165] Memory required for data: 1473384448
I0409 02:44:24.911314  5147 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 02:44:24.911319  5147 net.cpp:100] Creating Layer conv1_sTanH
I0409 02:44:24.911322  5147 net.cpp:434] conv1_sTanH <- conv1
I0409 02:44:24.911327  5147 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 02:44:24.911517  5147 net.cpp:150] Setting up conv1_sTanH
I0409 02:44:24.911530  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.911533  5147 net.cpp:165] Memory required for data: 2195918848
I0409 02:44:24.911537  5147 layer_factory.hpp:77] Creating layer conv1_postscale
I0409 02:44:24.911545  5147 net.cpp:100] Creating Layer conv1_postscale
I0409 02:44:24.911550  5147 net.cpp:434] conv1_postscale <- conv1
I0409 02:44:24.911554  5147 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0409 02:44:24.911648  5147 net.cpp:150] Setting up conv1_postscale
I0409 02:44:24.911658  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.911660  5147 net.cpp:165] Memory required for data: 2918453248
I0409 02:44:24.911665  5147 layer_factory.hpp:77] Creating layer pool1
I0409 02:44:24.911674  5147 net.cpp:100] Creating Layer pool1
I0409 02:44:24.911676  5147 net.cpp:434] pool1 <- conv1
I0409 02:44:24.911681  5147 net.cpp:408] pool1 -> pool1
I0409 02:44:24.911727  5147 net.cpp:150] Setting up pool1
I0409 02:44:24.911736  5147 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 02:44:24.911738  5147 net.cpp:165] Memory required for data: 3099086848
I0409 02:44:24.911761  5147 layer_factory.hpp:77] Creating layer conv2
I0409 02:44:24.911772  5147 net.cpp:100] Creating Layer conv2
I0409 02:44:24.911777  5147 net.cpp:434] conv2 <- pool1
I0409 02:44:24.911782  5147 net.cpp:408] conv2 -> conv2
I0409 02:44:24.916133  5147 net.cpp:150] Setting up conv2
I0409 02:44:24.916151  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.916154  5147 net.cpp:165] Memory required for data: 3298152448
I0409 02:44:24.916165  5147 layer_factory.hpp:77] Creating layer conv2_prescale
I0409 02:44:24.916173  5147 net.cpp:100] Creating Layer conv2_prescale
I0409 02:44:24.916177  5147 net.cpp:434] conv2_prescale <- conv2
I0409 02:44:24.916182  5147 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0409 02:44:24.916281  5147 net.cpp:150] Setting up conv2_prescale
I0409 02:44:24.916290  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.916293  5147 net.cpp:165] Memory required for data: 3497218048
I0409 02:44:24.916299  5147 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 02:44:24.916316  5147 net.cpp:100] Creating Layer conv2_sTanH
I0409 02:44:24.916321  5147 net.cpp:434] conv2_sTanH <- conv2
I0409 02:44:24.916324  5147 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 02:44:24.917059  5147 net.cpp:150] Setting up conv2_sTanH
I0409 02:44:24.917074  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.917078  5147 net.cpp:165] Memory required for data: 3696283648
I0409 02:44:24.917083  5147 layer_factory.hpp:77] Creating layer conv2_postscale
I0409 02:44:24.917089  5147 net.cpp:100] Creating Layer conv2_postscale
I0409 02:44:24.917093  5147 net.cpp:434] conv2_postscale <- conv2
I0409 02:44:24.917098  5147 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0409 02:44:24.917201  5147 net.cpp:150] Setting up conv2_postscale
I0409 02:44:24.917210  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.917214  5147 net.cpp:165] Memory required for data: 3895349248
I0409 02:44:24.917219  5147 layer_factory.hpp:77] Creating layer pool2
I0409 02:44:24.917225  5147 net.cpp:100] Creating Layer pool2
I0409 02:44:24.917229  5147 net.cpp:434] pool2 <- conv2
I0409 02:44:24.917234  5147 net.cpp:408] pool2 -> pool2
I0409 02:44:24.917271  5147 net.cpp:150] Setting up pool2
I0409 02:44:24.917279  5147 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 02:44:24.917282  5147 net.cpp:165] Memory required for data: 3945115648
I0409 02:44:24.917285  5147 layer_factory.hpp:77] Creating layer conv3
I0409 02:44:24.917294  5147 net.cpp:100] Creating Layer conv3
I0409 02:44:24.917299  5147 net.cpp:434] conv3 <- pool2
I0409 02:44:24.917304  5147 net.cpp:408] conv3 -> conv3
I0409 02:44:24.922703  5147 net.cpp:150] Setting up conv3
I0409 02:44:24.922719  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:24.922734  5147 net.cpp:165] Memory required for data: 3981979648
I0409 02:44:24.922744  5147 layer_factory.hpp:77] Creating layer conv3_prescale
I0409 02:44:24.922754  5147 net.cpp:100] Creating Layer conv3_prescale
I0409 02:44:24.922756  5147 net.cpp:434] conv3_prescale <- conv3
I0409 02:44:24.922762  5147 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0409 02:44:24.922852  5147 net.cpp:150] Setting up conv3_prescale
I0409 02:44:24.922861  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:24.922864  5147 net.cpp:165] Memory required for data: 4018843648
I0409 02:44:24.922869  5147 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 02:44:24.922874  5147 net.cpp:100] Creating Layer conv3_sTanH
I0409 02:44:24.922878  5147 net.cpp:434] conv3_sTanH <- conv3
I0409 02:44:24.922883  5147 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 02:44:24.923629  5147 net.cpp:150] Setting up conv3_sTanH
I0409 02:44:24.923643  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:24.923660  5147 net.cpp:165] Memory required for data: 4055707648
I0409 02:44:24.923665  5147 layer_factory.hpp:77] Creating layer conv3_postscale
I0409 02:44:24.923672  5147 net.cpp:100] Creating Layer conv3_postscale
I0409 02:44:24.923691  5147 net.cpp:434] conv3_postscale <- conv3
I0409 02:44:24.923697  5147 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0409 02:44:24.923794  5147 net.cpp:150] Setting up conv3_postscale
I0409 02:44:24.923802  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:24.923805  5147 net.cpp:165] Memory required for data: 4092571648
I0409 02:44:24.923811  5147 layer_factory.hpp:77] Creating layer pool3
I0409 02:44:24.923817  5147 net.cpp:100] Creating Layer pool3
I0409 02:44:24.923820  5147 net.cpp:434] pool3 <- conv3
I0409 02:44:24.923825  5147 net.cpp:408] pool3 -> pool3
I0409 02:44:24.923861  5147 net.cpp:150] Setting up pool3
I0409 02:44:24.923869  5147 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 02:44:24.923872  5147 net.cpp:165] Memory required for data: 4101787648
I0409 02:44:24.923876  5147 layer_factory.hpp:77] Creating layer fc4_300
I0409 02:44:24.923892  5147 net.cpp:100] Creating Layer fc4_300
I0409 02:44:24.923895  5147 net.cpp:434] fc4_300 <- pool3
I0409 02:44:24.923900  5147 net.cpp:408] fc4_300 -> fc4_300
I0409 02:44:24.929134  5147 net.cpp:150] Setting up fc4_300
I0409 02:44:24.929149  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:24.929167  5147 net.cpp:165] Memory required for data: 4103016448
I0409 02:44:24.929173  5147 layer_factory.hpp:77] Creating layer fc4_prescale
I0409 02:44:24.929180  5147 net.cpp:100] Creating Layer fc4_prescale
I0409 02:44:24.929184  5147 net.cpp:434] fc4_prescale <- fc4_300
I0409 02:44:24.929189  5147 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0409 02:44:24.929276  5147 net.cpp:150] Setting up fc4_prescale
I0409 02:44:24.929285  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:24.929287  5147 net.cpp:165] Memory required for data: 4104245248
I0409 02:44:24.929292  5147 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 02:44:24.929297  5147 net.cpp:100] Creating Layer fc4_sTanH
I0409 02:44:24.929301  5147 net.cpp:434] fc4_sTanH <- fc4_300
I0409 02:44:24.929306  5147 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 02:44:24.929484  5147 net.cpp:150] Setting up fc4_sTanH
I0409 02:44:24.929496  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:24.929499  5147 net.cpp:165] Memory required for data: 4105474048
I0409 02:44:24.929502  5147 layer_factory.hpp:77] Creating layer fc4_postscale
I0409 02:44:24.929509  5147 net.cpp:100] Creating Layer fc4_postscale
I0409 02:44:24.929512  5147 net.cpp:434] fc4_postscale <- fc4_300
I0409 02:44:24.929517  5147 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0409 02:44:24.929606  5147 net.cpp:150] Setting up fc4_postscale
I0409 02:44:24.929615  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:24.929617  5147 net.cpp:165] Memory required for data: 4106702848
I0409 02:44:24.929622  5147 layer_factory.hpp:77] Creating layer drop4
I0409 02:44:24.929630  5147 net.cpp:100] Creating Layer drop4
I0409 02:44:24.929632  5147 net.cpp:434] drop4 <- fc4_300
I0409 02:44:24.929637  5147 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 02:44:24.929662  5147 net.cpp:150] Setting up drop4
I0409 02:44:24.929671  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:24.929673  5147 net.cpp:165] Memory required for data: 4107931648
I0409 02:44:24.929677  5147 layer_factory.hpp:77] Creating layer fc5_67
I0409 02:44:24.929682  5147 net.cpp:100] Creating Layer fc5_67
I0409 02:44:24.929685  5147 net.cpp:434] fc5_67 <- fc4_300
I0409 02:44:24.929690  5147 net.cpp:408] fc5_67 -> fc5_classes
I0409 02:44:24.930915  5147 net.cpp:150] Setting up fc5_67
I0409 02:44:24.930930  5147 net.cpp:157] Top shape: 1024 67 (68608)
I0409 02:44:24.930933  5147 net.cpp:165] Memory required for data: 4108206080
I0409 02:44:24.930944  5147 layer_factory.hpp:77] Creating layer loss
I0409 02:44:24.930953  5147 net.cpp:100] Creating Layer loss
I0409 02:44:24.930955  5147 net.cpp:434] loss <- fc5_classes
I0409 02:44:24.930960  5147 net.cpp:434] loss <- label
I0409 02:44:24.930966  5147 net.cpp:408] loss -> loss
I0409 02:44:24.930979  5147 layer_factory.hpp:77] Creating layer loss
I0409 02:44:24.931298  5147 net.cpp:150] Setting up loss
I0409 02:44:24.931323  5147 net.cpp:157] Top shape: (1)
I0409 02:44:24.931326  5147 net.cpp:160]     with loss weight 1
I0409 02:44:24.931349  5147 net.cpp:165] Memory required for data: 4108206084
I0409 02:44:24.931352  5147 net.cpp:226] loss needs backward computation.
I0409 02:44:24.931360  5147 net.cpp:226] fc5_67 needs backward computation.
I0409 02:44:24.931365  5147 net.cpp:226] drop4 needs backward computation.
I0409 02:44:24.931367  5147 net.cpp:226] fc4_postscale needs backward computation.
I0409 02:44:24.931370  5147 net.cpp:226] fc4_sTanH needs backward computation.
I0409 02:44:24.931373  5147 net.cpp:226] fc4_prescale needs backward computation.
I0409 02:44:24.931376  5147 net.cpp:226] fc4_300 needs backward computation.
I0409 02:44:24.931380  5147 net.cpp:226] pool3 needs backward computation.
I0409 02:44:24.931383  5147 net.cpp:226] conv3_postscale needs backward computation.
I0409 02:44:24.931386  5147 net.cpp:226] conv3_sTanH needs backward computation.
I0409 02:44:24.931390  5147 net.cpp:226] conv3_prescale needs backward computation.
I0409 02:44:24.931392  5147 net.cpp:226] conv3 needs backward computation.
I0409 02:44:24.931396  5147 net.cpp:226] pool2 needs backward computation.
I0409 02:44:24.931398  5147 net.cpp:226] conv2_postscale needs backward computation.
I0409 02:44:24.931402  5147 net.cpp:226] conv2_sTanH needs backward computation.
I0409 02:44:24.931406  5147 net.cpp:226] conv2_prescale needs backward computation.
I0409 02:44:24.931408  5147 net.cpp:226] conv2 needs backward computation.
I0409 02:44:24.931411  5147 net.cpp:226] pool1 needs backward computation.
I0409 02:44:24.931414  5147 net.cpp:226] conv1_postscale needs backward computation.
I0409 02:44:24.931417  5147 net.cpp:226] conv1_sTanH needs backward computation.
I0409 02:44:24.931421  5147 net.cpp:226] conv1_prescale needs backward computation.
I0409 02:44:24.931423  5147 net.cpp:226] conv1 needs backward computation.
I0409 02:44:24.931427  5147 net.cpp:228] data does not need backward computation.
I0409 02:44:24.931432  5147 net.cpp:270] This network produces output loss
I0409 02:44:24.931445  5147 net.cpp:283] Network initialization done.
I0409 02:44:24.931738  5147 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_6/rtsd-r1/histeq/trial_1/test.prototxt
I0409 02:44:24.931941  5147 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 117
    mean_value: 114
    mean_value: 133
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/histeq/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0409 02:44:24.932060  5147 layer_factory.hpp:77] Creating layer data
I0409 02:44:24.932724  5147 net.cpp:100] Creating Layer data
I0409 02:44:24.932737  5147 net.cpp:408] data -> data
I0409 02:44:24.932749  5147 net.cpp:408] data -> label
I0409 02:44:24.934351  5274 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/histeq/test/lmdb
I0409 02:44:24.934550  5147 data_layer.cpp:41] output data size: 1024,3,48,48
I0409 02:44:24.979351  5147 net.cpp:150] Setting up data
I0409 02:44:24.979379  5147 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0409 02:44:24.979384  5147 net.cpp:157] Top shape: 1024 (1024)
I0409 02:44:24.979387  5147 net.cpp:165] Memory required for data: 28315648
I0409 02:44:24.979394  5147 layer_factory.hpp:77] Creating layer label_data_1_split
I0409 02:44:24.979411  5147 net.cpp:100] Creating Layer label_data_1_split
I0409 02:44:24.979415  5147 net.cpp:434] label_data_1_split <- label
I0409 02:44:24.979423  5147 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0409 02:44:24.979434  5147 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0409 02:44:24.979442  5147 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0409 02:44:24.979594  5147 net.cpp:150] Setting up label_data_1_split
I0409 02:44:24.979604  5147 net.cpp:157] Top shape: 1024 (1024)
I0409 02:44:24.979609  5147 net.cpp:157] Top shape: 1024 (1024)
I0409 02:44:24.979611  5147 net.cpp:157] Top shape: 1024 (1024)
I0409 02:44:24.979614  5147 net.cpp:165] Memory required for data: 28327936
I0409 02:44:24.979635  5147 layer_factory.hpp:77] Creating layer conv1
I0409 02:44:24.979652  5147 net.cpp:100] Creating Layer conv1
I0409 02:44:24.979668  5147 net.cpp:434] conv1 <- data
I0409 02:44:24.979674  5147 net.cpp:408] conv1 -> conv1
I0409 02:44:24.981578  5147 net.cpp:150] Setting up conv1
I0409 02:44:24.981595  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.981600  5147 net.cpp:165] Memory required for data: 750862336
I0409 02:44:24.981616  5147 layer_factory.hpp:77] Creating layer conv1_prescale
I0409 02:44:24.981624  5147 net.cpp:100] Creating Layer conv1_prescale
I0409 02:44:24.981628  5147 net.cpp:434] conv1_prescale <- conv1
I0409 02:44:24.981637  5147 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0409 02:44:24.981752  5147 net.cpp:150] Setting up conv1_prescale
I0409 02:44:24.981763  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.981766  5147 net.cpp:165] Memory required for data: 1473396736
I0409 02:44:24.981773  5147 layer_factory.hpp:77] Creating layer conv1_sTanH
I0409 02:44:24.981781  5147 net.cpp:100] Creating Layer conv1_sTanH
I0409 02:44:24.981783  5147 net.cpp:434] conv1_sTanH <- conv1
I0409 02:44:24.981791  5147 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0409 02:44:24.984289  5147 net.cpp:150] Setting up conv1_sTanH
I0409 02:44:24.984308  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.984313  5147 net.cpp:165] Memory required for data: 2195931136
I0409 02:44:24.984318  5147 layer_factory.hpp:77] Creating layer conv1_postscale
I0409 02:44:24.984325  5147 net.cpp:100] Creating Layer conv1_postscale
I0409 02:44:24.984329  5147 net.cpp:434] conv1_postscale <- conv1
I0409 02:44:24.984339  5147 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0409 02:44:24.984463  5147 net.cpp:150] Setting up conv1_postscale
I0409 02:44:24.984473  5147 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0409 02:44:24.984477  5147 net.cpp:165] Memory required for data: 2918465536
I0409 02:44:24.984483  5147 layer_factory.hpp:77] Creating layer pool1
I0409 02:44:24.984488  5147 net.cpp:100] Creating Layer pool1
I0409 02:44:24.984494  5147 net.cpp:434] pool1 <- conv1
I0409 02:44:24.984501  5147 net.cpp:408] pool1 -> pool1
I0409 02:44:24.984545  5147 net.cpp:150] Setting up pool1
I0409 02:44:24.984557  5147 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0409 02:44:24.984562  5147 net.cpp:165] Memory required for data: 3099099136
I0409 02:44:24.984565  5147 layer_factory.hpp:77] Creating layer conv2
I0409 02:44:24.984573  5147 net.cpp:100] Creating Layer conv2
I0409 02:44:24.984578  5147 net.cpp:434] conv2 <- pool1
I0409 02:44:24.984597  5147 net.cpp:408] conv2 -> conv2
I0409 02:44:24.989763  5147 net.cpp:150] Setting up conv2
I0409 02:44:24.989781  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.989785  5147 net.cpp:165] Memory required for data: 3298164736
I0409 02:44:24.989797  5147 layer_factory.hpp:77] Creating layer conv2_prescale
I0409 02:44:24.989812  5147 net.cpp:100] Creating Layer conv2_prescale
I0409 02:44:24.989816  5147 net.cpp:434] conv2_prescale <- conv2
I0409 02:44:24.989822  5147 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0409 02:44:24.989946  5147 net.cpp:150] Setting up conv2_prescale
I0409 02:44:24.989959  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.989964  5147 net.cpp:165] Memory required for data: 3497230336
I0409 02:44:24.989967  5147 layer_factory.hpp:77] Creating layer conv2_sTanH
I0409 02:44:24.989979  5147 net.cpp:100] Creating Layer conv2_sTanH
I0409 02:44:24.989984  5147 net.cpp:434] conv2_sTanH <- conv2
I0409 02:44:24.989989  5147 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0409 02:44:24.990917  5147 net.cpp:150] Setting up conv2_sTanH
I0409 02:44:24.990933  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.990937  5147 net.cpp:165] Memory required for data: 3696295936
I0409 02:44:24.990942  5147 layer_factory.hpp:77] Creating layer conv2_postscale
I0409 02:44:24.990950  5147 net.cpp:100] Creating Layer conv2_postscale
I0409 02:44:24.990970  5147 net.cpp:434] conv2_postscale <- conv2
I0409 02:44:24.990978  5147 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0409 02:44:24.991089  5147 net.cpp:150] Setting up conv2_postscale
I0409 02:44:24.991098  5147 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0409 02:44:24.991102  5147 net.cpp:165] Memory required for data: 3895361536
I0409 02:44:24.991107  5147 layer_factory.hpp:77] Creating layer pool2
I0409 02:44:24.991114  5147 net.cpp:100] Creating Layer pool2
I0409 02:44:24.991119  5147 net.cpp:434] pool2 <- conv2
I0409 02:44:24.991124  5147 net.cpp:408] pool2 -> pool2
I0409 02:44:24.991188  5147 net.cpp:150] Setting up pool2
I0409 02:44:24.991200  5147 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0409 02:44:24.991204  5147 net.cpp:165] Memory required for data: 3945127936
I0409 02:44:24.991207  5147 layer_factory.hpp:77] Creating layer conv3
I0409 02:44:24.991217  5147 net.cpp:100] Creating Layer conv3
I0409 02:44:24.991220  5147 net.cpp:434] conv3 <- pool2
I0409 02:44:24.991226  5147 net.cpp:408] conv3 -> conv3
I0409 02:44:24.998080  5147 net.cpp:150] Setting up conv3
I0409 02:44:24.998097  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:24.998101  5147 net.cpp:165] Memory required for data: 3981991936
I0409 02:44:24.998112  5147 layer_factory.hpp:77] Creating layer conv3_prescale
I0409 02:44:24.998123  5147 net.cpp:100] Creating Layer conv3_prescale
I0409 02:44:24.998127  5147 net.cpp:434] conv3_prescale <- conv3
I0409 02:44:24.998134  5147 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0409 02:44:24.998234  5147 net.cpp:150] Setting up conv3_prescale
I0409 02:44:24.998244  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:24.998246  5147 net.cpp:165] Memory required for data: 4018855936
I0409 02:44:24.998251  5147 layer_factory.hpp:77] Creating layer conv3_sTanH
I0409 02:44:24.998257  5147 net.cpp:100] Creating Layer conv3_sTanH
I0409 02:44:24.998260  5147 net.cpp:434] conv3_sTanH <- conv3
I0409 02:44:24.998266  5147 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0409 02:44:25.003049  5147 net.cpp:150] Setting up conv3_sTanH
I0409 02:44:25.003072  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:25.003075  5147 net.cpp:165] Memory required for data: 4055719936
I0409 02:44:25.003079  5147 layer_factory.hpp:77] Creating layer conv3_postscale
I0409 02:44:25.003087  5147 net.cpp:100] Creating Layer conv3_postscale
I0409 02:44:25.003093  5147 net.cpp:434] conv3_postscale <- conv3
I0409 02:44:25.003108  5147 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0409 02:44:25.003218  5147 net.cpp:150] Setting up conv3_postscale
I0409 02:44:25.003232  5147 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0409 02:44:25.003237  5147 net.cpp:165] Memory required for data: 4092583936
I0409 02:44:25.003242  5147 layer_factory.hpp:77] Creating layer pool3
I0409 02:44:25.003252  5147 net.cpp:100] Creating Layer pool3
I0409 02:44:25.003263  5147 net.cpp:434] pool3 <- conv3
I0409 02:44:25.003271  5147 net.cpp:408] pool3 -> pool3
I0409 02:44:25.003316  5147 net.cpp:150] Setting up pool3
I0409 02:44:25.003324  5147 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0409 02:44:25.003329  5147 net.cpp:165] Memory required for data: 4101799936
I0409 02:44:25.003331  5147 layer_factory.hpp:77] Creating layer fc4_300
I0409 02:44:25.003340  5147 net.cpp:100] Creating Layer fc4_300
I0409 02:44:25.003345  5147 net.cpp:434] fc4_300 <- pool3
I0409 02:44:25.003350  5147 net.cpp:408] fc4_300 -> fc4_300
I0409 02:44:25.013411  5147 net.cpp:150] Setting up fc4_300
I0409 02:44:25.013432  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:25.013435  5147 net.cpp:165] Memory required for data: 4103028736
I0409 02:44:25.013443  5147 layer_factory.hpp:77] Creating layer fc4_prescale
I0409 02:44:25.013453  5147 net.cpp:100] Creating Layer fc4_prescale
I0409 02:44:25.013458  5147 net.cpp:434] fc4_prescale <- fc4_300
I0409 02:44:25.013464  5147 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0409 02:44:25.013569  5147 net.cpp:150] Setting up fc4_prescale
I0409 02:44:25.013595  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:25.013599  5147 net.cpp:165] Memory required for data: 4104257536
I0409 02:44:25.013604  5147 layer_factory.hpp:77] Creating layer fc4_sTanH
I0409 02:44:25.013610  5147 net.cpp:100] Creating Layer fc4_sTanH
I0409 02:44:25.013614  5147 net.cpp:434] fc4_sTanH <- fc4_300
I0409 02:44:25.013622  5147 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0409 02:44:25.013828  5147 net.cpp:150] Setting up fc4_sTanH
I0409 02:44:25.013840  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:25.013844  5147 net.cpp:165] Memory required for data: 4105486336
I0409 02:44:25.013847  5147 layer_factory.hpp:77] Creating layer fc4_postscale
I0409 02:44:25.013856  5147 net.cpp:100] Creating Layer fc4_postscale
I0409 02:44:25.013864  5147 net.cpp:434] fc4_postscale <- fc4_300
I0409 02:44:25.013870  5147 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0409 02:44:25.013973  5147 net.cpp:150] Setting up fc4_postscale
I0409 02:44:25.013983  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:25.013985  5147 net.cpp:165] Memory required for data: 4106715136
I0409 02:44:25.013990  5147 layer_factory.hpp:77] Creating layer drop4
I0409 02:44:25.013998  5147 net.cpp:100] Creating Layer drop4
I0409 02:44:25.014000  5147 net.cpp:434] drop4 <- fc4_300
I0409 02:44:25.014006  5147 net.cpp:395] drop4 -> fc4_300 (in-place)
I0409 02:44:25.014030  5147 net.cpp:150] Setting up drop4
I0409 02:44:25.014039  5147 net.cpp:157] Top shape: 1024 300 (307200)
I0409 02:44:25.014042  5147 net.cpp:165] Memory required for data: 4107943936
I0409 02:44:25.014045  5147 layer_factory.hpp:77] Creating layer fc5_67
I0409 02:44:25.014052  5147 net.cpp:100] Creating Layer fc5_67
I0409 02:44:25.014056  5147 net.cpp:434] fc5_67 <- fc4_300
I0409 02:44:25.014060  5147 net.cpp:408] fc5_67 -> fc5_classes
I0409 02:44:25.014317  5147 net.cpp:150] Setting up fc5_67
I0409 02:44:25.014325  5147 net.cpp:157] Top shape: 1024 67 (68608)
I0409 02:44:25.014331  5147 net.cpp:165] Memory required for data: 4108218368
I0409 02:44:25.014343  5147 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0409 02:44:25.014353  5147 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0409 02:44:25.014356  5147 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0409 02:44:25.014363  5147 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0409 02:44:25.014370  5147 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0409 02:44:25.014376  5147 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0409 02:44:25.014430  5147 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0409 02:44:25.014437  5147 net.cpp:157] Top shape: 1024 67 (68608)
I0409 02:44:25.014441  5147 net.cpp:157] Top shape: 1024 67 (68608)
I0409 02:44:25.014444  5147 net.cpp:157] Top shape: 1024 67 (68608)
I0409 02:44:25.014447  5147 net.cpp:165] Memory required for data: 4109041664
I0409 02:44:25.014451  5147 layer_factory.hpp:77] Creating layer loss
I0409 02:44:25.014456  5147 net.cpp:100] Creating Layer loss
I0409 02:44:25.014461  5147 net.cpp:434] loss <- fc5_classes_fc5_67_0_split_0
I0409 02:44:25.014466  5147 net.cpp:434] loss <- label_data_1_split_0
I0409 02:44:25.014470  5147 net.cpp:408] loss -> loss
I0409 02:44:25.014483  5147 layer_factory.hpp:77] Creating layer loss
I0409 02:44:25.014827  5147 net.cpp:150] Setting up loss
I0409 02:44:25.014843  5147 net.cpp:157] Top shape: (1)
I0409 02:44:25.014847  5147 net.cpp:160]     with loss weight 1
I0409 02:44:25.014855  5147 net.cpp:165] Memory required for data: 4109041668
I0409 02:44:25.014858  5147 layer_factory.hpp:77] Creating layer accuracy_1
I0409 02:44:25.014868  5147 net.cpp:100] Creating Layer accuracy_1
I0409 02:44:25.014873  5147 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0409 02:44:25.014878  5147 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0409 02:44:25.014883  5147 net.cpp:408] accuracy_1 -> accuracy_1
I0409 02:44:25.014894  5147 net.cpp:150] Setting up accuracy_1
I0409 02:44:25.014909  5147 net.cpp:157] Top shape: (1)
I0409 02:44:25.014914  5147 net.cpp:165] Memory required for data: 4109041672
I0409 02:44:25.014916  5147 layer_factory.hpp:77] Creating layer accuracy_5
I0409 02:44:25.014922  5147 net.cpp:100] Creating Layer accuracy_5
I0409 02:44:25.014925  5147 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0409 02:44:25.014930  5147 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0409 02:44:25.014935  5147 net.cpp:408] accuracy_5 -> accuracy_5
I0409 02:44:25.014945  5147 net.cpp:150] Setting up accuracy_5
I0409 02:44:25.014950  5147 net.cpp:157] Top shape: (1)
I0409 02:44:25.014952  5147 net.cpp:165] Memory required for data: 4109041676
I0409 02:44:25.014955  5147 net.cpp:228] accuracy_5 does not need backward computation.
I0409 02:44:25.014958  5147 net.cpp:228] accuracy_1 does not need backward computation.
I0409 02:44:25.014962  5147 net.cpp:226] loss needs backward computation.
I0409 02:44:25.014967  5147 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0409 02:44:25.014971  5147 net.cpp:226] fc5_67 needs backward computation.
I0409 02:44:25.014974  5147 net.cpp:226] drop4 needs backward computation.
I0409 02:44:25.014977  5147 net.cpp:226] fc4_postscale needs backward computation.
I0409 02:44:25.014981  5147 net.cpp:226] fc4_sTanH needs backward computation.
I0409 02:44:25.014983  5147 net.cpp:226] fc4_prescale needs backward computation.
I0409 02:44:25.014986  5147 net.cpp:226] fc4_300 needs backward computation.
I0409 02:44:25.014989  5147 net.cpp:226] pool3 needs backward computation.
I0409 02:44:25.014993  5147 net.cpp:226] conv3_postscale needs backward computation.
I0409 02:44:25.014995  5147 net.cpp:226] conv3_sTanH needs backward computation.
I0409 02:44:25.014999  5147 net.cpp:226] conv3_prescale needs backward computation.
I0409 02:44:25.015002  5147 net.cpp:226] conv3 needs backward computation.
I0409 02:44:25.015005  5147 net.cpp:226] pool2 needs backward computation.
I0409 02:44:25.015009  5147 net.cpp:226] conv2_postscale needs backward computation.
I0409 02:44:25.015012  5147 net.cpp:226] conv2_sTanH needs backward computation.
I0409 02:44:25.015015  5147 net.cpp:226] conv2_prescale needs backward computation.
I0409 02:44:25.015018  5147 net.cpp:226] conv2 needs backward computation.
I0409 02:44:25.015022  5147 net.cpp:226] pool1 needs backward computation.
I0409 02:44:25.015025  5147 net.cpp:226] conv1_postscale needs backward computation.
I0409 02:44:25.015040  5147 net.cpp:226] conv1_sTanH needs backward computation.
I0409 02:44:25.015044  5147 net.cpp:226] conv1_prescale needs backward computation.
I0409 02:44:25.015048  5147 net.cpp:226] conv1 needs backward computation.
I0409 02:44:25.015051  5147 net.cpp:228] label_data_1_split does not need backward computation.
I0409 02:44:25.015055  5147 net.cpp:228] data does not need backward computation.
I0409 02:44:25.015058  5147 net.cpp:270] This network produces output accuracy_1
I0409 02:44:25.015061  5147 net.cpp:270] This network produces output accuracy_5
I0409 02:44:25.015065  5147 net.cpp:270] This network produces output loss
I0409 02:44:25.015089  5147 net.cpp:283] Network initialization done.
I0409 02:44:25.015169  5147 solver.cpp:72] Solver scaffolding done.
I0409 02:44:25.016155  5147 caffe.cpp:251] Starting Optimization
I0409 02:44:25.016166  5147 solver.cpp:291] Solving 
I0409 02:44:25.016170  5147 solver.cpp:292] Learning Rate Policy: step
I0409 02:44:25.019914  5147 solver.cpp:349] Iteration 0, Testing net (#0)
I0409 02:44:34.781147  5147 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00463207
I0409 02:44:34.781177  5147 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0299963
I0409 02:44:34.781199  5147 solver.cpp:416]     Test net output #2: loss = 4.59952 (* 1 = 4.59952 loss)
I0409 02:44:34.939311  5147 solver.cpp:240] Iteration 0, loss = 4.47587
I0409 02:44:34.939345  5147 solver.cpp:256]     Train net output #0: loss = 4.47587 (* 1 = 4.47587 loss)
I0409 02:44:34.939358  5147 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0409 02:44:35.320130  5147 solver.cpp:240] Iteration 1, loss = 10.292
I0409 02:44:35.320190  5147 solver.cpp:256]     Train net output #0: loss = 10.292 (* 1 = 10.292 loss)
I0409 02:44:35.320200  5147 sgd_solver.cpp:106] Iteration 1, lr = 0.1
I0409 02:44:35.692880  5147 solver.cpp:240] Iteration 2, loss = 35.7948
I0409 02:44:35.692917  5147 solver.cpp:256]     Train net output #0: loss = 35.7948 (* 1 = 35.7948 loss)
I0409 02:44:35.692926  5147 sgd_solver.cpp:106] Iteration 2, lr = 0.1
I0409 02:44:36.062733  5147 solver.cpp:240] Iteration 3, loss = 54.7368
I0409 02:44:36.062767  5147 solver.cpp:256]     Train net output #0: loss = 54.7368 (* 1 = 54.7368 loss)
I0409 02:44:36.062777  5147 sgd_solver.cpp:106] Iteration 3, lr = 0.1
I0409 02:44:36.434057  5147 solver.cpp:240] Iteration 4, loss = 59.293
I0409 02:44:36.434090  5147 solver.cpp:256]     Train net output #0: loss = 59.293 (* 1 = 59.293 loss)
I0409 02:44:36.434099  5147 sgd_solver.cpp:106] Iteration 4, lr = 0.1
I0409 02:44:36.806772  5147 solver.cpp:240] Iteration 5, loss = 62.0837
I0409 02:44:36.806805  5147 solver.cpp:256]     Train net output #0: loss = 62.0837 (* 1 = 62.0837 loss)
I0409 02:44:36.806814  5147 sgd_solver.cpp:106] Iteration 5, lr = 0.1
I0409 02:44:37.182970  5147 solver.cpp:240] Iteration 6, loss = 63.1047
I0409 02:44:37.183007  5147 solver.cpp:256]     Train net output #0: loss = 63.1047 (* 1 = 63.1047 loss)
I0409 02:44:37.183015  5147 sgd_solver.cpp:106] Iteration 6, lr = 0.1
I0409 02:44:37.554733  5147 solver.cpp:240] Iteration 7, loss = 65.1303
I0409 02:44:37.554767  5147 solver.cpp:256]     Train net output #0: loss = 65.1303 (* 1 = 65.1303 loss)
I0409 02:44:37.554776  5147 sgd_solver.cpp:106] Iteration 7, lr = 0.1
I0409 02:44:37.926657  5147 solver.cpp:240] Iteration 8, loss = 72.9963
I0409 02:44:37.926690  5147 solver.cpp:256]     Train net output #0: loss = 72.9963 (* 1 = 72.9963 loss)
I0409 02:44:37.926700  5147 sgd_solver.cpp:106] Iteration 8, lr = 0.1
I0409 02:44:38.303580  5147 solver.cpp:240] Iteration 9, loss = 70.3933
I0409 02:44:38.303616  5147 solver.cpp:256]     Train net output #0: loss = 70.3933 (* 1 = 70.3933 loss)
I0409 02:44:38.303623  5147 sgd_solver.cpp:106] Iteration 9, lr = 0.1
I0409 02:44:38.678619  5147 solver.cpp:240] Iteration 10, loss = 70.6724
I0409 02:44:38.678654  5147 solver.cpp:256]     Train net output #0: loss = 70.6724 (* 1 = 70.6724 loss)
I0409 02:44:38.678663  5147 sgd_solver.cpp:106] Iteration 10, lr = 0.1
I0409 02:44:39.049007  5147 solver.cpp:240] Iteration 11, loss = 74.5481
I0409 02:44:39.049041  5147 solver.cpp:256]     Train net output #0: loss = 74.5481 (* 1 = 74.5481 loss)
I0409 02:44:39.049049  5147 sgd_solver.cpp:106] Iteration 11, lr = 0.1
I0409 02:44:39.422420  5147 solver.cpp:240] Iteration 12, loss = 60.4614
I0409 02:44:39.422461  5147 solver.cpp:256]     Train net output #0: loss = 60.4614 (* 1 = 60.4614 loss)
I0409 02:44:39.422472  5147 sgd_solver.cpp:106] Iteration 12, lr = 0.1
I0409 02:44:39.792227  5147 solver.cpp:240] Iteration 13, loss = 57.8749
I0409 02:44:39.792266  5147 solver.cpp:256]     Train net output #0: loss = 57.8749 (* 1 = 57.8749 loss)
I0409 02:44:39.792276  5147 sgd_solver.cpp:106] Iteration 13, lr = 0.1
I0409 02:44:40.170367  5147 solver.cpp:240] Iteration 14, loss = 58.4312
I0409 02:44:40.170402  5147 solver.cpp:256]     Train net output #0: loss = 58.4312 (* 1 = 58.4312 loss)
I0409 02:44:40.170409  5147 sgd_solver.cpp:106] Iteration 14, lr = 0.1
I0409 02:44:40.543596  5147 solver.cpp:240] Iteration 15, loss = 55.5252
I0409 02:44:40.543627  5147 solver.cpp:256]     Train net output #0: loss = 55.5252 (* 1 = 55.5252 loss)
I0409 02:44:40.543637  5147 sgd_solver.cpp:106] Iteration 15, lr = 0.1
I0409 02:44:40.914927  5147 solver.cpp:240] Iteration 16, loss = 76.3699
I0409 02:44:40.914958  5147 solver.cpp:256]     Train net output #0: loss = 76.3699 (* 1 = 76.3699 loss)
I0409 02:44:40.914966  5147 sgd_solver.cpp:106] Iteration 16, lr = 0.1
I0409 02:44:41.287113  5147 solver.cpp:240] Iteration 17, loss = 64.7425
I0409 02:44:41.287149  5147 solver.cpp:256]     Train net output #0: loss = 64.7425 (* 1 = 64.7425 loss)
I0409 02:44:41.287184  5147 sgd_solver.cpp:106] Iteration 17, lr = 0.1
I0409 02:44:41.661231  5147 solver.cpp:240] Iteration 18, loss = 73.7481
I0409 02:44:41.661274  5147 solver.cpp:256]     Train net output #0: loss = 73.7481 (* 1 = 73.7481 loss)
I0409 02:44:41.661283  5147 sgd_solver.cpp:106] Iteration 18, lr = 0.1
I0409 02:44:42.037658  5147 solver.cpp:240] Iteration 19, loss = 44.5118
I0409 02:44:42.037708  5147 solver.cpp:256]     Train net output #0: loss = 44.5118 (* 1 = 44.5118 loss)
I0409 02:44:42.037717  5147 sgd_solver.cpp:106] Iteration 19, lr = 0.1
I0409 02:44:42.410439  5147 solver.cpp:240] Iteration 20, loss = 48.8736
I0409 02:44:42.410483  5147 solver.cpp:256]     Train net output #0: loss = 48.8736 (* 1 = 48.8736 loss)
I0409 02:44:42.410492  5147 sgd_solver.cpp:106] Iteration 20, lr = 0.1
I0409 02:44:42.780958  5147 solver.cpp:240] Iteration 21, loss = 20.1511
I0409 02:44:42.780992  5147 solver.cpp:256]     Train net output #0: loss = 20.1511 (* 1 = 20.1511 loss)
I0409 02:44:42.781002  5147 sgd_solver.cpp:106] Iteration 21, lr = 0.1
I0409 02:44:43.159834  5147 solver.cpp:240] Iteration 22, loss = 48.8363
I0409 02:44:43.159868  5147 solver.cpp:256]     Train net output #0: loss = 48.8363 (* 1 = 48.8363 loss)
I0409 02:44:43.159904  5147 sgd_solver.cpp:106] Iteration 22, lr = 0.1
I0409 02:44:43.535367  5147 solver.cpp:240] Iteration 23, loss = 32.4032
I0409 02:44:43.535400  5147 solver.cpp:256]     Train net output #0: loss = 32.4032 (* 1 = 32.4032 loss)
I0409 02:44:43.535409  5147 sgd_solver.cpp:106] Iteration 23, lr = 0.1
I0409 02:44:43.908077  5147 solver.cpp:240] Iteration 24, loss = 64.0776
I0409 02:44:43.908112  5147 solver.cpp:256]     Train net output #0: loss = 64.0776 (* 1 = 64.0776 loss)
I0409 02:44:43.908120  5147 sgd_solver.cpp:106] Iteration 24, lr = 0.1
I0409 02:44:44.280386  5147 solver.cpp:240] Iteration 25, loss = 33.9393
I0409 02:44:44.280421  5147 solver.cpp:256]     Train net output #0: loss = 33.9393 (* 1 = 33.9393 loss)
I0409 02:44:44.280428  5147 sgd_solver.cpp:106] Iteration 25, lr = 0.1
I0409 02:44:44.653102  5147 solver.cpp:240] Iteration 26, loss = 50.5105
I0409 02:44:44.653137  5147 solver.cpp:256]     Train net output #0: loss = 50.5105 (* 1 = 50.5105 loss)
I0409 02:44:44.653146  5147 sgd_solver.cpp:106] Iteration 26, lr = 0.1
I0409 02:44:45.022222  5147 solver.cpp:240] Iteration 27, loss = 60.2029
I0409 02:44:45.022255  5147 solver.cpp:256]     Train net output #0: loss = 60.2029 (* 1 = 60.2029 loss)
I0409 02:44:45.022264  5147 sgd_solver.cpp:106] Iteration 27, lr = 0.1
I0409 02:44:45.395898  5147 solver.cpp:240] Iteration 28, loss = 74.8342
I0409 02:44:45.395932  5147 solver.cpp:256]     Train net output #0: loss = 74.8342 (* 1 = 74.8342 loss)
I0409 02:44:45.395941  5147 sgd_solver.cpp:106] Iteration 28, lr = 0.1
I0409 02:44:45.766067  5147 solver.cpp:240] Iteration 29, loss = 52.8357
I0409 02:44:45.766099  5147 solver.cpp:256]     Train net output #0: loss = 52.8357 (* 1 = 52.8357 loss)
I0409 02:44:45.766108  5147 sgd_solver.cpp:106] Iteration 29, lr = 0.1
I0409 02:44:46.137277  5147 solver.cpp:240] Iteration 30, loss = 42.6193
I0409 02:44:46.137310  5147 solver.cpp:256]     Train net output #0: loss = 42.6193 (* 1 = 42.6193 loss)
I0409 02:44:46.137318  5147 sgd_solver.cpp:106] Iteration 30, lr = 0.1
I0409 02:44:46.513600  5147 solver.cpp:240] Iteration 31, loss = 61.5857
I0409 02:44:46.513633  5147 solver.cpp:256]     Train net output #0: loss = 61.5857 (* 1 = 61.5857 loss)
I0409 02:44:46.513643  5147 sgd_solver.cpp:106] Iteration 31, lr = 0.1
I0409 02:44:46.890678  5147 solver.cpp:240] Iteration 32, loss = 49.6675
I0409 02:44:46.890712  5147 solver.cpp:256]     Train net output #0: loss = 49.6675 (* 1 = 49.6675 loss)
I0409 02:44:46.890720  5147 sgd_solver.cpp:106] Iteration 32, lr = 0.1
I0409 02:44:47.263154  5147 solver.cpp:240] Iteration 33, loss = 59.9193
I0409 02:44:47.263200  5147 solver.cpp:256]     Train net output #0: loss = 59.9193 (* 1 = 59.9193 loss)
I0409 02:44:47.263209  5147 sgd_solver.cpp:106] Iteration 33, lr = 0.1
I0409 02:44:47.634390  5147 solver.cpp:240] Iteration 34, loss = 46.8083
I0409 02:44:47.634461  5147 solver.cpp:256]     Train net output #0: loss = 46.8083 (* 1 = 46.8083 loss)
I0409 02:44:47.634472  5147 sgd_solver.cpp:106] Iteration 34, lr = 0.1
I0409 02:44:48.012926  5147 solver.cpp:240] Iteration 35, loss = 43.3937
I0409 02:44:48.012959  5147 solver.cpp:256]     Train net output #0: loss = 43.3937 (* 1 = 43.3937 loss)
I0409 02:44:48.012969  5147 sgd_solver.cpp:106] Iteration 35, lr = 0.1
I0409 02:44:48.389339  5147 solver.cpp:240] Iteration 36, loss = 29.8261
I0409 02:44:48.389386  5147 solver.cpp:256]     Train net output #0: loss = 29.8261 (* 1 = 29.8261 loss)
I0409 02:44:48.389394  5147 sgd_solver.cpp:106] Iteration 36, lr = 0.1
I0409 02:44:48.763195  5147 solver.cpp:240] Iteration 37, loss = 40.5454
I0409 02:44:48.763228  5147 solver.cpp:256]     Train net output #0: loss = 40.5454 (* 1 = 40.5454 loss)
I0409 02:44:48.763237  5147 sgd_solver.cpp:106] Iteration 37, lr = 0.1
I0409 02:44:49.135020  5147 solver.cpp:240] Iteration 38, loss = 29.7208
I0409 02:44:49.135059  5147 solver.cpp:256]     Train net output #0: loss = 29.7208 (* 1 = 29.7208 loss)
I0409 02:44:49.135068  5147 sgd_solver.cpp:106] Iteration 38, lr = 0.1
I0409 02:44:49.506669  5147 solver.cpp:240] Iteration 39, loss = 35.1651
I0409 02:44:49.506714  5147 solver.cpp:256]     Train net output #0: loss = 35.1651 (* 1 = 35.1651 loss)
I0409 02:44:49.506722  5147 sgd_solver.cpp:106] Iteration 39, lr = 0.1
I0409 02:44:49.882823  5147 solver.cpp:240] Iteration 40, loss = 29.0617
I0409 02:44:49.882856  5147 solver.cpp:256]     Train net output #0: loss = 29.0617 (* 1 = 29.0617 loss)
I0409 02:44:49.882865  5147 sgd_solver.cpp:106] Iteration 40, lr = 0.1
I0409 02:44:50.256281  5147 solver.cpp:240] Iteration 41, loss = 70.2686
I0409 02:44:50.256317  5147 solver.cpp:256]     Train net output #0: loss = 70.2686 (* 1 = 70.2686 loss)
I0409 02:44:50.256326  5147 sgd_solver.cpp:106] Iteration 41, lr = 0.1
I0409 02:44:50.629075  5147 solver.cpp:240] Iteration 42, loss = 66.9788
I0409 02:44:50.629111  5147 solver.cpp:256]     Train net output #0: loss = 66.9788 (* 1 = 66.9788 loss)
I0409 02:44:50.629119  5147 sgd_solver.cpp:106] Iteration 42, lr = 0.1
I0409 02:44:51.000218  5147 solver.cpp:240] Iteration 43, loss = 73.3494
I0409 02:44:51.000263  5147 solver.cpp:256]     Train net output #0: loss = 73.3494 (* 1 = 73.3494 loss)
I0409 02:44:51.000272  5147 sgd_solver.cpp:106] Iteration 43, lr = 0.1
I0409 02:44:51.377116  5147 solver.cpp:240] Iteration 44, loss = 63.2447
I0409 02:44:51.377151  5147 solver.cpp:256]     Train net output #0: loss = 63.2447 (* 1 = 63.2447 loss)
I0409 02:44:51.377159  5147 sgd_solver.cpp:106] Iteration 44, lr = 0.1
I0409 02:44:51.753456  5147 solver.cpp:240] Iteration 45, loss = 62.0432
I0409 02:44:51.753489  5147 solver.cpp:256]     Train net output #0: loss = 62.0432 (* 1 = 62.0432 loss)
I0409 02:44:51.753497  5147 sgd_solver.cpp:106] Iteration 45, lr = 0.1
I0409 02:44:52.126057  5147 solver.cpp:240] Iteration 46, loss = 60.1394
I0409 02:44:52.126091  5147 solver.cpp:256]     Train net output #0: loss = 60.1394 (* 1 = 60.1394 loss)
I0409 02:44:52.126101  5147 sgd_solver.cpp:106] Iteration 46, lr = 0.1
I0409 02:44:52.499810  5147 solver.cpp:240] Iteration 47, loss = 52.4206
I0409 02:44:52.499853  5147 solver.cpp:256]     Train net output #0: loss = 52.4206 (* 1 = 52.4206 loss)
I0409 02:44:52.499861  5147 sgd_solver.cpp:106] Iteration 47, lr = 0.1
I0409 02:44:52.879142  5147 solver.cpp:240] Iteration 48, loss = 58.5866
I0409 02:44:52.879184  5147 solver.cpp:256]     Train net output #0: loss = 58.5866 (* 1 = 58.5866 loss)
I0409 02:44:52.879194  5147 sgd_solver.cpp:106] Iteration 48, lr = 0.1
I0409 02:44:53.253572  5147 solver.cpp:240] Iteration 49, loss = 80.2764
I0409 02:44:53.253605  5147 solver.cpp:256]     Train net output #0: loss = 80.2764 (* 1 = 80.2764 loss)
I0409 02:44:53.253618  5147 sgd_solver.cpp:106] Iteration 49, lr = 0.1
I0409 02:44:53.625906  5147 solver.cpp:240] Iteration 50, loss = 48.0592
I0409 02:44:53.626094  5147 solver.cpp:256]     Train net output #0: loss = 48.0592 (* 1 = 48.0592 loss)
I0409 02:44:53.626106  5147 sgd_solver.cpp:106] Iteration 50, lr = 0.1
I0409 02:44:53.999835  5147 solver.cpp:240] Iteration 51, loss = 67.233
I0409 02:44:53.999892  5147 solver.cpp:256]     Train net output #0: loss = 67.233 (* 1 = 67.233 loss)
I0409 02:44:53.999902  5147 sgd_solver.cpp:106] Iteration 51, lr = 0.1
I0409 02:44:54.374337  5147 solver.cpp:240] Iteration 52, loss = 68.4109
I0409 02:44:54.374382  5147 solver.cpp:256]     Train net output #0: loss = 68.4109 (* 1 = 68.4109 loss)
I0409 02:44:54.374390  5147 sgd_solver.cpp:106] Iteration 52, lr = 0.1
I0409 02:44:54.751765  5147 solver.cpp:240] Iteration 53, loss = 66.6848
I0409 02:44:54.751798  5147 solver.cpp:256]     Train net output #0: loss = 66.6848 (* 1 = 66.6848 loss)
I0409 02:44:54.751806  5147 sgd_solver.cpp:106] Iteration 53, lr = 0.1
I0409 02:44:55.125385  5147 solver.cpp:240] Iteration 54, loss = 75.281
I0409 02:44:55.125430  5147 solver.cpp:256]     Train net output #0: loss = 75.281 (* 1 = 75.281 loss)
I0409 02:44:55.125438  5147 sgd_solver.cpp:106] Iteration 54, lr = 0.1
I0409 02:44:55.496834  5147 solver.cpp:240] Iteration 55, loss = 66.0085
I0409 02:44:55.496866  5147 solver.cpp:256]     Train net output #0: loss = 66.0085 (* 1 = 66.0085 loss)
I0409 02:44:55.496876  5147 sgd_solver.cpp:106] Iteration 55, lr = 0.1
