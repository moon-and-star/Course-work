I0508 00:47:16.976680 17805 caffe.cpp:217] Using GPUs 1
I0508 00:47:17.193796 17805 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0508 00:47:18.138736 17805 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_15/RTSD/orig/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_15/RTSD/orig/trial_1/test.prototxt"
test_iter: 17
test_interval: 85
base_lr: 0.0001
display: 1
max_iter: 8500
lr_policy: "step"
gamma: 0.7
momentum: 0.9
weight_decay: 0.0005
stepsize: 1700
snapshot: 850
snapshot_prefix: "./snapshots/experiment_15/RTSD/orig/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0508 00:47:18.138880 17805 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_15/RTSD/orig/trial_1/train.prototxt
I0508 00:47:18.139345 17805 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: false
    crop_size: 48
    mean_value: 119
    mean_value: 113
    mean_value: 113
  }
  data_param {
    source: "../local_data/lmdb/RTSD/orig/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "fc5_116"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 116
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "fc5_classes"
  top: "softmax"
}
layer {
  name: "loss"
  type: "MultinomialLogisticLoss"
  bottom: "softmax"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
layer {
  name: "silence"
  type: "Silence"
  bottom: "accuracy_1"
  bottom: "accuracy_5"
}
I0508 00:47:18.139539 17805 layer_factory.hpp:77] Creating layer data
I0508 00:47:18.140697 17805 net.cpp:100] Creating Layer data
I0508 00:47:18.140715 17805 net.cpp:408] data -> data
I0508 00:47:18.140744 17805 net.cpp:408] data -> label
I0508 00:47:18.142381 17912 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/RTSD/orig/train/lmdb
I0508 00:47:18.163064 17805 data_layer.cpp:41] output data size: 1024,3,48,48
I0508 00:47:18.212096 17805 net.cpp:150] Setting up data
I0508 00:47:18.212127 17805 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0508 00:47:18.212136 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.212141 17805 net.cpp:165] Memory required for data: 28315648
I0508 00:47:18.212157 17805 layer_factory.hpp:77] Creating layer label_data_1_split
I0508 00:47:18.212175 17805 net.cpp:100] Creating Layer label_data_1_split
I0508 00:47:18.212183 17805 net.cpp:434] label_data_1_split <- label
I0508 00:47:18.212200 17805 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0508 00:47:18.212215 17805 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0508 00:47:18.212224 17805 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0508 00:47:18.212291 17805 net.cpp:150] Setting up label_data_1_split
I0508 00:47:18.212299 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.212304 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.212311 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.212316 17805 net.cpp:165] Memory required for data: 28327936
I0508 00:47:18.212321 17805 layer_factory.hpp:77] Creating layer conv1
I0508 00:47:18.212338 17805 net.cpp:100] Creating Layer conv1
I0508 00:47:18.212344 17805 net.cpp:434] conv1 <- data
I0508 00:47:18.212352 17805 net.cpp:408] conv1 -> conv1
I0508 00:47:18.595211 17805 net.cpp:150] Setting up conv1
I0508 00:47:18.595242 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.595245 17805 net.cpp:165] Memory required for data: 750862336
I0508 00:47:18.595268 17805 layer_factory.hpp:77] Creating layer conv1_prescale
I0508 00:47:18.595283 17805 net.cpp:100] Creating Layer conv1_prescale
I0508 00:47:18.595289 17805 net.cpp:434] conv1_prescale <- conv1
I0508 00:47:18.595296 17805 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0508 00:47:18.595408 17805 net.cpp:150] Setting up conv1_prescale
I0508 00:47:18.595418 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.595422 17805 net.cpp:165] Memory required for data: 1473396736
I0508 00:47:18.595428 17805 layer_factory.hpp:77] Creating layer conv1_sTanH
I0508 00:47:18.595438 17805 net.cpp:100] Creating Layer conv1_sTanH
I0508 00:47:18.595443 17805 net.cpp:434] conv1_sTanH <- conv1
I0508 00:47:18.595448 17805 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0508 00:47:18.595650 17805 net.cpp:150] Setting up conv1_sTanH
I0508 00:47:18.595662 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.595685 17805 net.cpp:165] Memory required for data: 2195931136
I0508 00:47:18.595688 17805 layer_factory.hpp:77] Creating layer conv1_postscale
I0508 00:47:18.595698 17805 net.cpp:100] Creating Layer conv1_postscale
I0508 00:47:18.595703 17805 net.cpp:434] conv1_postscale <- conv1
I0508 00:47:18.595710 17805 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0508 00:47:18.595813 17805 net.cpp:150] Setting up conv1_postscale
I0508 00:47:18.595824 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.595826 17805 net.cpp:165] Memory required for data: 2918465536
I0508 00:47:18.595831 17805 layer_factory.hpp:77] Creating layer pool1
I0508 00:47:18.595839 17805 net.cpp:100] Creating Layer pool1
I0508 00:47:18.595844 17805 net.cpp:434] pool1 <- conv1
I0508 00:47:18.595849 17805 net.cpp:408] pool1 -> pool1
I0508 00:47:18.595919 17805 net.cpp:150] Setting up pool1
I0508 00:47:18.595930 17805 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0508 00:47:18.595933 17805 net.cpp:165] Memory required for data: 3099099136
I0508 00:47:18.595937 17805 layer_factory.hpp:77] Creating layer conv2
I0508 00:47:18.595947 17805 net.cpp:100] Creating Layer conv2
I0508 00:47:18.595953 17805 net.cpp:434] conv2 <- pool1
I0508 00:47:18.595959 17805 net.cpp:408] conv2 -> conv2
I0508 00:47:18.601227 17805 net.cpp:150] Setting up conv2
I0508 00:47:18.601244 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.601248 17805 net.cpp:165] Memory required for data: 3298164736
I0508 00:47:18.601259 17805 layer_factory.hpp:77] Creating layer conv2_prescale
I0508 00:47:18.601271 17805 net.cpp:100] Creating Layer conv2_prescale
I0508 00:47:18.601277 17805 net.cpp:434] conv2_prescale <- conv2
I0508 00:47:18.601284 17805 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0508 00:47:18.601388 17805 net.cpp:150] Setting up conv2_prescale
I0508 00:47:18.601398 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.601402 17805 net.cpp:165] Memory required for data: 3497230336
I0508 00:47:18.601407 17805 layer_factory.hpp:77] Creating layer conv2_sTanH
I0508 00:47:18.601413 17805 net.cpp:100] Creating Layer conv2_sTanH
I0508 00:47:18.601416 17805 net.cpp:434] conv2_sTanH <- conv2
I0508 00:47:18.601421 17805 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0508 00:47:18.601605 17805 net.cpp:150] Setting up conv2_sTanH
I0508 00:47:18.601618 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.601620 17805 net.cpp:165] Memory required for data: 3696295936
I0508 00:47:18.601624 17805 layer_factory.hpp:77] Creating layer conv2_postscale
I0508 00:47:18.601631 17805 net.cpp:100] Creating Layer conv2_postscale
I0508 00:47:18.601636 17805 net.cpp:434] conv2_postscale <- conv2
I0508 00:47:18.601644 17805 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0508 00:47:18.601745 17805 net.cpp:150] Setting up conv2_postscale
I0508 00:47:18.601754 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.601758 17805 net.cpp:165] Memory required for data: 3895361536
I0508 00:47:18.601761 17805 layer_factory.hpp:77] Creating layer pool2
I0508 00:47:18.601769 17805 net.cpp:100] Creating Layer pool2
I0508 00:47:18.601774 17805 net.cpp:434] pool2 <- conv2
I0508 00:47:18.601780 17805 net.cpp:408] pool2 -> pool2
I0508 00:47:18.601826 17805 net.cpp:150] Setting up pool2
I0508 00:47:18.601836 17805 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0508 00:47:18.601840 17805 net.cpp:165] Memory required for data: 3945127936
I0508 00:47:18.601843 17805 layer_factory.hpp:77] Creating layer conv3
I0508 00:47:18.601852 17805 net.cpp:100] Creating Layer conv3
I0508 00:47:18.601855 17805 net.cpp:434] conv3 <- pool2
I0508 00:47:18.601861 17805 net.cpp:408] conv3 -> conv3
I0508 00:47:18.607568 17805 net.cpp:150] Setting up conv3
I0508 00:47:18.607587 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.607595 17805 net.cpp:165] Memory required for data: 3981991936
I0508 00:47:18.607609 17805 layer_factory.hpp:77] Creating layer conv3_prescale
I0508 00:47:18.607642 17805 net.cpp:100] Creating Layer conv3_prescale
I0508 00:47:18.607650 17805 net.cpp:434] conv3_prescale <- conv3
I0508 00:47:18.607657 17805 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0508 00:47:18.607759 17805 net.cpp:150] Setting up conv3_prescale
I0508 00:47:18.607769 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.607772 17805 net.cpp:165] Memory required for data: 4018855936
I0508 00:47:18.607780 17805 layer_factory.hpp:77] Creating layer conv3_sTanH
I0508 00:47:18.607789 17805 net.cpp:100] Creating Layer conv3_sTanH
I0508 00:47:18.607795 17805 net.cpp:434] conv3_sTanH <- conv3
I0508 00:47:18.607802 17805 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0508 00:47:18.608012 17805 net.cpp:150] Setting up conv3_sTanH
I0508 00:47:18.608026 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.608031 17805 net.cpp:165] Memory required for data: 4055719936
I0508 00:47:18.608036 17805 layer_factory.hpp:77] Creating layer conv3_postscale
I0508 00:47:18.608048 17805 net.cpp:100] Creating Layer conv3_postscale
I0508 00:47:18.608053 17805 net.cpp:434] conv3_postscale <- conv3
I0508 00:47:18.608060 17805 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0508 00:47:18.608160 17805 net.cpp:150] Setting up conv3_postscale
I0508 00:47:18.608170 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.608173 17805 net.cpp:165] Memory required for data: 4092583936
I0508 00:47:18.608181 17805 layer_factory.hpp:77] Creating layer pool3
I0508 00:47:18.608197 17805 net.cpp:100] Creating Layer pool3
I0508 00:47:18.608202 17805 net.cpp:434] pool3 <- conv3
I0508 00:47:18.608209 17805 net.cpp:408] pool3 -> pool3
I0508 00:47:18.608258 17805 net.cpp:150] Setting up pool3
I0508 00:47:18.608268 17805 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0508 00:47:18.608273 17805 net.cpp:165] Memory required for data: 4101799936
I0508 00:47:18.608291 17805 layer_factory.hpp:77] Creating layer fc4_300
I0508 00:47:18.608305 17805 net.cpp:100] Creating Layer fc4_300
I0508 00:47:18.608310 17805 net.cpp:434] fc4_300 <- pool3
I0508 00:47:18.608316 17805 net.cpp:408] fc4_300 -> fc4_300
I0508 00:47:18.613935 17805 net.cpp:150] Setting up fc4_300
I0508 00:47:18.613952 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.613960 17805 net.cpp:165] Memory required for data: 4103028736
I0508 00:47:18.613970 17805 layer_factory.hpp:77] Creating layer fc4_prescale
I0508 00:47:18.613981 17805 net.cpp:100] Creating Layer fc4_prescale
I0508 00:47:18.613988 17805 net.cpp:434] fc4_prescale <- fc4_300
I0508 00:47:18.613998 17805 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0508 00:47:18.614097 17805 net.cpp:150] Setting up fc4_prescale
I0508 00:47:18.614106 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.614110 17805 net.cpp:165] Memory required for data: 4104257536
I0508 00:47:18.614117 17805 layer_factory.hpp:77] Creating layer fc4_sTanH
I0508 00:47:18.614125 17805 net.cpp:100] Creating Layer fc4_sTanH
I0508 00:47:18.614131 17805 net.cpp:434] fc4_sTanH <- fc4_300
I0508 00:47:18.614137 17805 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0508 00:47:18.615394 17805 net.cpp:150] Setting up fc4_sTanH
I0508 00:47:18.615411 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.615418 17805 net.cpp:165] Memory required for data: 4105486336
I0508 00:47:18.615423 17805 layer_factory.hpp:77] Creating layer fc4_postscale
I0508 00:47:18.615437 17805 net.cpp:100] Creating Layer fc4_postscale
I0508 00:47:18.615442 17805 net.cpp:434] fc4_postscale <- fc4_300
I0508 00:47:18.615449 17805 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0508 00:47:18.615561 17805 net.cpp:150] Setting up fc4_postscale
I0508 00:47:18.615569 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.615573 17805 net.cpp:165] Memory required for data: 4106715136
I0508 00:47:18.615581 17805 layer_factory.hpp:77] Creating layer fc5_116
I0508 00:47:18.615591 17805 net.cpp:100] Creating Layer fc5_116
I0508 00:47:18.615597 17805 net.cpp:434] fc5_116 <- fc4_300
I0508 00:47:18.615607 17805 net.cpp:408] fc5_116 -> fc5_classes
I0508 00:47:18.617532 17805 net.cpp:150] Setting up fc5_116
I0508 00:47:18.617547 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.617552 17805 net.cpp:165] Memory required for data: 4107190272
I0508 00:47:18.617568 17805 layer_factory.hpp:77] Creating layer fc5_classes_fc5_116_0_split
I0508 00:47:18.617578 17805 net.cpp:100] Creating Layer fc5_classes_fc5_116_0_split
I0508 00:47:18.617586 17805 net.cpp:434] fc5_classes_fc5_116_0_split <- fc5_classes
I0508 00:47:18.617594 17805 net.cpp:408] fc5_classes_fc5_116_0_split -> fc5_classes_fc5_116_0_split_0
I0508 00:47:18.617604 17805 net.cpp:408] fc5_classes_fc5_116_0_split -> fc5_classes_fc5_116_0_split_1
I0508 00:47:18.617615 17805 net.cpp:408] fc5_classes_fc5_116_0_split -> fc5_classes_fc5_116_0_split_2
I0508 00:47:18.617674 17805 net.cpp:150] Setting up fc5_classes_fc5_116_0_split
I0508 00:47:18.617682 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.617687 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.617694 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.617698 17805 net.cpp:165] Memory required for data: 4108615680
I0508 00:47:18.617703 17805 layer_factory.hpp:77] Creating layer softmax
I0508 00:47:18.617712 17805 net.cpp:100] Creating Layer softmax
I0508 00:47:18.617718 17805 net.cpp:434] softmax <- fc5_classes_fc5_116_0_split_0
I0508 00:47:18.617725 17805 net.cpp:408] softmax -> softmax
I0508 00:47:18.617987 17805 net.cpp:150] Setting up softmax
I0508 00:47:18.618003 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.618010 17805 net.cpp:165] Memory required for data: 4109090816
I0508 00:47:18.618013 17805 layer_factory.hpp:77] Creating layer loss
I0508 00:47:18.618023 17805 net.cpp:100] Creating Layer loss
I0508 00:47:18.618028 17805 net.cpp:434] loss <- softmax
I0508 00:47:18.618036 17805 net.cpp:434] loss <- label_data_1_split_0
I0508 00:47:18.618044 17805 net.cpp:408] loss -> loss
I0508 00:47:18.618077 17805 net.cpp:150] Setting up loss
I0508 00:47:18.618085 17805 net.cpp:157] Top shape: (1)
I0508 00:47:18.618088 17805 net.cpp:160]     with loss weight 1
I0508 00:47:18.618116 17805 net.cpp:165] Memory required for data: 4109090820
I0508 00:47:18.618121 17805 layer_factory.hpp:77] Creating layer accuracy_1
I0508 00:47:18.618134 17805 net.cpp:100] Creating Layer accuracy_1
I0508 00:47:18.618139 17805 net.cpp:434] accuracy_1 <- fc5_classes_fc5_116_0_split_1
I0508 00:47:18.618145 17805 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0508 00:47:18.618152 17805 net.cpp:408] accuracy_1 -> accuracy_1
I0508 00:47:18.618167 17805 net.cpp:150] Setting up accuracy_1
I0508 00:47:18.618173 17805 net.cpp:157] Top shape: (1)
I0508 00:47:18.618177 17805 net.cpp:165] Memory required for data: 4109090824
I0508 00:47:18.618182 17805 layer_factory.hpp:77] Creating layer accuracy_5
I0508 00:47:18.618204 17805 net.cpp:100] Creating Layer accuracy_5
I0508 00:47:18.618208 17805 net.cpp:434] accuracy_5 <- fc5_classes_fc5_116_0_split_2
I0508 00:47:18.618214 17805 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0508 00:47:18.618238 17805 net.cpp:408] accuracy_5 -> accuracy_5
I0508 00:47:18.618248 17805 net.cpp:150] Setting up accuracy_5
I0508 00:47:18.618255 17805 net.cpp:157] Top shape: (1)
I0508 00:47:18.618258 17805 net.cpp:165] Memory required for data: 4109090828
I0508 00:47:18.618263 17805 layer_factory.hpp:77] Creating layer silence
I0508 00:47:18.618271 17805 net.cpp:100] Creating Layer silence
I0508 00:47:18.618275 17805 net.cpp:434] silence <- accuracy_1
I0508 00:47:18.618281 17805 net.cpp:434] silence <- accuracy_5
I0508 00:47:18.618288 17805 net.cpp:150] Setting up silence
I0508 00:47:18.618291 17805 net.cpp:165] Memory required for data: 4109090828
I0508 00:47:18.618296 17805 net.cpp:228] silence does not need backward computation.
I0508 00:47:18.618307 17805 net.cpp:228] accuracy_5 does not need backward computation.
I0508 00:47:18.618312 17805 net.cpp:228] accuracy_1 does not need backward computation.
I0508 00:47:18.618319 17805 net.cpp:226] loss needs backward computation.
I0508 00:47:18.618330 17805 net.cpp:226] softmax needs backward computation.
I0508 00:47:18.618347 17805 net.cpp:226] fc5_classes_fc5_116_0_split needs backward computation.
I0508 00:47:18.618352 17805 net.cpp:226] fc5_116 needs backward computation.
I0508 00:47:18.618357 17805 net.cpp:226] fc4_postscale needs backward computation.
I0508 00:47:18.618362 17805 net.cpp:226] fc4_sTanH needs backward computation.
I0508 00:47:18.618367 17805 net.cpp:226] fc4_prescale needs backward computation.
I0508 00:47:18.618371 17805 net.cpp:226] fc4_300 needs backward computation.
I0508 00:47:18.618376 17805 net.cpp:226] pool3 needs backward computation.
I0508 00:47:18.618381 17805 net.cpp:226] conv3_postscale needs backward computation.
I0508 00:47:18.618386 17805 net.cpp:226] conv3_sTanH needs backward computation.
I0508 00:47:18.618391 17805 net.cpp:226] conv3_prescale needs backward computation.
I0508 00:47:18.618396 17805 net.cpp:226] conv3 needs backward computation.
I0508 00:47:18.618401 17805 net.cpp:226] pool2 needs backward computation.
I0508 00:47:18.618405 17805 net.cpp:226] conv2_postscale needs backward computation.
I0508 00:47:18.618410 17805 net.cpp:226] conv2_sTanH needs backward computation.
I0508 00:47:18.618415 17805 net.cpp:226] conv2_prescale needs backward computation.
I0508 00:47:18.618420 17805 net.cpp:226] conv2 needs backward computation.
I0508 00:47:18.618425 17805 net.cpp:226] pool1 needs backward computation.
I0508 00:47:18.618430 17805 net.cpp:226] conv1_postscale needs backward computation.
I0508 00:47:18.618435 17805 net.cpp:226] conv1_sTanH needs backward computation.
I0508 00:47:18.618440 17805 net.cpp:226] conv1_prescale needs backward computation.
I0508 00:47:18.618445 17805 net.cpp:226] conv1 needs backward computation.
I0508 00:47:18.618450 17805 net.cpp:228] label_data_1_split does not need backward computation.
I0508 00:47:18.618456 17805 net.cpp:228] data does not need backward computation.
I0508 00:47:18.618461 17805 net.cpp:270] This network produces output loss
I0508 00:47:18.618487 17805 net.cpp:283] Network initialization done.
I0508 00:47:18.618768 17805 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_15/RTSD/orig/trial_1/test.prototxt
I0508 00:47:18.618952 17805 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: false
    crop_size: 48
    mean_value: 121
    mean_value: 117
    mean_value: 120
  }
  data_param {
    source: "../local_data/lmdb/RTSD/orig/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "fc5_116"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 116
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "softmax"
  type: "Softmax"
  bottom: "fc5_classes"
  top: "softmax"
}
layer {
  name: "loss"
  type: "MultinomialLogisticLoss"
  bottom: "softmax"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  accuracy_param {
    top_k: 5
  }
}
I0508 00:47:18.619104 17805 layer_factory.hpp:77] Creating layer data
I0508 00:47:18.619843 17805 net.cpp:100] Creating Layer data
I0508 00:47:18.619858 17805 net.cpp:408] data -> data
I0508 00:47:18.619873 17805 net.cpp:408] data -> label
I0508 00:47:18.622536 17970 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/RTSD/orig/test/lmdb
I0508 00:47:18.622684 17805 data_layer.cpp:41] output data size: 1024,3,48,48
I0508 00:47:18.675855 17805 net.cpp:150] Setting up data
I0508 00:47:18.675900 17805 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0508 00:47:18.675907 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.675912 17805 net.cpp:165] Memory required for data: 28315648
I0508 00:47:18.675922 17805 layer_factory.hpp:77] Creating layer label_data_1_split
I0508 00:47:18.675938 17805 net.cpp:100] Creating Layer label_data_1_split
I0508 00:47:18.675945 17805 net.cpp:434] label_data_1_split <- label
I0508 00:47:18.675956 17805 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0508 00:47:18.675973 17805 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0508 00:47:18.675982 17805 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0508 00:47:18.676084 17805 net.cpp:150] Setting up label_data_1_split
I0508 00:47:18.676095 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.676100 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.676105 17805 net.cpp:157] Top shape: 1024 (1024)
I0508 00:47:18.676110 17805 net.cpp:165] Memory required for data: 28327936
I0508 00:47:18.676134 17805 layer_factory.hpp:77] Creating layer conv1
I0508 00:47:18.676156 17805 net.cpp:100] Creating Layer conv1
I0508 00:47:18.676162 17805 net.cpp:434] conv1 <- data
I0508 00:47:18.676170 17805 net.cpp:408] conv1 -> conv1
I0508 00:47:18.678359 17805 net.cpp:150] Setting up conv1
I0508 00:47:18.678378 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.678385 17805 net.cpp:165] Memory required for data: 750862336
I0508 00:47:18.678401 17805 layer_factory.hpp:77] Creating layer conv1_prescale
I0508 00:47:18.678413 17805 net.cpp:100] Creating Layer conv1_prescale
I0508 00:47:18.678419 17805 net.cpp:434] conv1_prescale <- conv1
I0508 00:47:18.678429 17805 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0508 00:47:18.678546 17805 net.cpp:150] Setting up conv1_prescale
I0508 00:47:18.678555 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.678560 17805 net.cpp:165] Memory required for data: 1473396736
I0508 00:47:18.678570 17805 layer_factory.hpp:77] Creating layer conv1_sTanH
I0508 00:47:18.678583 17805 net.cpp:100] Creating Layer conv1_sTanH
I0508 00:47:18.678589 17805 net.cpp:434] conv1_sTanH <- conv1
I0508 00:47:18.678596 17805 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0508 00:47:18.678844 17805 net.cpp:150] Setting up conv1_sTanH
I0508 00:47:18.678858 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.678863 17805 net.cpp:165] Memory required for data: 2195931136
I0508 00:47:18.678869 17805 layer_factory.hpp:77] Creating layer conv1_postscale
I0508 00:47:18.678880 17805 net.cpp:100] Creating Layer conv1_postscale
I0508 00:47:18.678889 17805 net.cpp:434] conv1_postscale <- conv1
I0508 00:47:18.678899 17805 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0508 00:47:18.681154 17805 net.cpp:150] Setting up conv1_postscale
I0508 00:47:18.681167 17805 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0508 00:47:18.681170 17805 net.cpp:165] Memory required for data: 2918465536
I0508 00:47:18.681176 17805 layer_factory.hpp:77] Creating layer pool1
I0508 00:47:18.681186 17805 net.cpp:100] Creating Layer pool1
I0508 00:47:18.681193 17805 net.cpp:434] pool1 <- conv1
I0508 00:47:18.681200 17805 net.cpp:408] pool1 -> pool1
I0508 00:47:18.681243 17805 net.cpp:150] Setting up pool1
I0508 00:47:18.681254 17805 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0508 00:47:18.681260 17805 net.cpp:165] Memory required for data: 3099099136
I0508 00:47:18.681263 17805 layer_factory.hpp:77] Creating layer conv2
I0508 00:47:18.681272 17805 net.cpp:100] Creating Layer conv2
I0508 00:47:18.681275 17805 net.cpp:434] conv2 <- pool1
I0508 00:47:18.681282 17805 net.cpp:408] conv2 -> conv2
I0508 00:47:18.694540 17805 net.cpp:150] Setting up conv2
I0508 00:47:18.694568 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.694572 17805 net.cpp:165] Memory required for data: 3298164736
I0508 00:47:18.694586 17805 layer_factory.hpp:77] Creating layer conv2_prescale
I0508 00:47:18.694604 17805 net.cpp:100] Creating Layer conv2_prescale
I0508 00:47:18.694612 17805 net.cpp:434] conv2_prescale <- conv2
I0508 00:47:18.694617 17805 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0508 00:47:18.694737 17805 net.cpp:150] Setting up conv2_prescale
I0508 00:47:18.694751 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.694756 17805 net.cpp:165] Memory required for data: 3497230336
I0508 00:47:18.694761 17805 layer_factory.hpp:77] Creating layer conv2_sTanH
I0508 00:47:18.694766 17805 net.cpp:100] Creating Layer conv2_sTanH
I0508 00:47:18.694769 17805 net.cpp:434] conv2_sTanH <- conv2
I0508 00:47:18.694782 17805 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0508 00:47:18.694984 17805 net.cpp:150] Setting up conv2_sTanH
I0508 00:47:18.694998 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.695000 17805 net.cpp:165] Memory required for data: 3696295936
I0508 00:47:18.695003 17805 layer_factory.hpp:77] Creating layer conv2_postscale
I0508 00:47:18.695014 17805 net.cpp:100] Creating Layer conv2_postscale
I0508 00:47:18.695037 17805 net.cpp:434] conv2_postscale <- conv2
I0508 00:47:18.695046 17805 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0508 00:47:18.695157 17805 net.cpp:150] Setting up conv2_postscale
I0508 00:47:18.695165 17805 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0508 00:47:18.695168 17805 net.cpp:165] Memory required for data: 3895361536
I0508 00:47:18.695173 17805 layer_factory.hpp:77] Creating layer pool2
I0508 00:47:18.695180 17805 net.cpp:100] Creating Layer pool2
I0508 00:47:18.695185 17805 net.cpp:434] pool2 <- conv2
I0508 00:47:18.695194 17805 net.cpp:408] pool2 -> pool2
I0508 00:47:18.695240 17805 net.cpp:150] Setting up pool2
I0508 00:47:18.695248 17805 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0508 00:47:18.695251 17805 net.cpp:165] Memory required for data: 3945127936
I0508 00:47:18.695255 17805 layer_factory.hpp:77] Creating layer conv3
I0508 00:47:18.695267 17805 net.cpp:100] Creating Layer conv3
I0508 00:47:18.695276 17805 net.cpp:434] conv3 <- pool2
I0508 00:47:18.695281 17805 net.cpp:408] conv3 -> conv3
I0508 00:47:18.700726 17805 net.cpp:150] Setting up conv3
I0508 00:47:18.700749 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.700754 17805 net.cpp:165] Memory required for data: 3981991936
I0508 00:47:18.700767 17805 layer_factory.hpp:77] Creating layer conv3_prescale
I0508 00:47:18.700778 17805 net.cpp:100] Creating Layer conv3_prescale
I0508 00:47:18.700783 17805 net.cpp:434] conv3_prescale <- conv3
I0508 00:47:18.700790 17805 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0508 00:47:18.700901 17805 net.cpp:150] Setting up conv3_prescale
I0508 00:47:18.700909 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.700918 17805 net.cpp:165] Memory required for data: 4018855936
I0508 00:47:18.700923 17805 layer_factory.hpp:77] Creating layer conv3_sTanH
I0508 00:47:18.700929 17805 net.cpp:100] Creating Layer conv3_sTanH
I0508 00:47:18.700933 17805 net.cpp:434] conv3_sTanH <- conv3
I0508 00:47:18.700939 17805 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0508 00:47:18.701138 17805 net.cpp:150] Setting up conv3_sTanH
I0508 00:47:18.701153 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.701156 17805 net.cpp:165] Memory required for data: 4055719936
I0508 00:47:18.701160 17805 layer_factory.hpp:77] Creating layer conv3_postscale
I0508 00:47:18.701169 17805 net.cpp:100] Creating Layer conv3_postscale
I0508 00:47:18.701172 17805 net.cpp:434] conv3_postscale <- conv3
I0508 00:47:18.701179 17805 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0508 00:47:18.701283 17805 net.cpp:150] Setting up conv3_postscale
I0508 00:47:18.701292 17805 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0508 00:47:18.701297 17805 net.cpp:165] Memory required for data: 4092583936
I0508 00:47:18.701302 17805 layer_factory.hpp:77] Creating layer pool3
I0508 00:47:18.701315 17805 net.cpp:100] Creating Layer pool3
I0508 00:47:18.701320 17805 net.cpp:434] pool3 <- conv3
I0508 00:47:18.701326 17805 net.cpp:408] pool3 -> pool3
I0508 00:47:18.701373 17805 net.cpp:150] Setting up pool3
I0508 00:47:18.701381 17805 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0508 00:47:18.701385 17805 net.cpp:165] Memory required for data: 4101799936
I0508 00:47:18.701387 17805 layer_factory.hpp:77] Creating layer fc4_300
I0508 00:47:18.701396 17805 net.cpp:100] Creating Layer fc4_300
I0508 00:47:18.701401 17805 net.cpp:434] fc4_300 <- pool3
I0508 00:47:18.701406 17805 net.cpp:408] fc4_300 -> fc4_300
I0508 00:47:18.706971 17805 net.cpp:150] Setting up fc4_300
I0508 00:47:18.706991 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.706995 17805 net.cpp:165] Memory required for data: 4103028736
I0508 00:47:18.707002 17805 layer_factory.hpp:77] Creating layer fc4_prescale
I0508 00:47:18.707015 17805 net.cpp:100] Creating Layer fc4_prescale
I0508 00:47:18.707020 17805 net.cpp:434] fc4_prescale <- fc4_300
I0508 00:47:18.707028 17805 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0508 00:47:18.707123 17805 net.cpp:150] Setting up fc4_prescale
I0508 00:47:18.707132 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.707154 17805 net.cpp:165] Memory required for data: 4104257536
I0508 00:47:18.707159 17805 layer_factory.hpp:77] Creating layer fc4_sTanH
I0508 00:47:18.707167 17805 net.cpp:100] Creating Layer fc4_sTanH
I0508 00:47:18.707170 17805 net.cpp:434] fc4_sTanH <- fc4_300
I0508 00:47:18.707175 17805 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0508 00:47:18.709693 17805 net.cpp:150] Setting up fc4_sTanH
I0508 00:47:18.709710 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.709713 17805 net.cpp:165] Memory required for data: 4105486336
I0508 00:47:18.709717 17805 layer_factory.hpp:77] Creating layer fc4_postscale
I0508 00:47:18.709724 17805 net.cpp:100] Creating Layer fc4_postscale
I0508 00:47:18.709730 17805 net.cpp:434] fc4_postscale <- fc4_300
I0508 00:47:18.709739 17805 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0508 00:47:18.709851 17805 net.cpp:150] Setting up fc4_postscale
I0508 00:47:18.709861 17805 net.cpp:157] Top shape: 1024 300 (307200)
I0508 00:47:18.709862 17805 net.cpp:165] Memory required for data: 4106715136
I0508 00:47:18.709868 17805 layer_factory.hpp:77] Creating layer fc5_116
I0508 00:47:18.709875 17805 net.cpp:100] Creating Layer fc5_116
I0508 00:47:18.709880 17805 net.cpp:434] fc5_116 <- fc4_300
I0508 00:47:18.709887 17805 net.cpp:408] fc5_116 -> fc5_classes
I0508 00:47:18.710238 17805 net.cpp:150] Setting up fc5_116
I0508 00:47:18.710248 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.710252 17805 net.cpp:165] Memory required for data: 4107190272
I0508 00:47:18.710263 17805 layer_factory.hpp:77] Creating layer fc5_classes_fc5_116_0_split
I0508 00:47:18.710271 17805 net.cpp:100] Creating Layer fc5_classes_fc5_116_0_split
I0508 00:47:18.710278 17805 net.cpp:434] fc5_classes_fc5_116_0_split <- fc5_classes
I0508 00:47:18.710283 17805 net.cpp:408] fc5_classes_fc5_116_0_split -> fc5_classes_fc5_116_0_split_0
I0508 00:47:18.710290 17805 net.cpp:408] fc5_classes_fc5_116_0_split -> fc5_classes_fc5_116_0_split_1
I0508 00:47:18.710299 17805 net.cpp:408] fc5_classes_fc5_116_0_split -> fc5_classes_fc5_116_0_split_2
I0508 00:47:18.710351 17805 net.cpp:150] Setting up fc5_classes_fc5_116_0_split
I0508 00:47:18.710360 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.710363 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.710367 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.710369 17805 net.cpp:165] Memory required for data: 4108615680
I0508 00:47:18.710372 17805 layer_factory.hpp:77] Creating layer softmax
I0508 00:47:18.710381 17805 net.cpp:100] Creating Layer softmax
I0508 00:47:18.710386 17805 net.cpp:434] softmax <- fc5_classes_fc5_116_0_split_0
I0508 00:47:18.710391 17805 net.cpp:408] softmax -> softmax
I0508 00:47:18.710646 17805 net.cpp:150] Setting up softmax
I0508 00:47:18.710661 17805 net.cpp:157] Top shape: 1024 116 (118784)
I0508 00:47:18.710666 17805 net.cpp:165] Memory required for data: 4109090816
I0508 00:47:18.710670 17805 layer_factory.hpp:77] Creating layer loss
I0508 00:47:18.710677 17805 net.cpp:100] Creating Layer loss
I0508 00:47:18.710682 17805 net.cpp:434] loss <- softmax
I0508 00:47:18.710687 17805 net.cpp:434] loss <- label_data_1_split_0
I0508 00:47:18.710692 17805 net.cpp:408] loss -> loss
I0508 00:47:18.710722 17805 net.cpp:150] Setting up loss
I0508 00:47:18.710729 17805 net.cpp:157] Top shape: (1)
I0508 00:47:18.710732 17805 net.cpp:160]     with loss weight 1
I0508 00:47:18.710746 17805 net.cpp:165] Memory required for data: 4109090820
I0508 00:47:18.710748 17805 layer_factory.hpp:77] Creating layer accuracy_1
I0508 00:47:18.710757 17805 net.cpp:100] Creating Layer accuracy_1
I0508 00:47:18.710762 17805 net.cpp:434] accuracy_1 <- fc5_classes_fc5_116_0_split_1
I0508 00:47:18.710767 17805 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0508 00:47:18.710772 17805 net.cpp:408] accuracy_1 -> accuracy_1
I0508 00:47:18.710780 17805 net.cpp:150] Setting up accuracy_1
I0508 00:47:18.710785 17805 net.cpp:157] Top shape: (1)
I0508 00:47:18.710788 17805 net.cpp:165] Memory required for data: 4109090824
I0508 00:47:18.710805 17805 layer_factory.hpp:77] Creating layer accuracy_5
I0508 00:47:18.710811 17805 net.cpp:100] Creating Layer accuracy_5
I0508 00:47:18.710814 17805 net.cpp:434] accuracy_5 <- fc5_classes_fc5_116_0_split_2
I0508 00:47:18.710819 17805 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0508 00:47:18.710825 17805 net.cpp:408] accuracy_5 -> accuracy_5
I0508 00:47:18.710832 17805 net.cpp:150] Setting up accuracy_5
I0508 00:47:18.710839 17805 net.cpp:157] Top shape: (1)
I0508 00:47:18.710841 17805 net.cpp:165] Memory required for data: 4109090828
I0508 00:47:18.710844 17805 net.cpp:228] accuracy_5 does not need backward computation.
I0508 00:47:18.710849 17805 net.cpp:228] accuracy_1 does not need backward computation.
I0508 00:47:18.710852 17805 net.cpp:226] loss needs backward computation.
I0508 00:47:18.710856 17805 net.cpp:226] softmax needs backward computation.
I0508 00:47:18.710860 17805 net.cpp:226] fc5_classes_fc5_116_0_split needs backward computation.
I0508 00:47:18.710863 17805 net.cpp:226] fc5_116 needs backward computation.
I0508 00:47:18.710866 17805 net.cpp:226] fc4_postscale needs backward computation.
I0508 00:47:18.710870 17805 net.cpp:226] fc4_sTanH needs backward computation.
I0508 00:47:18.710872 17805 net.cpp:226] fc4_prescale needs backward computation.
I0508 00:47:18.710875 17805 net.cpp:226] fc4_300 needs backward computation.
I0508 00:47:18.710878 17805 net.cpp:226] pool3 needs backward computation.
I0508 00:47:18.710881 17805 net.cpp:226] conv3_postscale needs backward computation.
I0508 00:47:18.710885 17805 net.cpp:226] conv3_sTanH needs backward computation.
I0508 00:47:18.710887 17805 net.cpp:226] conv3_prescale needs backward computation.
I0508 00:47:18.710891 17805 net.cpp:226] conv3 needs backward computation.
I0508 00:47:18.710894 17805 net.cpp:226] pool2 needs backward computation.
I0508 00:47:18.710897 17805 net.cpp:226] conv2_postscale needs backward computation.
I0508 00:47:18.710901 17805 net.cpp:226] conv2_sTanH needs backward computation.
I0508 00:47:18.710903 17805 net.cpp:226] conv2_prescale needs backward computation.
I0508 00:47:18.710906 17805 net.cpp:226] conv2 needs backward computation.
I0508 00:47:18.710909 17805 net.cpp:226] pool1 needs backward computation.
I0508 00:47:18.710912 17805 net.cpp:226] conv1_postscale needs backward computation.
I0508 00:47:18.710917 17805 net.cpp:226] conv1_sTanH needs backward computation.
I0508 00:47:18.710921 17805 net.cpp:226] conv1_prescale needs backward computation.
I0508 00:47:18.710923 17805 net.cpp:226] conv1 needs backward computation.
I0508 00:47:18.710927 17805 net.cpp:228] label_data_1_split does not need backward computation.
I0508 00:47:18.710932 17805 net.cpp:228] data does not need backward computation.
I0508 00:47:18.710934 17805 net.cpp:270] This network produces output accuracy_1
I0508 00:47:18.710937 17805 net.cpp:270] This network produces output accuracy_5
I0508 00:47:18.710942 17805 net.cpp:270] This network produces output loss
I0508 00:47:18.710961 17805 net.cpp:283] Network initialization done.
I0508 00:47:18.711041 17805 solver.cpp:72] Solver scaffolding done.
I0508 00:47:18.711985 17805 caffe.cpp:251] Starting Optimization
I0508 00:47:18.711995 17805 solver.cpp:291] Solving 
I0508 00:47:18.711998 17805 solver.cpp:292] Learning Rate Policy: step
I0508 00:47:18.718144 17805 solver.cpp:349] Iteration 0, Testing net (#0)
I0508 00:47:18.719620 17805 net.cpp:693] Ignoring source layer silence
I0508 00:47:20.810637 17805 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00907629
I0508 00:47:20.810672 17805 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0471622
I0508 00:47:20.810681 17805 solver.cpp:416]     Test net output #2: loss = 4.79076 (* 1 = 4.79076 loss)
I0508 00:47:20.952802 17805 solver.cpp:240] Iteration 0, loss = 4.82803
I0508 00:47:20.952841 17805 solver.cpp:256]     Train net output #0: loss = 4.82803 (* 1 = 4.82803 loss)
I0508 00:47:20.952853 17805 sgd_solver.cpp:106] Iteration 0, lr = 0.0001
I0508 00:47:21.272505 17805 solver.cpp:240] Iteration 1, loss = 4.5455
I0508 00:47:21.272568 17805 solver.cpp:256]     Train net output #0: loss = 4.5455 (* 1 = 4.5455 loss)
I0508 00:47:21.272578 17805 sgd_solver.cpp:106] Iteration 1, lr = 0.0001
I0508 00:47:21.591025 17805 solver.cpp:240] Iteration 2, loss = 4.28803
I0508 00:47:21.591059 17805 solver.cpp:256]     Train net output #0: loss = 4.28803 (* 1 = 4.28803 loss)
I0508 00:47:21.591066 17805 sgd_solver.cpp:106] Iteration 2, lr = 0.0001
I0508 00:47:21.909456 17805 solver.cpp:240] Iteration 3, loss = 4.07368
I0508 00:47:21.909498 17805 solver.cpp:256]     Train net output #0: loss = 4.07368 (* 1 = 4.07368 loss)
I0508 00:47:21.909507 17805 sgd_solver.cpp:106] Iteration 3, lr = 0.0001
I0508 00:47:22.227892 17805 solver.cpp:240] Iteration 4, loss = 3.71418
I0508 00:47:22.227926 17805 solver.cpp:256]     Train net output #0: loss = 3.71418 (* 1 = 3.71418 loss)
I0508 00:47:22.227934 17805 sgd_solver.cpp:106] Iteration 4, lr = 0.0001
I0508 00:47:22.546113 17805 solver.cpp:240] Iteration 5, loss = 3.5101
I0508 00:47:22.546145 17805 solver.cpp:256]     Train net output #0: loss = 3.5101 (* 1 = 3.5101 loss)
I0508 00:47:22.546154 17805 sgd_solver.cpp:106] Iteration 5, lr = 0.0001
I0508 00:47:22.860088 17805 solver.cpp:240] Iteration 6, loss = 3.42841
I0508 00:47:22.860124 17805 solver.cpp:256]     Train net output #0: loss = 3.42841 (* 1 = 3.42841 loss)
I0508 00:47:22.860132 17805 sgd_solver.cpp:106] Iteration 6, lr = 0.0001
I0508 00:47:23.178452 17805 solver.cpp:240] Iteration 7, loss = 3.34699
I0508 00:47:23.178486 17805 solver.cpp:256]     Train net output #0: loss = 3.34699 (* 1 = 3.34699 loss)
I0508 00:47:23.178495 17805 sgd_solver.cpp:106] Iteration 7, lr = 0.0001
I0508 00:47:23.496726 17805 solver.cpp:240] Iteration 8, loss = 3.39394
I0508 00:47:23.496762 17805 solver.cpp:256]     Train net output #0: loss = 3.39394 (* 1 = 3.39394 loss)
I0508 00:47:23.496769 17805 sgd_solver.cpp:106] Iteration 8, lr = 0.0001
I0508 00:47:23.815134 17805 solver.cpp:240] Iteration 9, loss = 3.29183
I0508 00:47:23.815167 17805 solver.cpp:256]     Train net output #0: loss = 3.29183 (* 1 = 3.29183 loss)
I0508 00:47:23.815176 17805 sgd_solver.cpp:106] Iteration 9, lr = 0.0001
I0508 00:47:24.133059 17805 solver.cpp:240] Iteration 10, loss = 3.17512
I0508 00:47:24.133100 17805 solver.cpp:256]     Train net output #0: loss = 3.17512 (* 1 = 3.17512 loss)
I0508 00:47:24.133108 17805 sgd_solver.cpp:106] Iteration 10, lr = 0.0001
I0508 00:47:24.451495 17805 solver.cpp:240] Iteration 11, loss = 3.18544
I0508 00:47:24.451539 17805 solver.cpp:256]     Train net output #0: loss = 3.18544 (* 1 = 3.18544 loss)
I0508 00:47:24.451546 17805 sgd_solver.cpp:106] Iteration 11, lr = 0.0001
I0508 00:47:24.769419 17805 solver.cpp:240] Iteration 12, loss = 3.05493
I0508 00:47:24.769460 17805 solver.cpp:256]     Train net output #0: loss = 3.05493 (* 1 = 3.05493 loss)
I0508 00:47:24.769469 17805 sgd_solver.cpp:106] Iteration 12, lr = 0.0001
I0508 00:47:25.088013 17805 solver.cpp:240] Iteration 13, loss = 3.14785
I0508 00:47:25.088058 17805 solver.cpp:256]     Train net output #0: loss = 3.14785 (* 1 = 3.14785 loss)
I0508 00:47:25.088068 17805 sgd_solver.cpp:106] Iteration 13, lr = 0.0001
I0508 00:47:25.406584 17805 solver.cpp:240] Iteration 14, loss = 2.86896
I0508 00:47:25.406618 17805 solver.cpp:256]     Train net output #0: loss = 2.86896 (* 1 = 2.86896 loss)
I0508 00:47:25.406626 17805 sgd_solver.cpp:106] Iteration 14, lr = 0.0001
I0508 00:47:25.725119 17805 solver.cpp:240] Iteration 15, loss = 2.96155
I0508 00:47:25.725158 17805 solver.cpp:256]     Train net output #0: loss = 2.96155 (* 1 = 2.96155 loss)
I0508 00:47:25.725165 17805 sgd_solver.cpp:106] Iteration 15, lr = 0.0001
I0508 00:47:26.043557 17805 solver.cpp:240] Iteration 16, loss = 2.86629
I0508 00:47:26.043591 17805 solver.cpp:256]     Train net output #0: loss = 2.86629 (* 1 = 2.86629 loss)
I0508 00:47:26.043599 17805 sgd_solver.cpp:106] Iteration 16, lr = 0.0001
I0508 00:47:26.361858 17805 solver.cpp:240] Iteration 17, loss = 2.79813
I0508 00:47:26.361901 17805 solver.cpp:256]     Train net output #0: loss = 2.79813 (* 1 = 2.79813 loss)
I0508 00:47:26.361934 17805 sgd_solver.cpp:106] Iteration 17, lr = 0.0001
I0508 00:47:26.680392 17805 solver.cpp:240] Iteration 18, loss = 2.8466
I0508 00:47:26.680428 17805 solver.cpp:256]     Train net output #0: loss = 2.8466 (* 1 = 2.8466 loss)
I0508 00:47:26.680436 17805 sgd_solver.cpp:106] Iteration 18, lr = 0.0001
I0508 00:47:26.998805 17805 solver.cpp:240] Iteration 19, loss = 2.65223
I0508 00:47:26.998839 17805 solver.cpp:256]     Train net output #0: loss = 2.65223 (* 1 = 2.65223 loss)
I0508 00:47:26.998847 17805 sgd_solver.cpp:106] Iteration 19, lr = 0.0001
I0508 00:47:27.317318 17805 solver.cpp:240] Iteration 20, loss = 2.72274
I0508 00:47:27.317354 17805 solver.cpp:256]     Train net output #0: loss = 2.72274 (* 1 = 2.72274 loss)
I0508 00:47:27.317363 17805 sgd_solver.cpp:106] Iteration 20, lr = 0.0001
I0508 00:47:27.635730 17805 solver.cpp:240] Iteration 21, loss = 2.49034
I0508 00:47:27.635766 17805 solver.cpp:256]     Train net output #0: loss = 2.49034 (* 1 = 2.49034 loss)
I0508 00:47:27.635774 17805 sgd_solver.cpp:106] Iteration 21, lr = 0.0001
I0508 00:47:27.954391 17805 solver.cpp:240] Iteration 22, loss = 2.60248
I0508 00:47:27.954426 17805 solver.cpp:256]     Train net output #0: loss = 2.60248 (* 1 = 2.60248 loss)
I0508 00:47:27.954432 17805 sgd_solver.cpp:106] Iteration 22, lr = 0.0001
I0508 00:47:28.273387 17805 solver.cpp:240] Iteration 23, loss = 2.60493
I0508 00:47:28.273424 17805 solver.cpp:256]     Train net output #0: loss = 2.60493 (* 1 = 2.60493 loss)
I0508 00:47:28.273433 17805 sgd_solver.cpp:106] Iteration 23, lr = 0.0001
I0508 00:47:28.591893 17805 solver.cpp:240] Iteration 24, loss = 2.6022
I0508 00:47:28.591929 17805 solver.cpp:256]     Train net output #0: loss = 2.6022 (* 1 = 2.6022 loss)
I0508 00:47:28.591938 17805 sgd_solver.cpp:106] Iteration 24, lr = 0.0001
I0508 00:47:28.910838 17805 solver.cpp:240] Iteration 25, loss = 2.50184
I0508 00:47:28.910874 17805 solver.cpp:256]     Train net output #0: loss = 2.50184 (* 1 = 2.50184 loss)
I0508 00:47:28.910882 17805 sgd_solver.cpp:106] Iteration 25, lr = 0.0001
I0508 00:47:29.229598 17805 solver.cpp:240] Iteration 26, loss = 2.48619
I0508 00:47:29.229632 17805 solver.cpp:256]     Train net output #0: loss = 2.48619 (* 1 = 2.48619 loss)
I0508 00:47:29.229640 17805 sgd_solver.cpp:106] Iteration 26, lr = 0.0001
I0508 00:47:29.548434 17805 solver.cpp:240] Iteration 27, loss = 2.34859
I0508 00:47:29.548467 17805 solver.cpp:256]     Train net output #0: loss = 2.34859 (* 1 = 2.34859 loss)
I0508 00:47:29.548475 17805 sgd_solver.cpp:106] Iteration 27, lr = 0.0001
I0508 00:47:29.867229 17805 solver.cpp:240] Iteration 28, loss = 2.34642
I0508 00:47:29.867264 17805 solver.cpp:256]     Train net output #0: loss = 2.34642 (* 1 = 2.34642 loss)
I0508 00:47:29.867271 17805 sgd_solver.cpp:106] Iteration 28, lr = 0.0001
I0508 00:47:30.186024 17805 solver.cpp:240] Iteration 29, loss = 2.14288
I0508 00:47:30.186063 17805 solver.cpp:256]     Train net output #0: loss = 2.14288 (* 1 = 2.14288 loss)
I0508 00:47:30.186070 17805 sgd_solver.cpp:106] Iteration 29, lr = 0.0001
I0508 00:47:30.504791 17805 solver.cpp:240] Iteration 30, loss = 2.2194
I0508 00:47:30.504827 17805 solver.cpp:256]     Train net output #0: loss = 2.2194 (* 1 = 2.2194 loss)
I0508 00:47:30.504835 17805 sgd_solver.cpp:106] Iteration 30, lr = 0.0001
I0508 00:47:30.822895 17805 solver.cpp:240] Iteration 31, loss = 2.21347
I0508 00:47:30.822929 17805 solver.cpp:256]     Train net output #0: loss = 2.21347 (* 1 = 2.21347 loss)
I0508 00:47:30.822937 17805 sgd_solver.cpp:106] Iteration 31, lr = 0.0001
I0508 00:47:31.141460 17805 solver.cpp:240] Iteration 32, loss = 2.33737
I0508 00:47:31.141499 17805 solver.cpp:256]     Train net output #0: loss = 2.33737 (* 1 = 2.33737 loss)
I0508 00:47:31.141506 17805 sgd_solver.cpp:106] Iteration 32, lr = 0.0001
I0508 00:47:31.460283 17805 solver.cpp:240] Iteration 33, loss = 2.18516
I0508 00:47:31.460316 17805 solver.cpp:256]     Train net output #0: loss = 2.18516 (* 1 = 2.18516 loss)
I0508 00:47:31.460324 17805 sgd_solver.cpp:106] Iteration 33, lr = 0.0001
I0508 00:47:31.779332 17805 solver.cpp:240] Iteration 34, loss = 2.25403
I0508 00:47:31.779367 17805 solver.cpp:256]     Train net output #0: loss = 2.25403 (* 1 = 2.25403 loss)
I0508 00:47:31.779376 17805 sgd_solver.cpp:106] Iteration 34, lr = 0.0001
I0508 00:47:32.097784 17805 solver.cpp:240] Iteration 35, loss = 2.2042
I0508 00:47:32.097817 17805 solver.cpp:256]     Train net output #0: loss = 2.2042 (* 1 = 2.2042 loss)
I0508 00:47:32.097826 17805 sgd_solver.cpp:106] Iteration 35, lr = 0.0001
I0508 00:47:32.417834 17805 solver.cpp:240] Iteration 36, loss = 2.24344
I0508 00:47:32.417879 17805 solver.cpp:256]     Train net output #0: loss = 2.24344 (* 1 = 2.24344 loss)
I0508 00:47:32.417888 17805 sgd_solver.cpp:106] Iteration 36, lr = 0.0001
I0508 00:47:32.736017 17805 solver.cpp:240] Iteration 37, loss = 2.15115
I0508 00:47:32.736052 17805 solver.cpp:256]     Train net output #0: loss = 2.15115 (* 1 = 2.15115 loss)
I0508 00:47:32.736062 17805 sgd_solver.cpp:106] Iteration 37, lr = 0.0001
I0508 00:47:33.054690 17805 solver.cpp:240] Iteration 38, loss = 2.11364
I0508 00:47:33.054728 17805 solver.cpp:256]     Train net output #0: loss = 2.11364 (* 1 = 2.11364 loss)
I0508 00:47:33.054736 17805 sgd_solver.cpp:106] Iteration 38, lr = 0.0001
I0508 00:47:33.373432 17805 solver.cpp:240] Iteration 39, loss = 2.06624
I0508 00:47:33.373467 17805 solver.cpp:256]     Train net output #0: loss = 2.06624 (* 1 = 2.06624 loss)
I0508 00:47:33.373476 17805 sgd_solver.cpp:106] Iteration 39, lr = 0.0001
I0508 00:47:33.692104 17805 solver.cpp:240] Iteration 40, loss = 2.02911
I0508 00:47:33.692143 17805 solver.cpp:256]     Train net output #0: loss = 2.02911 (* 1 = 2.02911 loss)
I0508 00:47:33.692152 17805 sgd_solver.cpp:106] Iteration 40, lr = 0.0001
I0508 00:47:34.010686 17805 solver.cpp:240] Iteration 41, loss = 2.04072
I0508 00:47:34.010722 17805 solver.cpp:256]     Train net output #0: loss = 2.04072 (* 1 = 2.04072 loss)
I0508 00:47:34.010730 17805 sgd_solver.cpp:106] Iteration 41, lr = 0.0001
I0508 00:47:34.328840 17805 solver.cpp:240] Iteration 42, loss = 2.12562
I0508 00:47:34.328874 17805 solver.cpp:256]     Train net output #0: loss = 2.12562 (* 1 = 2.12562 loss)
I0508 00:47:34.328882 17805 sgd_solver.cpp:106] Iteration 42, lr = 0.0001
I0508 00:47:34.647259 17805 solver.cpp:240] Iteration 43, loss = 1.95872
I0508 00:47:34.647292 17805 solver.cpp:256]     Train net output #0: loss = 1.95872 (* 1 = 1.95872 loss)
I0508 00:47:34.647300 17805 sgd_solver.cpp:106] Iteration 43, lr = 0.0001
I0508 00:47:34.966298 17805 solver.cpp:240] Iteration 44, loss = 1.95226
I0508 00:47:34.966338 17805 solver.cpp:256]     Train net output #0: loss = 1.95226 (* 1 = 1.95226 loss)
I0508 00:47:34.966346 17805 sgd_solver.cpp:106] Iteration 44, lr = 0.0001
I0508 00:47:35.285284 17805 solver.cpp:240] Iteration 45, loss = 1.96334
I0508 00:47:35.285318 17805 solver.cpp:256]     Train net output #0: loss = 1.96334 (* 1 = 1.96334 loss)
I0508 00:47:35.285326 17805 sgd_solver.cpp:106] Iteration 45, lr = 0.0001
I0508 00:47:35.603778 17805 solver.cpp:240] Iteration 46, loss = 1.89875
I0508 00:47:35.603813 17805 solver.cpp:256]     Train net output #0: loss = 1.89875 (* 1 = 1.89875 loss)
I0508 00:47:35.603821 17805 sgd_solver.cpp:106] Iteration 46, lr = 0.0001
I0508 00:47:35.922194 17805 solver.cpp:240] Iteration 47, loss = 1.83514
I0508 00:47:35.922230 17805 solver.cpp:256]     Train net output #0: loss = 1.83514 (* 1 = 1.83514 loss)
I0508 00:47:35.922238 17805 sgd_solver.cpp:106] Iteration 47, lr = 0.0001
I0508 00:47:36.241045 17805 solver.cpp:240] Iteration 48, loss = 1.91236
I0508 00:47:36.241080 17805 solver.cpp:256]     Train net output #0: loss = 1.91236 (* 1 = 1.91236 loss)
I0508 00:47:36.241088 17805 sgd_solver.cpp:106] Iteration 48, lr = 0.0001
I0508 00:47:36.559451 17805 solver.cpp:240] Iteration 49, loss = 1.79456
I0508 00:47:36.559487 17805 solver.cpp:256]     Train net output #0: loss = 1.79456 (* 1 = 1.79456 loss)
I0508 00:47:36.559494 17805 sgd_solver.cpp:106] Iteration 49, lr = 0.0001
I0508 00:47:36.878108 17805 solver.cpp:240] Iteration 50, loss = 1.94312
I0508 00:47:36.878167 17805 solver.cpp:256]     Train net output #0: loss = 1.94312 (* 1 = 1.94312 loss)
I0508 00:47:36.878176 17805 sgd_solver.cpp:106] Iteration 50, lr = 0.0001
I0508 00:47:37.196684 17805 solver.cpp:240] Iteration 51, loss = 1.77756
I0508 00:47:37.196720 17805 solver.cpp:256]     Train net output #0: loss = 1.77756 (* 1 = 1.77756 loss)
I0508 00:47:37.196727 17805 sgd_solver.cpp:106] Iteration 51, lr = 0.0001
I0508 00:47:37.514154 17805 solver.cpp:240] Iteration 52, loss = 1.78565
I0508 00:47:37.514189 17805 solver.cpp:256]     Train net output #0: loss = 1.78565 (* 1 = 1.78565 loss)
I0508 00:47:37.514197 17805 sgd_solver.cpp:106] Iteration 52, lr = 0.0001
I0508 00:47:37.831017 17805 solver.cpp:240] Iteration 53, loss = 1.80553
I0508 00:47:37.831051 17805 solver.cpp:256]     Train net output #0: loss = 1.80553 (* 1 = 1.80553 loss)
I0508 00:47:37.831058 17805 sgd_solver.cpp:106] Iteration 53, lr = 0.0001
I0508 00:47:38.149755 17805 solver.cpp:240] Iteration 54, loss = 1.78865
I0508 00:47:38.149790 17805 solver.cpp:256]     Train net output #0: loss = 1.78865 (* 1 = 1.78865 loss)
I0508 00:47:38.149796 17805 sgd_solver.cpp:106] Iteration 54, lr = 0.0001
I0508 00:47:38.468694 17805 solver.cpp:240] Iteration 55, loss = 1.8021
I0508 00:47:38.468730 17805 solver.cpp:256]     Train net output #0: loss = 1.8021 (* 1 = 1.8021 loss)
I0508 00:47:38.468739 17805 sgd_solver.cpp:106] Iteration 55, lr = 0.0001
I0508 00:47:38.787241 17805 solver.cpp:240] Iteration 56, loss = 1.87879
I0508 00:47:38.787277 17805 solver.cpp:256]     Train net output #0: loss = 1.87879 (* 1 = 1.87879 loss)
I0508 00:47:38.787286 17805 sgd_solver.cpp:106] Iteration 56, lr = 0.0001
I0508 00:47:39.105877 17805 solver.cpp:240] Iteration 57, loss = 1.78374
I0508 00:47:39.105913 17805 solver.cpp:256]     Train net output #0: loss = 1.78374 (* 1 = 1.78374 loss)
I0508 00:47:39.105921 17805 sgd_solver.cpp:106] Iteration 57, lr = 0.0001
I0508 00:47:39.424234 17805 solver.cpp:240] Iteration 58, loss = 1.76197
I0508 00:47:39.424268 17805 solver.cpp:256]     Train net output #0: loss = 1.76197 (* 1 = 1.76197 loss)
I0508 00:47:39.424276 17805 sgd_solver.cpp:106] Iteration 58, lr = 0.0001
I0508 00:47:39.743027 17805 solver.cpp:240] Iteration 59, loss = 1.73865
I0508 00:47:39.743062 17805 solver.cpp:256]     Train net output #0: loss = 1.73865 (* 1 = 1.73865 loss)
I0508 00:47:39.743070 17805 sgd_solver.cpp:106] Iteration 59, lr = 0.0001
I0508 00:47:40.061944 17805 solver.cpp:240] Iteration 60, loss = 1.69271
I0508 00:47:40.061982 17805 solver.cpp:256]     Train net output #0: loss = 1.69271 (* 1 = 1.69271 loss)
I0508 00:47:40.061990 17805 sgd_solver.cpp:106] Iteration 60, lr = 0.0001
I0508 00:47:40.380743 17805 solver.cpp:240] Iteration 61, loss = 1.73157
I0508 00:47:40.380779 17805 solver.cpp:256]     Train net output #0: loss = 1.73157 (* 1 = 1.73157 loss)
I0508 00:47:40.380786 17805 sgd_solver.cpp:106] Iteration 61, lr = 0.0001
I0508 00:47:40.698734 17805 solver.cpp:240] Iteration 62, loss = 1.73397
I0508 00:47:40.698767 17805 solver.cpp:256]     Train net output #0: loss = 1.73397 (* 1 = 1.73397 loss)
I0508 00:47:40.698776 17805 sgd_solver.cpp:106] Iteration 62, lr = 0.0001
I0508 00:47:41.016301 17805 solver.cpp:240] Iteration 63, loss = 1.69902
I0508 00:47:41.016337 17805 solver.cpp:256]     Train net output #0: loss = 1.69902 (* 1 = 1.69902 loss)
I0508 00:47:41.016345 17805 sgd_solver.cpp:106] Iteration 63, lr = 0.0001
I0508 00:47:41.335090 17805 solver.cpp:240] Iteration 64, loss = 1.72726
I0508 00:47:41.335126 17805 solver.cpp:256]     Train net output #0: loss = 1.72726 (* 1 = 1.72726 loss)
I0508 00:47:41.335134 17805 sgd_solver.cpp:106] Iteration 64, lr = 0.0001
I0508 00:47:41.653952 17805 solver.cpp:240] Iteration 65, loss = 1.69127
I0508 00:47:41.653986 17805 solver.cpp:256]     Train net output #0: loss = 1.69127 (* 1 = 1.69127 loss)
I0508 00:47:41.653995 17805 sgd_solver.cpp:106] Iteration 65, lr = 0.0001
I0508 00:47:41.972635 17805 solver.cpp:240] Iteration 66, loss = 1.57379
I0508 00:47:41.972695 17805 solver.cpp:256]     Train net output #0: loss = 1.57379 (* 1 = 1.57379 loss)
I0508 00:47:41.972704 17805 sgd_solver.cpp:106] Iteration 66, lr = 0.0001
I0508 00:47:42.291415 17805 solver.cpp:240] Iteration 67, loss = 1.67955
I0508 00:47:42.291450 17805 solver.cpp:256]     Train net output #0: loss = 1.67955 (* 1 = 1.67955 loss)
I0508 00:47:42.291457 17805 sgd_solver.cpp:106] Iteration 67, lr = 0.0001
I0508 00:47:42.609674 17805 solver.cpp:240] Iteration 68, loss = 1.53694
I0508 00:47:42.609711 17805 solver.cpp:256]     Train net output #0: loss = 1.53694 (* 1 = 1.53694 loss)
I0508 00:47:42.609719 17805 sgd_solver.cpp:106] Iteration 68, lr = 0.0001
I0508 00:47:42.928434 17805 solver.cpp:240] Iteration 69, loss = 1.67191
I0508 00:47:42.928472 17805 solver.cpp:256]     Train net output #0: loss = 1.67191 (* 1 = 1.67191 loss)
I0508 00:47:42.928479 17805 sgd_solver.cpp:106] Iteration 69, lr = 0.0001
I0508 00:47:43.247380 17805 solver.cpp:240] Iteration 70, loss = 1.67386
I0508 00:47:43.247418 17805 solver.cpp:256]     Train net output #0: loss = 1.67386 (* 1 = 1.67386 loss)
I0508 00:47:43.247426 17805 sgd_solver.cpp:106] Iteration 70, lr = 0.0001
I0508 00:47:43.566112 17805 solver.cpp:240] Iteration 71, loss = 1.54244
I0508 00:47:43.566145 17805 solver.cpp:256]     Train net output #0: loss = 1.54244 (* 1 = 1.54244 loss)
I0508 00:47:43.566154 17805 sgd_solver.cpp:106] Iteration 71, lr = 0.0001
I0508 00:47:43.884632 17805 solver.cpp:240] Iteration 72, loss = 1.61896
I0508 00:47:43.884670 17805 solver.cpp:256]     Train net output #0: loss = 1.61896 (* 1 = 1.61896 loss)
I0508 00:47:43.884676 17805 sgd_solver.cpp:106] Iteration 72, lr = 0.0001
I0508 00:47:44.203032 17805 solver.cpp:240] Iteration 73, loss = 1.56709
I0508 00:47:44.203073 17805 solver.cpp:256]     Train net output #0: loss = 1.56709 (* 1 = 1.56709 loss)
I0508 00:47:44.203080 17805 sgd_solver.cpp:106] Iteration 73, lr = 0.0001
I0508 00:47:44.521466 17805 solver.cpp:240] Iteration 74, loss = 1.55564
I0508 00:47:44.521505 17805 solver.cpp:256]     Train net output #0: loss = 1.55564 (* 1 = 1.55564 loss)
I0508 00:47:44.521514 17805 sgd_solver.cpp:106] Iteration 74, lr = 0.0001
I0508 00:47:44.840571 17805 solver.cpp:240] Iteration 75, loss = 1.5639
I0508 00:47:44.840607 17805 solver.cpp:256]     Train net output #0: loss = 1.5639 (* 1 = 1.5639 loss)
I0508 00:47:44.840615 17805 sgd_solver.cpp:106] Iteration 75, lr = 0.0001
I0508 00:47:45.159344 17805 solver.cpp:240] Iteration 76, loss = 1.51026
I0508 00:47:45.159382 17805 solver.cpp:256]     Train net output #0: loss = 1.51026 (* 1 = 1.51026 loss)
I0508 00:47:45.159390 17805 sgd_solver.cpp:106] Iteration 76, lr = 0.0001
I0508 00:47:45.477849 17805 solver.cpp:240] Iteration 77, loss = 1.45128
I0508 00:47:45.477885 17805 solver.cpp:256]     Train net output #0: loss = 1.45128 (* 1 = 1.45128 loss)
I0508 00:47:45.477893 17805 sgd_solver.cpp:106] Iteration 77, lr = 0.0001
I0508 00:47:45.796535 17805 solver.cpp:240] Iteration 78, loss = 1.49237
I0508 00:47:45.796571 17805 solver.cpp:256]     Train net output #0: loss = 1.49237 (* 1 = 1.49237 loss)
I0508 00:47:45.796578 17805 sgd_solver.cpp:106] Iteration 78, lr = 0.0001
I0508 00:47:46.115476 17805 solver.cpp:240] Iteration 79, loss = 1.60421
I0508 00:47:46.115511 17805 solver.cpp:256]     Train net output #0: loss = 1.60421 (* 1 = 1.60421 loss)
I0508 00:47:46.115520 17805 sgd_solver.cpp:106] Iteration 79, lr = 0.0001
I0508 00:47:46.434371 17805 solver.cpp:240] Iteration 80, loss = 1.44905
I0508 00:47:46.434406 17805 solver.cpp:256]     Train net output #0: loss = 1.44905 (* 1 = 1.44905 loss)
I0508 00:47:46.434413 17805 sgd_solver.cpp:106] Iteration 80, lr = 0.0001
I0508 00:47:46.753335 17805 solver.cpp:240] Iteration 81, loss = 1.48897
I0508 00:47:46.753372 17805 solver.cpp:256]     Train net output #0: loss = 1.48897 (* 1 = 1.48897 loss)
I0508 00:47:46.753381 17805 sgd_solver.cpp:106] Iteration 81, lr = 0.0001
I0508 00:47:47.071995 17805 solver.cpp:240] Iteration 82, loss = 1.50947
I0508 00:47:47.073040 17805 solver.cpp:256]     Train net output #0: loss = 1.50947 (* 1 = 1.50947 loss)
I0508 00:47:47.073051 17805 sgd_solver.cpp:106] Iteration 82, lr = 0.0001
I0508 00:47:47.390584 17805 solver.cpp:240] Iteration 83, loss = 1.54994
I0508 00:47:47.390619 17805 solver.cpp:256]     Train net output #0: loss = 1.54994 (* 1 = 1.54994 loss)
I0508 00:47:47.390626 17805 sgd_solver.cpp:106] Iteration 83, lr = 0.0001
I0508 00:47:47.709302 17805 solver.cpp:240] Iteration 84, loss = 1.41881
I0508 00:47:47.709338 17805 solver.cpp:256]     Train net output #0: loss = 1.41881 (* 1 = 1.41881 loss)
I0508 00:47:47.709347 17805 sgd_solver.cpp:106] Iteration 84, lr = 0.0001
I0508 00:47:47.709668 17805 solver.cpp:349] Iteration 85, Testing net (#0)
I0508 00:47:47.709686 17805 net.cpp:693] Ignoring source layer silence
I0508 00:47:49.946141 17805 solver.cpp:416]     Test net output #0: accuracy_1 = 0.643612
I0508 00:47:49.946177 17805 solver.cpp:416]     Test net output #1: accuracy_5 = 0.798196
I0508 00:47:49.946187 17805 solver.cpp:416]     Test net output #2: loss = 1.71718 (* 1 = 1.71718 loss)
I0508 00:47:50.065361 17805 solver.cpp:240] Iteration 85, loss = 1.41535
I0508 00:47:50.065395 17805 solver.cpp:256]     Train net output #0: loss = 1.41535 (* 1 = 1.41535 loss)
I0508 00:47:50.065403 17805 sgd_solver.cpp:106] Iteration 85, lr = 0.0001
I0508 00:47:50.381758 17805 solver.cpp:240] Iteration 86, loss = 1.52512
I0508 00:47:50.381793 17805 solver.cpp:256]     Train net output #0: loss = 1.52512 (* 1 = 1.52512 loss)
I0508 00:47:50.381800 17805 sgd_solver.cpp:106] Iteration 86, lr = 0.0001
I0508 00:47:50.700706 17805 solver.cpp:240] Iteration 87, loss = 1.50915
I0508 00:47:50.700740 17805 solver.cpp:256]     Train net output #0: loss = 1.50915 (* 1 = 1.50915 loss)
I0508 00:47:50.700748 17805 sgd_solver.cpp:106] Iteration 87, lr = 0.0001
I0508 00:47:51.019634 17805 solver.cpp:240] Iteration 88, loss = 1.39926
I0508 00:47:51.019668 17805 solver.cpp:256]     Train net output #0: loss = 1.39926 (* 1 = 1.39926 loss)
I0508 00:47:51.019675 17805 sgd_solver.cpp:106] Iteration 88, lr = 0.0001
I0508 00:47:51.338281 17805 solver.cpp:240] Iteration 89, loss = 1.34348
I0508 00:47:51.338320 17805 solver.cpp:256]     Train net output #0: loss = 1.34348 (* 1 = 1.34348 loss)
I0508 00:47:51.338326 17805 sgd_solver.cpp:106] Iteration 89, lr = 0.0001
I0508 00:47:51.657286 17805 solver.cpp:240] Iteration 90, loss = 1.40733
I0508 00:47:51.657320 17805 solver.cpp:256]     Train net output #0: loss = 1.40733 (* 1 = 1.40733 loss)
I0508 00:47:51.657327 17805 sgd_solver.cpp:106] Iteration 90, lr = 0.0001
I0508 00:47:51.977344 17805 solver.cpp:240] Iteration 91, loss = 1.38728
I0508 00:47:51.977390 17805 solver.cpp:256]     Train net output #0: loss = 1.38728 (* 1 = 1.38728 loss)
I0508 00:47:51.977399 17805 sgd_solver.cpp:106] Iteration 91, lr = 0.0001
I0508 00:47:52.295958 17805 solver.cpp:240] Iteration 92, loss = 1.41588
I0508 00:47:52.295994 17805 solver.cpp:256]     Train net output #0: loss = 1.41588 (* 1 = 1.41588 loss)
I0508 00:47:52.296001 17805 sgd_solver.cpp:106] Iteration 92, lr = 0.0001
I0508 00:47:52.614562 17805 solver.cpp:240] Iteration 93, loss = 1.505
I0508 00:47:52.614604 17805 solver.cpp:256]     Train net output #0: loss = 1.505 (* 1 = 1.505 loss)
I0508 00:47:52.614612 17805 sgd_solver.cpp:106] Iteration 93, lr = 0.0001
I0508 00:47:52.934525 17805 solver.cpp:240] Iteration 94, loss = 1.37036
I0508 00:47:52.934574 17805 solver.cpp:256]     Train net output #0: loss = 1.37036 (* 1 = 1.37036 loss)
I0508 00:47:52.934587 17805 sgd_solver.cpp:106] Iteration 94, lr = 0.0001
I0508 00:47:53.252833 17805 solver.cpp:240] Iteration 95, loss = 1.43024
I0508 00:47:53.252882 17805 solver.cpp:256]     Train net output #0: loss = 1.43024 (* 1 = 1.43024 loss)
I0508 00:47:53.252890 17805 sgd_solver.cpp:106] Iteration 95, lr = 0.0001
I0508 00:47:53.570794 17805 solver.cpp:240] Iteration 96, loss = 1.40395
I0508 00:47:53.570832 17805 solver.cpp:256]     Train net output #0: loss = 1.40395 (* 1 = 1.40395 loss)
I0508 00:47:53.570839 17805 sgd_solver.cpp:106] Iteration 96, lr = 0.0001
I0508 00:47:53.889391 17805 solver.cpp:240] Iteration 97, loss = 1.47633
I0508 00:47:53.889425 17805 solver.cpp:256]     Train net output #0: loss = 1.47633 (* 1 = 1.47633 loss)
I0508 00:47:53.889433 17805 sgd_solver.cpp:106] Iteration 97, lr = 0.0001
I0508 00:47:54.208017 17805 solver.cpp:240] Iteration 98, loss = 1.36631
I0508 00:47:54.208055 17805 solver.cpp:256]     Train net output #0: loss = 1.36631 (* 1 = 1.36631 loss)
I0508 00:47:54.208063 17805 sgd_solver.cpp:106] Iteration 98, lr = 0.0001
I0508 00:47:54.526870 17805 solver.cpp:240] Iteration 99, loss = 1.44011
I0508 00:47:54.526906 17805 solver.cpp:256]     Train net output #0: loss = 1.44011 (* 1 = 1.44011 loss)
I0508 00:47:54.526916 17805 sgd_solver.cpp:106] Iteration 99, lr = 0.0001
I0508 00:47:54.845810 17805 solver.cpp:240] Iteration 100, loss = 1.36897
I0508 00:47:54.845845 17805 solver.cpp:256]     Train net output #0: loss = 1.36897 (* 1 = 1.36897 loss)
I0508 00:47:54.845852 17805 sgd_solver.cpp:106] Iteration 100, lr = 0.0001
I0508 00:47:55.164490 17805 solver.cpp:240] Iteration 101, loss = 1.38318
I0508 00:47:55.164525 17805 solver.cpp:256]     Train net output #0: loss = 1.38318 (* 1 = 1.38318 loss)
I0508 00:47:55.164532 17805 sgd_solver.cpp:106] Iteration 101, lr = 0.0001
I0508 00:47:55.483448 17805 solver.cpp:240] Iteration 102, loss = 1.4183
I0508 00:47:55.483486 17805 solver.cpp:256]     Train net output #0: loss = 1.4183 (* 1 = 1.4183 loss)
I0508 00:47:55.483495 17805 sgd_solver.cpp:106] Iteration 102, lr = 0.0001
I0508 00:47:55.802335 17805 solver.cpp:240] Iteration 103, loss = 1.30575
I0508 00:47:55.802371 17805 solver.cpp:256]     Train net output #0: loss = 1.30575 (* 1 = 1.30575 loss)
I0508 00:47:55.802378 17805 sgd_solver.cpp:106] Iteration 103, lr = 0.0001
I0508 00:47:56.120967 17805 solver.cpp:240] Iteration 104, loss = 1.37468
I0508 00:47:56.121002 17805 solver.cpp:256]     Train net output #0: loss = 1.37468 (* 1 = 1.37468 loss)
I0508 00:47:56.121011 17805 sgd_solver.cpp:106] Iteration 104, lr = 0.0001
I0508 00:47:56.438832 17805 solver.cpp:240] Iteration 105, loss = 1.31868
I0508 00:47:56.438869 17805 solver.cpp:256]     Train net output #0: loss = 1.31868 (* 1 = 1.31868 loss)
I0508 00:47:56.438876 17805 sgd_solver.cpp:106] Iteration 105, lr = 0.0001
I0508 00:47:56.756539 17805 solver.cpp:240] Iteration 106, loss = 1.34684
I0508 00:47:56.756574 17805 solver.cpp:256]     Train net output #0: loss = 1.34684 (* 1 = 1.34684 loss)
I0508 00:47:56.756583 17805 sgd_solver.cpp:106] Iteration 106, lr = 0.0001
I0508 00:47:57.073035 17805 solver.cpp:240] Iteration 107, loss = 1.40394
I0508 00:47:57.073072 17805 solver.cpp:256]     Train net output #0: loss = 1.40394 (* 1 = 1.40394 loss)
I0508 00:47:57.073082 17805 sgd_solver.cpp:106] Iteration 107, lr = 0.0001
I0508 00:47:57.390153 17805 solver.cpp:240] Iteration 108, loss = 1.3928
I0508 00:47:57.390189 17805 solver.cpp:256]     Train net output #0: loss = 1.3928 (* 1 = 1.3928 loss)
I0508 00:47:57.390197 17805 sgd_solver.cpp:106] Iteration 108, lr = 0.0001
I0508 00:47:57.707182 17805 solver.cpp:240] Iteration 109, loss = 1.37987
I0508 00:47:57.707219 17805 solver.cpp:256]     Train net output #0: loss = 1.37987 (* 1 = 1.37987 loss)
I0508 00:47:57.707226 17805 sgd_solver.cpp:106] Iteration 109, lr = 0.0001
I0508 00:47:58.024097 17805 solver.cpp:240] Iteration 110, loss = 1.38535
I0508 00:47:58.024132 17805 solver.cpp:256]     Train net output #0: loss = 1.38535 (* 1 = 1.38535 loss)
I0508 00:47:58.024140 17805 sgd_solver.cpp:106] Iteration 110, lr = 0.0001
I0508 00:47:58.341003 17805 solver.cpp:240] Iteration 111, loss = 1.35213
I0508 00:47:58.341038 17805 solver.cpp:256]     Train net output #0: loss = 1.35213 (* 1 = 1.35213 loss)
I0508 00:47:58.341047 17805 sgd_solver.cpp:106] Iteration 111, lr = 0.0001
I0508 00:47:58.657490 17805 solver.cpp:240] Iteration 112, loss = 1.29382
I0508 00:47:58.657523 17805 solver.cpp:256]     Train net output #0: loss = 1.29382 (* 1 = 1.29382 loss)
I0508 00:47:58.657531 17805 sgd_solver.cpp:106] Iteration 112, lr = 0.0001
I0508 00:47:58.974112 17805 solver.cpp:240] Iteration 113, loss = 1.18533
I0508 00:47:58.974179 17805 solver.cpp:256]     Train net output #0: loss = 1.18533 (* 1 = 1.18533 loss)
I0508 00:47:58.974189 17805 sgd_solver.cpp:106] Iteration 113, lr = 0.0001
I0508 00:47:59.291167 17805 solver.cpp:240] Iteration 114, loss = 1.23182
I0508 00:47:59.291203 17805 solver.cpp:256]     Train net output #0: loss = 1.23182 (* 1 = 1.23182 loss)
I0508 00:47:59.291211 17805 sgd_solver.cpp:106] Iteration 114, lr = 0.0001
I0508 00:47:59.607465 17805 solver.cpp:240] Iteration 115, loss = 1.29748
I0508 00:47:59.607501 17805 solver.cpp:256]     Train net output #0: loss = 1.29748 (* 1 = 1.29748 loss)
I0508 00:47:59.607508 17805 sgd_solver.cpp:106] Iteration 115, lr = 0.0001
I0508 00:47:59.923269 17805 solver.cpp:240] Iteration 116, loss = 1.3334
I0508 00:47:59.923305 17805 solver.cpp:256]     Train net output #0: loss = 1.3334 (* 1 = 1.3334 loss)
I0508 00:47:59.923311 17805 sgd_solver.cpp:106] Iteration 116, lr = 0.0001
I0508 00:48:00.240394 17805 solver.cpp:240] Iteration 117, loss = 1.34868
I0508 00:48:00.240429 17805 solver.cpp:256]     Train net output #0: loss = 1.34868 (* 1 = 1.34868 loss)
I0508 00:48:00.240437 17805 sgd_solver.cpp:106] Iteration 117, lr = 0.0001
I0508 00:48:00.557181 17805 solver.cpp:240] Iteration 118, loss = 1.30928
I0508 00:48:00.557216 17805 solver.cpp:256]     Train net output #0: loss = 1.30928 (* 1 = 1.30928 loss)
I0508 00:48:00.557225 17805 sgd_solver.cpp:106] Iteration 118, lr = 0.0001
I0508 00:48:00.873955 17805 solver.cpp:240] Iteration 119, loss = 1.2646
I0508 00:48:00.873987 17805 solver.cpp:256]     Train net output #0: loss = 1.2646 (* 1 = 1.2646 loss)
I0508 00:48:00.873996 17805 sgd_solver.cpp:106] Iteration 119, lr = 0.0001
I0508 00:48:01.191098 17805 solver.cpp:240] Iteration 120, loss = 1.31858
I0508 00:48:01.191135 17805 solver.cpp:256]     Train net output #0: loss = 1.31858 (* 1 = 1.31858 loss)
I0508 00:48:01.191144 17805 sgd_solver.cpp:106] Iteration 120, lr = 0.0001
I0508 00:48:01.507846 17805 solver.cpp:240] Iteration 121, loss = 1.28326
I0508 00:48:01.507890 17805 solver.cpp:256]     Train net output #0: loss = 1.28326 (* 1 = 1.28326 loss)
I0508 00:48:01.507899 17805 sgd_solver.cpp:106] Iteration 121, lr = 0.0001
I0508 00:48:01.824524 17805 solver.cpp:240] Iteration 122, loss = 1.30542
I0508 00:48:01.824559 17805 solver.cpp:256]     Train net output #0: loss = 1.30542 (* 1 = 1.30542 loss)
I0508 00:48:01.824568 17805 sgd_solver.cpp:106] Iteration 122, lr = 0.0001
I0508 00:48:02.140980 17805 solver.cpp:240] Iteration 123, loss = 1.25568
I0508 00:48:02.141018 17805 solver.cpp:256]     Train net output #0: loss = 1.25568 (* 1 = 1.25568 loss)
I0508 00:48:02.141026 17805 sgd_solver.cpp:106] Iteration 123, lr = 0.0001
I0508 00:48:02.457877 17805 solver.cpp:240] Iteration 124, loss = 1.22625
I0508 00:48:02.457913 17805 solver.cpp:256]     Train net output #0: loss = 1.22625 (* 1 = 1.22625 loss)
I0508 00:48:02.457921 17805 sgd_solver.cpp:106] Iteration 124, lr = 0.0001
I0508 00:48:02.773509 17805 solver.cpp:240] Iteration 125, loss = 1.27091
I0508 00:48:02.773546 17805 solver.cpp:256]     Train net output #0: loss = 1.27091 (* 1 = 1.27091 loss)
I0508 00:48:02.773555 17805 sgd_solver.cpp:106] Iteration 125, lr = 0.0001
I0508 00:48:03.088248 17805 solver.cpp:240] Iteration 126, loss = 1.31855
I0508 00:48:03.088284 17805 solver.cpp:256]     Train net output #0: loss = 1.31855 (* 1 = 1.31855 loss)
I0508 00:48:03.088291 17805 sgd_solver.cpp:106] Iteration 126, lr = 0.0001
I0508 00:48:03.404990 17805 solver.cpp:240] Iteration 127, loss = 1.26149
I0508 00:48:03.405025 17805 solver.cpp:256]     Train net output #0: loss = 1.26149 (* 1 = 1.26149 loss)
I0508 00:48:03.405032 17805 sgd_solver.cpp:106] Iteration 127, lr = 0.0001
I0508 00:48:03.721742 17805 solver.cpp:240] Iteration 128, loss = 1.23798
I0508 00:48:03.721781 17805 solver.cpp:256]     Train net output #0: loss = 1.23798 (* 1 = 1.23798 loss)
I0508 00:48:03.721788 17805 sgd_solver.cpp:106] Iteration 128, lr = 0.0001
I0508 00:48:04.038262 17805 solver.cpp:240] Iteration 129, loss = 1.25978
I0508 00:48:04.038324 17805 solver.cpp:256]     Train net output #0: loss = 1.25978 (* 1 = 1.25978 loss)
I0508 00:48:04.038334 17805 sgd_solver.cpp:106] Iteration 129, lr = 0.0001
I0508 00:48:04.354894 17805 solver.cpp:240] Iteration 130, loss = 1.24631
I0508 00:48:04.354928 17805 solver.cpp:256]     Train net output #0: loss = 1.24631 (* 1 = 1.24631 loss)
I0508 00:48:04.354936 17805 sgd_solver.cpp:106] Iteration 130, lr = 0.0001
I0508 00:48:04.671535 17805 solver.cpp:240] Iteration 131, loss = 1.20225
I0508 00:48:04.671571 17805 solver.cpp:256]     Train net output #0: loss = 1.20225 (* 1 = 1.20225 loss)
I0508 00:48:04.671578 17805 sgd_solver.cpp:106] Iteration 131, lr = 0.0001
I0508 00:48:04.988147 17805 solver.cpp:240] Iteration 132, loss = 1.18722
I0508 00:48:04.988183 17805 solver.cpp:256]     Train net output #0: loss = 1.18722 (* 1 = 1.18722 loss)
I0508 00:48:04.988190 17805 sgd_solver.cpp:106] Iteration 132, lr = 0.0001
I0508 00:48:05.304774 17805 solver.cpp:240] Iteration 133, loss = 1.16986
I0508 00:48:05.304810 17805 solver.cpp:256]     Train net output #0: loss = 1.16986 (* 1 = 1.16986 loss)
I0508 00:48:05.304818 17805 sgd_solver.cpp:106] Iteration 133, lr = 0.0001
I0508 00:48:05.620707 17805 solver.cpp:240] Iteration 134, loss = 1.21523
I0508 00:48:05.620740 17805 solver.cpp:256]     Train net output #0: loss = 1.21523 (* 1 = 1.21523 loss)
I0508 00:48:05.620748 17805 sgd_solver.cpp:106] Iteration 134, lr = 0.0001
I0508 00:48:05.936111 17805 solver.cpp:240] Iteration 135, loss = 1.17132
I0508 00:48:05.936146 17805 solver.cpp:256]     Train net output #0: loss = 1.17132 (* 1 = 1.17132 loss)
I0508 00:48:05.936153 17805 sgd_solver.cpp:106] Iteration 135, lr = 0.0001
I0508 00:48:06.252848 17805 solver.cpp:240] Iteration 136, loss = 1.22663
I0508 00:48:06.252882 17805 solver.cpp:256]     Train net output #0: loss = 1.22663 (* 1 = 1.22663 loss)
I0508 00:48:06.252890 17805 sgd_solver.cpp:106] Iteration 136, lr = 0.0001
I0508 00:48:06.569344 17805 solver.cpp:240] Iteration 137, loss = 1.16027
I0508 00:48:06.569378 17805 solver.cpp:256]     Train net output #0: loss = 1.16027 (* 1 = 1.16027 loss)
I0508 00:48:06.569386 17805 sgd_solver.cpp:106] Iteration 137, lr = 0.0001
I0508 00:48:06.886278 17805 solver.cpp:240] Iteration 138, loss = 1.22956
I0508 00:48:06.886313 17805 solver.cpp:256]     Train net output #0: loss = 1.22956 (* 1 = 1.22956 loss)
I0508 00:48:06.886322 17805 sgd_solver.cpp:106] Iteration 138, lr = 0.0001
I0508 00:48:07.203498 17805 solver.cpp:240] Iteration 139, loss = 1.23037
I0508 00:48:07.203529 17805 solver.cpp:256]     Train net output #0: loss = 1.23037 (* 1 = 1.23037 loss)
I0508 00:48:07.203537 17805 sgd_solver.cpp:106] Iteration 139, lr = 0.0001
I0508 00:48:07.520148 17805 solver.cpp:240] Iteration 140, loss = 1.27441
I0508 00:48:07.520184 17805 solver.cpp:256]     Train net output #0: loss = 1.27441 (* 1 = 1.27441 loss)
I0508 00:48:07.520192 17805 sgd_solver.cpp:106] Iteration 140, lr = 0.0001
I0508 00:48:07.836994 17805 solver.cpp:240] Iteration 141, loss = 1.18511
I0508 00:48:07.837033 17805 solver.cpp:256]     Train net output #0: loss = 1.18511 (* 1 = 1.18511 loss)
I0508 00:48:07.837050 17805 sgd_solver.cpp:106] Iteration 141, lr = 0.0001
I0508 00:48:08.153632 17805 solver.cpp:240] Iteration 142, loss = 1.18111
I0508 00:48:08.153669 17805 solver.cpp:256]     Train net output #0: loss = 1.18111 (* 1 = 1.18111 loss)
I0508 00:48:08.153678 17805 sgd_solver.cpp:106] Iteration 142, lr = 0.0001
I0508 00:48:08.470543 17805 solver.cpp:240] Iteration 143, loss = 1.17551
I0508 00:48:08.470585 17805 solver.cpp:256]     Train net output #0: loss = 1.17551 (* 1 = 1.17551 loss)
I0508 00:48:08.470593 17805 sgd_solver.cpp:106] Iteration 143, lr = 0.0001
I0508 00:48:08.787055 17805 solver.cpp:240] Iteration 144, loss = 1.14676
I0508 00:48:08.787092 17805 solver.cpp:256]     Train net output #0: loss = 1.14676 (* 1 = 1.14676 loss)
I0508 00:48:08.787101 17805 sgd_solver.cpp:106] Iteration 144, lr = 0.0001
I0508 00:48:09.103972 17805 solver.cpp:240] Iteration 145, loss = 1.20073
I0508 00:48:09.104008 17805 solver.cpp:256]     Train net output #0: loss = 1.20073 (* 1 = 1.20073 loss)
I0508 00:48:09.104043 17805 sgd_solver.cpp:106] Iteration 145, lr = 0.0001
I0508 00:48:09.420598 17805 solver.cpp:240] Iteration 146, loss = 1.19501
I0508 00:48:09.420634 17805 solver.cpp:256]     Train net output #0: loss = 1.19501 (* 1 = 1.19501 loss)
I0508 00:48:09.420641 17805 sgd_solver.cpp:106] Iteration 146, lr = 0.0001
I0508 00:48:09.737324 17805 solver.cpp:240] Iteration 147, loss = 1.15601
I0508 00:48:09.737361 17805 solver.cpp:256]     Train net output #0: loss = 1.15601 (* 1 = 1.15601 loss)
I0508 00:48:09.737370 17805 sgd_solver.cpp:106] Iteration 147, lr = 0.0001
I0508 00:48:10.069411 17805 solver.cpp:240] Iteration 148, loss = 1.22662
I0508 00:48:10.069447 17805 solver.cpp:256]     Train net output #0: loss = 1.22662 (* 1 = 1.22662 loss)
I0508 00:48:10.069455 17805 sgd_solver.cpp:106] Iteration 148, lr = 0.0001
I0508 00:48:10.388394 17805 solver.cpp:240] Iteration 149, loss = 1.16104
I0508 00:48:10.388437 17805 solver.cpp:256]     Train net output #0: loss = 1.16104 (* 1 = 1.16104 loss)
I0508 00:48:10.388447 17805 sgd_solver.cpp:106] Iteration 149, lr = 0.0001
I0508 00:48:10.707509 17805 solver.cpp:240] Iteration 150, loss = 1.097
I0508 00:48:10.707542 17805 solver.cpp:256]     Train net output #0: loss = 1.097 (* 1 = 1.097 loss)
I0508 00:48:10.707551 17805 sgd_solver.cpp:106] Iteration 150, lr = 0.0001
I0508 00:48:11.026578 17805 solver.cpp:240] Iteration 151, loss = 1.19965
I0508 00:48:11.026623 17805 solver.cpp:256]     Train net output #0: loss = 1.19965 (* 1 = 1.19965 loss)
I0508 00:48:11.026633 17805 sgd_solver.cpp:106] Iteration 151, lr = 0.0001
I0508 00:48:11.345448 17805 solver.cpp:240] Iteration 152, loss = 1.11403
I0508 00:48:11.345485 17805 solver.cpp:256]     Train net output #0: loss = 1.11403 (* 1 = 1.11403 loss)
I0508 00:48:11.345494 17805 sgd_solver.cpp:106] Iteration 152, lr = 0.0001
I0508 00:48:11.664460 17805 solver.cpp:240] Iteration 153, loss = 1.17878
I0508 00:48:11.664496 17805 solver.cpp:256]     Train net output #0: loss = 1.17878 (* 1 = 1.17878 loss)
I0508 00:48:11.664505 17805 sgd_solver.cpp:106] Iteration 153, lr = 0.0001
I0508 00:48:11.983037 17805 solver.cpp:240] Iteration 154, loss = 1.22413
I0508 00:48:11.983072 17805 solver.cpp:256]     Train net output #0: loss = 1.22413 (* 1 = 1.22413 loss)
I0508 00:48:11.983080 17805 sgd_solver.cpp:106] Iteration 154, lr = 0.0001
I0508 00:48:12.301909 17805 solver.cpp:240] Iteration 155, loss = 1.08795
I0508 00:48:12.301944 17805 solver.cpp:256]     Train net output #0: loss = 1.08795 (* 1 = 1.08795 loss)
I0508 00:48:12.301951 17805 sgd_solver.cpp:106] Iteration 155, lr = 0.0001
I0508 00:48:12.620923 17805 solver.cpp:240] Iteration 156, loss = 1.17762
I0508 00:48:12.620959 17805 solver.cpp:256]     Train net output #0: loss = 1.17762 (* 1 = 1.17762 loss)
I0508 00:48:12.620967 17805 sgd_solver.cpp:106] Iteration 156, lr = 0.0001
I0508 00:48:12.939826 17805 solver.cpp:240] Iteration 157, loss = 1.08336
I0508 00:48:12.939862 17805 solver.cpp:256]     Train net output #0: loss = 1.08336 (* 1 = 1.08336 loss)
I0508 00:48:12.939868 17805 sgd_solver.cpp:106] Iteration 157, lr = 0.0001
I0508 00:48:13.259330 17805 solver.cpp:240] Iteration 158, loss = 1.12105
I0508 00:48:13.259369 17805 solver.cpp:256]     Train net output #0: loss = 1.12105 (* 1 = 1.12105 loss)
I0508 00:48:13.259377 17805 sgd_solver.cpp:106] Iteration 158, lr = 0.0001
I0508 00:48:13.578131 17805 solver.cpp:240] Iteration 159, loss = 1.11867
I0508 00:48:13.578176 17805 solver.cpp:256]     Train net output #0: loss = 1.11867 (* 1 = 1.11867 loss)
I0508 00:48:13.578183 17805 sgd_solver.cpp:106] Iteration 159, lr = 0.0001
I0508 00:48:13.896916 17805 solver.cpp:240] Iteration 160, loss = 1.11376
I0508 00:48:13.896957 17805 solver.cpp:256]     Train net output #0: loss = 1.11376 (* 1 = 1.11376 loss)
I0508 00:48:13.896965 17805 sgd_solver.cpp:106] Iteration 160, lr = 0.0001
I0508 00:48:14.215850 17805 solver.cpp:240] Iteration 161, loss = 1.01641
I0508 00:48:14.215898 17805 solver.cpp:256]     Train net output #0: loss = 1.01641 (* 1 = 1.01641 loss)
I0508 00:48:14.215936 17805 sgd_solver.cpp:106] Iteration 161, lr = 0.0001
I0508 00:48:14.534512 17805 solver.cpp:240] Iteration 162, loss = 1.10857
I0508 00:48:14.534549 17805 solver.cpp:256]     Train net output #0: loss = 1.10857 (* 1 = 1.10857 loss)
I0508 00:48:14.534557 17805 sgd_solver.cpp:106] Iteration 162, lr = 0.0001
I0508 00:48:14.853505 17805 solver.cpp:240] Iteration 163, loss = 1.14389
I0508 00:48:14.853543 17805 solver.cpp:256]     Train net output #0: loss = 1.14389 (* 1 = 1.14389 loss)
I0508 00:48:14.853550 17805 sgd_solver.cpp:106] Iteration 163, lr = 0.0001
I0508 00:48:15.172444 17805 solver.cpp:240] Iteration 164, loss = 1.04712
I0508 00:48:15.172482 17805 solver.cpp:256]     Train net output #0: loss = 1.04712 (* 1 = 1.04712 loss)
I0508 00:48:15.172490 17805 sgd_solver.cpp:106] Iteration 164, lr = 0.0001
I0508 00:48:15.491102 17805 solver.cpp:240] Iteration 165, loss = 1.09494
I0508 00:48:15.491139 17805 solver.cpp:256]     Train net output #0: loss = 1.09494 (* 1 = 1.09494 loss)
I0508 00:48:15.491147 17805 sgd_solver.cpp:106] Iteration 165, lr = 0.0001
I0508 00:48:15.809938 17805 solver.cpp:240] Iteration 166, loss = 1.05683
I0508 00:48:15.809976 17805 solver.cpp:256]     Train net output #0: loss = 1.05683 (* 1 = 1.05683 loss)
I0508 00:48:15.809985 17805 sgd_solver.cpp:106] Iteration 166, lr = 0.0001
I0508 00:48:16.128733 17805 solver.cpp:240] Iteration 167, loss = 1.16546
I0508 00:48:16.128770 17805 solver.cpp:256]     Train net output #0: loss = 1.16546 (* 1 = 1.16546 loss)
I0508 00:48:16.128778 17805 sgd_solver.cpp:106] Iteration 167, lr = 0.0001
I0508 00:48:16.447471 17805 solver.cpp:240] Iteration 168, loss = 1.03543
I0508 00:48:16.447510 17805 solver.cpp:256]     Train net output #0: loss = 1.03543 (* 1 = 1.03543 loss)
I0508 00:48:16.447517 17805 sgd_solver.cpp:106] Iteration 168, lr = 0.0001
I0508 00:48:16.766626 17805 solver.cpp:240] Iteration 169, loss = 1.03169
I0508 00:48:16.766665 17805 solver.cpp:256]     Train net output #0: loss = 1.03169 (* 1 = 1.03169 loss)
I0508 00:48:16.766674 17805 sgd_solver.cpp:106] Iteration 169, lr = 0.0001
I0508 00:48:16.766995 17805 solver.cpp:349] Iteration 170, Testing net (#0)
I0508 00:48:16.767014 17805 net.cpp:693] Ignoring source layer silence
I0508 00:48:19.004182 17805 solver.cpp:416]     Test net output #0: accuracy_1 = 0.728171
I0508 00:48:19.004362 17805 solver.cpp:416]     Test net output #1: accuracy_5 = 0.847943
I0508 00:48:19.004384 17805 solver.cpp:416]     Test net output #2: loss = 1.28193 (* 1 = 1.28193 loss)
I0508 00:48:19.124915 17805 solver.cpp:240] Iteration 170, loss = 1.18893
I0508 00:48:19.124949 17805 solver.cpp:256]     Train net output #0: loss = 1.18893 (* 1 = 1.18893 loss)
I0508 00:48:19.124958 17805 sgd_solver.cpp:106] Iteration 170, lr = 0.0001
I0508 00:48:19.444098 17805 solver.cpp:240] Iteration 171, loss = 1.10938
I0508 00:48:19.444134 17805 solver.cpp:256]     Train net output #0: loss = 1.10938 (* 1 = 1.10938 loss)
I0508 00:48:19.444142 17805 sgd_solver.cpp:106] Iteration 171, lr = 0.0001
I0508 00:48:19.762444 17805 solver.cpp:240] Iteration 172, loss = 1.09975
I0508 00:48:19.762480 17805 solver.cpp:256]     Train net output #0: loss = 1.09975 (* 1 = 1.09975 loss)
I0508 00:48:19.762488 17805 sgd_solver.cpp:106] Iteration 172, lr = 0.0001
I0508 00:48:20.081228 17805 solver.cpp:240] Iteration 173, loss = 0.986144
I0508 00:48:20.081261 17805 solver.cpp:256]     Train net output #0: loss = 0.986144 (* 1 = 0.986144 loss)
I0508 00:48:20.081270 17805 sgd_solver.cpp:106] Iteration 173, lr = 0.0001
I0508 00:48:20.400055 17805 solver.cpp:240] Iteration 174, loss = 1.01568
I0508 00:48:20.400090 17805 solver.cpp:256]     Train net output #0: loss = 1.01568 (* 1 = 1.01568 loss)
I0508 00:48:20.400097 17805 sgd_solver.cpp:106] Iteration 174, lr = 0.0001
I0508 00:48:20.718912 17805 solver.cpp:240] Iteration 175, loss = 1.05954
I0508 00:48:20.718950 17805 solver.cpp:256]     Train net output #0: loss = 1.05954 (* 1 = 1.05954 loss)
I0508 00:48:20.718958 17805 sgd_solver.cpp:106] Iteration 175, lr = 0.0001
I0508 00:48:21.037861 17805 solver.cpp:240] Iteration 176, loss = 1.03607
I0508 00:48:21.037899 17805 solver.cpp:256]     Train net output #0: loss = 1.03607 (* 1 = 1.03607 loss)
I0508 00:48:21.037906 17805 sgd_solver.cpp:106] Iteration 176, lr = 0.0001
I0508 00:48:21.356542 17805 solver.cpp:240] Iteration 177, loss = 1.10938
I0508 00:48:21.356577 17805 solver.cpp:256]     Train net output #0: loss = 1.10938 (* 1 = 1.10938 loss)
I0508 00:48:21.356585 17805 sgd_solver.cpp:106] Iteration 177, lr = 0.0001
I0508 00:48:21.674932 17805 solver.cpp:240] Iteration 178, loss = 1.03979
I0508 00:48:21.674968 17805 solver.cpp:256]     Train net output #0: loss = 1.03979 (* 1 = 1.03979 loss)
I0508 00:48:21.674976 17805 sgd_solver.cpp:106] Iteration 178, lr = 0.0001
I0508 00:48:21.993968 17805 solver.cpp:240] Iteration 179, loss = 1.06107
I0508 00:48:21.994004 17805 solver.cpp:256]     Train net output #0: loss = 1.06107 (* 1 = 1.06107 loss)
I0508 00:48:21.994011 17805 sgd_solver.cpp:106] Iteration 179, lr = 0.0001
I0508 00:48:22.313230 17805 solver.cpp:240] Iteration 180, loss = 1.0796
I0508 00:48:22.313271 17805 solver.cpp:256]     Train net output #0: loss = 1.0796 (* 1 = 1.0796 loss)
I0508 00:48:22.313279 17805 sgd_solver.cpp:106] Iteration 180, lr = 0.0001
I0508 00:48:22.632062 17805 solver.cpp:240] Iteration 181, loss = 1.11076
I0508 00:48:22.632104 17805 solver.cpp:256]     Train net output #0: loss = 1.11076 (* 1 = 1.11076 loss)
I0508 00:48:22.632112 17805 sgd_solver.cpp:106] Iteration 181, lr = 0.0001
I0508 00:48:22.951263 17805 solver.cpp:240] Iteration 182, loss = 1.09984
I0508 00:48:22.951299 17805 solver.cpp:256]     Train net output #0: loss = 1.09984 (* 1 = 1.09984 loss)
I0508 00:48:22.951308 17805 sgd_solver.cpp:106] Iteration 182, lr = 0.0001
I0508 00:48:23.270321 17805 solver.cpp:240] Iteration 183, loss = 1.06329
I0508 00:48:23.270357 17805 solver.cpp:256]     Train net output #0: loss = 1.06329 (* 1 = 1.06329 loss)
I0508 00:48:23.270365 17805 sgd_solver.cpp:106] Iteration 183, lr = 0.0001
I0508 00:48:23.589444 17805 solver.cpp:240] Iteration 184, loss = 1.03351
I0508 00:48:23.589480 17805 solver.cpp:256]     Train net output #0: loss = 1.03351 (* 1 = 1.03351 loss)
I0508 00:48:23.589488 17805 sgd_solver.cpp:106] Iteration 184, lr = 0.0001
I0508 00:48:23.908365 17805 solver.cpp:240] Iteration 185, loss = 1.05248
I0508 00:48:23.908401 17805 solver.cpp:256]     Train net output #0: loss = 1.05248 (* 1 = 1.05248 loss)
I0508 00:48:23.908434 17805 sgd_solver.cpp:106] Iteration 185, lr = 0.0001
I0508 00:48:24.227669 17805 solver.cpp:240] Iteration 186, loss = 1.10016
I0508 00:48:24.227704 17805 solver.cpp:256]     Train net output #0: loss = 1.10016 (* 1 = 1.10016 loss)
I0508 00:48:24.227710 17805 sgd_solver.cpp:106] Iteration 186, lr = 0.0001
I0508 00:48:24.546272 17805 solver.cpp:240] Iteration 187, loss = 0.993147
I0508 00:48:24.546309 17805 solver.cpp:256]     Train net output #0: loss = 0.993147 (* 1 = 0.993147 loss)
I0508 00:48:24.546316 17805 sgd_solver.cpp:106] Iteration 187, lr = 0.0001
I0508 00:48:24.864090 17805 solver.cpp:240] Iteration 188, loss = 1.05879
I0508 00:48:24.864125 17805 solver.cpp:256]     Train net output #0: loss = 1.05879 (* 1 = 1.05879 loss)
I0508 00:48:24.864133 17805 sgd_solver.cpp:106] Iteration 188, lr = 0.0001
I0508 00:48:25.184017 17805 solver.cpp:240] Iteration 189, loss = 1.04182
I0508 00:48:25.184070 17805 solver.cpp:256]     Train net output #0: loss = 1.04182 (* 1 = 1.04182 loss)
I0508 00:48:25.184083 17805 sgd_solver.cpp:106] Iteration 189, lr = 0.0001
I0508 00:48:25.502940 17805 solver.cpp:240] Iteration 190, loss = 1.06877
I0508 00:48:25.502977 17805 solver.cpp:256]     Train net output #0: loss = 1.06877 (* 1 = 1.06877 loss)
I0508 00:48:25.502986 17805 sgd_solver.cpp:106] Iteration 190, lr = 0.0001
I0508 00:48:25.821661 17805 solver.cpp:240] Iteration 191, loss = 1.03577
I0508 00:48:25.821696 17805 solver.cpp:256]     Train net output #0: loss = 1.03577 (* 1 = 1.03577 loss)
I0508 00:48:25.821703 17805 sgd_solver.cpp:106] Iteration 191, lr = 0.0001
I0508 00:48:26.140866 17805 solver.cpp:240] Iteration 192, loss = 1.02863
I0508 00:48:26.140899 17805 solver.cpp:256]     Train net output #0: loss = 1.02863 (* 1 = 1.02863 loss)
I0508 00:48:26.140907 17805 sgd_solver.cpp:106] Iteration 192, lr = 0.0001
I0508 00:48:26.459916 17805 solver.cpp:240] Iteration 193, loss = 1.11953
I0508 00:48:26.459952 17805 solver.cpp:256]     Train net output #0: loss = 1.11953 (* 1 = 1.11953 loss)
I0508 00:48:26.459960 17805 sgd_solver.cpp:106] Iteration 193, lr = 0.0001
I0508 00:48:26.778667 17805 solver.cpp:240] Iteration 194, loss = 1.0545
I0508 00:48:26.778714 17805 solver.cpp:256]     Train net output #0: loss = 1.0545 (* 1 = 1.0545 loss)
I0508 00:48:26.778723 17805 sgd_solver.cpp:106] Iteration 194, lr = 0.0001
I0508 00:48:27.097590 17805 solver.cpp:240] Iteration 195, loss = 1.08661
I0508 00:48:27.097625 17805 solver.cpp:256]     Train net output #0: loss = 1.08661 (* 1 = 1.08661 loss)
I0508 00:48:27.097633 17805 sgd_solver.cpp:106] Iteration 195, lr = 0.0001
I0508 00:48:27.416739 17805 solver.cpp:240] Iteration 196, loss = 0.962031
I0508 00:48:27.416774 17805 solver.cpp:256]     Train net output #0: loss = 0.962031 (* 1 = 0.962031 loss)
I0508 00:48:27.416780 17805 sgd_solver.cpp:106] Iteration 196, lr = 0.0001
I0508 00:48:27.736161 17805 solver.cpp:240] Iteration 197, loss = 0.908341
I0508 00:48:27.736196 17805 solver.cpp:256]     Train net output #0: loss = 0.908341 (* 1 = 0.908341 loss)
I0508 00:48:27.736203 17805 sgd_solver.cpp:106] Iteration 197, lr = 0.0001
I0508 00:48:28.054802 17805 solver.cpp:240] Iteration 198, loss = 0.955565
I0508 00:48:28.054839 17805 solver.cpp:256]     Train net output #0: loss = 0.955565 (* 1 = 0.955565 loss)
I0508 00:48:28.054847 17805 sgd_solver.cpp:106] Iteration 198, lr = 0.0001
I0508 00:48:28.373386 17805 solver.cpp:240] Iteration 199, loss = 1.03967
I0508 00:48:28.373423 17805 solver.cpp:256]     Train net output #0: loss = 1.03967 (* 1 = 1.03967 loss)
I0508 00:48:28.373431 17805 sgd_solver.cpp:106] Iteration 199, lr = 0.0001
I0508 00:48:28.692668 17805 solver.cpp:240] Iteration 200, loss = 1.07007
I0508 00:48:28.692710 17805 solver.cpp:256]     Train net output #0: loss = 1.07007 (* 1 = 1.07007 loss)
I0508 00:48:28.692720 17805 sgd_solver.cpp:106] Iteration 200, lr = 0.0001
I0508 00:48:29.012146 17805 solver.cpp:240] Iteration 201, loss = 1.06626
I0508 00:48:29.012187 17805 solver.cpp:256]     Train net output #0: loss = 1.06626 (* 1 = 1.06626 loss)
I0508 00:48:29.012221 17805 sgd_solver.cpp:106] Iteration 201, lr = 0.0001
I0508 00:48:29.331686 17805 solver.cpp:240] Iteration 202, loss = 1.02623
I0508 00:48:29.331719 17805 solver.cpp:256]     Train net output #0: loss = 1.02623 (* 1 = 1.02623 loss)
I0508 00:48:29.331727 17805 sgd_solver.cpp:106] Iteration 202, lr = 0.0001
I0508 00:48:29.650782 17805 solver.cpp:240] Iteration 203, loss = 1.01794
I0508 00:48:29.650820 17805 solver.cpp:256]     Train net output #0: loss = 1.01794 (* 1 = 1.01794 loss)
I0508 00:48:29.650827 17805 sgd_solver.cpp:106] Iteration 203, lr = 0.0001
I0508 00:48:29.967473 17805 solver.cpp:240] Iteration 204, loss = 1.00258
I0508 00:48:29.967512 17805 solver.cpp:256]     Train net output #0: loss = 1.00258 (* 1 = 1.00258 loss)
I0508 00:48:29.967520 17805 sgd_solver.cpp:106] Iteration 204, lr = 0.0001
I0508 00:48:30.286816 17805 solver.cpp:240] Iteration 205, loss = 1.06088
I0508 00:48:30.286854 17805 solver.cpp:256]     Train net output #0: loss = 1.06088 (* 1 = 1.06088 loss)
I0508 00:48:30.286860 17805 sgd_solver.cpp:106] Iteration 205, lr = 0.0001
I0508 00:48:30.605978 17805 solver.cpp:240] Iteration 206, loss = 1.03733
I0508 00:48:30.606016 17805 solver.cpp:256]     Train net output #0: loss = 1.03733 (* 1 = 1.03733 loss)
I0508 00:48:30.606025 17805 sgd_solver.cpp:106] Iteration 206, lr = 0.0001
I0508 00:48:30.925114 17805 solver.cpp:240] Iteration 207, loss = 0.991072
I0508 00:48:30.925148 17805 solver.cpp:256]     Train net output #0: loss = 0.991072 (* 1 = 0.991072 loss)
I0508 00:48:30.925158 17805 sgd_solver.cpp:106] Iteration 207, lr = 0.0001
I0508 00:48:31.243788 17805 solver.cpp:240] Iteration 208, loss = 0.897009
I0508 00:48:31.243825 17805 solver.cpp:256]     Train net output #0: loss = 0.897009 (* 1 = 0.897009 loss)
I0508 00:48:31.243834 17805 sgd_solver.cpp:106] Iteration 208, lr = 0.0001
I0508 00:48:31.562397 17805 solver.cpp:240] Iteration 209, loss = 0.929333
I0508 00:48:31.562433 17805 solver.cpp:256]     Train net output #0: loss = 0.929333 (* 1 = 0.929333 loss)
I0508 00:48:31.562441 17805 sgd_solver.cpp:106] Iteration 209, lr = 0.0001
I0508 00:48:31.881443 17805 solver.cpp:240] Iteration 210, loss = 1.04195
I0508 00:48:31.881480 17805 solver.cpp:256]     Train net output #0: loss = 1.04195 (* 1 = 1.04195 loss)
I0508 00:48:31.881489 17805 sgd_solver.cpp:106] Iteration 210, lr = 0.0001
I0508 00:48:32.200621 17805 solver.cpp:240] Iteration 211, loss = 1.02126
I0508 00:48:32.200657 17805 solver.cpp:256]     Train net output #0: loss = 1.02126 (* 1 = 1.02126 loss)
I0508 00:48:32.200665 17805 sgd_solver.cpp:106] Iteration 211, lr = 0.0001
I0508 00:48:32.519796 17805 solver.cpp:240] Iteration 212, loss = 0.966761
I0508 00:48:32.519834 17805 solver.cpp:256]     Train net output #0: loss = 0.966761 (* 1 = 0.966761 loss)
I0508 00:48:32.519841 17805 sgd_solver.cpp:106] Iteration 212, lr = 0.0001
I0508 00:48:32.839184 17805 solver.cpp:240] Iteration 213, loss = 0.979274
I0508 00:48:32.839220 17805 solver.cpp:256]     Train net output #0: loss = 0.979274 (* 1 = 0.979274 loss)
I0508 00:48:32.839227 17805 sgd_solver.cpp:106] Iteration 213, lr = 0.0001
I0508 00:48:33.158361 17805 solver.cpp:240] Iteration 214, loss = 1.02088
I0508 00:48:33.158397 17805 solver.cpp:256]     Train net output #0: loss = 1.02088 (* 1 = 1.02088 loss)
I0508 00:48:33.158406 17805 sgd_solver.cpp:106] Iteration 214, lr = 0.0001
I0508 00:48:33.477159 17805 solver.cpp:240] Iteration 215, loss = 0.895363
I0508 00:48:33.477195 17805 solver.cpp:256]     Train net output #0: loss = 0.895363 (* 1 = 0.895363 loss)
I0508 00:48:33.477203 17805 sgd_solver.cpp:106] Iteration 215, lr = 0.0001
I0508 00:48:33.796098 17805 solver.cpp:240] Iteration 216, loss = 0.968699
I0508 00:48:33.796134 17805 solver.cpp:256]     Train net output #0: loss = 0.968699 (* 1 = 0.968699 loss)
I0508 00:48:33.796142 17805 sgd_solver.cpp:106] Iteration 216, lr = 0.0001
I0508 00:48:34.115058 17805 solver.cpp:240] Iteration 217, loss = 0.907909
I0508 00:48:34.115094 17805 solver.cpp:256]     Train net output #0: loss = 0.907909 (* 1 = 0.907909 loss)
I0508 00:48:34.115126 17805 sgd_solver.cpp:106] Iteration 217, lr = 0.0001
I0508 00:48:34.434283 17805 solver.cpp:240] Iteration 218, loss = 0.956506
I0508 00:48:34.434319 17805 solver.cpp:256]     Train net output #0: loss = 0.956506 (* 1 = 0.956506 loss)
I0508 00:48:34.434325 17805 sgd_solver.cpp:106] Iteration 218, lr = 0.0001
I0508 00:48:34.753057 17805 solver.cpp:240] Iteration 219, loss = 0.915682
I0508 00:48:34.753092 17805 solver.cpp:256]     Train net output #0: loss = 0.915682 (* 1 = 0.915682 loss)
I0508 00:48:34.753099 17805 sgd_solver.cpp:106] Iteration 219, lr = 0.0001
I0508 00:48:35.071071 17805 solver.cpp:240] Iteration 220, loss = 0.994161
I0508 00:48:35.071108 17805 solver.cpp:256]     Train net output #0: loss = 0.994161 (* 1 = 0.994161 loss)
I0508 00:48:35.071116 17805 sgd_solver.cpp:106] Iteration 220, lr = 0.0001
I0508 00:48:35.388180 17805 solver.cpp:240] Iteration 221, loss = 0.917853
I0508 00:48:35.388219 17805 solver.cpp:256]     Train net output #0: loss = 0.917853 (* 1 = 0.917853 loss)
I0508 00:48:35.388228 17805 sgd_solver.cpp:106] Iteration 221, lr = 0.0001
I0508 00:48:35.707841 17805 solver.cpp:240] Iteration 222, loss = 0.949824
I0508 00:48:35.707887 17805 solver.cpp:256]     Train net output #0: loss = 0.949824 (* 1 = 0.949824 loss)
I0508 00:48:35.707896 17805 sgd_solver.cpp:106] Iteration 222, lr = 0.0001
I0508 00:48:36.027679 17805 solver.cpp:240] Iteration 223, loss = 1.01013
I0508 00:48:36.027714 17805 solver.cpp:256]     Train net output #0: loss = 1.01013 (* 1 = 1.01013 loss)
I0508 00:48:36.027720 17805 sgd_solver.cpp:106] Iteration 223, lr = 0.0001
I0508 00:48:36.346662 17805 solver.cpp:240] Iteration 224, loss = 0.967046
I0508 00:48:36.346700 17805 solver.cpp:256]     Train net output #0: loss = 0.967046 (* 1 = 0.967046 loss)
I0508 00:48:36.346709 17805 sgd_solver.cpp:106] Iteration 224, lr = 0.0001
I0508 00:48:36.665802 17805 solver.cpp:240] Iteration 225, loss = 0.942883
I0508 00:48:36.665838 17805 solver.cpp:256]     Train net output #0: loss = 0.942883 (* 1 = 0.942883 loss)
I0508 00:48:36.665844 17805 sgd_solver.cpp:106] Iteration 225, lr = 0.0001
I0508 00:48:36.985102 17805 solver.cpp:240] Iteration 226, loss = 0.956517
I0508 00:48:36.985138 17805 solver.cpp:256]     Train net output #0: loss = 0.956517 (* 1 = 0.956517 loss)
I0508 00:48:36.985146 17805 sgd_solver.cpp:106] Iteration 226, lr = 0.0001
I0508 00:48:37.304630 17805 solver.cpp:240] Iteration 227, loss = 0.935826
I0508 00:48:37.304668 17805 solver.cpp:256]     Train net output #0: loss = 0.935826 (* 1 = 0.935826 loss)
I0508 00:48:37.304675 17805 sgd_solver.cpp:106] Iteration 227, lr = 0.0001
I0508 00:48:37.623685 17805 solver.cpp:240] Iteration 228, loss = 0.99223
I0508 00:48:37.623723 17805 solver.cpp:256]     Train net output #0: loss = 0.99223 (* 1 = 0.99223 loss)
I0508 00:48:37.623730 17805 sgd_solver.cpp:106] Iteration 228, lr = 0.0001
I0508 00:48:37.942927 17805 solver.cpp:240] Iteration 229, loss = 0.954005
I0508 00:48:37.942963 17805 solver.cpp:256]     Train net output #0: loss = 0.954005 (* 1 = 0.954005 loss)
I0508 00:48:37.942971 17805 sgd_solver.cpp:106] Iteration 229, lr = 0.0001
I0508 00:48:38.261615 17805 solver.cpp:240] Iteration 230, loss = 0.969432
I0508 00:48:38.261648 17805 solver.cpp:256]     Train net output #0: loss = 0.969432 (* 1 = 0.969432 loss)
I0508 00:48:38.261656 17805 sgd_solver.cpp:106] Iteration 230, lr = 0.0001
I0508 00:48:38.580288 17805 solver.cpp:240] Iteration 231, loss = 0.929746
I0508 00:48:38.580324 17805 solver.cpp:256]     Train net output #0: loss = 0.929746 (* 1 = 0.929746 loss)
I0508 00:48:38.580333 17805 sgd_solver.cpp:106] Iteration 231, lr = 0.0001
I0508 00:48:38.899487 17805 solver.cpp:240] Iteration 232, loss = 0.987268
I0508 00:48:38.899521 17805 solver.cpp:256]     Train net output #0: loss = 0.987268 (* 1 = 0.987268 loss)
I0508 00:48:38.899529 17805 sgd_solver.cpp:106] Iteration 232, lr = 0.0001
I0508 00:48:39.218590 17805 solver.cpp:240] Iteration 233, loss = 0.939724
I0508 00:48:39.218629 17805 solver.cpp:256]     Train net output #0: loss = 0.939724 (* 1 = 0.939724 loss)
I0508 00:48:39.218662 17805 sgd_solver.cpp:106] Iteration 233, lr = 0.0001
I0508 00:48:39.537493 17805 solver.cpp:240] Iteration 234, loss = 0.91331
I0508 00:48:39.537530 17805 solver.cpp:256]     Train net output #0: loss = 0.91331 (* 1 = 0.91331 loss)
I0508 00:48:39.537539 17805 sgd_solver.cpp:106] Iteration 234, lr = 0.0001
I0508 00:48:39.856431 17805 solver.cpp:240] Iteration 235, loss = 0.917159
I0508 00:48:39.856468 17805 solver.cpp:256]     Train net output #0: loss = 0.917159 (* 1 = 0.917159 loss)
I0508 00:48:39.856475 17805 sgd_solver.cpp:106] Iteration 235, lr = 0.0001
I0508 00:48:40.173024 17805 solver.cpp:240] Iteration 236, loss = 0.902135
I0508 00:48:40.173063 17805 solver.cpp:256]     Train net output #0: loss = 0.902135 (* 1 = 0.902135 loss)
I0508 00:48:40.173070 17805 sgd_solver.cpp:106] Iteration 236, lr = 0.0001
I0508 00:48:40.492221 17805 solver.cpp:240] Iteration 237, loss = 0.972012
I0508 00:48:40.492257 17805 solver.cpp:256]     Train net output #0: loss = 0.972012 (* 1 = 0.972012 loss)
I0508 00:48:40.492264 17805 sgd_solver.cpp:106] Iteration 237, lr = 0.0001
I0508 00:48:40.811431 17805 solver.cpp:240] Iteration 238, loss = 0.970497
I0508 00:48:40.811465 17805 solver.cpp:256]     Train net output #0: loss = 0.970497 (* 1 = 0.970497 loss)
I0508 00:48:40.811473 17805 sgd_solver.cpp:106] Iteration 238, lr = 0.0001
I0508 00:48:41.130606 17805 solver.cpp:240] Iteration 239, loss = 0.910227
I0508 00:48:41.130645 17805 solver.cpp:256]     Train net output #0: loss = 0.910227 (* 1 = 0.910227 loss)
I0508 00:48:41.130653 17805 sgd_solver.cpp:106] Iteration 239, lr = 0.0001
I0508 00:48:41.449132 17805 solver.cpp:240] Iteration 240, loss = 0.941939
I0508 00:48:41.449168 17805 solver.cpp:256]     Train net output #0: loss = 0.941939 (* 1 = 0.941939 loss)
I0508 00:48:41.449177 17805 sgd_solver.cpp:106] Iteration 240, lr = 0.0001
I0508 00:48:41.768262 17805 solver.cpp:240] Iteration 241, loss = 0.914501
I0508 00:48:41.768298 17805 solver.cpp:256]     Train net output #0: loss = 0.914501 (* 1 = 0.914501 loss)
I0508 00:48:41.768306 17805 sgd_solver.cpp:106] Iteration 241, lr = 0.0001
I0508 00:48:42.087282 17805 solver.cpp:240] Iteration 242, loss = 0.86721
I0508 00:48:42.087318 17805 solver.cpp:256]     Train net output #0: loss = 0.86721 (* 1 = 0.86721 loss)
I0508 00:48:42.087326 17805 sgd_solver.cpp:106] Iteration 242, lr = 0.0001
I0508 00:48:42.406560 17805 solver.cpp:240] Iteration 243, loss = 0.939347
I0508 00:48:42.406599 17805 solver.cpp:256]     Train net output #0: loss = 0.939347 (* 1 = 0.939347 loss)
I0508 00:48:42.406605 17805 sgd_solver.cpp:106] Iteration 243, lr = 0.0001
I0508 00:48:42.725762 17805 solver.cpp:240] Iteration 244, loss = 0.884195
I0508 00:48:42.725800 17805 solver.cpp:256]     Train net output #0: loss = 0.884195 (* 1 = 0.884195 loss)
I0508 00:48:42.725807 17805 sgd_solver.cpp:106] Iteration 244, lr = 0.0001
I0508 00:48:43.045047 17805 solver.cpp:240] Iteration 245, loss = 0.863263
I0508 00:48:43.045089 17805 solver.cpp:256]     Train net output #0: loss = 0.863263 (* 1 = 0.863263 loss)
I0508 00:48:43.045097 17805 sgd_solver.cpp:106] Iteration 245, lr = 0.0001
I0508 00:48:43.363922 17805 solver.cpp:240] Iteration 246, loss = 0.891676
I0508 00:48:43.363963 17805 solver.cpp:256]     Train net output #0: loss = 0.891676 (* 1 = 0.891676 loss)
I0508 00:48:43.363971 17805 sgd_solver.cpp:106] Iteration 246, lr = 0.0001
I0508 00:48:43.683418 17805 solver.cpp:240] Iteration 247, loss = 0.926224
I0508 00:48:43.683454 17805 solver.cpp:256]     Train net output #0: loss = 0.926224 (* 1 = 0.926224 loss)
I0508 00:48:43.683461 17805 sgd_solver.cpp:106] Iteration 247, lr = 0.0001
I0508 00:48:44.002449 17805 solver.cpp:240] Iteration 248, loss = 0.91173
I0508 00:48:44.002485 17805 solver.cpp:256]     Train net output #0: loss = 0.91173 (* 1 = 0.91173 loss)
I0508 00:48:44.002492 17805 sgd_solver.cpp:106] Iteration 248, lr = 0.0001
I0508 00:48:44.321727 17805 solver.cpp:240] Iteration 249, loss = 0.932857
I0508 00:48:44.321765 17805 solver.cpp:256]     Train net output #0: loss = 0.932857 (* 1 = 0.932857 loss)
I0508 00:48:44.321799 17805 sgd_solver.cpp:106] Iteration 249, lr = 0.0001
I0508 00:48:44.640986 17805 solver.cpp:240] Iteration 250, loss = 0.913968
I0508 00:48:44.641021 17805 solver.cpp:256]     Train net output #0: loss = 0.913968 (* 1 = 0.913968 loss)
I0508 00:48:44.641028 17805 sgd_solver.cpp:106] Iteration 250, lr = 0.0001
I0508 00:48:44.960167 17805 solver.cpp:240] Iteration 251, loss = 0.948614
I0508 00:48:44.960201 17805 solver.cpp:256]     Train net output #0: loss = 0.948614 (* 1 = 0.948614 loss)
I0508 00:48:44.960209 17805 sgd_solver.cpp:106] Iteration 251, lr = 0.0001
I0508 00:48:45.278470 17805 solver.cpp:240] Iteration 252, loss = 0.884689
I0508 00:48:45.278503 17805 solver.cpp:256]     Train net output #0: loss = 0.884689 (* 1 = 0.884689 loss)
I0508 00:48:45.278511 17805 sgd_solver.cpp:106] Iteration 252, lr = 0.0001
I0508 00:48:45.597841 17805 solver.cpp:240] Iteration 253, loss = 0.851797
I0508 00:48:45.597877 17805 solver.cpp:256]     Train net output #0: loss = 0.851797 (* 1 = 0.851797 loss)
I0508 00:48:45.597883 17805 sgd_solver.cpp:106] Iteration 253, lr = 0.0001
I0508 00:48:45.917065 17805 solver.cpp:240] Iteration 254, loss = 0.986215
I0508 00:48:45.917101 17805 solver.cpp:256]     Train net output #0: loss = 0.986215 (* 1 = 0.986215 loss)
I0508 00:48:45.917109 17805 sgd_solver.cpp:106] Iteration 254, lr = 0.0001
I0508 00:48:45.917420 17805 solver.cpp:349] Iteration 255, Testing net (#0)
I0508 00:48:45.917439 17805 net.cpp:693] Ignoring source layer silence
I0508 00:48:48.156301 17805 solver.cpp:416]     Test net output #0: accuracy_1 = 0.763557
I0508 00:48:48.156330 17805 solver.cpp:416]     Test net output #1: accuracy_5 = 0.879366
I0508 00:48:48.156340 17805 solver.cpp:416]     Test net output #2: loss = 1.07748 (* 1 = 1.07748 loss)
I0508 00:48:48.276952 17805 solver.cpp:240] Iteration 255, loss = 0.997738
I0508 00:48:48.276986 17805 solver.cpp:256]     Train net output #0: loss = 0.997738 (* 1 = 0.997738 loss)
I0508 00:48:48.276995 17805 sgd_solver.cpp:106] Iteration 255, lr = 0.0001
I0508 00:48:48.596101 17805 solver.cpp:240] Iteration 256, loss = 0.948262
I0508 00:48:48.596137 17805 solver.cpp:256]     Train net output #0: loss = 0.948262 (* 1 = 0.948262 loss)
I0508 00:48:48.596144 17805 sgd_solver.cpp:106] Iteration 256, lr = 0.0001
I0508 00:48:48.915349 17805 solver.cpp:240] Iteration 257, loss = 0.953763
I0508 00:48:48.915387 17805 solver.cpp:256]     Train net output #0: loss = 0.953763 (* 1 = 0.953763 loss)
I0508 00:48:48.915395 17805 sgd_solver.cpp:106] Iteration 257, lr = 0.0001
I0508 00:48:49.234228 17805 solver.cpp:240] Iteration 258, loss = 0.917459
I0508 00:48:49.235375 17805 solver.cpp:256]     Train net output #0: loss = 0.917459 (* 1 = 0.917459 loss)
I0508 00:48:49.235386 17805 sgd_solver.cpp:106] Iteration 258, lr = 0.0001
I0508 00:48:49.553417 17805 solver.cpp:240] Iteration 259, loss = 1.01591
I0508 00:48:49.553458 17805 solver.cpp:256]     Train net output #0: loss = 1.01591 (* 1 = 1.01591 loss)
I0508 00:48:49.553467 17805 sgd_solver.cpp:106] Iteration 259, lr = 0.0001
I0508 00:48:49.872545 17805 solver.cpp:240] Iteration 260, loss = 1.0235
I0508 00:48:49.872586 17805 solver.cpp:256]     Train net output #0: loss = 1.0235 (* 1 = 1.0235 loss)
I0508 00:48:49.872593 17805 sgd_solver.cpp:106] Iteration 260, lr = 0.0001
I0508 00:48:50.191402 17805 solver.cpp:240] Iteration 261, loss = 1.11238
I0508 00:48:50.191454 17805 solver.cpp:256]     Train net output #0: loss = 1.11238 (* 1 = 1.11238 loss)
I0508 00:48:50.191463 17805 sgd_solver.cpp:106] Iteration 261, lr = 0.0001
I0508 00:48:50.510610 17805 solver.cpp:240] Iteration 262, loss = 1.11079
I0508 00:48:50.510649 17805 solver.cpp:256]     Train net output #0: loss = 1.11079 (* 1 = 1.11079 loss)
I0508 00:48:50.510658 17805 sgd_solver.cpp:106] Iteration 262, lr = 0.0001
I0508 00:48:50.829980 17805 solver.cpp:240] Iteration 263, loss = 1.15305
I0508 00:48:50.830018 17805 solver.cpp:256]     Train net output #0: loss = 1.15305 (* 1 = 1.15305 loss)
I0508 00:48:50.830025 17805 sgd_solver.cpp:106] Iteration 263, lr = 0.0001
I0508 00:48:51.149178 17805 solver.cpp:240] Iteration 264, loss = 1.23636
I0508 00:48:51.149212 17805 solver.cpp:256]     Train net output #0: loss = 1.23636 (* 1 = 1.23636 loss)
I0508 00:48:51.149220 17805 sgd_solver.cpp:106] Iteration 264, lr = 0.0001
I0508 00:48:51.467806 17805 solver.cpp:240] Iteration 265, loss = 1.34877
I0508 00:48:51.467841 17805 solver.cpp:256]     Train net output #0: loss = 1.34877 (* 1 = 1.34877 loss)
I0508 00:48:51.467849 17805 sgd_solver.cpp:106] Iteration 265, lr = 0.0001
I0508 00:48:51.787226 17805 solver.cpp:240] Iteration 266, loss = 1.37886
I0508 00:48:51.787264 17805 solver.cpp:256]     Train net output #0: loss = 1.37886 (* 1 = 1.37886 loss)
I0508 00:48:51.787272 17805 sgd_solver.cpp:106] Iteration 266, lr = 0.0001
I0508 00:48:52.106408 17805 solver.cpp:240] Iteration 267, loss = 1.45981
I0508 00:48:52.106444 17805 solver.cpp:256]     Train net output #0: loss = 1.45981 (* 1 = 1.45981 loss)
I0508 00:48:52.106452 17805 sgd_solver.cpp:106] Iteration 267, lr = 0.0001
I0508 00:48:52.425452 17805 solver.cpp:240] Iteration 268, loss = 1.40846
I0508 00:48:52.425487 17805 solver.cpp:256]     Train net output #0: loss = 1.40846 (* 1 = 1.40846 loss)
I0508 00:48:52.425495 17805 sgd_solver.cpp:106] Iteration 268, lr = 0.0001
I0508 00:48:52.744602 17805 solver.cpp:240] Iteration 269, loss = 1.50807
I0508 00:48:52.744640 17805 solver.cpp:256]     Train net output #0: loss = 1.50807 (* 1 = 1.50807 loss)
I0508 00:48:52.744648 17805 sgd_solver.cpp:106] Iteration 269, lr = 0.0001
I0508 00:48:53.063807 17805 solver.cpp:240] Iteration 270, loss = 1.54805
I0508 00:48:53.063843 17805 solver.cpp:256]     Train net output #0: loss = 1.54805 (* 1 = 1.54805 loss)
I0508 00:48:53.063850 17805 sgd_solver.cpp:106] Iteration 270, lr = 0.0001
I0508 00:48:53.382827 17805 solver.cpp:240] Iteration 271, loss = 1.53
I0508 00:48:53.382863 17805 solver.cpp:256]     Train net output #0: loss = 1.53 (* 1 = 1.53 loss)
I0508 00:48:53.382871 17805 sgd_solver.cpp:106] Iteration 271, lr = 0.0001
I0508 00:48:53.701952 17805 solver.cpp:240] Iteration 272, loss = 1.71621
I0508 00:48:53.701987 17805 solver.cpp:256]     Train net output #0: loss = 1.71621 (* 1 = 1.71621 loss)
I0508 00:48:53.701994 17805 sgd_solver.cpp:106] Iteration 272, lr = 0.0001
I0508 00:48:54.021462 17805 solver.cpp:240] Iteration 273, loss = 1.61305
I0508 00:48:54.021497 17805 solver.cpp:256]     Train net output #0: loss = 1.61305 (* 1 = 1.61305 loss)
I0508 00:48:54.021504 17805 sgd_solver.cpp:106] Iteration 273, lr = 0.0001
I0508 00:48:54.340540 17805 solver.cpp:240] Iteration 274, loss = 1.66649
I0508 00:48:54.340575 17805 solver.cpp:256]     Train net output #0: loss = 1.66649 (* 1 = 1.66649 loss)
I0508 00:48:54.340607 17805 sgd_solver.cpp:106] Iteration 274, lr = 0.0001
I0508 00:48:54.659584 17805 solver.cpp:240] Iteration 275, loss = 1.78517
I0508 00:48:54.659623 17805 solver.cpp:256]     Train net output #0: loss = 1.78517 (* 1 = 1.78517 loss)
I0508 00:48:54.659631 17805 sgd_solver.cpp:106] Iteration 275, lr = 0.0001
I0508 00:48:54.978190 17805 solver.cpp:240] Iteration 276, loss = 1.85914
I0508 00:48:54.978224 17805 solver.cpp:256]     Train net output #0: loss = 1.85914 (* 1 = 1.85914 loss)
I0508 00:48:54.978233 17805 sgd_solver.cpp:106] Iteration 276, lr = 0.0001
I0508 00:48:55.297292 17805 solver.cpp:240] Iteration 277, loss = 1.86091
I0508 00:48:55.297334 17805 solver.cpp:256]     Train net output #0: loss = 1.86091 (* 1 = 1.86091 loss)
I0508 00:48:55.297343 17805 sgd_solver.cpp:106] Iteration 277, lr = 0.0001
I0508 00:48:55.616454 17805 solver.cpp:240] Iteration 278, loss = 1.83855
I0508 00:48:55.616488 17805 solver.cpp:256]     Train net output #0: loss = 1.83855 (* 1 = 1.83855 loss)
I0508 00:48:55.616497 17805 sgd_solver.cpp:106] Iteration 278, lr = 0.0001
I0508 00:48:55.935425 17805 solver.cpp:240] Iteration 279, loss = 1.93913
I0508 00:48:55.935461 17805 solver.cpp:256]     Train net output #0: loss = 1.93913 (* 1 = 1.93913 loss)
I0508 00:48:55.935468 17805 sgd_solver.cpp:106] Iteration 279, lr = 0.0001
I0508 00:48:56.254590 17805 solver.cpp:240] Iteration 280, loss = 1.94554
I0508 00:48:56.254626 17805 solver.cpp:256]     Train net output #0: loss = 1.94554 (* 1 = 1.94554 loss)
I0508 00:48:56.254634 17805 sgd_solver.cpp:106] Iteration 280, lr = 0.0001
I0508 00:48:56.571319 17805 solver.cpp:240] Iteration 281, loss = 1.88198
I0508 00:48:56.571357 17805 solver.cpp:256]     Train net output #0: loss = 1.88198 (* 1 = 1.88198 loss)
I0508 00:48:56.571363 17805 sgd_solver.cpp:106] Iteration 281, lr = 0.0001
I0508 00:48:56.890293 17805 solver.cpp:240] Iteration 282, loss = 2.01403
I0508 00:48:56.890334 17805 solver.cpp:256]     Train net output #0: loss = 2.01403 (* 1 = 2.01403 loss)
I0508 00:48:56.890342 17805 sgd_solver.cpp:106] Iteration 282, lr = 0.0001
I0508 00:48:57.209417 17805 solver.cpp:240] Iteration 283, loss = 2.08508
I0508 00:48:57.209460 17805 solver.cpp:256]     Train net output #0: loss = 2.08508 (* 1 = 2.08508 loss)
I0508 00:48:57.209468 17805 sgd_solver.cpp:106] Iteration 283, lr = 0.0001
I0508 00:48:57.528673 17805 solver.cpp:240] Iteration 284, loss = 2.21367
I0508 00:48:57.528712 17805 solver.cpp:256]     Train net output #0: loss = 2.21367 (* 1 = 2.21367 loss)
I0508 00:48:57.528719 17805 sgd_solver.cpp:106] Iteration 284, lr = 0.0001
I0508 00:48:57.847298 17805 solver.cpp:240] Iteration 285, loss = 2.19386
I0508 00:48:57.847334 17805 solver.cpp:256]     Train net output #0: loss = 2.19386 (* 1 = 2.19386 loss)
I0508 00:48:57.847342 17805 sgd_solver.cpp:106] Iteration 285, lr = 0.0001
I0508 00:48:58.166774 17805 solver.cpp:240] Iteration 286, loss = 2.33071
I0508 00:48:58.166815 17805 solver.cpp:256]     Train net output #0: loss = 2.33071 (* 1 = 2.33071 loss)
I0508 00:48:58.166823 17805 sgd_solver.cpp:106] Iteration 286, lr = 0.0001
I0508 00:48:58.486218 17805 solver.cpp:240] Iteration 287, loss = 2.35821
I0508 00:48:58.486253 17805 solver.cpp:256]     Train net output #0: loss = 2.35821 (* 1 = 2.35821 loss)
I0508 00:48:58.486260 17805 sgd_solver.cpp:106] Iteration 287, lr = 0.0001
I0508 00:48:58.805239 17805 solver.cpp:240] Iteration 288, loss = 2.41688
I0508 00:48:58.805275 17805 solver.cpp:256]     Train net output #0: loss = 2.41688 (* 1 = 2.41688 loss)
I0508 00:48:58.805284 17805 sgd_solver.cpp:106] Iteration 288, lr = 0.0001
I0508 00:48:59.124493 17805 solver.cpp:240] Iteration 289, loss = 2.53013
I0508 00:48:59.124529 17805 solver.cpp:256]     Train net output #0: loss = 2.53013 (* 1 = 2.53013 loss)
I0508 00:48:59.124537 17805 sgd_solver.cpp:106] Iteration 289, lr = 0.0001
I0508 00:48:59.443668 17805 solver.cpp:240] Iteration 290, loss = 2.57848
I0508 00:48:59.443703 17805 solver.cpp:256]     Train net output #0: loss = 2.57848 (* 1 = 2.57848 loss)
I0508 00:48:59.443737 17805 sgd_solver.cpp:106] Iteration 290, lr = 0.0001
I0508 00:48:59.763331 17805 solver.cpp:240] Iteration 291, loss = 2.6083
I0508 00:48:59.763367 17805 solver.cpp:256]     Train net output #0: loss = 2.6083 (* 1 = 2.6083 loss)
I0508 00:48:59.763375 17805 sgd_solver.cpp:106] Iteration 291, lr = 0.0001
I0508 00:49:00.082397 17805 solver.cpp:240] Iteration 292, loss = 2.55752
I0508 00:49:00.082432 17805 solver.cpp:256]     Train net output #0: loss = 2.55752 (* 1 = 2.55752 loss)
I0508 00:49:00.082440 17805 sgd_solver.cpp:106] Iteration 292, lr = 0.0001
I0508 00:49:00.401751 17805 solver.cpp:240] Iteration 293, loss = 2.63369
I0508 00:49:00.401784 17805 solver.cpp:256]     Train net output #0: loss = 2.63369 (* 1 = 2.63369 loss)
I0508 00:49:00.401793 17805 sgd_solver.cpp:106] Iteration 293, lr = 0.0001
I0508 00:49:00.720835 17805 solver.cpp:240] Iteration 294, loss = 2.69077
I0508 00:49:00.720871 17805 solver.cpp:256]     Train net output #0: loss = 2.69077 (* 1 = 2.69077 loss)
I0508 00:49:00.720881 17805 sgd_solver.cpp:106] Iteration 294, lr = 0.0001
I0508 00:49:01.039840 17805 solver.cpp:240] Iteration 295, loss = 2.71683
I0508 00:49:01.039887 17805 solver.cpp:256]     Train net output #0: loss = 2.71683 (* 1 = 2.71683 loss)
I0508 00:49:01.039896 17805 sgd_solver.cpp:106] Iteration 295, lr = 0.0001
I0508 00:49:01.358580 17805 solver.cpp:240] Iteration 296, loss = 2.7763
I0508 00:49:01.358616 17805 solver.cpp:256]     Train net output #0: loss = 2.7763 (* 1 = 2.7763 loss)
I0508 00:49:01.358624 17805 sgd_solver.cpp:106] Iteration 296, lr = 0.0001
