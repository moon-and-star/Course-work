I0411 13:16:38.835523 22203 caffe.cpp:217] Using GPUs 1
I0411 13:16:39.182438 22203 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0411 13:16:40.078106 22203 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_9/rtsd-r1/CoNorm/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_9/rtsd-r1/CoNorm/trial_1/test.prototxt"
test_iter: 8
test_interval: 25
base_lr: 0.001
display: 1
max_iter: 2500
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 250
snapshot_prefix: "./snapshots/experiment_9/rtsd-r1/CoNorm/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0411 13:16:40.078358 22203 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_9/rtsd-r1/CoNorm/trial_1/train.prototxt
I0411 13:16:40.078742 22203 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0411 13:16:40.078755 22203 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0411 13:16:40.078943 22203 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215689
    mirror: false
    crop_size: 48
    mean_value: 132
    mean_value: 132
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
I0411 13:16:40.079071 22203 layer_factory.hpp:77] Creating layer data
I0411 13:16:40.080375 22203 net.cpp:100] Creating Layer data
I0411 13:16:40.080394 22203 net.cpp:408] data -> data
I0411 13:16:40.080420 22203 net.cpp:408] data -> label
I0411 13:16:40.082379 22314 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0411 13:16:40.103518 22203 data_layer.cpp:41] output data size: 1024,3,48,48
I0411 13:16:40.170331 22203 net.cpp:150] Setting up data
I0411 13:16:40.170367 22203 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0411 13:16:40.170374 22203 net.cpp:157] Top shape: 1024 (1024)
I0411 13:16:40.170377 22203 net.cpp:165] Memory required for data: 28315648
I0411 13:16:40.170388 22203 layer_factory.hpp:77] Creating layer conv1
I0411 13:16:40.170414 22203 net.cpp:100] Creating Layer conv1
I0411 13:16:40.170423 22203 net.cpp:434] conv1 <- data
I0411 13:16:40.170438 22203 net.cpp:408] conv1 -> conv1
I0411 13:16:40.692241 22203 net.cpp:150] Setting up conv1
I0411 13:16:40.692284 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.692288 22203 net.cpp:165] Memory required for data: 750850048
I0411 13:16:40.692309 22203 layer_factory.hpp:77] Creating layer conv1_prescale
I0411 13:16:40.692325 22203 net.cpp:100] Creating Layer conv1_prescale
I0411 13:16:40.692329 22203 net.cpp:434] conv1_prescale <- conv1
I0411 13:16:40.692337 22203 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0411 13:16:40.692448 22203 net.cpp:150] Setting up conv1_prescale
I0411 13:16:40.692457 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.692461 22203 net.cpp:165] Memory required for data: 1473384448
I0411 13:16:40.692467 22203 layer_factory.hpp:77] Creating layer conv1_sTanH
I0411 13:16:40.692476 22203 net.cpp:100] Creating Layer conv1_sTanH
I0411 13:16:40.692478 22203 net.cpp:434] conv1_sTanH <- conv1
I0411 13:16:40.692482 22203 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0411 13:16:40.692683 22203 net.cpp:150] Setting up conv1_sTanH
I0411 13:16:40.692695 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.692698 22203 net.cpp:165] Memory required for data: 2195918848
I0411 13:16:40.692701 22203 layer_factory.hpp:77] Creating layer conv1_postscale
I0411 13:16:40.692709 22203 net.cpp:100] Creating Layer conv1_postscale
I0411 13:16:40.692713 22203 net.cpp:434] conv1_postscale <- conv1
I0411 13:16:40.692719 22203 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0411 13:16:40.692823 22203 net.cpp:150] Setting up conv1_postscale
I0411 13:16:40.692831 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.692834 22203 net.cpp:165] Memory required for data: 2918453248
I0411 13:16:40.692839 22203 layer_factory.hpp:77] Creating layer pool1
I0411 13:16:40.692847 22203 net.cpp:100] Creating Layer pool1
I0411 13:16:40.692849 22203 net.cpp:434] pool1 <- conv1
I0411 13:16:40.692857 22203 net.cpp:408] pool1 -> pool1
I0411 13:16:40.692939 22203 net.cpp:150] Setting up pool1
I0411 13:16:40.692950 22203 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0411 13:16:40.692953 22203 net.cpp:165] Memory required for data: 3099086848
I0411 13:16:40.692957 22203 layer_factory.hpp:77] Creating layer conv2
I0411 13:16:40.692968 22203 net.cpp:100] Creating Layer conv2
I0411 13:16:40.692975 22203 net.cpp:434] conv2 <- pool1
I0411 13:16:40.692980 22203 net.cpp:408] conv2 -> conv2
I0411 13:16:40.697348 22203 net.cpp:150] Setting up conv2
I0411 13:16:40.697366 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.697369 22203 net.cpp:165] Memory required for data: 3298152448
I0411 13:16:40.697381 22203 layer_factory.hpp:77] Creating layer conv2_prescale
I0411 13:16:40.697389 22203 net.cpp:100] Creating Layer conv2_prescale
I0411 13:16:40.697393 22203 net.cpp:434] conv2_prescale <- conv2
I0411 13:16:40.697398 22203 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0411 13:16:40.697511 22203 net.cpp:150] Setting up conv2_prescale
I0411 13:16:40.697520 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.697523 22203 net.cpp:165] Memory required for data: 3497218048
I0411 13:16:40.697528 22203 layer_factory.hpp:77] Creating layer conv2_sTanH
I0411 13:16:40.697536 22203 net.cpp:100] Creating Layer conv2_sTanH
I0411 13:16:40.697541 22203 net.cpp:434] conv2_sTanH <- conv2
I0411 13:16:40.697546 22203 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0411 13:16:40.698302 22203 net.cpp:150] Setting up conv2_sTanH
I0411 13:16:40.698320 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.698323 22203 net.cpp:165] Memory required for data: 3696283648
I0411 13:16:40.698328 22203 layer_factory.hpp:77] Creating layer conv2_postscale
I0411 13:16:40.698333 22203 net.cpp:100] Creating Layer conv2_postscale
I0411 13:16:40.698338 22203 net.cpp:434] conv2_postscale <- conv2
I0411 13:16:40.698343 22203 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0411 13:16:40.698443 22203 net.cpp:150] Setting up conv2_postscale
I0411 13:16:40.698453 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.698457 22203 net.cpp:165] Memory required for data: 3895349248
I0411 13:16:40.698462 22203 layer_factory.hpp:77] Creating layer pool2
I0411 13:16:40.698467 22203 net.cpp:100] Creating Layer pool2
I0411 13:16:40.698470 22203 net.cpp:434] pool2 <- conv2
I0411 13:16:40.698475 22203 net.cpp:408] pool2 -> pool2
I0411 13:16:40.698519 22203 net.cpp:150] Setting up pool2
I0411 13:16:40.698528 22203 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0411 13:16:40.698530 22203 net.cpp:165] Memory required for data: 3945115648
I0411 13:16:40.698534 22203 layer_factory.hpp:77] Creating layer conv3
I0411 13:16:40.698542 22203 net.cpp:100] Creating Layer conv3
I0411 13:16:40.698546 22203 net.cpp:434] conv3 <- pool2
I0411 13:16:40.698554 22203 net.cpp:408] conv3 -> conv3
I0411 13:16:40.704061 22203 net.cpp:150] Setting up conv3
I0411 13:16:40.704079 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.704083 22203 net.cpp:165] Memory required for data: 3981979648
I0411 13:16:40.704093 22203 layer_factory.hpp:77] Creating layer conv3_prescale
I0411 13:16:40.704102 22203 net.cpp:100] Creating Layer conv3_prescale
I0411 13:16:40.704107 22203 net.cpp:434] conv3_prescale <- conv3
I0411 13:16:40.704111 22203 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0411 13:16:40.704210 22203 net.cpp:150] Setting up conv3_prescale
I0411 13:16:40.704219 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.704222 22203 net.cpp:165] Memory required for data: 4018843648
I0411 13:16:40.704226 22203 layer_factory.hpp:77] Creating layer conv3_sTanH
I0411 13:16:40.704231 22203 net.cpp:100] Creating Layer conv3_sTanH
I0411 13:16:40.704234 22203 net.cpp:434] conv3_sTanH <- conv3
I0411 13:16:40.704241 22203 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0411 13:16:40.705168 22203 net.cpp:150] Setting up conv3_sTanH
I0411 13:16:40.705183 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.705186 22203 net.cpp:165] Memory required for data: 4055707648
I0411 13:16:40.705204 22203 layer_factory.hpp:77] Creating layer conv3_postscale
I0411 13:16:40.705214 22203 net.cpp:100] Creating Layer conv3_postscale
I0411 13:16:40.705219 22203 net.cpp:434] conv3_postscale <- conv3
I0411 13:16:40.705224 22203 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0411 13:16:40.705328 22203 net.cpp:150] Setting up conv3_postscale
I0411 13:16:40.705338 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.705340 22203 net.cpp:165] Memory required for data: 4092571648
I0411 13:16:40.705345 22203 layer_factory.hpp:77] Creating layer pool3
I0411 13:16:40.705351 22203 net.cpp:100] Creating Layer pool3
I0411 13:16:40.705354 22203 net.cpp:434] pool3 <- conv3
I0411 13:16:40.705360 22203 net.cpp:408] pool3 -> pool3
I0411 13:16:40.705400 22203 net.cpp:150] Setting up pool3
I0411 13:16:40.705409 22203 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0411 13:16:40.705411 22203 net.cpp:165] Memory required for data: 4101787648
I0411 13:16:40.705415 22203 layer_factory.hpp:77] Creating layer fc4_300
I0411 13:16:40.705425 22203 net.cpp:100] Creating Layer fc4_300
I0411 13:16:40.705428 22203 net.cpp:434] fc4_300 <- pool3
I0411 13:16:40.705433 22203 net.cpp:408] fc4_300 -> fc4_300
I0411 13:16:40.710891 22203 net.cpp:150] Setting up fc4_300
I0411 13:16:40.710908 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.710911 22203 net.cpp:165] Memory required for data: 4103016448
I0411 13:16:40.710918 22203 layer_factory.hpp:77] Creating layer fc4_prescale
I0411 13:16:40.710927 22203 net.cpp:100] Creating Layer fc4_prescale
I0411 13:16:40.710930 22203 net.cpp:434] fc4_prescale <- fc4_300
I0411 13:16:40.710937 22203 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0411 13:16:40.711027 22203 net.cpp:150] Setting up fc4_prescale
I0411 13:16:40.711036 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.711040 22203 net.cpp:165] Memory required for data: 4104245248
I0411 13:16:40.711043 22203 layer_factory.hpp:77] Creating layer fc4_sTanH
I0411 13:16:40.711048 22203 net.cpp:100] Creating Layer fc4_sTanH
I0411 13:16:40.711051 22203 net.cpp:434] fc4_sTanH <- fc4_300
I0411 13:16:40.711055 22203 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0411 13:16:40.711247 22203 net.cpp:150] Setting up fc4_sTanH
I0411 13:16:40.711258 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.711261 22203 net.cpp:165] Memory required for data: 4105474048
I0411 13:16:40.711264 22203 layer_factory.hpp:77] Creating layer fc4_postscale
I0411 13:16:40.711272 22203 net.cpp:100] Creating Layer fc4_postscale
I0411 13:16:40.711275 22203 net.cpp:434] fc4_postscale <- fc4_300
I0411 13:16:40.711280 22203 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0411 13:16:40.711379 22203 net.cpp:150] Setting up fc4_postscale
I0411 13:16:40.711387 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.711390 22203 net.cpp:165] Memory required for data: 4106702848
I0411 13:16:40.711395 22203 layer_factory.hpp:77] Creating layer drop4
I0411 13:16:40.711400 22203 net.cpp:100] Creating Layer drop4
I0411 13:16:40.711403 22203 net.cpp:434] drop4 <- fc4_300
I0411 13:16:40.711408 22203 net.cpp:395] drop4 -> fc4_300 (in-place)
I0411 13:16:40.711438 22203 net.cpp:150] Setting up drop4
I0411 13:16:40.711446 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.711448 22203 net.cpp:165] Memory required for data: 4107931648
I0411 13:16:40.711452 22203 layer_factory.hpp:77] Creating layer fc5_67
I0411 13:16:40.711459 22203 net.cpp:100] Creating Layer fc5_67
I0411 13:16:40.711462 22203 net.cpp:434] fc5_67 <- fc4_300
I0411 13:16:40.711467 22203 net.cpp:408] fc5_67 -> fc5_classes
I0411 13:16:40.713316 22203 net.cpp:150] Setting up fc5_67
I0411 13:16:40.713332 22203 net.cpp:157] Top shape: 1024 67 (68608)
I0411 13:16:40.713336 22203 net.cpp:165] Memory required for data: 4108206080
I0411 13:16:40.713348 22203 layer_factory.hpp:77] Creating layer loss
I0411 13:16:40.713356 22203 net.cpp:100] Creating Layer loss
I0411 13:16:40.713359 22203 net.cpp:434] loss <- fc5_classes
I0411 13:16:40.713363 22203 net.cpp:434] loss <- label
I0411 13:16:40.713384 22203 net.cpp:408] loss -> loss
I0411 13:16:40.713398 22203 layer_factory.hpp:77] Creating layer loss
I0411 13:16:40.713750 22203 net.cpp:150] Setting up loss
I0411 13:16:40.713762 22203 net.cpp:157] Top shape: (1)
I0411 13:16:40.713764 22203 net.cpp:160]     with loss weight 1
I0411 13:16:40.713785 22203 net.cpp:165] Memory required for data: 4108206084
I0411 13:16:40.713789 22203 net.cpp:226] loss needs backward computation.
I0411 13:16:40.713796 22203 net.cpp:226] fc5_67 needs backward computation.
I0411 13:16:40.713799 22203 net.cpp:226] drop4 needs backward computation.
I0411 13:16:40.713802 22203 net.cpp:226] fc4_postscale needs backward computation.
I0411 13:16:40.713804 22203 net.cpp:226] fc4_sTanH needs backward computation.
I0411 13:16:40.713807 22203 net.cpp:226] fc4_prescale needs backward computation.
I0411 13:16:40.713810 22203 net.cpp:226] fc4_300 needs backward computation.
I0411 13:16:40.713812 22203 net.cpp:226] pool3 needs backward computation.
I0411 13:16:40.713815 22203 net.cpp:226] conv3_postscale needs backward computation.
I0411 13:16:40.713819 22203 net.cpp:226] conv3_sTanH needs backward computation.
I0411 13:16:40.713821 22203 net.cpp:226] conv3_prescale needs backward computation.
I0411 13:16:40.713824 22203 net.cpp:226] conv3 needs backward computation.
I0411 13:16:40.713826 22203 net.cpp:226] pool2 needs backward computation.
I0411 13:16:40.713829 22203 net.cpp:226] conv2_postscale needs backward computation.
I0411 13:16:40.713832 22203 net.cpp:226] conv2_sTanH needs backward computation.
I0411 13:16:40.713835 22203 net.cpp:226] conv2_prescale needs backward computation.
I0411 13:16:40.713837 22203 net.cpp:226] conv2 needs backward computation.
I0411 13:16:40.713841 22203 net.cpp:226] pool1 needs backward computation.
I0411 13:16:40.713843 22203 net.cpp:226] conv1_postscale needs backward computation.
I0411 13:16:40.713846 22203 net.cpp:226] conv1_sTanH needs backward computation.
I0411 13:16:40.713850 22203 net.cpp:226] conv1_prescale needs backward computation.
I0411 13:16:40.713851 22203 net.cpp:226] conv1 needs backward computation.
I0411 13:16:40.713855 22203 net.cpp:228] data does not need backward computation.
I0411 13:16:40.713858 22203 net.cpp:270] This network produces output loss
I0411 13:16:40.713878 22203 net.cpp:283] Network initialization done.
I0411 13:16:40.714157 22203 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_9/rtsd-r1/CoNorm/trial_1/test.prototxt
I0411 13:16:40.714345 22203 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215689
    mirror: false
    crop_size: 48
    mean_value: 133
    mean_value: 133
    mean_value: 132
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
    bias_term: false
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
    bias_term: false
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0411 13:16:40.714471 22203 layer_factory.hpp:77] Creating layer data
I0411 13:16:40.715147 22203 net.cpp:100] Creating Layer data
I0411 13:16:40.715158 22203 net.cpp:408] data -> data
I0411 13:16:40.715169 22203 net.cpp:408] data -> label
I0411 13:16:40.716940 22384 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0411 13:16:40.717090 22203 data_layer.cpp:41] output data size: 1024,3,48,48
I0411 13:16:40.775475 22203 net.cpp:150] Setting up data
I0411 13:16:40.775540 22203 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0411 13:16:40.775547 22203 net.cpp:157] Top shape: 1024 (1024)
I0411 13:16:40.775550 22203 net.cpp:165] Memory required for data: 28315648
I0411 13:16:40.775557 22203 layer_factory.hpp:77] Creating layer label_data_1_split
I0411 13:16:40.775571 22203 net.cpp:100] Creating Layer label_data_1_split
I0411 13:16:40.775575 22203 net.cpp:434] label_data_1_split <- label
I0411 13:16:40.775584 22203 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0411 13:16:40.775598 22203 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0411 13:16:40.775631 22203 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0411 13:16:40.775712 22203 net.cpp:150] Setting up label_data_1_split
I0411 13:16:40.775720 22203 net.cpp:157] Top shape: 1024 (1024)
I0411 13:16:40.775723 22203 net.cpp:157] Top shape: 1024 (1024)
I0411 13:16:40.775727 22203 net.cpp:157] Top shape: 1024 (1024)
I0411 13:16:40.775729 22203 net.cpp:165] Memory required for data: 28327936
I0411 13:16:40.775732 22203 layer_factory.hpp:77] Creating layer conv1
I0411 13:16:40.775744 22203 net.cpp:100] Creating Layer conv1
I0411 13:16:40.775749 22203 net.cpp:434] conv1 <- data
I0411 13:16:40.775760 22203 net.cpp:408] conv1 -> conv1
I0411 13:16:40.777884 22203 net.cpp:150] Setting up conv1
I0411 13:16:40.777904 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.777906 22203 net.cpp:165] Memory required for data: 750862336
I0411 13:16:40.777918 22203 layer_factory.hpp:77] Creating layer conv1_prescale
I0411 13:16:40.777930 22203 net.cpp:100] Creating Layer conv1_prescale
I0411 13:16:40.777933 22203 net.cpp:434] conv1_prescale <- conv1
I0411 13:16:40.777938 22203 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0411 13:16:40.778046 22203 net.cpp:150] Setting up conv1_prescale
I0411 13:16:40.778056 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.778059 22203 net.cpp:165] Memory required for data: 1473396736
I0411 13:16:40.778065 22203 layer_factory.hpp:77] Creating layer conv1_sTanH
I0411 13:16:40.778074 22203 net.cpp:100] Creating Layer conv1_sTanH
I0411 13:16:40.778077 22203 net.cpp:434] conv1_sTanH <- conv1
I0411 13:16:40.778082 22203 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0411 13:16:40.778277 22203 net.cpp:150] Setting up conv1_sTanH
I0411 13:16:40.778290 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.778293 22203 net.cpp:165] Memory required for data: 2195931136
I0411 13:16:40.778296 22203 layer_factory.hpp:77] Creating layer conv1_postscale
I0411 13:16:40.778302 22203 net.cpp:100] Creating Layer conv1_postscale
I0411 13:16:40.778306 22203 net.cpp:434] conv1_postscale <- conv1
I0411 13:16:40.778311 22203 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0411 13:16:40.778425 22203 net.cpp:150] Setting up conv1_postscale
I0411 13:16:40.778434 22203 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0411 13:16:40.778437 22203 net.cpp:165] Memory required for data: 2918465536
I0411 13:16:40.778442 22203 layer_factory.hpp:77] Creating layer pool1
I0411 13:16:40.778453 22203 net.cpp:100] Creating Layer pool1
I0411 13:16:40.778456 22203 net.cpp:434] pool1 <- conv1
I0411 13:16:40.778462 22203 net.cpp:408] pool1 -> pool1
I0411 13:16:40.778506 22203 net.cpp:150] Setting up pool1
I0411 13:16:40.778513 22203 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0411 13:16:40.778517 22203 net.cpp:165] Memory required for data: 3099099136
I0411 13:16:40.778519 22203 layer_factory.hpp:77] Creating layer conv2
I0411 13:16:40.778528 22203 net.cpp:100] Creating Layer conv2
I0411 13:16:40.778533 22203 net.cpp:434] conv2 <- pool1
I0411 13:16:40.778538 22203 net.cpp:408] conv2 -> conv2
I0411 13:16:40.785396 22203 net.cpp:150] Setting up conv2
I0411 13:16:40.785418 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.785423 22203 net.cpp:165] Memory required for data: 3298164736
I0411 13:16:40.785434 22203 layer_factory.hpp:77] Creating layer conv2_prescale
I0411 13:16:40.785445 22203 net.cpp:100] Creating Layer conv2_prescale
I0411 13:16:40.785449 22203 net.cpp:434] conv2_prescale <- conv2
I0411 13:16:40.785459 22203 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0411 13:16:40.785578 22203 net.cpp:150] Setting up conv2_prescale
I0411 13:16:40.785588 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.785590 22203 net.cpp:165] Memory required for data: 3497230336
I0411 13:16:40.785594 22203 layer_factory.hpp:77] Creating layer conv2_sTanH
I0411 13:16:40.785601 22203 net.cpp:100] Creating Layer conv2_sTanH
I0411 13:16:40.785604 22203 net.cpp:434] conv2_sTanH <- conv2
I0411 13:16:40.785609 22203 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0411 13:16:40.787259 22203 net.cpp:150] Setting up conv2_sTanH
I0411 13:16:40.787276 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.787279 22203 net.cpp:165] Memory required for data: 3696295936
I0411 13:16:40.787283 22203 layer_factory.hpp:77] Creating layer conv2_postscale
I0411 13:16:40.787292 22203 net.cpp:100] Creating Layer conv2_postscale
I0411 13:16:40.787295 22203 net.cpp:434] conv2_postscale <- conv2
I0411 13:16:40.787302 22203 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0411 13:16:40.787413 22203 net.cpp:150] Setting up conv2_postscale
I0411 13:16:40.787422 22203 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0411 13:16:40.787426 22203 net.cpp:165] Memory required for data: 3895361536
I0411 13:16:40.787431 22203 layer_factory.hpp:77] Creating layer pool2
I0411 13:16:40.787437 22203 net.cpp:100] Creating Layer pool2
I0411 13:16:40.787441 22203 net.cpp:434] pool2 <- conv2
I0411 13:16:40.787447 22203 net.cpp:408] pool2 -> pool2
I0411 13:16:40.787500 22203 net.cpp:150] Setting up pool2
I0411 13:16:40.787509 22203 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0411 13:16:40.787511 22203 net.cpp:165] Memory required for data: 3945127936
I0411 13:16:40.787514 22203 layer_factory.hpp:77] Creating layer conv3
I0411 13:16:40.787524 22203 net.cpp:100] Creating Layer conv3
I0411 13:16:40.787528 22203 net.cpp:434] conv3 <- pool2
I0411 13:16:40.787533 22203 net.cpp:408] conv3 -> conv3
I0411 13:16:40.793614 22203 net.cpp:150] Setting up conv3
I0411 13:16:40.793632 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.793637 22203 net.cpp:165] Memory required for data: 3981991936
I0411 13:16:40.793648 22203 layer_factory.hpp:77] Creating layer conv3_prescale
I0411 13:16:40.793659 22203 net.cpp:100] Creating Layer conv3_prescale
I0411 13:16:40.793664 22203 net.cpp:434] conv3_prescale <- conv3
I0411 13:16:40.793671 22203 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0411 13:16:40.793773 22203 net.cpp:150] Setting up conv3_prescale
I0411 13:16:40.793782 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.793787 22203 net.cpp:165] Memory required for data: 4018855936
I0411 13:16:40.793792 22203 layer_factory.hpp:77] Creating layer conv3_sTanH
I0411 13:16:40.793797 22203 net.cpp:100] Creating Layer conv3_sTanH
I0411 13:16:40.793800 22203 net.cpp:434] conv3_sTanH <- conv3
I0411 13:16:40.793807 22203 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0411 13:16:40.800052 22203 net.cpp:150] Setting up conv3_sTanH
I0411 13:16:40.800072 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.800076 22203 net.cpp:165] Memory required for data: 4055719936
I0411 13:16:40.800079 22203 layer_factory.hpp:77] Creating layer conv3_postscale
I0411 13:16:40.800089 22203 net.cpp:100] Creating Layer conv3_postscale
I0411 13:16:40.800096 22203 net.cpp:434] conv3_postscale <- conv3
I0411 13:16:40.800101 22203 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0411 13:16:40.800213 22203 net.cpp:150] Setting up conv3_postscale
I0411 13:16:40.800222 22203 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0411 13:16:40.800225 22203 net.cpp:165] Memory required for data: 4092583936
I0411 13:16:40.800231 22203 layer_factory.hpp:77] Creating layer pool3
I0411 13:16:40.800241 22203 net.cpp:100] Creating Layer pool3
I0411 13:16:40.800246 22203 net.cpp:434] pool3 <- conv3
I0411 13:16:40.800252 22203 net.cpp:408] pool3 -> pool3
I0411 13:16:40.800297 22203 net.cpp:150] Setting up pool3
I0411 13:16:40.800304 22203 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0411 13:16:40.800307 22203 net.cpp:165] Memory required for data: 4101799936
I0411 13:16:40.800310 22203 layer_factory.hpp:77] Creating layer fc4_300
I0411 13:16:40.800318 22203 net.cpp:100] Creating Layer fc4_300
I0411 13:16:40.800321 22203 net.cpp:434] fc4_300 <- pool3
I0411 13:16:40.800326 22203 net.cpp:408] fc4_300 -> fc4_300
I0411 13:16:40.808344 22203 net.cpp:150] Setting up fc4_300
I0411 13:16:40.808363 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.808367 22203 net.cpp:165] Memory required for data: 4103028736
I0411 13:16:40.808393 22203 layer_factory.hpp:77] Creating layer fc4_prescale
I0411 13:16:40.808405 22203 net.cpp:100] Creating Layer fc4_prescale
I0411 13:16:40.808409 22203 net.cpp:434] fc4_prescale <- fc4_300
I0411 13:16:40.808416 22203 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0411 13:16:40.808519 22203 net.cpp:150] Setting up fc4_prescale
I0411 13:16:40.808531 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.808533 22203 net.cpp:165] Memory required for data: 4104257536
I0411 13:16:40.808537 22203 layer_factory.hpp:77] Creating layer fc4_sTanH
I0411 13:16:40.808543 22203 net.cpp:100] Creating Layer fc4_sTanH
I0411 13:16:40.808547 22203 net.cpp:434] fc4_sTanH <- fc4_300
I0411 13:16:40.808552 22203 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0411 13:16:40.808758 22203 net.cpp:150] Setting up fc4_sTanH
I0411 13:16:40.808770 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.808773 22203 net.cpp:165] Memory required for data: 4105486336
I0411 13:16:40.808776 22203 layer_factory.hpp:77] Creating layer fc4_postscale
I0411 13:16:40.808782 22203 net.cpp:100] Creating Layer fc4_postscale
I0411 13:16:40.808786 22203 net.cpp:434] fc4_postscale <- fc4_300
I0411 13:16:40.808799 22203 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0411 13:16:40.808907 22203 net.cpp:150] Setting up fc4_postscale
I0411 13:16:40.808921 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.808924 22203 net.cpp:165] Memory required for data: 4106715136
I0411 13:16:40.808929 22203 layer_factory.hpp:77] Creating layer drop4
I0411 13:16:40.808941 22203 net.cpp:100] Creating Layer drop4
I0411 13:16:40.808948 22203 net.cpp:434] drop4 <- fc4_300
I0411 13:16:40.808955 22203 net.cpp:395] drop4 -> fc4_300 (in-place)
I0411 13:16:40.808984 22203 net.cpp:150] Setting up drop4
I0411 13:16:40.808993 22203 net.cpp:157] Top shape: 1024 300 (307200)
I0411 13:16:40.808995 22203 net.cpp:165] Memory required for data: 4107943936
I0411 13:16:40.808998 22203 layer_factory.hpp:77] Creating layer fc5_67
I0411 13:16:40.809005 22203 net.cpp:100] Creating Layer fc5_67
I0411 13:16:40.809007 22203 net.cpp:434] fc5_67 <- fc4_300
I0411 13:16:40.809012 22203 net.cpp:408] fc5_67 -> fc5_classes
I0411 13:16:40.809264 22203 net.cpp:150] Setting up fc5_67
I0411 13:16:40.809273 22203 net.cpp:157] Top shape: 1024 67 (68608)
I0411 13:16:40.809276 22203 net.cpp:165] Memory required for data: 4108218368
I0411 13:16:40.809286 22203 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0411 13:16:40.809298 22203 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0411 13:16:40.809304 22203 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0411 13:16:40.809310 22203 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0411 13:16:40.809319 22203 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0411 13:16:40.809324 22203 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0411 13:16:40.809386 22203 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0411 13:16:40.809392 22203 net.cpp:157] Top shape: 1024 67 (68608)
I0411 13:16:40.809396 22203 net.cpp:157] Top shape: 1024 67 (68608)
I0411 13:16:40.809399 22203 net.cpp:157] Top shape: 1024 67 (68608)
I0411 13:16:40.809401 22203 net.cpp:165] Memory required for data: 4109041664
I0411 13:16:40.809415 22203 layer_factory.hpp:77] Creating layer loss
I0411 13:16:40.809422 22203 net.cpp:100] Creating Layer loss
I0411 13:16:40.809425 22203 net.cpp:434] loss <- fc5_classes_fc5_67_0_split_0
I0411 13:16:40.809429 22203 net.cpp:434] loss <- label_data_1_split_0
I0411 13:16:40.809434 22203 net.cpp:408] loss -> loss
I0411 13:16:40.809448 22203 layer_factory.hpp:77] Creating layer loss
I0411 13:16:40.809805 22203 net.cpp:150] Setting up loss
I0411 13:16:40.809818 22203 net.cpp:157] Top shape: (1)
I0411 13:16:40.809821 22203 net.cpp:160]     with loss weight 1
I0411 13:16:40.809834 22203 net.cpp:165] Memory required for data: 4109041668
I0411 13:16:40.809836 22203 layer_factory.hpp:77] Creating layer accuracy_1
I0411 13:16:40.809859 22203 net.cpp:100] Creating Layer accuracy_1
I0411 13:16:40.809864 22203 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0411 13:16:40.809870 22203 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0411 13:16:40.809875 22203 net.cpp:408] accuracy_1 -> accuracy_1
I0411 13:16:40.809885 22203 net.cpp:150] Setting up accuracy_1
I0411 13:16:40.809890 22203 net.cpp:157] Top shape: (1)
I0411 13:16:40.809893 22203 net.cpp:165] Memory required for data: 4109041672
I0411 13:16:40.809896 22203 layer_factory.hpp:77] Creating layer accuracy_5
I0411 13:16:40.809902 22203 net.cpp:100] Creating Layer accuracy_5
I0411 13:16:40.809906 22203 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0411 13:16:40.809909 22203 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0411 13:16:40.809914 22203 net.cpp:408] accuracy_5 -> accuracy_5
I0411 13:16:40.809921 22203 net.cpp:150] Setting up accuracy_5
I0411 13:16:40.809924 22203 net.cpp:157] Top shape: (1)
I0411 13:16:40.809926 22203 net.cpp:165] Memory required for data: 4109041676
I0411 13:16:40.809929 22203 net.cpp:228] accuracy_5 does not need backward computation.
I0411 13:16:40.809933 22203 net.cpp:228] accuracy_1 does not need backward computation.
I0411 13:16:40.809937 22203 net.cpp:226] loss needs backward computation.
I0411 13:16:40.809940 22203 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0411 13:16:40.809943 22203 net.cpp:226] fc5_67 needs backward computation.
I0411 13:16:40.809947 22203 net.cpp:226] drop4 needs backward computation.
I0411 13:16:40.809950 22203 net.cpp:226] fc4_postscale needs backward computation.
I0411 13:16:40.809953 22203 net.cpp:226] fc4_sTanH needs backward computation.
I0411 13:16:40.809955 22203 net.cpp:226] fc4_prescale needs backward computation.
I0411 13:16:40.809958 22203 net.cpp:226] fc4_300 needs backward computation.
I0411 13:16:40.809962 22203 net.cpp:226] pool3 needs backward computation.
I0411 13:16:40.809963 22203 net.cpp:226] conv3_postscale needs backward computation.
I0411 13:16:40.809967 22203 net.cpp:226] conv3_sTanH needs backward computation.
I0411 13:16:40.809970 22203 net.cpp:226] conv3_prescale needs backward computation.
I0411 13:16:40.809973 22203 net.cpp:226] conv3 needs backward computation.
I0411 13:16:40.809975 22203 net.cpp:226] pool2 needs backward computation.
I0411 13:16:40.809978 22203 net.cpp:226] conv2_postscale needs backward computation.
I0411 13:16:40.809981 22203 net.cpp:226] conv2_sTanH needs backward computation.
I0411 13:16:40.809984 22203 net.cpp:226] conv2_prescale needs backward computation.
I0411 13:16:40.809986 22203 net.cpp:226] conv2 needs backward computation.
I0411 13:16:40.809990 22203 net.cpp:226] pool1 needs backward computation.
I0411 13:16:40.809993 22203 net.cpp:226] conv1_postscale needs backward computation.
I0411 13:16:40.809998 22203 net.cpp:226] conv1_sTanH needs backward computation.
I0411 13:16:40.809999 22203 net.cpp:226] conv1_prescale needs backward computation.
I0411 13:16:40.810003 22203 net.cpp:226] conv1 needs backward computation.
I0411 13:16:40.810006 22203 net.cpp:228] label_data_1_split does not need backward computation.
I0411 13:16:40.810010 22203 net.cpp:228] data does not need backward computation.
I0411 13:16:40.810012 22203 net.cpp:270] This network produces output accuracy_1
I0411 13:16:40.810015 22203 net.cpp:270] This network produces output accuracy_5
I0411 13:16:40.810019 22203 net.cpp:270] This network produces output loss
I0411 13:16:40.810039 22203 net.cpp:283] Network initialization done.
I0411 13:16:40.810111 22203 solver.cpp:72] Solver scaffolding done.
I0411 13:16:40.811039 22203 caffe.cpp:251] Starting Optimization
I0411 13:16:40.811048 22203 solver.cpp:291] Solving 
I0411 13:16:40.811051 22203 solver.cpp:292] Learning Rate Policy: step
I0411 13:16:40.815613 22203 solver.cpp:349] Iteration 0, Testing net (#0)
I0411 13:16:41.924643 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.00793457
I0411 13:16:41.924671 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0469971
I0411 13:16:41.924705 22203 solver.cpp:416]     Test net output #2: loss = 4.36455 (* 1 = 4.36455 loss)
I0411 13:16:42.082443 22203 solver.cpp:240] Iteration 0, loss = 4.37322
I0411 13:16:42.082476 22203 solver.cpp:256]     Train net output #0: loss = 4.37322 (* 1 = 4.37322 loss)
I0411 13:16:42.082497 22203 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0411 13:16:42.448709 22203 solver.cpp:240] Iteration 1, loss = 4.43551
I0411 13:16:42.448741 22203 solver.cpp:256]     Train net output #0: loss = 4.43551 (* 1 = 4.43551 loss)
I0411 13:16:42.448750 22203 sgd_solver.cpp:106] Iteration 1, lr = 0.001
I0411 13:16:42.820175 22203 solver.cpp:240] Iteration 2, loss = 5.45425
I0411 13:16:42.820233 22203 solver.cpp:256]     Train net output #0: loss = 5.45425 (* 1 = 5.45425 loss)
I0411 13:16:42.820241 22203 sgd_solver.cpp:106] Iteration 2, lr = 0.001
I0411 13:16:43.191722 22203 solver.cpp:240] Iteration 3, loss = 6.15992
I0411 13:16:43.191754 22203 solver.cpp:256]     Train net output #0: loss = 6.15992 (* 1 = 6.15992 loss)
I0411 13:16:43.191762 22203 sgd_solver.cpp:106] Iteration 3, lr = 0.001
I0411 13:16:43.567595 22203 solver.cpp:240] Iteration 4, loss = 8.06835
I0411 13:16:43.567629 22203 solver.cpp:256]     Train net output #0: loss = 8.06835 (* 1 = 8.06835 loss)
I0411 13:16:43.567637 22203 sgd_solver.cpp:106] Iteration 4, lr = 0.001
I0411 13:16:43.939275 22203 solver.cpp:240] Iteration 5, loss = 9.57925
I0411 13:16:43.939321 22203 solver.cpp:256]     Train net output #0: loss = 9.57925 (* 1 = 9.57925 loss)
I0411 13:16:43.939329 22203 sgd_solver.cpp:106] Iteration 5, lr = 0.001
I0411 13:16:44.310901 22203 solver.cpp:240] Iteration 6, loss = 11.2821
I0411 13:16:44.310938 22203 solver.cpp:256]     Train net output #0: loss = 11.2821 (* 1 = 11.2821 loss)
I0411 13:16:44.310947 22203 sgd_solver.cpp:106] Iteration 6, lr = 0.001
I0411 13:16:44.684253 22203 solver.cpp:240] Iteration 7, loss = 13.3722
I0411 13:16:44.684288 22203 solver.cpp:256]     Train net output #0: loss = 13.3722 (* 1 = 13.3722 loss)
I0411 13:16:44.684295 22203 sgd_solver.cpp:106] Iteration 7, lr = 0.001
I0411 13:16:45.055260 22203 solver.cpp:240] Iteration 8, loss = 14.3902
I0411 13:16:45.055295 22203 solver.cpp:256]     Train net output #0: loss = 14.3902 (* 1 = 14.3902 loss)
I0411 13:16:45.055305 22203 sgd_solver.cpp:106] Iteration 8, lr = 0.001
I0411 13:16:45.429855 22203 solver.cpp:240] Iteration 9, loss = 15.0267
I0411 13:16:45.429890 22203 solver.cpp:256]     Train net output #0: loss = 15.0267 (* 1 = 15.0267 loss)
I0411 13:16:45.429899 22203 sgd_solver.cpp:106] Iteration 9, lr = 0.001
I0411 13:16:45.800622 22203 solver.cpp:240] Iteration 10, loss = 15.4471
I0411 13:16:45.800657 22203 solver.cpp:256]     Train net output #0: loss = 15.4471 (* 1 = 15.4471 loss)
I0411 13:16:45.800667 22203 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0411 13:16:46.173162 22203 solver.cpp:240] Iteration 11, loss = 15.6675
I0411 13:16:46.173198 22203 solver.cpp:256]     Train net output #0: loss = 15.6675 (* 1 = 15.6675 loss)
I0411 13:16:46.173207 22203 sgd_solver.cpp:106] Iteration 11, lr = 0.001
I0411 13:16:46.543020 22203 solver.cpp:240] Iteration 12, loss = 15.5
I0411 13:16:46.543056 22203 solver.cpp:256]     Train net output #0: loss = 15.5 (* 1 = 15.5 loss)
I0411 13:16:46.543066 22203 sgd_solver.cpp:106] Iteration 12, lr = 0.001
I0411 13:16:46.919061 22203 solver.cpp:240] Iteration 13, loss = 15.5433
I0411 13:16:46.919097 22203 solver.cpp:256]     Train net output #0: loss = 15.5433 (* 1 = 15.5433 loss)
I0411 13:16:46.919107 22203 sgd_solver.cpp:106] Iteration 13, lr = 0.001
I0411 13:16:47.292984 22203 solver.cpp:240] Iteration 14, loss = 14.7276
I0411 13:16:47.293018 22203 solver.cpp:256]     Train net output #0: loss = 14.7276 (* 1 = 14.7276 loss)
I0411 13:16:47.293026 22203 sgd_solver.cpp:106] Iteration 14, lr = 0.001
I0411 13:16:47.664772 22203 solver.cpp:240] Iteration 15, loss = 14.084
I0411 13:16:47.664805 22203 solver.cpp:256]     Train net output #0: loss = 14.084 (* 1 = 14.084 loss)
I0411 13:16:47.664814 22203 sgd_solver.cpp:106] Iteration 15, lr = 0.001
I0411 13:16:48.037128 22203 solver.cpp:240] Iteration 16, loss = 13.6547
I0411 13:16:48.037163 22203 solver.cpp:256]     Train net output #0: loss = 13.6547 (* 1 = 13.6547 loss)
I0411 13:16:48.037171 22203 sgd_solver.cpp:106] Iteration 16, lr = 0.001
I0411 13:16:48.410271 22203 solver.cpp:240] Iteration 17, loss = 12.7676
I0411 13:16:48.410306 22203 solver.cpp:256]     Train net output #0: loss = 12.7676 (* 1 = 12.7676 loss)
I0411 13:16:48.410315 22203 sgd_solver.cpp:106] Iteration 17, lr = 0.001
I0411 13:16:48.785084 22203 solver.cpp:240] Iteration 18, loss = 12.2578
I0411 13:16:48.785121 22203 solver.cpp:256]     Train net output #0: loss = 12.2578 (* 1 = 12.2578 loss)
I0411 13:16:48.785130 22203 sgd_solver.cpp:106] Iteration 18, lr = 0.001
I0411 13:16:49.157539 22203 solver.cpp:240] Iteration 19, loss = 11.7136
I0411 13:16:49.157573 22203 solver.cpp:256]     Train net output #0: loss = 11.7136 (* 1 = 11.7136 loss)
I0411 13:16:49.157582 22203 sgd_solver.cpp:106] Iteration 19, lr = 0.001
I0411 13:16:49.529723 22203 solver.cpp:240] Iteration 20, loss = 11.0696
I0411 13:16:49.529754 22203 solver.cpp:256]     Train net output #0: loss = 11.0696 (* 1 = 11.0696 loss)
I0411 13:16:49.529774 22203 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0411 13:16:49.900005 22203 solver.cpp:240] Iteration 21, loss = 10.355
I0411 13:16:49.900038 22203 solver.cpp:256]     Train net output #0: loss = 10.355 (* 1 = 10.355 loss)
I0411 13:16:49.900046 22203 sgd_solver.cpp:106] Iteration 21, lr = 0.001
I0411 13:16:50.274777 22203 solver.cpp:240] Iteration 22, loss = 9.96732
I0411 13:16:50.274812 22203 solver.cpp:256]     Train net output #0: loss = 9.96732 (* 1 = 9.96732 loss)
I0411 13:16:50.274821 22203 sgd_solver.cpp:106] Iteration 22, lr = 0.001
I0411 13:16:50.649567 22203 solver.cpp:240] Iteration 23, loss = 9.17697
I0411 13:16:50.649603 22203 solver.cpp:256]     Train net output #0: loss = 9.17697 (* 1 = 9.17697 loss)
I0411 13:16:50.649611 22203 sgd_solver.cpp:106] Iteration 23, lr = 0.001
I0411 13:16:51.020387 22203 solver.cpp:240] Iteration 24, loss = 8.50177
I0411 13:16:51.020418 22203 solver.cpp:256]     Train net output #0: loss = 8.50177 (* 1 = 8.50177 loss)
I0411 13:16:51.020426 22203 sgd_solver.cpp:106] Iteration 24, lr = 0.001
I0411 13:16:51.020738 22203 solver.cpp:349] Iteration 25, Testing net (#0)
I0411 13:16:52.313040 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.13501
I0411 13:16:52.313067 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.248535
I0411 13:16:52.313076 22203 solver.cpp:416]     Test net output #2: loss = 7.00156 (* 1 = 7.00156 loss)
I0411 13:16:52.443084 22203 solver.cpp:240] Iteration 25, loss = 7.86746
I0411 13:16:52.443117 22203 solver.cpp:256]     Train net output #0: loss = 7.86746 (* 1 = 7.86746 loss)
I0411 13:16:52.443126 22203 sgd_solver.cpp:106] Iteration 25, lr = 0.001
I0411 13:16:52.817436 22203 solver.cpp:240] Iteration 26, loss = 7.37609
I0411 13:16:52.817468 22203 solver.cpp:256]     Train net output #0: loss = 7.37609 (* 1 = 7.37609 loss)
I0411 13:16:52.817476 22203 sgd_solver.cpp:106] Iteration 26, lr = 0.001
I0411 13:16:53.189479 22203 solver.cpp:240] Iteration 27, loss = 7.10794
I0411 13:16:53.189512 22203 solver.cpp:256]     Train net output #0: loss = 7.10794 (* 1 = 7.10794 loss)
I0411 13:16:53.189520 22203 sgd_solver.cpp:106] Iteration 27, lr = 0.001
I0411 13:16:53.562695 22203 solver.cpp:240] Iteration 28, loss = 6.62985
I0411 13:16:53.562727 22203 solver.cpp:256]     Train net output #0: loss = 6.62985 (* 1 = 6.62985 loss)
I0411 13:16:53.562736 22203 sgd_solver.cpp:106] Iteration 28, lr = 0.001
I0411 13:16:53.939126 22203 solver.cpp:240] Iteration 29, loss = 6.28516
I0411 13:16:53.939168 22203 solver.cpp:256]     Train net output #0: loss = 6.28516 (* 1 = 6.28516 loss)
I0411 13:16:53.939175 22203 sgd_solver.cpp:106] Iteration 29, lr = 0.001
I0411 13:16:54.314637 22203 solver.cpp:240] Iteration 30, loss = 6.04522
I0411 13:16:54.314669 22203 solver.cpp:256]     Train net output #0: loss = 6.04522 (* 1 = 6.04522 loss)
I0411 13:16:54.314677 22203 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0411 13:16:54.687546 22203 solver.cpp:240] Iteration 31, loss = 5.79989
I0411 13:16:54.687578 22203 solver.cpp:256]     Train net output #0: loss = 5.79989 (* 1 = 5.79989 loss)
I0411 13:16:54.687587 22203 sgd_solver.cpp:106] Iteration 31, lr = 0.001
I0411 13:16:55.060492 22203 solver.cpp:240] Iteration 32, loss = 5.6474
I0411 13:16:55.060526 22203 solver.cpp:256]     Train net output #0: loss = 5.6474 (* 1 = 5.6474 loss)
I0411 13:16:55.060534 22203 sgd_solver.cpp:106] Iteration 32, lr = 0.001
I0411 13:16:55.433419 22203 solver.cpp:240] Iteration 33, loss = 5.24798
I0411 13:16:55.433454 22203 solver.cpp:256]     Train net output #0: loss = 5.24798 (* 1 = 5.24798 loss)
I0411 13:16:55.433460 22203 sgd_solver.cpp:106] Iteration 33, lr = 0.001
I0411 13:16:55.807006 22203 solver.cpp:240] Iteration 34, loss = 5.10187
I0411 13:16:55.807052 22203 solver.cpp:256]     Train net output #0: loss = 5.10187 (* 1 = 5.10187 loss)
I0411 13:16:55.807071 22203 sgd_solver.cpp:106] Iteration 34, lr = 0.001
I0411 13:16:56.180191 22203 solver.cpp:240] Iteration 35, loss = 4.80662
I0411 13:16:56.180223 22203 solver.cpp:256]     Train net output #0: loss = 4.80662 (* 1 = 4.80662 loss)
I0411 13:16:56.180232 22203 sgd_solver.cpp:106] Iteration 35, lr = 0.001
I0411 13:16:56.553318 22203 solver.cpp:240] Iteration 36, loss = 4.79301
I0411 13:16:56.553352 22203 solver.cpp:256]     Train net output #0: loss = 4.79301 (* 1 = 4.79301 loss)
I0411 13:16:56.553360 22203 sgd_solver.cpp:106] Iteration 36, lr = 0.001
I0411 13:16:56.925106 22203 solver.cpp:240] Iteration 37, loss = 4.66921
I0411 13:16:56.925137 22203 solver.cpp:256]     Train net output #0: loss = 4.66921 (* 1 = 4.66921 loss)
I0411 13:16:56.925145 22203 sgd_solver.cpp:106] Iteration 37, lr = 0.001
I0411 13:16:57.297075 22203 solver.cpp:240] Iteration 38, loss = 4.61141
I0411 13:16:57.297107 22203 solver.cpp:256]     Train net output #0: loss = 4.61141 (* 1 = 4.61141 loss)
I0411 13:16:57.297116 22203 sgd_solver.cpp:106] Iteration 38, lr = 0.001
I0411 13:16:57.672672 22203 solver.cpp:240] Iteration 39, loss = 4.64421
I0411 13:16:57.672705 22203 solver.cpp:256]     Train net output #0: loss = 4.64421 (* 1 = 4.64421 loss)
I0411 13:16:57.672713 22203 sgd_solver.cpp:106] Iteration 39, lr = 0.001
I0411 13:16:58.045214 22203 solver.cpp:240] Iteration 40, loss = 4.62027
I0411 13:16:58.045248 22203 solver.cpp:256]     Train net output #0: loss = 4.62027 (* 1 = 4.62027 loss)
I0411 13:16:58.045255 22203 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0411 13:16:58.418443 22203 solver.cpp:240] Iteration 41, loss = 4.66879
I0411 13:16:58.418480 22203 solver.cpp:256]     Train net output #0: loss = 4.66879 (* 1 = 4.66879 loss)
I0411 13:16:58.418489 22203 sgd_solver.cpp:106] Iteration 41, lr = 0.001
I0411 13:16:58.797055 22203 solver.cpp:240] Iteration 42, loss = 4.61428
I0411 13:16:58.797087 22203 solver.cpp:256]     Train net output #0: loss = 4.61428 (* 1 = 4.61428 loss)
I0411 13:16:58.797096 22203 sgd_solver.cpp:106] Iteration 42, lr = 0.001
I0411 13:16:59.172052 22203 solver.cpp:240] Iteration 43, loss = 4.78488
I0411 13:16:59.172085 22203 solver.cpp:256]     Train net output #0: loss = 4.78488 (* 1 = 4.78488 loss)
I0411 13:16:59.172092 22203 sgd_solver.cpp:106] Iteration 43, lr = 0.001
I0411 13:16:59.543607 22203 solver.cpp:240] Iteration 44, loss = 4.65278
I0411 13:16:59.543645 22203 solver.cpp:256]     Train net output #0: loss = 4.65278 (* 1 = 4.65278 loss)
I0411 13:16:59.543653 22203 sgd_solver.cpp:106] Iteration 44, lr = 0.001
I0411 13:16:59.917771 22203 solver.cpp:240] Iteration 45, loss = 4.55328
I0411 13:16:59.917815 22203 solver.cpp:256]     Train net output #0: loss = 4.55328 (* 1 = 4.55328 loss)
I0411 13:16:59.917825 22203 sgd_solver.cpp:106] Iteration 45, lr = 0.001
I0411 13:17:00.294960 22203 solver.cpp:240] Iteration 46, loss = 4.81099
I0411 13:17:00.294999 22203 solver.cpp:256]     Train net output #0: loss = 4.81099 (* 1 = 4.81099 loss)
I0411 13:17:00.295009 22203 sgd_solver.cpp:106] Iteration 46, lr = 0.001
I0411 13:17:00.667927 22203 solver.cpp:240] Iteration 47, loss = 4.74825
I0411 13:17:00.667985 22203 solver.cpp:256]     Train net output #0: loss = 4.74825 (* 1 = 4.74825 loss)
I0411 13:17:00.667994 22203 sgd_solver.cpp:106] Iteration 47, lr = 0.001
I0411 13:17:01.042210 22203 solver.cpp:240] Iteration 48, loss = 4.68199
I0411 13:17:01.042249 22203 solver.cpp:256]     Train net output #0: loss = 4.68199 (* 1 = 4.68199 loss)
I0411 13:17:01.042259 22203 sgd_solver.cpp:106] Iteration 48, lr = 0.001
I0411 13:17:01.416148 22203 solver.cpp:240] Iteration 49, loss = 4.7377
I0411 13:17:01.416182 22203 solver.cpp:256]     Train net output #0: loss = 4.7377 (* 1 = 4.7377 loss)
I0411 13:17:01.416190 22203 sgd_solver.cpp:106] Iteration 49, lr = 0.001
I0411 13:17:01.416503 22203 solver.cpp:349] Iteration 50, Testing net (#0)
I0411 13:17:02.714238 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0422363
I0411 13:17:02.714267 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.288208
I0411 13:17:02.714275 22203 solver.cpp:416]     Test net output #2: loss = 4.28527 (* 1 = 4.28527 loss)
I0411 13:17:02.844487 22203 solver.cpp:240] Iteration 50, loss = 4.49124
I0411 13:17:02.844521 22203 solver.cpp:256]     Train net output #0: loss = 4.49124 (* 1 = 4.49124 loss)
I0411 13:17:02.844528 22203 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0411 13:17:03.220181 22203 solver.cpp:240] Iteration 51, loss = 4.56731
I0411 13:17:03.220216 22203 solver.cpp:256]     Train net output #0: loss = 4.56731 (* 1 = 4.56731 loss)
I0411 13:17:03.220224 22203 sgd_solver.cpp:106] Iteration 51, lr = 0.001
I0411 13:17:03.593464 22203 solver.cpp:240] Iteration 52, loss = 4.61634
I0411 13:17:03.593500 22203 solver.cpp:256]     Train net output #0: loss = 4.61634 (* 1 = 4.61634 loss)
I0411 13:17:03.593508 22203 sgd_solver.cpp:106] Iteration 52, lr = 0.001
I0411 13:17:03.965155 22203 solver.cpp:240] Iteration 53, loss = 4.63386
I0411 13:17:03.965188 22203 solver.cpp:256]     Train net output #0: loss = 4.63386 (* 1 = 4.63386 loss)
I0411 13:17:03.965196 22203 sgd_solver.cpp:106] Iteration 53, lr = 0.001
I0411 13:17:04.339396 22203 solver.cpp:240] Iteration 54, loss = 4.65645
I0411 13:17:04.339429 22203 solver.cpp:256]     Train net output #0: loss = 4.65645 (* 1 = 4.65645 loss)
I0411 13:17:04.339437 22203 sgd_solver.cpp:106] Iteration 54, lr = 0.001
I0411 13:17:04.714996 22203 solver.cpp:240] Iteration 55, loss = 4.65417
I0411 13:17:04.715031 22203 solver.cpp:256]     Train net output #0: loss = 4.65417 (* 1 = 4.65417 loss)
I0411 13:17:04.715039 22203 sgd_solver.cpp:106] Iteration 55, lr = 0.001
I0411 13:17:05.089727 22203 solver.cpp:240] Iteration 56, loss = 4.54309
I0411 13:17:05.089762 22203 solver.cpp:256]     Train net output #0: loss = 4.54309 (* 1 = 4.54309 loss)
I0411 13:17:05.089771 22203 sgd_solver.cpp:106] Iteration 56, lr = 0.001
I0411 13:17:05.460817 22203 solver.cpp:240] Iteration 57, loss = 4.57984
I0411 13:17:05.460853 22203 solver.cpp:256]     Train net output #0: loss = 4.57984 (* 1 = 4.57984 loss)
I0411 13:17:05.460861 22203 sgd_solver.cpp:106] Iteration 57, lr = 0.001
I0411 13:17:05.839753 22203 solver.cpp:240] Iteration 58, loss = 4.58886
I0411 13:17:05.839792 22203 solver.cpp:256]     Train net output #0: loss = 4.58886 (* 1 = 4.58886 loss)
I0411 13:17:05.839799 22203 sgd_solver.cpp:106] Iteration 58, lr = 0.001
I0411 13:17:06.214937 22203 solver.cpp:240] Iteration 59, loss = 4.57994
I0411 13:17:06.214969 22203 solver.cpp:256]     Train net output #0: loss = 4.57994 (* 1 = 4.57994 loss)
I0411 13:17:06.214977 22203 sgd_solver.cpp:106] Iteration 59, lr = 0.001
I0411 13:17:06.586715 22203 solver.cpp:240] Iteration 60, loss = 4.51046
I0411 13:17:06.586750 22203 solver.cpp:256]     Train net output #0: loss = 4.51046 (* 1 = 4.51046 loss)
I0411 13:17:06.586758 22203 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0411 13:17:06.962062 22203 solver.cpp:240] Iteration 61, loss = 4.60647
I0411 13:17:06.962095 22203 solver.cpp:256]     Train net output #0: loss = 4.60647 (* 1 = 4.60647 loss)
I0411 13:17:06.962103 22203 sgd_solver.cpp:106] Iteration 61, lr = 0.001
I0411 13:17:07.340772 22203 solver.cpp:240] Iteration 62, loss = 4.42241
I0411 13:17:07.340833 22203 solver.cpp:256]     Train net output #0: loss = 4.42241 (* 1 = 4.42241 loss)
I0411 13:17:07.340847 22203 sgd_solver.cpp:106] Iteration 62, lr = 0.001
I0411 13:17:07.716437 22203 solver.cpp:240] Iteration 63, loss = 4.48018
I0411 13:17:07.716471 22203 solver.cpp:256]     Train net output #0: loss = 4.48018 (* 1 = 4.48018 loss)
I0411 13:17:07.716480 22203 sgd_solver.cpp:106] Iteration 63, lr = 0.001
I0411 13:17:08.087373 22203 solver.cpp:240] Iteration 64, loss = 4.55172
I0411 13:17:08.087409 22203 solver.cpp:256]     Train net output #0: loss = 4.55172 (* 1 = 4.55172 loss)
I0411 13:17:08.087416 22203 sgd_solver.cpp:106] Iteration 64, lr = 0.001
I0411 13:17:08.462420 22203 solver.cpp:240] Iteration 65, loss = 4.54702
I0411 13:17:08.462455 22203 solver.cpp:256]     Train net output #0: loss = 4.54702 (* 1 = 4.54702 loss)
I0411 13:17:08.462463 22203 sgd_solver.cpp:106] Iteration 65, lr = 0.001
I0411 13:17:08.838179 22203 solver.cpp:240] Iteration 66, loss = 4.46292
I0411 13:17:08.838362 22203 solver.cpp:256]     Train net output #0: loss = 4.46292 (* 1 = 4.46292 loss)
I0411 13:17:08.838373 22203 sgd_solver.cpp:106] Iteration 66, lr = 0.001
I0411 13:17:09.214509 22203 solver.cpp:240] Iteration 67, loss = 4.36603
I0411 13:17:09.214545 22203 solver.cpp:256]     Train net output #0: loss = 4.36603 (* 1 = 4.36603 loss)
I0411 13:17:09.214552 22203 sgd_solver.cpp:106] Iteration 67, lr = 0.001
I0411 13:17:09.587168 22203 solver.cpp:240] Iteration 68, loss = 4.44602
I0411 13:17:09.587258 22203 solver.cpp:256]     Train net output #0: loss = 4.44602 (* 1 = 4.44602 loss)
I0411 13:17:09.587288 22203 sgd_solver.cpp:106] Iteration 68, lr = 0.001
I0411 13:17:09.962751 22203 solver.cpp:240] Iteration 69, loss = 4.37692
I0411 13:17:09.962785 22203 solver.cpp:256]     Train net output #0: loss = 4.37692 (* 1 = 4.37692 loss)
I0411 13:17:09.962792 22203 sgd_solver.cpp:106] Iteration 69, lr = 0.001
I0411 13:17:10.337317 22203 solver.cpp:240] Iteration 70, loss = 4.40175
I0411 13:17:10.337352 22203 solver.cpp:256]     Train net output #0: loss = 4.40175 (* 1 = 4.40175 loss)
I0411 13:17:10.337359 22203 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0411 13:17:10.712699 22203 solver.cpp:240] Iteration 71, loss = 4.49868
I0411 13:17:10.712745 22203 solver.cpp:256]     Train net output #0: loss = 4.49868 (* 1 = 4.49868 loss)
I0411 13:17:10.712754 22203 sgd_solver.cpp:106] Iteration 71, lr = 0.001
I0411 13:17:11.086349 22203 solver.cpp:240] Iteration 72, loss = 4.4002
I0411 13:17:11.086382 22203 solver.cpp:256]     Train net output #0: loss = 4.4002 (* 1 = 4.4002 loss)
I0411 13:17:11.086391 22203 sgd_solver.cpp:106] Iteration 72, lr = 0.001
I0411 13:17:11.458818 22203 solver.cpp:240] Iteration 73, loss = 4.34568
I0411 13:17:11.458853 22203 solver.cpp:256]     Train net output #0: loss = 4.34568 (* 1 = 4.34568 loss)
I0411 13:17:11.458860 22203 sgd_solver.cpp:106] Iteration 73, lr = 0.001
I0411 13:17:11.832253 22203 solver.cpp:240] Iteration 74, loss = 4.43119
I0411 13:17:11.832298 22203 solver.cpp:256]     Train net output #0: loss = 4.43119 (* 1 = 4.43119 loss)
I0411 13:17:11.832307 22203 sgd_solver.cpp:106] Iteration 74, lr = 0.001
I0411 13:17:11.832635 22203 solver.cpp:349] Iteration 75, Testing net (#0)
I0411 13:17:13.131832 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0423584
I0411 13:17:13.131860 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.273071
I0411 13:17:13.131870 22203 solver.cpp:416]     Test net output #2: loss = 3.82161 (* 1 = 3.82161 loss)
I0411 13:17:13.260291 22203 solver.cpp:240] Iteration 75, loss = 4.27665
I0411 13:17:13.260325 22203 solver.cpp:256]     Train net output #0: loss = 4.27665 (* 1 = 4.27665 loss)
I0411 13:17:13.260334 22203 sgd_solver.cpp:106] Iteration 75, lr = 0.001
I0411 13:17:13.636072 22203 solver.cpp:240] Iteration 76, loss = 4.2312
I0411 13:17:13.636106 22203 solver.cpp:256]     Train net output #0: loss = 4.2312 (* 1 = 4.2312 loss)
I0411 13:17:13.636114 22203 sgd_solver.cpp:106] Iteration 76, lr = 0.001
I0411 13:17:14.014174 22203 solver.cpp:240] Iteration 77, loss = 4.32429
I0411 13:17:14.014210 22203 solver.cpp:256]     Train net output #0: loss = 4.32429 (* 1 = 4.32429 loss)
I0411 13:17:14.014219 22203 sgd_solver.cpp:106] Iteration 77, lr = 0.001
I0411 13:17:14.391119 22203 solver.cpp:240] Iteration 78, loss = 4.34912
I0411 13:17:14.391155 22203 solver.cpp:256]     Train net output #0: loss = 4.34912 (* 1 = 4.34912 loss)
I0411 13:17:14.391165 22203 sgd_solver.cpp:106] Iteration 78, lr = 0.001
I0411 13:17:14.766778 22203 solver.cpp:240] Iteration 79, loss = 4.25572
I0411 13:17:14.766824 22203 solver.cpp:256]     Train net output #0: loss = 4.25572 (* 1 = 4.25572 loss)
I0411 13:17:14.766832 22203 sgd_solver.cpp:106] Iteration 79, lr = 0.001
I0411 13:17:15.142892 22203 solver.cpp:240] Iteration 80, loss = 4.46022
I0411 13:17:15.142926 22203 solver.cpp:256]     Train net output #0: loss = 4.46022 (* 1 = 4.46022 loss)
I0411 13:17:15.142935 22203 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0411 13:17:15.515442 22203 solver.cpp:240] Iteration 81, loss = 4.33871
I0411 13:17:15.515499 22203 solver.cpp:256]     Train net output #0: loss = 4.33871 (* 1 = 4.33871 loss)
I0411 13:17:15.515508 22203 sgd_solver.cpp:106] Iteration 81, lr = 0.001
I0411 13:17:15.893612 22203 solver.cpp:240] Iteration 82, loss = 4.19557
I0411 13:17:15.893646 22203 solver.cpp:256]     Train net output #0: loss = 4.19557 (* 1 = 4.19557 loss)
I0411 13:17:15.893654 22203 sgd_solver.cpp:106] Iteration 82, lr = 0.001
I0411 13:17:16.270715 22203 solver.cpp:240] Iteration 83, loss = 4.23582
I0411 13:17:16.270746 22203 solver.cpp:256]     Train net output #0: loss = 4.23582 (* 1 = 4.23582 loss)
I0411 13:17:16.270754 22203 sgd_solver.cpp:106] Iteration 83, lr = 0.001
I0411 13:17:16.646916 22203 solver.cpp:240] Iteration 84, loss = 4.24596
I0411 13:17:16.646961 22203 solver.cpp:256]     Train net output #0: loss = 4.24596 (* 1 = 4.24596 loss)
I0411 13:17:16.646978 22203 sgd_solver.cpp:106] Iteration 84, lr = 0.001
I0411 13:17:17.021113 22203 solver.cpp:240] Iteration 85, loss = 4.32284
I0411 13:17:17.021147 22203 solver.cpp:256]     Train net output #0: loss = 4.32284 (* 1 = 4.32284 loss)
I0411 13:17:17.021157 22203 sgd_solver.cpp:106] Iteration 85, lr = 0.001
I0411 13:17:17.399018 22203 solver.cpp:240] Iteration 86, loss = 4.30584
I0411 13:17:17.399061 22203 solver.cpp:256]     Train net output #0: loss = 4.30584 (* 1 = 4.30584 loss)
I0411 13:17:17.399070 22203 sgd_solver.cpp:106] Iteration 86, lr = 0.001
I0411 13:17:17.774916 22203 solver.cpp:240] Iteration 87, loss = 4.21952
I0411 13:17:17.774948 22203 solver.cpp:256]     Train net output #0: loss = 4.21952 (* 1 = 4.21952 loss)
I0411 13:17:17.774956 22203 sgd_solver.cpp:106] Iteration 87, lr = 0.001
I0411 13:17:18.150588 22203 solver.cpp:240] Iteration 88, loss = 4.31394
I0411 13:17:18.150620 22203 solver.cpp:256]     Train net output #0: loss = 4.31394 (* 1 = 4.31394 loss)
I0411 13:17:18.150629 22203 sgd_solver.cpp:106] Iteration 88, lr = 0.001
I0411 13:17:18.525322 22203 solver.cpp:240] Iteration 89, loss = 4.32125
I0411 13:17:18.525357 22203 solver.cpp:256]     Train net output #0: loss = 4.32125 (* 1 = 4.32125 loss)
I0411 13:17:18.525364 22203 sgd_solver.cpp:106] Iteration 89, lr = 0.001
I0411 13:17:18.903025 22203 solver.cpp:240] Iteration 90, loss = 4.25429
I0411 13:17:18.903059 22203 solver.cpp:256]     Train net output #0: loss = 4.25429 (* 1 = 4.25429 loss)
I0411 13:17:18.903066 22203 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0411 13:17:19.280040 22203 solver.cpp:240] Iteration 91, loss = 4.29614
I0411 13:17:19.280072 22203 solver.cpp:256]     Train net output #0: loss = 4.29614 (* 1 = 4.29614 loss)
I0411 13:17:19.280081 22203 sgd_solver.cpp:106] Iteration 91, lr = 0.001
I0411 13:17:19.655122 22203 solver.cpp:240] Iteration 92, loss = 4.26841
I0411 13:17:19.655154 22203 solver.cpp:256]     Train net output #0: loss = 4.26841 (* 1 = 4.26841 loss)
I0411 13:17:19.655163 22203 sgd_solver.cpp:106] Iteration 92, lr = 0.001
I0411 13:17:20.029899 22203 solver.cpp:240] Iteration 93, loss = 4.23907
I0411 13:17:20.029937 22203 solver.cpp:256]     Train net output #0: loss = 4.23907 (* 1 = 4.23907 loss)
I0411 13:17:20.029947 22203 sgd_solver.cpp:106] Iteration 93, lr = 0.001
I0411 13:17:20.407793 22203 solver.cpp:240] Iteration 94, loss = 4.1442
I0411 13:17:20.407829 22203 solver.cpp:256]     Train net output #0: loss = 4.1442 (* 1 = 4.1442 loss)
I0411 13:17:20.407838 22203 sgd_solver.cpp:106] Iteration 94, lr = 0.001
I0411 13:17:20.784379 22203 solver.cpp:240] Iteration 95, loss = 4.22826
I0411 13:17:20.784416 22203 solver.cpp:256]     Train net output #0: loss = 4.22826 (* 1 = 4.22826 loss)
I0411 13:17:20.784425 22203 sgd_solver.cpp:106] Iteration 95, lr = 0.001
I0411 13:17:21.160920 22203 solver.cpp:240] Iteration 96, loss = 4.33844
I0411 13:17:21.160954 22203 solver.cpp:256]     Train net output #0: loss = 4.33844 (* 1 = 4.33844 loss)
I0411 13:17:21.160962 22203 sgd_solver.cpp:106] Iteration 96, lr = 0.001
I0411 13:17:21.534165 22203 solver.cpp:240] Iteration 97, loss = 4.23915
I0411 13:17:21.534198 22203 solver.cpp:256]     Train net output #0: loss = 4.23915 (* 1 = 4.23915 loss)
I0411 13:17:21.534235 22203 sgd_solver.cpp:106] Iteration 97, lr = 0.001
I0411 13:17:21.911917 22203 solver.cpp:240] Iteration 98, loss = 4.36571
I0411 13:17:21.911950 22203 solver.cpp:256]     Train net output #0: loss = 4.36571 (* 1 = 4.36571 loss)
I0411 13:17:21.911958 22203 sgd_solver.cpp:106] Iteration 98, lr = 0.001
I0411 13:17:22.288780 22203 solver.cpp:240] Iteration 99, loss = 4.25347
I0411 13:17:22.288813 22203 solver.cpp:256]     Train net output #0: loss = 4.25347 (* 1 = 4.25347 loss)
I0411 13:17:22.288821 22203 sgd_solver.cpp:106] Iteration 99, lr = 0.001
I0411 13:17:22.289142 22203 solver.cpp:349] Iteration 100, Testing net (#0)
I0411 13:17:23.592806 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.136108
I0411 13:17:23.592834 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.29895
I0411 13:17:23.592844 22203 solver.cpp:416]     Test net output #2: loss = 3.79851 (* 1 = 3.79851 loss)
I0411 13:17:23.722782 22203 solver.cpp:240] Iteration 100, loss = 4.31464
I0411 13:17:23.722816 22203 solver.cpp:256]     Train net output #0: loss = 4.31464 (* 1 = 4.31464 loss)
I0411 13:17:23.722825 22203 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0411 13:17:24.099616 22203 solver.cpp:240] Iteration 101, loss = 4.24538
I0411 13:17:24.099647 22203 solver.cpp:256]     Train net output #0: loss = 4.24538 (* 1 = 4.24538 loss)
I0411 13:17:24.099656 22203 sgd_solver.cpp:106] Iteration 101, lr = 0.001
I0411 13:17:24.475852 22203 solver.cpp:240] Iteration 102, loss = 4.32214
I0411 13:17:24.475894 22203 solver.cpp:256]     Train net output #0: loss = 4.32214 (* 1 = 4.32214 loss)
I0411 13:17:24.475903 22203 sgd_solver.cpp:106] Iteration 102, lr = 0.001
I0411 13:17:24.853092 22203 solver.cpp:240] Iteration 103, loss = 4.22357
I0411 13:17:24.853127 22203 solver.cpp:256]     Train net output #0: loss = 4.22357 (* 1 = 4.22357 loss)
I0411 13:17:24.853135 22203 sgd_solver.cpp:106] Iteration 103, lr = 0.001
I0411 13:17:25.228415 22203 solver.cpp:240] Iteration 104, loss = 4.2395
I0411 13:17:25.228447 22203 solver.cpp:256]     Train net output #0: loss = 4.2395 (* 1 = 4.2395 loss)
I0411 13:17:25.228456 22203 sgd_solver.cpp:106] Iteration 104, lr = 0.001
I0411 13:17:25.605733 22203 solver.cpp:240] Iteration 105, loss = 4.23896
I0411 13:17:25.605767 22203 solver.cpp:256]     Train net output #0: loss = 4.23896 (* 1 = 4.23896 loss)
I0411 13:17:25.605773 22203 sgd_solver.cpp:106] Iteration 105, lr = 0.001
I0411 13:17:25.981709 22203 solver.cpp:240] Iteration 106, loss = 4.24003
I0411 13:17:25.981744 22203 solver.cpp:256]     Train net output #0: loss = 4.24003 (* 1 = 4.24003 loss)
I0411 13:17:25.981751 22203 sgd_solver.cpp:106] Iteration 106, lr = 0.001
I0411 13:17:26.358402 22203 solver.cpp:240] Iteration 107, loss = 4.20456
I0411 13:17:26.358434 22203 solver.cpp:256]     Train net output #0: loss = 4.20456 (* 1 = 4.20456 loss)
I0411 13:17:26.358443 22203 sgd_solver.cpp:106] Iteration 107, lr = 0.001
I0411 13:17:26.733088 22203 solver.cpp:240] Iteration 108, loss = 4.28908
I0411 13:17:26.733121 22203 solver.cpp:256]     Train net output #0: loss = 4.28908 (* 1 = 4.28908 loss)
I0411 13:17:26.733129 22203 sgd_solver.cpp:106] Iteration 108, lr = 0.001
I0411 13:17:27.108559 22203 solver.cpp:240] Iteration 109, loss = 4.20899
I0411 13:17:27.108590 22203 solver.cpp:256]     Train net output #0: loss = 4.20899 (* 1 = 4.20899 loss)
I0411 13:17:27.108598 22203 sgd_solver.cpp:106] Iteration 109, lr = 0.001
I0411 13:17:27.485473 22203 solver.cpp:240] Iteration 110, loss = 4.19171
I0411 13:17:27.485508 22203 solver.cpp:256]     Train net output #0: loss = 4.19171 (* 1 = 4.19171 loss)
I0411 13:17:27.485517 22203 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0411 13:17:27.861984 22203 solver.cpp:240] Iteration 111, loss = 4.21957
I0411 13:17:27.862023 22203 solver.cpp:256]     Train net output #0: loss = 4.21957 (* 1 = 4.21957 loss)
I0411 13:17:27.862032 22203 sgd_solver.cpp:106] Iteration 111, lr = 0.001
I0411 13:17:28.237059 22203 solver.cpp:240] Iteration 112, loss = 4.25601
I0411 13:17:28.237098 22203 solver.cpp:256]     Train net output #0: loss = 4.25601 (* 1 = 4.25601 loss)
I0411 13:17:28.237130 22203 sgd_solver.cpp:106] Iteration 112, lr = 0.001
I0411 13:17:28.615429 22203 solver.cpp:240] Iteration 113, loss = 4.2207
I0411 13:17:28.615468 22203 solver.cpp:256]     Train net output #0: loss = 4.2207 (* 1 = 4.2207 loss)
I0411 13:17:28.615475 22203 sgd_solver.cpp:106] Iteration 113, lr = 0.001
I0411 13:17:28.990850 22203 solver.cpp:240] Iteration 114, loss = 4.25334
I0411 13:17:28.990885 22203 solver.cpp:256]     Train net output #0: loss = 4.25334 (* 1 = 4.25334 loss)
I0411 13:17:28.990892 22203 sgd_solver.cpp:106] Iteration 114, lr = 0.001
I0411 13:17:29.368338 22203 solver.cpp:240] Iteration 115, loss = 4.20694
I0411 13:17:29.368372 22203 solver.cpp:256]     Train net output #0: loss = 4.20694 (* 1 = 4.20694 loss)
I0411 13:17:29.368381 22203 sgd_solver.cpp:106] Iteration 115, lr = 0.001
I0411 13:17:29.743988 22203 solver.cpp:240] Iteration 116, loss = 4.21727
I0411 13:17:29.744020 22203 solver.cpp:256]     Train net output #0: loss = 4.21727 (* 1 = 4.21727 loss)
I0411 13:17:29.744029 22203 sgd_solver.cpp:106] Iteration 116, lr = 0.001
I0411 13:17:30.119364 22203 solver.cpp:240] Iteration 117, loss = 4.12041
I0411 13:17:30.119407 22203 solver.cpp:256]     Train net output #0: loss = 4.12041 (* 1 = 4.12041 loss)
I0411 13:17:30.119415 22203 sgd_solver.cpp:106] Iteration 117, lr = 0.001
I0411 13:17:30.496362 22203 solver.cpp:240] Iteration 118, loss = 4.18446
I0411 13:17:30.496394 22203 solver.cpp:256]     Train net output #0: loss = 4.18446 (* 1 = 4.18446 loss)
I0411 13:17:30.496402 22203 sgd_solver.cpp:106] Iteration 118, lr = 0.001
I0411 13:17:30.872223 22203 solver.cpp:240] Iteration 119, loss = 4.12192
I0411 13:17:30.872256 22203 solver.cpp:256]     Train net output #0: loss = 4.12192 (* 1 = 4.12192 loss)
I0411 13:17:30.872263 22203 sgd_solver.cpp:106] Iteration 119, lr = 0.001
I0411 13:17:31.248167 22203 solver.cpp:240] Iteration 120, loss = 4.18392
I0411 13:17:31.248199 22203 solver.cpp:256]     Train net output #0: loss = 4.18392 (* 1 = 4.18392 loss)
I0411 13:17:31.248208 22203 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0411 13:17:31.623482 22203 solver.cpp:240] Iteration 121, loss = 4.21216
I0411 13:17:31.623513 22203 solver.cpp:256]     Train net output #0: loss = 4.21216 (* 1 = 4.21216 loss)
I0411 13:17:31.623520 22203 sgd_solver.cpp:106] Iteration 121, lr = 0.001
I0411 13:17:31.998385 22203 solver.cpp:240] Iteration 122, loss = 4.19594
I0411 13:17:31.998432 22203 solver.cpp:256]     Train net output #0: loss = 4.19594 (* 1 = 4.19594 loss)
I0411 13:17:31.998441 22203 sgd_solver.cpp:106] Iteration 122, lr = 0.001
I0411 13:17:32.375447 22203 solver.cpp:240] Iteration 123, loss = 4.25745
I0411 13:17:32.375479 22203 solver.cpp:256]     Train net output #0: loss = 4.25745 (* 1 = 4.25745 loss)
I0411 13:17:32.375486 22203 sgd_solver.cpp:106] Iteration 123, lr = 0.001
I0411 13:17:32.751638 22203 solver.cpp:240] Iteration 124, loss = 4.20388
I0411 13:17:32.751682 22203 solver.cpp:256]     Train net output #0: loss = 4.20388 (* 1 = 4.20388 loss)
I0411 13:17:32.751691 22203 sgd_solver.cpp:106] Iteration 124, lr = 0.001
I0411 13:17:32.752027 22203 solver.cpp:349] Iteration 125, Testing net (#0)
I0411 13:17:34.056406 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.133057
I0411 13:17:34.056433 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.296509
I0411 13:17:34.056443 22203 solver.cpp:416]     Test net output #2: loss = 3.79882 (* 1 = 3.79882 loss)
I0411 13:17:34.185186 22203 solver.cpp:240] Iteration 125, loss = 4.22806
I0411 13:17:34.185219 22203 solver.cpp:256]     Train net output #0: loss = 4.22806 (* 1 = 4.22806 loss)
I0411 13:17:34.185227 22203 sgd_solver.cpp:106] Iteration 125, lr = 0.001
I0411 13:17:34.561790 22203 solver.cpp:240] Iteration 126, loss = 4.14299
I0411 13:17:34.561825 22203 solver.cpp:256]     Train net output #0: loss = 4.14299 (* 1 = 4.14299 loss)
I0411 13:17:34.561832 22203 sgd_solver.cpp:106] Iteration 126, lr = 0.001
I0411 13:17:34.937347 22203 solver.cpp:240] Iteration 127, loss = 4.17725
I0411 13:17:34.937405 22203 solver.cpp:256]     Train net output #0: loss = 4.17725 (* 1 = 4.17725 loss)
I0411 13:17:34.937414 22203 sgd_solver.cpp:106] Iteration 127, lr = 0.001
I0411 13:17:35.315011 22203 solver.cpp:240] Iteration 128, loss = 4.17378
I0411 13:17:35.315044 22203 solver.cpp:256]     Train net output #0: loss = 4.17378 (* 1 = 4.17378 loss)
I0411 13:17:35.315053 22203 sgd_solver.cpp:106] Iteration 128, lr = 0.001
I0411 13:17:35.692179 22203 solver.cpp:240] Iteration 129, loss = 4.18489
I0411 13:17:35.692215 22203 solver.cpp:256]     Train net output #0: loss = 4.18489 (* 1 = 4.18489 loss)
I0411 13:17:35.692224 22203 sgd_solver.cpp:106] Iteration 129, lr = 0.001
I0411 13:17:36.071321 22203 solver.cpp:240] Iteration 130, loss = 4.10767
I0411 13:17:36.071357 22203 solver.cpp:256]     Train net output #0: loss = 4.10767 (* 1 = 4.10767 loss)
I0411 13:17:36.071364 22203 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0411 13:17:36.447324 22203 solver.cpp:240] Iteration 131, loss = 4.2179
I0411 13:17:36.447358 22203 solver.cpp:256]     Train net output #0: loss = 4.2179 (* 1 = 4.2179 loss)
I0411 13:17:36.447366 22203 sgd_solver.cpp:106] Iteration 131, lr = 0.001
I0411 13:17:36.826277 22203 solver.cpp:240] Iteration 132, loss = 4.07314
I0411 13:17:36.826311 22203 solver.cpp:256]     Train net output #0: loss = 4.07314 (* 1 = 4.07314 loss)
I0411 13:17:36.826319 22203 sgd_solver.cpp:106] Iteration 132, lr = 0.001
I0411 13:17:37.202445 22203 solver.cpp:240] Iteration 133, loss = 4.28604
I0411 13:17:37.202478 22203 solver.cpp:256]     Train net output #0: loss = 4.28604 (* 1 = 4.28604 loss)
I0411 13:17:37.202486 22203 sgd_solver.cpp:106] Iteration 133, lr = 0.001
I0411 13:17:37.578644 22203 solver.cpp:240] Iteration 134, loss = 4.17557
I0411 13:17:37.578678 22203 solver.cpp:256]     Train net output #0: loss = 4.17557 (* 1 = 4.17557 loss)
I0411 13:17:37.578686 22203 sgd_solver.cpp:106] Iteration 134, lr = 0.001
I0411 13:17:37.955209 22203 solver.cpp:240] Iteration 135, loss = 4.16866
I0411 13:17:37.955245 22203 solver.cpp:256]     Train net output #0: loss = 4.16866 (* 1 = 4.16866 loss)
I0411 13:17:37.955252 22203 sgd_solver.cpp:106] Iteration 135, lr = 0.001
I0411 13:17:38.333899 22203 solver.cpp:240] Iteration 136, loss = 4.11922
I0411 13:17:38.333938 22203 solver.cpp:256]     Train net output #0: loss = 4.11922 (* 1 = 4.11922 loss)
I0411 13:17:38.333946 22203 sgd_solver.cpp:106] Iteration 136, lr = 0.001
I0411 13:17:38.710526 22203 solver.cpp:240] Iteration 137, loss = 4.22938
I0411 13:17:38.710563 22203 solver.cpp:256]     Train net output #0: loss = 4.22938 (* 1 = 4.22938 loss)
I0411 13:17:38.710572 22203 sgd_solver.cpp:106] Iteration 137, lr = 0.001
I0411 13:17:39.085114 22203 solver.cpp:240] Iteration 138, loss = 4.20765
I0411 13:17:39.085783 22203 solver.cpp:256]     Train net output #0: loss = 4.20765 (* 1 = 4.20765 loss)
I0411 13:17:39.085795 22203 sgd_solver.cpp:106] Iteration 138, lr = 0.001
I0411 13:17:39.461850 22203 solver.cpp:240] Iteration 139, loss = 4.2393
I0411 13:17:39.461885 22203 solver.cpp:256]     Train net output #0: loss = 4.2393 (* 1 = 4.2393 loss)
I0411 13:17:39.461894 22203 sgd_solver.cpp:106] Iteration 139, lr = 0.001
I0411 13:17:39.839661 22203 solver.cpp:240] Iteration 140, loss = 4.20724
I0411 13:17:39.839694 22203 solver.cpp:256]     Train net output #0: loss = 4.20724 (* 1 = 4.20724 loss)
I0411 13:17:39.839702 22203 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0411 13:17:40.217314 22203 solver.cpp:240] Iteration 141, loss = 4.06638
I0411 13:17:40.217346 22203 solver.cpp:256]     Train net output #0: loss = 4.06638 (* 1 = 4.06638 loss)
I0411 13:17:40.217355 22203 sgd_solver.cpp:106] Iteration 141, lr = 0.001
I0411 13:17:40.594666 22203 solver.cpp:240] Iteration 142, loss = 4.24566
I0411 13:17:40.594697 22203 solver.cpp:256]     Train net output #0: loss = 4.24566 (* 1 = 4.24566 loss)
I0411 13:17:40.594704 22203 sgd_solver.cpp:106] Iteration 142, lr = 0.001
I0411 13:17:40.972201 22203 solver.cpp:240] Iteration 143, loss = 4.13552
I0411 13:17:40.972239 22203 solver.cpp:256]     Train net output #0: loss = 4.13552 (* 1 = 4.13552 loss)
I0411 13:17:40.972249 22203 sgd_solver.cpp:106] Iteration 143, lr = 0.001
I0411 13:17:41.347690 22203 solver.cpp:240] Iteration 144, loss = 4.17048
I0411 13:17:41.347723 22203 solver.cpp:256]     Train net output #0: loss = 4.17048 (* 1 = 4.17048 loss)
I0411 13:17:41.347733 22203 sgd_solver.cpp:106] Iteration 144, lr = 0.001
I0411 13:17:41.725973 22203 solver.cpp:240] Iteration 145, loss = 4.13135
I0411 13:17:41.726006 22203 solver.cpp:256]     Train net output #0: loss = 4.13135 (* 1 = 4.13135 loss)
I0411 13:17:41.726013 22203 sgd_solver.cpp:106] Iteration 145, lr = 0.001
I0411 13:17:42.102777 22203 solver.cpp:240] Iteration 146, loss = 4.1801
I0411 13:17:42.102808 22203 solver.cpp:256]     Train net output #0: loss = 4.1801 (* 1 = 4.1801 loss)
I0411 13:17:42.102816 22203 sgd_solver.cpp:106] Iteration 146, lr = 0.001
I0411 13:17:42.484288 22203 solver.cpp:240] Iteration 147, loss = 4.12865
I0411 13:17:42.484320 22203 solver.cpp:256]     Train net output #0: loss = 4.12865 (* 1 = 4.12865 loss)
I0411 13:17:42.484333 22203 sgd_solver.cpp:106] Iteration 147, lr = 0.001
I0411 13:17:42.864673 22203 solver.cpp:240] Iteration 148, loss = 4.17382
I0411 13:17:42.864707 22203 solver.cpp:256]     Train net output #0: loss = 4.17382 (* 1 = 4.17382 loss)
I0411 13:17:42.864715 22203 sgd_solver.cpp:106] Iteration 148, lr = 0.001
I0411 13:17:43.241204 22203 solver.cpp:240] Iteration 149, loss = 4.14574
I0411 13:17:43.241237 22203 solver.cpp:256]     Train net output #0: loss = 4.14574 (* 1 = 4.14574 loss)
I0411 13:17:43.241245 22203 sgd_solver.cpp:106] Iteration 149, lr = 0.001
I0411 13:17:43.241574 22203 solver.cpp:349] Iteration 150, Testing net (#0)
I0411 13:17:44.546612 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.137085
I0411 13:17:44.546643 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.297363
I0411 13:17:44.546651 22203 solver.cpp:416]     Test net output #2: loss = 3.79103 (* 1 = 3.79103 loss)
I0411 13:17:44.677731 22203 solver.cpp:240] Iteration 150, loss = 4.18014
I0411 13:17:44.677763 22203 solver.cpp:256]     Train net output #0: loss = 4.18014 (* 1 = 4.18014 loss)
I0411 13:17:44.677772 22203 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0411 13:17:45.055668 22203 solver.cpp:240] Iteration 151, loss = 4.10447
I0411 13:17:45.055701 22203 solver.cpp:256]     Train net output #0: loss = 4.10447 (* 1 = 4.10447 loss)
I0411 13:17:45.055708 22203 sgd_solver.cpp:106] Iteration 151, lr = 0.001
I0411 13:17:45.432827 22203 solver.cpp:240] Iteration 152, loss = 4.23315
I0411 13:17:45.432860 22203 solver.cpp:256]     Train net output #0: loss = 4.23315 (* 1 = 4.23315 loss)
I0411 13:17:45.432868 22203 sgd_solver.cpp:106] Iteration 152, lr = 0.001
I0411 13:17:45.809855 22203 solver.cpp:240] Iteration 153, loss = 4.16284
I0411 13:17:45.809926 22203 solver.cpp:256]     Train net output #0: loss = 4.16284 (* 1 = 4.16284 loss)
I0411 13:17:45.809937 22203 sgd_solver.cpp:106] Iteration 153, lr = 0.001
I0411 13:17:46.185832 22203 solver.cpp:240] Iteration 154, loss = 4.07733
I0411 13:17:46.185865 22203 solver.cpp:256]     Train net output #0: loss = 4.07733 (* 1 = 4.07733 loss)
I0411 13:17:46.185873 22203 sgd_solver.cpp:106] Iteration 154, lr = 0.001
I0411 13:17:46.564160 22203 solver.cpp:240] Iteration 155, loss = 4.16645
I0411 13:17:46.564193 22203 solver.cpp:256]     Train net output #0: loss = 4.16645 (* 1 = 4.16645 loss)
I0411 13:17:46.564200 22203 sgd_solver.cpp:106] Iteration 155, lr = 0.001
I0411 13:17:46.942674 22203 solver.cpp:240] Iteration 156, loss = 4.09376
I0411 13:17:46.942708 22203 solver.cpp:256]     Train net output #0: loss = 4.09376 (* 1 = 4.09376 loss)
I0411 13:17:46.942716 22203 sgd_solver.cpp:106] Iteration 156, lr = 0.001
I0411 13:17:47.319766 22203 solver.cpp:240] Iteration 157, loss = 4.04478
I0411 13:17:47.319802 22203 solver.cpp:256]     Train net output #0: loss = 4.04478 (* 1 = 4.04478 loss)
I0411 13:17:47.319809 22203 sgd_solver.cpp:106] Iteration 157, lr = 0.001
I0411 13:17:47.693528 22203 solver.cpp:240] Iteration 158, loss = 4.16018
I0411 13:17:47.693562 22203 solver.cpp:256]     Train net output #0: loss = 4.16018 (* 1 = 4.16018 loss)
I0411 13:17:47.693572 22203 sgd_solver.cpp:106] Iteration 158, lr = 0.001
I0411 13:17:48.072067 22203 solver.cpp:240] Iteration 159, loss = 4.1606
I0411 13:17:48.072099 22203 solver.cpp:256]     Train net output #0: loss = 4.1606 (* 1 = 4.1606 loss)
I0411 13:17:48.072108 22203 sgd_solver.cpp:106] Iteration 159, lr = 0.001
I0411 13:17:48.449198 22203 solver.cpp:240] Iteration 160, loss = 4.14194
I0411 13:17:48.449230 22203 solver.cpp:256]     Train net output #0: loss = 4.14194 (* 1 = 4.14194 loss)
I0411 13:17:48.449240 22203 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0411 13:17:48.826536 22203 solver.cpp:240] Iteration 161, loss = 4.07498
I0411 13:17:48.826581 22203 solver.cpp:256]     Train net output #0: loss = 4.07498 (* 1 = 4.07498 loss)
I0411 13:17:48.826588 22203 sgd_solver.cpp:106] Iteration 161, lr = 0.001
I0411 13:17:49.207816 22203 solver.cpp:240] Iteration 162, loss = 4.12928
I0411 13:17:49.207849 22203 solver.cpp:256]     Train net output #0: loss = 4.12928 (* 1 = 4.12928 loss)
I0411 13:17:49.207857 22203 sgd_solver.cpp:106] Iteration 162, lr = 0.001
I0411 13:17:49.587491 22203 solver.cpp:240] Iteration 163, loss = 4.20719
I0411 13:17:49.587523 22203 solver.cpp:256]     Train net output #0: loss = 4.20719 (* 1 = 4.20719 loss)
I0411 13:17:49.587530 22203 sgd_solver.cpp:106] Iteration 163, lr = 0.001
I0411 13:17:49.964730 22203 solver.cpp:240] Iteration 164, loss = 4.09218
I0411 13:17:49.964764 22203 solver.cpp:256]     Train net output #0: loss = 4.09218 (* 1 = 4.09218 loss)
I0411 13:17:49.964772 22203 sgd_solver.cpp:106] Iteration 164, lr = 0.001
I0411 13:17:50.341291 22203 solver.cpp:240] Iteration 165, loss = 4.09649
I0411 13:17:50.341328 22203 solver.cpp:256]     Train net output #0: loss = 4.09649 (* 1 = 4.09649 loss)
I0411 13:17:50.341336 22203 sgd_solver.cpp:106] Iteration 165, lr = 0.001
I0411 13:17:50.719868 22203 solver.cpp:240] Iteration 166, loss = 4.07542
I0411 13:17:50.719919 22203 solver.cpp:256]     Train net output #0: loss = 4.07542 (* 1 = 4.07542 loss)
I0411 13:17:50.719928 22203 sgd_solver.cpp:106] Iteration 166, lr = 0.001
I0411 13:17:51.098481 22203 solver.cpp:240] Iteration 167, loss = 4.06449
I0411 13:17:51.098513 22203 solver.cpp:256]     Train net output #0: loss = 4.06449 (* 1 = 4.06449 loss)
I0411 13:17:51.098521 22203 sgd_solver.cpp:106] Iteration 167, lr = 0.001
I0411 13:17:51.477047 22203 solver.cpp:240] Iteration 168, loss = 4.05201
I0411 13:17:51.477079 22203 solver.cpp:256]     Train net output #0: loss = 4.05201 (* 1 = 4.05201 loss)
I0411 13:17:51.477087 22203 sgd_solver.cpp:106] Iteration 168, lr = 0.001
I0411 13:17:51.853003 22203 solver.cpp:240] Iteration 169, loss = 4.09587
I0411 13:17:51.853073 22203 solver.cpp:256]     Train net output #0: loss = 4.09587 (* 1 = 4.09587 loss)
I0411 13:17:51.853081 22203 sgd_solver.cpp:106] Iteration 169, lr = 0.001
I0411 13:17:52.232898 22203 solver.cpp:240] Iteration 170, loss = 4.05364
I0411 13:17:52.232930 22203 solver.cpp:256]     Train net output #0: loss = 4.05364 (* 1 = 4.05364 loss)
I0411 13:17:52.232939 22203 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0411 13:17:52.609477 22203 solver.cpp:240] Iteration 171, loss = 4.18938
I0411 13:17:52.609509 22203 solver.cpp:256]     Train net output #0: loss = 4.18938 (* 1 = 4.18938 loss)
I0411 13:17:52.609516 22203 sgd_solver.cpp:106] Iteration 171, lr = 0.001
I0411 13:17:52.985150 22203 solver.cpp:240] Iteration 172, loss = 4.12663
I0411 13:17:52.985185 22203 solver.cpp:256]     Train net output #0: loss = 4.12663 (* 1 = 4.12663 loss)
I0411 13:17:52.985193 22203 sgd_solver.cpp:106] Iteration 172, lr = 0.001
I0411 13:17:53.364101 22203 solver.cpp:240] Iteration 173, loss = 4.12101
I0411 13:17:53.364132 22203 solver.cpp:256]     Train net output #0: loss = 4.12101 (* 1 = 4.12101 loss)
I0411 13:17:53.364141 22203 sgd_solver.cpp:106] Iteration 173, lr = 0.001
I0411 13:17:53.744319 22203 solver.cpp:240] Iteration 174, loss = 4.04498
I0411 13:17:53.744351 22203 solver.cpp:256]     Train net output #0: loss = 4.04498 (* 1 = 4.04498 loss)
I0411 13:17:53.744359 22203 sgd_solver.cpp:106] Iteration 174, lr = 0.001
I0411 13:17:53.744683 22203 solver.cpp:349] Iteration 175, Testing net (#0)
I0411 13:17:55.056514 22203 solver.cpp:416]     Test net output #0: accuracy_1 = 0.134399
I0411 13:17:55.056542 22203 solver.cpp:416]     Test net output #1: accuracy_5 = 0.291626
I0411 13:17:55.056551 22203 solver.cpp:416]     Test net output #2: loss = 3.80022 (* 1 = 3.80022 loss)
I0411 13:17:55.186137 22203 solver.cpp:240] Iteration 175, loss = 4.08633
I0411 13:17:55.186169 22203 solver.cpp:256]     Train net output #0: loss = 4.08633 (* 1 = 4.08633 loss)
I0411 13:17:55.186177 22203 sgd_solver.cpp:106] Iteration 175, lr = 0.001
I0411 13:17:55.567343 22203 solver.cpp:240] Iteration 176, loss = 4.08653
I0411 13:17:55.567376 22203 solver.cpp:256]     Train net output #0: loss = 4.08653 (* 1 = 4.08653 loss)
I0411 13:17:55.567385 22203 sgd_solver.cpp:106] Iteration 176, lr = 0.001
I0411 13:17:55.946002 22203 solver.cpp:240] Iteration 177, loss = 4.11712
I0411 13:17:55.946036 22203 solver.cpp:256]     Train net output #0: loss = 4.11712 (* 1 = 4.11712 loss)
I0411 13:17:55.946044 22203 sgd_solver.cpp:106] Iteration 177, lr = 0.001
I0411 13:17:56.323235 22203 solver.cpp:240] Iteration 178, loss = 4.10401
I0411 13:17:56.323266 22203 solver.cpp:256]     Train net output #0: loss = 4.10401 (* 1 = 4.10401 loss)
I0411 13:17:56.323274 22203 sgd_solver.cpp:106] Iteration 178, lr = 0.001
I0411 13:17:56.699062 22203 solver.cpp:240] Iteration 179, loss = 4.07394
I0411 13:17:56.699095 22203 solver.cpp:256]     Train net output #0: loss = 4.07394 (* 1 = 4.07394 loss)
I0411 13:17:56.699102 22203 sgd_solver.cpp:106] Iteration 179, lr = 0.001
I0411 13:17:57.079632 22203 solver.cpp:240] Iteration 180, loss = 4.01749
I0411 13:17:57.079663 22203 solver.cpp:256]     Train net output #0: loss = 4.01749 (* 1 = 4.01749 loss)
I0411 13:17:57.079671 22203 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0411 13:17:57.457883 22203 solver.cpp:240] Iteration 181, loss = 4.12839
I0411 13:17:57.457919 22203 solver.cpp:256]     Train net output #0: loss = 4.12839 (* 1 = 4.12839 loss)
I0411 13:17:57.457927 22203 sgd_solver.cpp:106] Iteration 181, lr = 0.001
I0411 13:17:57.836052 22203 solver.cpp:240] Iteration 182, loss = 4.03199
I0411 13:17:57.836084 22203 solver.cpp:256]     Train net output #0: loss = 4.03199 (* 1 = 4.03199 loss)
I0411 13:17:57.836092 22203 sgd_solver.cpp:106] Iteration 182, lr = 0.001
I0411 13:17:58.212736 22203 solver.cpp:240] Iteration 183, loss = 4.10412
I0411 13:17:58.212767 22203 solver.cpp:256]     Train net output #0: loss = 4.10412 (* 1 = 4.10412 loss)
I0411 13:17:58.212776 22203 sgd_solver.cpp:106] Iteration 183, lr = 0.001
I0411 13:17:58.592453 22203 solver.cpp:240] Iteration 184, loss = 4.11736
I0411 13:17:58.592511 22203 solver.cpp:256]     Train net output #0: loss = 4.11736 (* 1 = 4.11736 loss)
I0411 13:17:58.592520 22203 sgd_solver.cpp:106] Iteration 184, lr = 0.001
I0411 13:17:58.969008 22203 solver.cpp:240] Iteration 185, loss = 4.11067
I0411 13:17:58.969040 22203 solver.cpp:256]     Train net output #0: loss = 4.11067 (* 1 = 4.11067 loss)
I0411 13:17:58.969048 22203 sgd_solver.cpp:106] Iteration 185, lr = 0.001
I0411 13:17:59.344635 22203 solver.cpp:240] Iteration 186, loss = 4.00731
I0411 13:17:59.344669 22203 solver.cpp:256]     Train net output #0: loss = 4.00731 (* 1 = 4.00731 loss)
I0411 13:17:59.344677 22203 sgd_solver.cpp:106] Iteration 186, lr = 0.001
