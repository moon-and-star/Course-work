I0410 23:47:32.749774  7697 caffe.cpp:217] Using GPUs 1
I0410 23:47:33.051508  7697 caffe.cpp:222] GPU 1: GeForce GTX 1070
I0410 23:47:33.766968  7697 solver.cpp:60] Initializing solver from parameters: 
train_net: "./Prototxt/experiment_8/rtsd-r1/CoNorm/trial_1/train.prototxt"
test_net: "./Prototxt/experiment_8/rtsd-r1/CoNorm/trial_1/test.prototxt"
test_iter: 8
test_interval: 25
base_lr: 0.0005
display: 1
max_iter: 2500
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 500
snapshot: 250
snapshot_prefix: "./snapshots/experiment_8/rtsd-r1/CoNorm/trial_1/snap"
solver_mode: GPU
device_id: 1
train_state {
  level: 0
  stage: ""
}
iter_size: 1
type: "Adam"
I0410 23:47:33.767107  7697 solver.cpp:93] Creating training net from train_net file: ./Prototxt/experiment_8/rtsd-r1/CoNorm/trial_1/train.prototxt
I0410 23:47:33.767406  7697 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_1
I0410 23:47:33.767418  7697 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_5
I0410 23:47:33.767576  7697 net.cpp:58] Initializing net from parameters: 
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 132
    mean_value: 132
    mean_value: 131
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
I0410 23:47:33.767688  7697 layer_factory.hpp:77] Creating layer data
I0410 23:47:33.768748  7697 net.cpp:100] Creating Layer data
I0410 23:47:33.768762  7697 net.cpp:408] data -> data
I0410 23:47:33.768784  7697 net.cpp:408] data -> label
I0410 23:47:33.769973  7887 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/train/lmdb
I0410 23:47:33.786785  7697 data_layer.cpp:41] output data size: 1024,3,48,48
I0410 23:47:33.832979  7697 net.cpp:150] Setting up data
I0410 23:47:33.833009  7697 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0410 23:47:33.833014  7697 net.cpp:157] Top shape: 1024 (1024)
I0410 23:47:33.833016  7697 net.cpp:165] Memory required for data: 28315648
I0410 23:47:33.833025  7697 layer_factory.hpp:77] Creating layer conv1
I0410 23:47:33.833047  7697 net.cpp:100] Creating Layer conv1
I0410 23:47:33.833055  7697 net.cpp:434] conv1 <- data
I0410 23:47:33.833066  7697 net.cpp:408] conv1 -> conv1
I0410 23:47:34.152523  7697 net.cpp:150] Setting up conv1
I0410 23:47:34.152550  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.152554  7697 net.cpp:165] Memory required for data: 750850048
I0410 23:47:34.152575  7697 layer_factory.hpp:77] Creating layer conv1_prescale
I0410 23:47:34.152601  7697 net.cpp:100] Creating Layer conv1_prescale
I0410 23:47:34.152604  7697 net.cpp:434] conv1_prescale <- conv1
I0410 23:47:34.152611  7697 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0410 23:47:34.152719  7697 net.cpp:150] Setting up conv1_prescale
I0410 23:47:34.152729  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.152730  7697 net.cpp:165] Memory required for data: 1473384448
I0410 23:47:34.152737  7697 layer_factory.hpp:77] Creating layer conv1_sTanH
I0410 23:47:34.152743  7697 net.cpp:100] Creating Layer conv1_sTanH
I0410 23:47:34.152746  7697 net.cpp:434] conv1_sTanH <- conv1
I0410 23:47:34.152751  7697 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0410 23:47:34.152948  7697 net.cpp:150] Setting up conv1_sTanH
I0410 23:47:34.152959  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.152962  7697 net.cpp:165] Memory required for data: 2195918848
I0410 23:47:34.152966  7697 layer_factory.hpp:77] Creating layer conv1_postscale
I0410 23:47:34.152974  7697 net.cpp:100] Creating Layer conv1_postscale
I0410 23:47:34.152977  7697 net.cpp:434] conv1_postscale <- conv1
I0410 23:47:34.152981  7697 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0410 23:47:34.153076  7697 net.cpp:150] Setting up conv1_postscale
I0410 23:47:34.153084  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.153086  7697 net.cpp:165] Memory required for data: 2918453248
I0410 23:47:34.153091  7697 layer_factory.hpp:77] Creating layer pool1
I0410 23:47:34.153097  7697 net.cpp:100] Creating Layer pool1
I0410 23:47:34.153100  7697 net.cpp:434] pool1 <- conv1
I0410 23:47:34.153105  7697 net.cpp:408] pool1 -> pool1
I0410 23:47:34.153154  7697 net.cpp:150] Setting up pool1
I0410 23:47:34.153162  7697 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0410 23:47:34.153167  7697 net.cpp:165] Memory required for data: 3099086848
I0410 23:47:34.153189  7697 layer_factory.hpp:77] Creating layer conv2
I0410 23:47:34.153199  7697 net.cpp:100] Creating Layer conv2
I0410 23:47:34.153203  7697 net.cpp:434] conv2 <- pool1
I0410 23:47:34.153208  7697 net.cpp:408] conv2 -> conv2
I0410 23:47:34.158912  7697 net.cpp:150] Setting up conv2
I0410 23:47:34.158929  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.158932  7697 net.cpp:165] Memory required for data: 3298152448
I0410 23:47:34.158942  7697 layer_factory.hpp:77] Creating layer conv2_prescale
I0410 23:47:34.158951  7697 net.cpp:100] Creating Layer conv2_prescale
I0410 23:47:34.158953  7697 net.cpp:434] conv2_prescale <- conv2
I0410 23:47:34.158958  7697 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0410 23:47:34.159063  7697 net.cpp:150] Setting up conv2_prescale
I0410 23:47:34.159071  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.159075  7697 net.cpp:165] Memory required for data: 3497218048
I0410 23:47:34.159080  7697 layer_factory.hpp:77] Creating layer conv2_sTanH
I0410 23:47:34.159085  7697 net.cpp:100] Creating Layer conv2_sTanH
I0410 23:47:34.159088  7697 net.cpp:434] conv2_sTanH <- conv2
I0410 23:47:34.159092  7697 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0410 23:47:34.161614  7697 net.cpp:150] Setting up conv2_sTanH
I0410 23:47:34.161633  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.161636  7697 net.cpp:165] Memory required for data: 3696283648
I0410 23:47:34.161639  7697 layer_factory.hpp:77] Creating layer conv2_postscale
I0410 23:47:34.161648  7697 net.cpp:100] Creating Layer conv2_postscale
I0410 23:47:34.161650  7697 net.cpp:434] conv2_postscale <- conv2
I0410 23:47:34.161655  7697 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0410 23:47:34.161748  7697 net.cpp:150] Setting up conv2_postscale
I0410 23:47:34.161756  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.161759  7697 net.cpp:165] Memory required for data: 3895349248
I0410 23:47:34.161764  7697 layer_factory.hpp:77] Creating layer pool2
I0410 23:47:34.161769  7697 net.cpp:100] Creating Layer pool2
I0410 23:47:34.161772  7697 net.cpp:434] pool2 <- conv2
I0410 23:47:34.161777  7697 net.cpp:408] pool2 -> pool2
I0410 23:47:34.161813  7697 net.cpp:150] Setting up pool2
I0410 23:47:34.161820  7697 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0410 23:47:34.161823  7697 net.cpp:165] Memory required for data: 3945115648
I0410 23:47:34.161825  7697 layer_factory.hpp:77] Creating layer conv3
I0410 23:47:34.161833  7697 net.cpp:100] Creating Layer conv3
I0410 23:47:34.161835  7697 net.cpp:434] conv3 <- pool2
I0410 23:47:34.161840  7697 net.cpp:408] conv3 -> conv3
I0410 23:47:34.167378  7697 net.cpp:150] Setting up conv3
I0410 23:47:34.167395  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.167398  7697 net.cpp:165] Memory required for data: 3981979648
I0410 23:47:34.167408  7697 layer_factory.hpp:77] Creating layer conv3_prescale
I0410 23:47:34.167415  7697 net.cpp:100] Creating Layer conv3_prescale
I0410 23:47:34.167418  7697 net.cpp:434] conv3_prescale <- conv3
I0410 23:47:34.167423  7697 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0410 23:47:34.167512  7697 net.cpp:150] Setting up conv3_prescale
I0410 23:47:34.167521  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.167524  7697 net.cpp:165] Memory required for data: 4018843648
I0410 23:47:34.167528  7697 layer_factory.hpp:77] Creating layer conv3_sTanH
I0410 23:47:34.167533  7697 net.cpp:100] Creating Layer conv3_sTanH
I0410 23:47:34.167536  7697 net.cpp:434] conv3_sTanH <- conv3
I0410 23:47:34.167539  7697 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0410 23:47:34.173365  7697 net.cpp:150] Setting up conv3_sTanH
I0410 23:47:34.173383  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.173387  7697 net.cpp:165] Memory required for data: 4055707648
I0410 23:47:34.173390  7697 layer_factory.hpp:77] Creating layer conv3_postscale
I0410 23:47:34.173398  7697 net.cpp:100] Creating Layer conv3_postscale
I0410 23:47:34.173421  7697 net.cpp:434] conv3_postscale <- conv3
I0410 23:47:34.173429  7697 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0410 23:47:34.173527  7697 net.cpp:150] Setting up conv3_postscale
I0410 23:47:34.173535  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.173538  7697 net.cpp:165] Memory required for data: 4092571648
I0410 23:47:34.173543  7697 layer_factory.hpp:77] Creating layer pool3
I0410 23:47:34.173548  7697 net.cpp:100] Creating Layer pool3
I0410 23:47:34.173552  7697 net.cpp:434] pool3 <- conv3
I0410 23:47:34.173555  7697 net.cpp:408] pool3 -> pool3
I0410 23:47:34.173593  7697 net.cpp:150] Setting up pool3
I0410 23:47:34.173599  7697 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0410 23:47:34.173602  7697 net.cpp:165] Memory required for data: 4101787648
I0410 23:47:34.173604  7697 layer_factory.hpp:77] Creating layer fc4_300
I0410 23:47:34.173612  7697 net.cpp:100] Creating Layer fc4_300
I0410 23:47:34.173615  7697 net.cpp:434] fc4_300 <- pool3
I0410 23:47:34.173620  7697 net.cpp:408] fc4_300 -> fc4_300
I0410 23:47:34.184756  7697 net.cpp:150] Setting up fc4_300
I0410 23:47:34.184773  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.184777  7697 net.cpp:165] Memory required for data: 4103016448
I0410 23:47:34.184783  7697 layer_factory.hpp:77] Creating layer fc4_prescale
I0410 23:47:34.184792  7697 net.cpp:100] Creating Layer fc4_prescale
I0410 23:47:34.184794  7697 net.cpp:434] fc4_prescale <- fc4_300
I0410 23:47:34.184799  7697 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0410 23:47:34.184904  7697 net.cpp:150] Setting up fc4_prescale
I0410 23:47:34.184922  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.184927  7697 net.cpp:165] Memory required for data: 4104245248
I0410 23:47:34.184931  7697 layer_factory.hpp:77] Creating layer fc4_sTanH
I0410 23:47:34.184937  7697 net.cpp:100] Creating Layer fc4_sTanH
I0410 23:47:34.184940  7697 net.cpp:434] fc4_sTanH <- fc4_300
I0410 23:47:34.184944  7697 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0410 23:47:34.185137  7697 net.cpp:150] Setting up fc4_sTanH
I0410 23:47:34.185148  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.185150  7697 net.cpp:165] Memory required for data: 4105474048
I0410 23:47:34.185154  7697 layer_factory.hpp:77] Creating layer fc4_postscale
I0410 23:47:34.185160  7697 net.cpp:100] Creating Layer fc4_postscale
I0410 23:47:34.185163  7697 net.cpp:434] fc4_postscale <- fc4_300
I0410 23:47:34.185170  7697 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0410 23:47:34.185268  7697 net.cpp:150] Setting up fc4_postscale
I0410 23:47:34.185277  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.185279  7697 net.cpp:165] Memory required for data: 4106702848
I0410 23:47:34.185284  7697 layer_factory.hpp:77] Creating layer drop4
I0410 23:47:34.185290  7697 net.cpp:100] Creating Layer drop4
I0410 23:47:34.185293  7697 net.cpp:434] drop4 <- fc4_300
I0410 23:47:34.185300  7697 net.cpp:395] drop4 -> fc4_300 (in-place)
I0410 23:47:34.185326  7697 net.cpp:150] Setting up drop4
I0410 23:47:34.185335  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.185338  7697 net.cpp:165] Memory required for data: 4107931648
I0410 23:47:34.185340  7697 layer_factory.hpp:77] Creating layer fc5_67
I0410 23:47:34.185346  7697 net.cpp:100] Creating Layer fc5_67
I0410 23:47:34.185349  7697 net.cpp:434] fc5_67 <- fc4_300
I0410 23:47:34.185354  7697 net.cpp:408] fc5_67 -> fc5_classes
I0410 23:47:34.186624  7697 net.cpp:150] Setting up fc5_67
I0410 23:47:34.186636  7697 net.cpp:157] Top shape: 1024 67 (68608)
I0410 23:47:34.186640  7697 net.cpp:165] Memory required for data: 4108206080
I0410 23:47:34.186650  7697 layer_factory.hpp:77] Creating layer loss
I0410 23:47:34.186655  7697 net.cpp:100] Creating Layer loss
I0410 23:47:34.186658  7697 net.cpp:434] loss <- fc5_classes
I0410 23:47:34.186662  7697 net.cpp:434] loss <- label
I0410 23:47:34.186671  7697 net.cpp:408] loss -> loss
I0410 23:47:34.186682  7697 layer_factory.hpp:77] Creating layer loss
I0410 23:47:34.187044  7697 net.cpp:150] Setting up loss
I0410 23:47:34.187067  7697 net.cpp:157] Top shape: (1)
I0410 23:47:34.187072  7697 net.cpp:160]     with loss weight 1
I0410 23:47:34.187084  7697 net.cpp:165] Memory required for data: 4108206084
I0410 23:47:34.187088  7697 net.cpp:226] loss needs backward computation.
I0410 23:47:34.187094  7697 net.cpp:226] fc5_67 needs backward computation.
I0410 23:47:34.187098  7697 net.cpp:226] drop4 needs backward computation.
I0410 23:47:34.187100  7697 net.cpp:226] fc4_postscale needs backward computation.
I0410 23:47:34.187103  7697 net.cpp:226] fc4_sTanH needs backward computation.
I0410 23:47:34.187105  7697 net.cpp:226] fc4_prescale needs backward computation.
I0410 23:47:34.187108  7697 net.cpp:226] fc4_300 needs backward computation.
I0410 23:47:34.187110  7697 net.cpp:226] pool3 needs backward computation.
I0410 23:47:34.187114  7697 net.cpp:226] conv3_postscale needs backward computation.
I0410 23:47:34.187129  7697 net.cpp:226] conv3_sTanH needs backward computation.
I0410 23:47:34.187130  7697 net.cpp:226] conv3_prescale needs backward computation.
I0410 23:47:34.187134  7697 net.cpp:226] conv3 needs backward computation.
I0410 23:47:34.187136  7697 net.cpp:226] pool2 needs backward computation.
I0410 23:47:34.187139  7697 net.cpp:226] conv2_postscale needs backward computation.
I0410 23:47:34.187141  7697 net.cpp:226] conv2_sTanH needs backward computation.
I0410 23:47:34.187144  7697 net.cpp:226] conv2_prescale needs backward computation.
I0410 23:47:34.187146  7697 net.cpp:226] conv2 needs backward computation.
I0410 23:47:34.187150  7697 net.cpp:226] pool1 needs backward computation.
I0410 23:47:34.187152  7697 net.cpp:226] conv1_postscale needs backward computation.
I0410 23:47:34.187155  7697 net.cpp:226] conv1_sTanH needs backward computation.
I0410 23:47:34.187157  7697 net.cpp:226] conv1_prescale needs backward computation.
I0410 23:47:34.187160  7697 net.cpp:226] conv1 needs backward computation.
I0410 23:47:34.187163  7697 net.cpp:228] data does not need backward computation.
I0410 23:47:34.187166  7697 net.cpp:270] This network produces output loss
I0410 23:47:34.187183  7697 net.cpp:283] Network initialization done.
I0410 23:47:34.187446  7697 solver.cpp:193] Creating test net (#0) specified by test_net file: ./Prototxt/experiment_8/rtsd-r1/CoNorm/trial_1/test.prototxt
I0410 23:47:34.187628  7697 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 133
    mean_value: 133
    mean_value: 132
  }
  data_param {
    source: "../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb"
    batch_size: 1024
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 100
    pad: 0
    kernel_size: 7
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv1_prescale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv1_sTanH"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_postscale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 150
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv2_prescale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv2_sTanH"
  type: "TanH"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv2_postscale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  convolution_param {
    num_output: 250
    pad: 0
    kernel_size: 4
    group: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "conv3_prescale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "conv3_sTanH"
  type: "TanH"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_postscale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc4_300"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc4_300"
  inner_product_param {
    num_output: 300
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fc4_prescale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 0.6666
    }
  }
}
layer {
  name: "fc4_sTanH"
  type: "TanH"
  bottom: "fc4_300"
  top: "fc4_300"
}
layer {
  name: "fc4_postscale"
  type: "Scale"
  bottom: "fc4_300"
  top: "fc4_300"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1.7159
    }
  }
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4_300"
  top: "fc4_300"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc5_67"
  type: "InnerProduct"
  bottom: "fc4_300"
  top: "fc5_classes"
  inner_product_param {
    num_output: 67
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc5_classes"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_1"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_1"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
layer {
  name: "accuracy_5"
  type: "Accuracy"
  bottom: "fc5_classes"
  bottom: "label"
  top: "accuracy_5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0410 23:47:34.187755  7697 layer_factory.hpp:77] Creating layer data
I0410 23:47:34.188448  7697 net.cpp:100] Creating Layer data
I0410 23:47:34.188464  7697 net.cpp:408] data -> data
I0410 23:47:34.188488  7697 net.cpp:408] data -> label
I0410 23:47:34.191552  8023 db_lmdb.cpp:35] Opened lmdb ../local_data/lmdb/rtsd-r1/CoNorm/test/lmdb
I0410 23:47:34.191762  7697 data_layer.cpp:41] output data size: 1024,3,48,48
I0410 23:47:34.235885  7697 net.cpp:150] Setting up data
I0410 23:47:34.235930  7697 net.cpp:157] Top shape: 1024 3 48 48 (7077888)
I0410 23:47:34.235935  7697 net.cpp:157] Top shape: 1024 (1024)
I0410 23:47:34.235937  7697 net.cpp:165] Memory required for data: 28315648
I0410 23:47:34.235944  7697 layer_factory.hpp:77] Creating layer label_data_1_split
I0410 23:47:34.235957  7697 net.cpp:100] Creating Layer label_data_1_split
I0410 23:47:34.235962  7697 net.cpp:434] label_data_1_split <- label
I0410 23:47:34.235970  7697 net.cpp:408] label_data_1_split -> label_data_1_split_0
I0410 23:47:34.235982  7697 net.cpp:408] label_data_1_split -> label_data_1_split_1
I0410 23:47:34.235990  7697 net.cpp:408] label_data_1_split -> label_data_1_split_2
I0410 23:47:34.236099  7697 net.cpp:150] Setting up label_data_1_split
I0410 23:47:34.236109  7697 net.cpp:157] Top shape: 1024 (1024)
I0410 23:47:34.236112  7697 net.cpp:157] Top shape: 1024 (1024)
I0410 23:47:34.236115  7697 net.cpp:157] Top shape: 1024 (1024)
I0410 23:47:34.236119  7697 net.cpp:165] Memory required for data: 28327936
I0410 23:47:34.236141  7697 layer_factory.hpp:77] Creating layer conv1
I0410 23:47:34.236156  7697 net.cpp:100] Creating Layer conv1
I0410 23:47:34.236161  7697 net.cpp:434] conv1 <- data
I0410 23:47:34.236174  7697 net.cpp:408] conv1 -> conv1
I0410 23:47:34.240121  7697 net.cpp:150] Setting up conv1
I0410 23:47:34.240139  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.240144  7697 net.cpp:165] Memory required for data: 750862336
I0410 23:47:34.240156  7697 layer_factory.hpp:77] Creating layer conv1_prescale
I0410 23:47:34.240165  7697 net.cpp:100] Creating Layer conv1_prescale
I0410 23:47:34.240170  7697 net.cpp:434] conv1_prescale <- conv1
I0410 23:47:34.240182  7697 net.cpp:395] conv1_prescale -> conv1 (in-place)
I0410 23:47:34.240303  7697 net.cpp:150] Setting up conv1_prescale
I0410 23:47:34.240312  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.240315  7697 net.cpp:165] Memory required for data: 1473396736
I0410 23:47:34.240322  7697 layer_factory.hpp:77] Creating layer conv1_sTanH
I0410 23:47:34.240332  7697 net.cpp:100] Creating Layer conv1_sTanH
I0410 23:47:34.240339  7697 net.cpp:434] conv1_sTanH <- conv1
I0410 23:47:34.240342  7697 net.cpp:395] conv1_sTanH -> conv1 (in-place)
I0410 23:47:34.240541  7697 net.cpp:150] Setting up conv1_sTanH
I0410 23:47:34.240555  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.240557  7697 net.cpp:165] Memory required for data: 2195931136
I0410 23:47:34.240561  7697 layer_factory.hpp:77] Creating layer conv1_postscale
I0410 23:47:34.240567  7697 net.cpp:100] Creating Layer conv1_postscale
I0410 23:47:34.240571  7697 net.cpp:434] conv1_postscale <- conv1
I0410 23:47:34.240579  7697 net.cpp:395] conv1_postscale -> conv1 (in-place)
I0410 23:47:34.240691  7697 net.cpp:150] Setting up conv1_postscale
I0410 23:47:34.240700  7697 net.cpp:157] Top shape: 1024 100 42 42 (180633600)
I0410 23:47:34.240701  7697 net.cpp:165] Memory required for data: 2918465536
I0410 23:47:34.240708  7697 layer_factory.hpp:77] Creating layer pool1
I0410 23:47:34.240717  7697 net.cpp:100] Creating Layer pool1
I0410 23:47:34.240720  7697 net.cpp:434] pool1 <- conv1
I0410 23:47:34.240725  7697 net.cpp:408] pool1 -> pool1
I0410 23:47:34.240785  7697 net.cpp:150] Setting up pool1
I0410 23:47:34.240794  7697 net.cpp:157] Top shape: 1024 100 21 21 (45158400)
I0410 23:47:34.240797  7697 net.cpp:165] Memory required for data: 3099099136
I0410 23:47:34.240800  7697 layer_factory.hpp:77] Creating layer conv2
I0410 23:47:34.240810  7697 net.cpp:100] Creating Layer conv2
I0410 23:47:34.240814  7697 net.cpp:434] conv2 <- pool1
I0410 23:47:34.240820  7697 net.cpp:408] conv2 -> conv2
I0410 23:47:34.244812  7697 net.cpp:150] Setting up conv2
I0410 23:47:34.244843  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.244849  7697 net.cpp:165] Memory required for data: 3298164736
I0410 23:47:34.244858  7697 layer_factory.hpp:77] Creating layer conv2_prescale
I0410 23:47:34.244882  7697 net.cpp:100] Creating Layer conv2_prescale
I0410 23:47:34.244886  7697 net.cpp:434] conv2_prescale <- conv2
I0410 23:47:34.244891  7697 net.cpp:395] conv2_prescale -> conv2 (in-place)
I0410 23:47:34.245005  7697 net.cpp:150] Setting up conv2_prescale
I0410 23:47:34.245014  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.245018  7697 net.cpp:165] Memory required for data: 3497230336
I0410 23:47:34.245023  7697 layer_factory.hpp:77] Creating layer conv2_sTanH
I0410 23:47:34.245030  7697 net.cpp:100] Creating Layer conv2_sTanH
I0410 23:47:34.245036  7697 net.cpp:434] conv2_sTanH <- conv2
I0410 23:47:34.245041  7697 net.cpp:395] conv2_sTanH -> conv2 (in-place)
I0410 23:47:34.245863  7697 net.cpp:150] Setting up conv2_sTanH
I0410 23:47:34.245879  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.245882  7697 net.cpp:165] Memory required for data: 3696295936
I0410 23:47:34.245887  7697 layer_factory.hpp:77] Creating layer conv2_postscale
I0410 23:47:34.245893  7697 net.cpp:100] Creating Layer conv2_postscale
I0410 23:47:34.245910  7697 net.cpp:434] conv2_postscale <- conv2
I0410 23:47:34.245919  7697 net.cpp:395] conv2_postscale -> conv2 (in-place)
I0410 23:47:34.246039  7697 net.cpp:150] Setting up conv2_postscale
I0410 23:47:34.246049  7697 net.cpp:157] Top shape: 1024 150 18 18 (49766400)
I0410 23:47:34.246052  7697 net.cpp:165] Memory required for data: 3895361536
I0410 23:47:34.246057  7697 layer_factory.hpp:77] Creating layer pool2
I0410 23:47:34.246063  7697 net.cpp:100] Creating Layer pool2
I0410 23:47:34.246067  7697 net.cpp:434] pool2 <- conv2
I0410 23:47:34.246074  7697 net.cpp:408] pool2 -> pool2
I0410 23:47:34.246130  7697 net.cpp:150] Setting up pool2
I0410 23:47:34.246139  7697 net.cpp:157] Top shape: 1024 150 9 9 (12441600)
I0410 23:47:34.246141  7697 net.cpp:165] Memory required for data: 3945127936
I0410 23:47:34.246145  7697 layer_factory.hpp:77] Creating layer conv3
I0410 23:47:34.246156  7697 net.cpp:100] Creating Layer conv3
I0410 23:47:34.246161  7697 net.cpp:434] conv3 <- pool2
I0410 23:47:34.246166  7697 net.cpp:408] conv3 -> conv3
I0410 23:47:34.251713  7697 net.cpp:150] Setting up conv3
I0410 23:47:34.251744  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.251749  7697 net.cpp:165] Memory required for data: 3981991936
I0410 23:47:34.251757  7697 layer_factory.hpp:77] Creating layer conv3_prescale
I0410 23:47:34.251766  7697 net.cpp:100] Creating Layer conv3_prescale
I0410 23:47:34.251770  7697 net.cpp:434] conv3_prescale <- conv3
I0410 23:47:34.251776  7697 net.cpp:395] conv3_prescale -> conv3 (in-place)
I0410 23:47:34.251890  7697 net.cpp:150] Setting up conv3_prescale
I0410 23:47:34.251900  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.251904  7697 net.cpp:165] Memory required for data: 4018855936
I0410 23:47:34.251909  7697 layer_factory.hpp:77] Creating layer conv3_sTanH
I0410 23:47:34.251917  7697 net.cpp:100] Creating Layer conv3_sTanH
I0410 23:47:34.251920  7697 net.cpp:434] conv3_sTanH <- conv3
I0410 23:47:34.251926  7697 net.cpp:395] conv3_sTanH -> conv3 (in-place)
I0410 23:47:34.252745  7697 net.cpp:150] Setting up conv3_sTanH
I0410 23:47:34.252764  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.252779  7697 net.cpp:165] Memory required for data: 4055719936
I0410 23:47:34.252782  7697 layer_factory.hpp:77] Creating layer conv3_postscale
I0410 23:47:34.252789  7697 net.cpp:100] Creating Layer conv3_postscale
I0410 23:47:34.252794  7697 net.cpp:434] conv3_postscale <- conv3
I0410 23:47:34.252800  7697 net.cpp:395] conv3_postscale -> conv3 (in-place)
I0410 23:47:34.252912  7697 net.cpp:150] Setting up conv3_postscale
I0410 23:47:34.252920  7697 net.cpp:157] Top shape: 1024 250 6 6 (9216000)
I0410 23:47:34.252923  7697 net.cpp:165] Memory required for data: 4092583936
I0410 23:47:34.252928  7697 layer_factory.hpp:77] Creating layer pool3
I0410 23:47:34.252938  7697 net.cpp:100] Creating Layer pool3
I0410 23:47:34.252943  7697 net.cpp:434] pool3 <- conv3
I0410 23:47:34.252948  7697 net.cpp:408] pool3 -> pool3
I0410 23:47:34.252990  7697 net.cpp:150] Setting up pool3
I0410 23:47:34.252998  7697 net.cpp:157] Top shape: 1024 250 3 3 (2304000)
I0410 23:47:34.253018  7697 net.cpp:165] Memory required for data: 4101799936
I0410 23:47:34.253021  7697 layer_factory.hpp:77] Creating layer fc4_300
I0410 23:47:34.253031  7697 net.cpp:100] Creating Layer fc4_300
I0410 23:47:34.253033  7697 net.cpp:434] fc4_300 <- pool3
I0410 23:47:34.253038  7697 net.cpp:408] fc4_300 -> fc4_300
I0410 23:47:34.258368  7697 net.cpp:150] Setting up fc4_300
I0410 23:47:34.258388  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.258402  7697 net.cpp:165] Memory required for data: 4103028736
I0410 23:47:34.258409  7697 layer_factory.hpp:77] Creating layer fc4_prescale
I0410 23:47:34.258416  7697 net.cpp:100] Creating Layer fc4_prescale
I0410 23:47:34.258420  7697 net.cpp:434] fc4_prescale <- fc4_300
I0410 23:47:34.258425  7697 net.cpp:395] fc4_prescale -> fc4_300 (in-place)
I0410 23:47:34.258523  7697 net.cpp:150] Setting up fc4_prescale
I0410 23:47:34.258551  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.258554  7697 net.cpp:165] Memory required for data: 4104257536
I0410 23:47:34.258559  7697 layer_factory.hpp:77] Creating layer fc4_sTanH
I0410 23:47:34.258565  7697 net.cpp:100] Creating Layer fc4_sTanH
I0410 23:47:34.258569  7697 net.cpp:434] fc4_sTanH <- fc4_300
I0410 23:47:34.258572  7697 net.cpp:395] fc4_sTanH -> fc4_300 (in-place)
I0410 23:47:34.258782  7697 net.cpp:150] Setting up fc4_sTanH
I0410 23:47:34.258793  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.258796  7697 net.cpp:165] Memory required for data: 4105486336
I0410 23:47:34.258800  7697 layer_factory.hpp:77] Creating layer fc4_postscale
I0410 23:47:34.258808  7697 net.cpp:100] Creating Layer fc4_postscale
I0410 23:47:34.258811  7697 net.cpp:434] fc4_postscale <- fc4_300
I0410 23:47:34.258816  7697 net.cpp:395] fc4_postscale -> fc4_300 (in-place)
I0410 23:47:34.258925  7697 net.cpp:150] Setting up fc4_postscale
I0410 23:47:34.258934  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.258936  7697 net.cpp:165] Memory required for data: 4106715136
I0410 23:47:34.258940  7697 layer_factory.hpp:77] Creating layer drop4
I0410 23:47:34.258947  7697 net.cpp:100] Creating Layer drop4
I0410 23:47:34.258949  7697 net.cpp:434] drop4 <- fc4_300
I0410 23:47:34.258955  7697 net.cpp:395] drop4 -> fc4_300 (in-place)
I0410 23:47:34.258980  7697 net.cpp:150] Setting up drop4
I0410 23:47:34.258986  7697 net.cpp:157] Top shape: 1024 300 (307200)
I0410 23:47:34.258990  7697 net.cpp:165] Memory required for data: 4107943936
I0410 23:47:34.258992  7697 layer_factory.hpp:77] Creating layer fc5_67
I0410 23:47:34.259001  7697 net.cpp:100] Creating Layer fc5_67
I0410 23:47:34.259003  7697 net.cpp:434] fc5_67 <- fc4_300
I0410 23:47:34.259009  7697 net.cpp:408] fc5_67 -> fc5_classes
I0410 23:47:34.259258  7697 net.cpp:150] Setting up fc5_67
I0410 23:47:34.259268  7697 net.cpp:157] Top shape: 1024 67 (68608)
I0410 23:47:34.259269  7697 net.cpp:165] Memory required for data: 4108218368
I0410 23:47:34.259279  7697 layer_factory.hpp:77] Creating layer fc5_classes_fc5_67_0_split
I0410 23:47:34.259286  7697 net.cpp:100] Creating Layer fc5_classes_fc5_67_0_split
I0410 23:47:34.259289  7697 net.cpp:434] fc5_classes_fc5_67_0_split <- fc5_classes
I0410 23:47:34.259296  7697 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_0
I0410 23:47:34.259302  7697 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_1
I0410 23:47:34.259308  7697 net.cpp:408] fc5_classes_fc5_67_0_split -> fc5_classes_fc5_67_0_split_2
I0410 23:47:34.259361  7697 net.cpp:150] Setting up fc5_classes_fc5_67_0_split
I0410 23:47:34.259367  7697 net.cpp:157] Top shape: 1024 67 (68608)
I0410 23:47:34.259371  7697 net.cpp:157] Top shape: 1024 67 (68608)
I0410 23:47:34.259374  7697 net.cpp:157] Top shape: 1024 67 (68608)
I0410 23:47:34.259377  7697 net.cpp:165] Memory required for data: 4109041664
I0410 23:47:34.259379  7697 layer_factory.hpp:77] Creating layer loss
I0410 23:47:34.259384  7697 net.cpp:100] Creating Layer loss
I0410 23:47:34.259388  7697 net.cpp:434] loss <- fc5_classes_fc5_67_0_split_0
I0410 23:47:34.259393  7697 net.cpp:434] loss <- label_data_1_split_0
I0410 23:47:34.259399  7697 net.cpp:408] loss -> loss
I0410 23:47:34.259409  7697 layer_factory.hpp:77] Creating layer loss
I0410 23:47:34.259753  7697 net.cpp:150] Setting up loss
I0410 23:47:34.259768  7697 net.cpp:157] Top shape: (1)
I0410 23:47:34.259770  7697 net.cpp:160]     with loss weight 1
I0410 23:47:34.259780  7697 net.cpp:165] Memory required for data: 4109041668
I0410 23:47:34.259783  7697 layer_factory.hpp:77] Creating layer accuracy_1
I0410 23:47:34.259793  7697 net.cpp:100] Creating Layer accuracy_1
I0410 23:47:34.259798  7697 net.cpp:434] accuracy_1 <- fc5_classes_fc5_67_0_split_1
I0410 23:47:34.259802  7697 net.cpp:434] accuracy_1 <- label_data_1_split_1
I0410 23:47:34.259806  7697 net.cpp:408] accuracy_1 -> accuracy_1
I0410 23:47:34.259816  7697 net.cpp:150] Setting up accuracy_1
I0410 23:47:34.259832  7697 net.cpp:157] Top shape: (1)
I0410 23:47:34.259835  7697 net.cpp:165] Memory required for data: 4109041672
I0410 23:47:34.259838  7697 layer_factory.hpp:77] Creating layer accuracy_5
I0410 23:47:34.259843  7697 net.cpp:100] Creating Layer accuracy_5
I0410 23:47:34.259846  7697 net.cpp:434] accuracy_5 <- fc5_classes_fc5_67_0_split_2
I0410 23:47:34.259850  7697 net.cpp:434] accuracy_5 <- label_data_1_split_2
I0410 23:47:34.259855  7697 net.cpp:408] accuracy_5 -> accuracy_5
I0410 23:47:34.259861  7697 net.cpp:150] Setting up accuracy_5
I0410 23:47:34.259873  7697 net.cpp:157] Top shape: (1)
I0410 23:47:34.259876  7697 net.cpp:165] Memory required for data: 4109041676
I0410 23:47:34.259891  7697 net.cpp:228] accuracy_5 does not need backward computation.
I0410 23:47:34.259894  7697 net.cpp:228] accuracy_1 does not need backward computation.
I0410 23:47:34.259898  7697 net.cpp:226] loss needs backward computation.
I0410 23:47:34.259907  7697 net.cpp:226] fc5_classes_fc5_67_0_split needs backward computation.
I0410 23:47:34.259910  7697 net.cpp:226] fc5_67 needs backward computation.
I0410 23:47:34.259913  7697 net.cpp:226] drop4 needs backward computation.
I0410 23:47:34.259915  7697 net.cpp:226] fc4_postscale needs backward computation.
I0410 23:47:34.259918  7697 net.cpp:226] fc4_sTanH needs backward computation.
I0410 23:47:34.259920  7697 net.cpp:226] fc4_prescale needs backward computation.
I0410 23:47:34.259923  7697 net.cpp:226] fc4_300 needs backward computation.
I0410 23:47:34.259927  7697 net.cpp:226] pool3 needs backward computation.
I0410 23:47:34.259932  7697 net.cpp:226] conv3_postscale needs backward computation.
I0410 23:47:34.259934  7697 net.cpp:226] conv3_sTanH needs backward computation.
I0410 23:47:34.259938  7697 net.cpp:226] conv3_prescale needs backward computation.
I0410 23:47:34.259939  7697 net.cpp:226] conv3 needs backward computation.
I0410 23:47:34.259943  7697 net.cpp:226] pool2 needs backward computation.
I0410 23:47:34.259945  7697 net.cpp:226] conv2_postscale needs backward computation.
I0410 23:47:34.259948  7697 net.cpp:226] conv2_sTanH needs backward computation.
I0410 23:47:34.259955  7697 net.cpp:226] conv2_prescale needs backward computation.
I0410 23:47:34.259958  7697 net.cpp:226] conv2 needs backward computation.
I0410 23:47:34.259961  7697 net.cpp:226] pool1 needs backward computation.
I0410 23:47:34.259964  7697 net.cpp:226] conv1_postscale needs backward computation.
I0410 23:47:34.259968  7697 net.cpp:226] conv1_sTanH needs backward computation.
I0410 23:47:34.259969  7697 net.cpp:226] conv1_prescale needs backward computation.
I0410 23:47:34.259973  7697 net.cpp:226] conv1 needs backward computation.
I0410 23:47:34.259976  7697 net.cpp:228] label_data_1_split does not need backward computation.
I0410 23:47:34.259980  7697 net.cpp:228] data does not need backward computation.
I0410 23:47:34.259984  7697 net.cpp:270] This network produces output accuracy_1
I0410 23:47:34.259986  7697 net.cpp:270] This network produces output accuracy_5
I0410 23:47:34.259989  7697 net.cpp:270] This network produces output loss
I0410 23:47:34.260010  7697 net.cpp:283] Network initialization done.
I0410 23:47:34.260084  7697 solver.cpp:72] Solver scaffolding done.
I0410 23:47:34.261001  7697 caffe.cpp:251] Starting Optimization
I0410 23:47:34.261011  7697 solver.cpp:291] Solving 
I0410 23:47:34.261013  7697 solver.cpp:292] Learning Rate Policy: step
I0410 23:47:34.263177  7697 solver.cpp:349] Iteration 0, Testing net (#0)
I0410 23:47:35.343166  7697 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0131836
I0410 23:47:35.343194  7697 solver.cpp:416]     Test net output #1: accuracy_5 = 0.0957031
I0410 23:47:35.343204  7697 solver.cpp:416]     Test net output #2: loss = 4.29553 (* 1 = 4.29553 loss)
I0410 23:47:35.506485  7697 solver.cpp:240] Iteration 0, loss = 4.64935
I0410 23:47:35.506523  7697 solver.cpp:256]     Train net output #0: loss = 4.64935 (* 1 = 4.64935 loss)
I0410 23:47:35.506539  7697 sgd_solver.cpp:106] Iteration 0, lr = 0.0005
I0410 23:47:35.870853  7697 solver.cpp:240] Iteration 1, loss = 5.42943
I0410 23:47:35.870910  7697 solver.cpp:256]     Train net output #0: loss = 5.42943 (* 1 = 5.42943 loss)
I0410 23:47:35.870919  7697 sgd_solver.cpp:106] Iteration 1, lr = 0.0005
I0410 23:47:36.239924  7697 solver.cpp:240] Iteration 2, loss = 6.14436
I0410 23:47:36.239958  7697 solver.cpp:256]     Train net output #0: loss = 6.14436 (* 1 = 6.14436 loss)
I0410 23:47:36.239966  7697 sgd_solver.cpp:106] Iteration 2, lr = 0.0005
I0410 23:47:36.609797  7697 solver.cpp:240] Iteration 3, loss = 6.20223
I0410 23:47:36.609829  7697 solver.cpp:256]     Train net output #0: loss = 6.20223 (* 1 = 6.20223 loss)
I0410 23:47:36.609838  7697 sgd_solver.cpp:106] Iteration 3, lr = 0.0005
I0410 23:47:36.976246  7697 solver.cpp:240] Iteration 4, loss = 6.889
I0410 23:47:36.976289  7697 solver.cpp:256]     Train net output #0: loss = 6.889 (* 1 = 6.889 loss)
I0410 23:47:36.976299  7697 sgd_solver.cpp:106] Iteration 4, lr = 0.0005
I0410 23:47:37.341647  7697 solver.cpp:240] Iteration 5, loss = 7.21288
I0410 23:47:37.341682  7697 solver.cpp:256]     Train net output #0: loss = 7.21288 (* 1 = 7.21288 loss)
I0410 23:47:37.341691  7697 sgd_solver.cpp:106] Iteration 5, lr = 0.0005
I0410 23:47:37.707644  7697 solver.cpp:240] Iteration 6, loss = 7.60319
I0410 23:47:37.707686  7697 solver.cpp:256]     Train net output #0: loss = 7.60319 (* 1 = 7.60319 loss)
I0410 23:47:37.707695  7697 sgd_solver.cpp:106] Iteration 6, lr = 0.0005
I0410 23:47:38.079339  7697 solver.cpp:240] Iteration 7, loss = 7.85299
I0410 23:47:38.079385  7697 solver.cpp:256]     Train net output #0: loss = 7.85299 (* 1 = 7.85299 loss)
I0410 23:47:38.079393  7697 sgd_solver.cpp:106] Iteration 7, lr = 0.0005
I0410 23:47:38.447165  7697 solver.cpp:240] Iteration 8, loss = 8.22894
I0410 23:47:38.447198  7697 solver.cpp:256]     Train net output #0: loss = 8.22894 (* 1 = 8.22894 loss)
I0410 23:47:38.447206  7697 sgd_solver.cpp:106] Iteration 8, lr = 0.0005
I0410 23:47:38.814985  7697 solver.cpp:240] Iteration 9, loss = 9.21159
I0410 23:47:38.815027  7697 solver.cpp:256]     Train net output #0: loss = 9.21159 (* 1 = 9.21159 loss)
I0410 23:47:38.815037  7697 sgd_solver.cpp:106] Iteration 9, lr = 0.0005
I0410 23:47:39.182323  7697 solver.cpp:240] Iteration 10, loss = 10.362
I0410 23:47:39.182355  7697 solver.cpp:256]     Train net output #0: loss = 10.362 (* 1 = 10.362 loss)
I0410 23:47:39.182363  7697 sgd_solver.cpp:106] Iteration 10, lr = 0.0005
I0410 23:47:39.551177  7697 solver.cpp:240] Iteration 11, loss = 10.7519
I0410 23:47:39.551221  7697 solver.cpp:256]     Train net output #0: loss = 10.7519 (* 1 = 10.7519 loss)
I0410 23:47:39.551230  7697 sgd_solver.cpp:106] Iteration 11, lr = 0.0005
I0410 23:47:39.922329  7697 solver.cpp:240] Iteration 12, loss = 11.285
I0410 23:47:39.922363  7697 solver.cpp:256]     Train net output #0: loss = 11.285 (* 1 = 11.285 loss)
I0410 23:47:39.922372  7697 sgd_solver.cpp:106] Iteration 12, lr = 0.0005
I0410 23:47:40.289887  7697 solver.cpp:240] Iteration 13, loss = 11.7791
I0410 23:47:40.289930  7697 solver.cpp:256]     Train net output #0: loss = 11.7791 (* 1 = 11.7791 loss)
I0410 23:47:40.289938  7697 sgd_solver.cpp:106] Iteration 13, lr = 0.0005
I0410 23:47:40.656455  7697 solver.cpp:240] Iteration 14, loss = 12.2872
I0410 23:47:40.656489  7697 solver.cpp:256]     Train net output #0: loss = 12.2872 (* 1 = 12.2872 loss)
I0410 23:47:40.656498  7697 sgd_solver.cpp:106] Iteration 14, lr = 0.0005
I0410 23:47:41.023681  7697 solver.cpp:240] Iteration 15, loss = 13.131
I0410 23:47:41.023723  7697 solver.cpp:256]     Train net output #0: loss = 13.131 (* 1 = 13.131 loss)
I0410 23:47:41.023731  7697 sgd_solver.cpp:106] Iteration 15, lr = 0.0005
I0410 23:47:41.392674  7697 solver.cpp:240] Iteration 16, loss = 14.1879
I0410 23:47:41.392719  7697 solver.cpp:256]     Train net output #0: loss = 14.1879 (* 1 = 14.1879 loss)
I0410 23:47:41.392729  7697 sgd_solver.cpp:106] Iteration 16, lr = 0.0005
I0410 23:47:41.754544  7697 solver.cpp:240] Iteration 17, loss = 15.4571
I0410 23:47:41.754590  7697 solver.cpp:256]     Train net output #0: loss = 15.4571 (* 1 = 15.4571 loss)
I0410 23:47:41.754622  7697 sgd_solver.cpp:106] Iteration 17, lr = 0.0005
I0410 23:47:42.123786  7697 solver.cpp:240] Iteration 18, loss = 16.2241
I0410 23:47:42.123821  7697 solver.cpp:256]     Train net output #0: loss = 16.2241 (* 1 = 16.2241 loss)
I0410 23:47:42.123829  7697 sgd_solver.cpp:106] Iteration 18, lr = 0.0005
I0410 23:47:42.491408  7697 solver.cpp:240] Iteration 19, loss = 16.2984
I0410 23:47:42.491438  7697 solver.cpp:256]     Train net output #0: loss = 16.2984 (* 1 = 16.2984 loss)
I0410 23:47:42.491447  7697 sgd_solver.cpp:106] Iteration 19, lr = 0.0005
I0410 23:47:42.856725  7697 solver.cpp:240] Iteration 20, loss = 16.0232
I0410 23:47:42.856760  7697 solver.cpp:256]     Train net output #0: loss = 16.0232 (* 1 = 16.0232 loss)
I0410 23:47:42.856770  7697 sgd_solver.cpp:106] Iteration 20, lr = 0.0005
I0410 23:47:43.223093  7697 solver.cpp:240] Iteration 21, loss = 16.247
I0410 23:47:43.223125  7697 solver.cpp:256]     Train net output #0: loss = 16.247 (* 1 = 16.247 loss)
I0410 23:47:43.223134  7697 sgd_solver.cpp:106] Iteration 21, lr = 0.0005
I0410 23:47:43.596722  7697 solver.cpp:240] Iteration 22, loss = 16.2575
I0410 23:47:43.596766  7697 solver.cpp:256]     Train net output #0: loss = 16.2575 (* 1 = 16.2575 loss)
I0410 23:47:43.596774  7697 sgd_solver.cpp:106] Iteration 22, lr = 0.0005
I0410 23:47:43.965059  7697 solver.cpp:240] Iteration 23, loss = 16.4795
I0410 23:47:43.965092  7697 solver.cpp:256]     Train net output #0: loss = 16.4795 (* 1 = 16.4795 loss)
I0410 23:47:43.965101  7697 sgd_solver.cpp:106] Iteration 23, lr = 0.0005
I0410 23:47:44.333140  7697 solver.cpp:240] Iteration 24, loss = 15.8907
I0410 23:47:44.333173  7697 solver.cpp:256]     Train net output #0: loss = 15.8907 (* 1 = 15.8907 loss)
I0410 23:47:44.333181  7697 sgd_solver.cpp:106] Iteration 24, lr = 0.0005
I0410 23:47:44.333497  7697 solver.cpp:349] Iteration 25, Testing net (#0)
I0410 23:47:45.608150  7697 solver.cpp:416]     Test net output #0: accuracy_1 = 0.0012207
I0410 23:47:45.608176  7697 solver.cpp:416]     Test net output #1: accuracy_5 = 0.103027
I0410 23:47:45.608186  7697 solver.cpp:416]     Test net output #2: loss = 15.8694 (* 1 = 15.8694 loss)
I0410 23:47:45.734839  7697 solver.cpp:240] Iteration 25, loss = 15.7287
I0410 23:47:45.734872  7697 solver.cpp:256]     Train net output #0: loss = 15.7287 (* 1 = 15.7287 loss)
I0410 23:47:45.734880  7697 sgd_solver.cpp:106] Iteration 25, lr = 0.0005
I0410 23:47:46.100160  7697 solver.cpp:240] Iteration 26, loss = 15.4332
I0410 23:47:46.100193  7697 solver.cpp:256]     Train net output #0: loss = 15.4332 (* 1 = 15.4332 loss)
I0410 23:47:46.100203  7697 sgd_solver.cpp:106] Iteration 26, lr = 0.0005
I0410 23:47:46.467950  7697 solver.cpp:240] Iteration 27, loss = 14.931
I0410 23:47:46.467984  7697 solver.cpp:256]     Train net output #0: loss = 14.931 (* 1 = 14.931 loss)
I0410 23:47:46.467993  7697 sgd_solver.cpp:106] Iteration 27, lr = 0.0005
